<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 29 Bagging. Random Forest  | Fundamentos de ciencia de datos con R</title>
  <meta name="description" content="Falta hacer" />
  <meta name="generator" content="bookdown 0.28 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 29 Bagging. Random Forest  | Fundamentos de ciencia de datos con R" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Falta hacer" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 29 Bagging. Random Forest  | Fundamentos de ciencia de datos con R" />
  
  <meta name="twitter:description" content="Falta hacer" />
  

<meta name="author" content="Gema Fernández-Avilés y José-María Montero" />


<meta name="date" content="2022-12-01" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="naive-bayes.html"/>
<link rel="next" href="boosting.-xgboost..html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-33KQ1S5ZCJ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-33KQ1S5ZCJ');
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"> Ciencia de datos con <strong>R</strong></a></li>

<li class="divider"></li>
<li class="part"><span><b>I Fundamentos y ‘tool-kit’ de la ciencia de datos</b></span></li>
<li class="chapter" data-level="1" data-path="ciencia-datos.html"><a href="ciencia-datos.html"><i class="fa fa-check"></i><b>1</b> ¿Es la Ciencia de datos una Ciencia?</a>
<ul>
<li class="chapter" data-level="1.1" data-path="ciencia-datos.html"><a href="ciencia-datos.html#ciencia"><i class="fa fa-check"></i><b>1.1</b> ¿Qué se entiende por Ciencia?</a></li>
<li class="chapter" data-level="1.2" data-path="ciencia-datos.html"><a href="ciencia-datos.html#qué-es-la-ciencia-de-datos"><i class="fa fa-check"></i><b>1.2</b> ¿Qué es la Ciencia de Datos?</a></li>
<li class="chapter" data-level="1.3" data-path="ciencia-datos.html"><a href="ciencia-datos.html#lo-científico-de-la-ciencia-de-datos"><i class="fa fa-check"></i><b>1.3</b> Lo científico de la Ciencia de datos</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="metodología.html"><a href="metodología.html"><i class="fa fa-check"></i><b>2</b> Metodología para la Ciencia de datos</a>
<ul>
<li class="chapter" data-level="2.1" data-path="metodología.html"><a href="metodología.html#preliminares"><i class="fa fa-check"></i><b>2.1</b> Preliminares</a></li>
<li class="chapter" data-level="2.2" data-path="metodología.html"><a href="metodología.html#principales-metodologías-en-ciencia-de-datos"><i class="fa fa-check"></i><b>2.2</b> Principales metodologías en Ciencia de datos</a></li>
<li class="chapter" data-level="2.3" data-path="metodología.html"><a href="metodología.html#met-crisp-dm"><i class="fa fa-check"></i><b>2.3</b> CRISP-DM para Ciencia de datos</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ch-110003.html"><a href="ch-110003.html"><i class="fa fa-check"></i><b>3</b> R para ciencia de datos</a>
<ul>
<li class="chapter" data-level="3.1" data-path="ch-110003.html"><a href="ch-110003.html#introducción"><i class="fa fa-check"></i><b>3.1</b> Introducción</a></li>
<li class="chapter" data-level="3.2" data-path="ch-110003.html"><a href="ch-110003.html#id_110003-bases"><i class="fa fa-check"></i><b>3.2</b> La sesión de R</a></li>
<li class="chapter" data-level="3.3" data-path="ch-110003.html"><a href="ch-110003.html#instalación-de-r"><i class="fa fa-check"></i><b>3.3</b> Instalación de R</a></li>
<li class="chapter" data-level="3.4" data-path="ch-110003.html"><a href="ch-110003.html#id_110003-proyectos"><i class="fa fa-check"></i><b>3.4</b> Trabajar con proyectos de RStudio</a></li>
<li class="chapter" data-level="3.5" data-path="ch-110003.html"><a href="ch-110003.html#manipulación-de-datos-con-r"><i class="fa fa-check"></i><b>3.5</b> Manipulación de datos con R</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="ch-110003.html"><a href="ch-110003.html#id_110003-estructuras"><i class="fa fa-check"></i><b>3.5.1</b> Estructuras y tipos de datos</a></li>
<li class="chapter" data-level="3.5.2" data-path="ch-110003.html"><a href="ch-110003.html#id_110003-importacion"><i class="fa fa-check"></i><b>3.5.2</b> Importación de datos</a></li>
<li class="chapter" data-level="3.5.3" data-path="ch-110003.html"><a href="ch-110003.html#exportación-y-archivos-de-datos-de-r"><i class="fa fa-check"></i><b>3.5.3</b> Exportación y archivos de datos de R</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="ch-110003.html"><a href="ch-110003.html#id_110003-tidyverse"><i class="fa fa-check"></i><b>3.6</b> Organización de datos con el <em>tidyverse</em></a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="ch-110003.html"><a href="ch-110003.html#el-tidyverse-y-su-flujo-de-trabajo"><i class="fa fa-check"></i><b>3.6.1</b> El <em>tidyverse</em> y su flujo de trabajo</a></li>
<li class="chapter" data-level="3.6.2" data-path="ch-110003.html"><a href="ch-110003.html#transformación-de-datos-con-dplyr"><i class="fa fa-check"></i><b>3.6.2</b> Transformación de datos con <code>dplyr</code></a></li>
<li class="chapter" data-level="3.6.3" data-path="ch-110003.html"><a href="ch-110003.html#combinación-de-datos"><i class="fa fa-check"></i><b>3.6.3</b> Combinación de datos</a></li>
<li class="chapter" data-level="3.6.4" data-path="ch-110003.html"><a href="ch-110003.html#reorganización-de-datos"><i class="fa fa-check"></i><b>3.6.4</b> Reorganización de datos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html"><a href="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html"><i class="fa fa-check"></i><b>4</b> Gestión y operación de datos con bases de datos relacionales</a>
<ul>
<li class="chapter" data-level="4.1" data-path="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html"><a href="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html#introducción-1"><i class="fa fa-check"></i><b>4.1</b> Introducción</a></li>
<li class="chapter" data-level="4.2" data-path="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html"><a href="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html#concepto-de-base-de-datos"><i class="fa fa-check"></i><b>4.2</b> Concepto de Base de datos</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html"><a href="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html#gestión-de-los-datos-en-una-base-o-repositorio-de-datos"><i class="fa fa-check"></i><b>4.2.1</b> Gestión de los datos en una base o repositorio de datos</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html"><a href="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html#el-lenguaje-estructurado-de-consulta-sql"><i class="fa fa-check"></i><b>4.3</b> El Lenguaje Estructurado de Consulta (SQL)</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html"><a href="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html#sql-como-lenguaje-de-definición-de-datos-ldd"><i class="fa fa-check"></i><b>4.3.1</b> SQL como Lenguaje de Definición de Datos (LDD)</a></li>
<li class="chapter" data-level="4.3.2" data-path="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html"><a href="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html#sql-como-lenguaje-de-manipulación-de-datos-lmd"><i class="fa fa-check"></i><b>4.3.2</b> SQL como Lenguaje de Manipulación de Datos (LMD)</a></li>
<li class="chapter" data-level="4.3.3" data-path="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html"><a href="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html#sql-como-lenguaje-de-administración-de-datos-lad"><i class="fa fa-check"></i><b>4.3.3</b> SQL como Lenguaje de Administración de Datos (LAD)</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html"><a href="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html#usando-bases-de-datos-desde-r"><i class="fa fa-check"></i><b>4.4</b> Usando bases de datos desde R</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html"><a href="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html#conexión-a-una-base-de-datos"><i class="fa fa-check"></i><b>4.4.1</b> Conexión a una base de datos</a></li>
<li class="chapter" data-level="4.4.2" data-path="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html"><a href="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html#operaciones-de-lectura-selección-read-de-datos"><i class="fa fa-check"></i><b>4.4.2</b> Operaciones de lectura / selección (<em>read</em>) de datos</a></li>
<li class="chapter" data-level="4.4.3" data-path="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html"><a href="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html#operaciones-de-inserción-create-y-actualización-update-de-datos"><i class="fa fa-check"></i><b>4.4.3</b> Operaciones de inserción (<em>create</em>) y actualización (<em>update</em>) de datos</a></li>
<li class="chapter" data-level="4.4.4" data-path="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html"><a href="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html#operaciones-de-borrado-de-datos-delete"><i class="fa fa-check"></i><b>4.4.4</b> Operaciones de Borrado de datos (<em>delete</em>)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="datos-no-sql.html"><a href="datos-no-sql.html"><i class="fa fa-check"></i><b>5</b> Gestión y operación de datos masivos (BigData) con bases de datos NoSQL</a>
<ul>
<li class="chapter" data-level="5.1" data-path="datos-no-sql.html"><a href="datos-no-sql.html#introducción-al-big-data"><i class="fa fa-check"></i><b>5.1</b> Introducción al Big Data</a></li>
<li class="chapter" data-level="5.2" data-path="datos-no-sql.html"><a href="datos-no-sql.html#VsBigData"><i class="fa fa-check"></i><b>5.2</b> Las V’s del Big Data</a></li>
<li class="chapter" data-level="5.3" data-path="datos-no-sql.html"><a href="datos-no-sql.html#fuentes-de-datos-en-entornos-big-data"><i class="fa fa-check"></i><b>5.3</b> Fuentes de Datos en entornos Big Data</a></li>
<li class="chapter" data-level="5.4" data-path="datos-no-sql.html"><a href="datos-no-sql.html#bases-de-datos-relacionales-vs.-nosql"><i class="fa fa-check"></i><b>5.4</b> Bases de datos Relacionales vs. NoSQL</a></li>
<li class="chapter" data-level="5.5" data-path="datos-no-sql.html"><a href="datos-no-sql.html#bases-de-datos-nosql"><i class="fa fa-check"></i><b>5.5</b> Bases de datos NoSQL</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="datos-no-sql.html"><a href="datos-no-sql.html#definición-de-bases-de-datos-nosql"><i class="fa fa-check"></i><b>5.5.1</b> Definición de bases de datos NoSQL</a></li>
<li class="chapter" data-level="5.5.2" data-path="datos-no-sql.html"><a href="datos-no-sql.html#necesidades-no-cubiertas-por-las-bases-de-datos-relacionales"><i class="fa fa-check"></i><b>5.5.2</b> Necesidades no cubiertas por las bases de datos relacionales</a></li>
<li class="chapter" data-level="5.5.3" data-path="datos-no-sql.html"><a href="datos-no-sql.html#tipos-de-almacenamiento-en-bases-de-datos-nosql"><i class="fa fa-check"></i><b>5.5.3</b> Tipos de almacenamiento en bases de datos NoSQL</a></li>
<li class="chapter" data-level="5.5.4" data-path="datos-no-sql.html"><a href="datos-no-sql.html#limitaciones-de-las-bases-de-datos-nosql"><i class="fa fa-check"></i><b>5.5.4</b> Limitaciones de las bases de datos NoSQL</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="datos-no-sql.html"><a href="datos-no-sql.html#ejemplo-de-integración-de-una-base-de-datos-nosql-y-análisis-de-datos-en-r"><i class="fa fa-check"></i><b>5.6</b> Ejemplo de integración de una base de datos NoSQL y análisis de datos en R</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="datos-no-sql.html"><a href="datos-no-sql.html#introMongo"><i class="fa fa-check"></i><b>5.6.1</b> Introducción a MongoDB</a></li>
<li class="chapter" data-level="5.6.2" data-path="datos-no-sql.html"><a href="datos-no-sql.html#paquetesCaso"><i class="fa fa-check"></i><b>5.6.2</b> Plataforma tecnológica para el caso práctico</a></li>
<li class="chapter" data-level="5.6.3" data-path="datos-no-sql.html"><a href="datos-no-sql.html#conexionMongo"><i class="fa fa-check"></i><b>5.6.3</b> Conexión y acceso a MongoDB desde R</a></li>
<li class="chapter" data-level="5.6.4" data-path="datos-no-sql.html"><a href="datos-no-sql.html#consultaViajes"><i class="fa fa-check"></i><b>5.6.4</b> Obtención de datos en R desde MongoDB</a></li>
<li class="chapter" data-level="5.6.5" data-path="datos-no-sql.html"><a href="datos-no-sql.html#analisisViajes"><i class="fa fa-check"></i><b>5.6.5</b> Analizando datos de MongoDB en R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="id_120007-informes.html"><a href="id_120007-informes.html"><i class="fa fa-check"></i><b>6</b> Informes reproducibles con R-markdown -&gt; Quarto</a>
<ul>
<li class="chapter" data-level="6.1" data-path="id_120007-informes.html"><a href="id_120007-informes.html#introducción-2"><i class="fa fa-check"></i><b>6.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="id_120007-informes.html"><a href="id_120007-informes.html#por-qué-informes-reproducibles"><i class="fa fa-check"></i><b>6.1.1</b> ¿Por qué informes reproducibles?</a></li>
<li class="chapter" data-level="6.1.2" data-path="id_120007-informes.html"><a href="id_120007-informes.html#markdown-r-markdown-y-rstudio"><i class="fa fa-check"></i><b>6.1.2</b> Markdown, R Markdown y RStudio</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="id_120007-informes.html"><a href="id_120007-informes.html#documentos-r-markdown"><i class="fa fa-check"></i><b>6.2</b> Documentos R Markdown</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="id_120007-informes.html"><a href="id_120007-informes.html#encabezado-yaml-y-configuración"><i class="fa fa-check"></i><b>6.2.1</b> Encabezado YAML y configuración</a></li>
<li class="chapter" data-level="6.2.2" data-path="id_120007-informes.html"><a href="id_120007-informes.html#formateado-de-texto"><i class="fa fa-check"></i><b>6.2.2</b> Formateado de texto</a></li>
<li class="chapter" data-level="6.2.3" data-path="id_120007-informes.html"><a href="id_120007-informes.html#inclusión-de-código"><i class="fa fa-check"></i><b>6.2.3</b> Inclusión de código</a></li>
<li class="chapter" data-level="6.2.4" data-path="id_120007-informes.html"><a href="id_120007-informes.html#opciones-de-los-bloques-de-código-chunks"><i class="fa fa-check"></i><b>6.2.4</b> Opciones de los bloques de código (<em>chunks</em>)</a></li>
<li class="chapter" data-level="6.2.5" data-path="id_120007-informes.html"><a href="id_120007-informes.html#editor-visual"><i class="fa fa-check"></i><b>6.2.5</b> Editor visual</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="id_120007-informes.html"><a href="id_120007-informes.html#otros-formatos"><i class="fa fa-check"></i><b>6.3</b> Otros formatos</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="github.html"><a href="github.html"><i class="fa fa-check"></i><b>7</b> Git y GitHub en R</a>
<ul>
<li class="chapter" data-level="7.1" data-path="github.html"><a href="github.html#qué-es-git"><i class="fa fa-check"></i><b>7.1</b> ¿Qué es Git?</a></li>
<li class="chapter" data-level="7.2" data-path="github.html"><a href="github.html#qué-es-github"><i class="fa fa-check"></i><b>7.2</b> ¿Qué es GitHub?</a></li>
<li class="chapter" data-level="7.3" data-path="github.html"><a href="github.html#por-qué-usar-git-y-github"><i class="fa fa-check"></i><b>7.3</b> ¿Por qué usar Git y GitHub?</a></li>
<li class="chapter" data-level="7.4" data-path="github.html"><a href="github.html#configuración"><i class="fa fa-check"></i><b>7.4</b> Configuración</a></li>
<li class="chapter" data-level="7.5" data-path="github.html"><a href="github.html#configurar-git"><i class="fa fa-check"></i><b>7.5</b> Configurar git</a></li>
<li class="chapter" data-level="7.6" data-path="github.html"><a href="github.html#workflow"><i class="fa fa-check"></i><b>7.6</b> Workflow</a></li>
</ul></li>
<li class="part"><span><b>II Manipulación de datos con R. Técnicas y herramientas</b></span></li>
<li class="chapter" data-level="8" data-path="id_120006-aed.html"><a href="id_120006-aed.html"><i class="fa fa-check"></i><b>8</b> Análisis exploratorio de datos</a>
<ul>
<li class="chapter" data-level="8.1" data-path="id_120006-aed.html"><a href="id_120006-aed.html#introducción-3"><i class="fa fa-check"></i><b>8.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="id_120006-aed.html"><a href="id_120006-aed.html#el-cuarterto-de-anscombe"><i class="fa fa-check"></i><b>8.1.1</b> El cuarterto de Anscombe</a></li>
<li class="chapter" data-level="8.1.2" data-path="id_120006-aed.html"><a href="id_120006-aed.html#conceptos-generales"><i class="fa fa-check"></i><b>8.1.2</b> Conceptos generales</a></li>
<li class="chapter" data-level="8.1.3" data-path="id_120006-aed.html"><a href="id_120006-aed.html#componentes-de-un-gráfico-y-su-representación-en-r"><i class="fa fa-check"></i><b>8.1.3</b> Componentes de un gráfico y su representación en R</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="id_120006-aed.html"><a href="id_120006-aed.html#id_120006-aeduni"><i class="fa fa-check"></i><b>8.2</b> Análisis exploratorio de una característica</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="id_120006-aed.html"><a href="id_120006-aed.html#variables-cualitativas"><i class="fa fa-check"></i><b>8.2.1</b> Variables cualitativas</a></li>
<li class="chapter" data-level="8.2.2" data-path="id_120006-aed.html"><a href="id_120006-aed.html#variables-cuantitativas"><i class="fa fa-check"></i><b>8.2.2</b> Variables cuantitativas</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="id_120006-aed.html"><a href="id_120006-aed.html#id_120006-aedmulti"><i class="fa fa-check"></i><b>8.3</b> Análisis exploratorio de varias características</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="id_120006-aed.html"><a href="id_120006-aed.html#variables-cualitativas-1"><i class="fa fa-check"></i><b>8.3.1</b> Variables cualitativas</a></li>
<li class="chapter" data-level="8.3.2" data-path="id_120006-aed.html"><a href="id_120006-aed.html#variables-cuantitativas-1"><i class="fa fa-check"></i><b>8.3.2</b> Variables cuantitativas</a></li>
<li class="chapter" data-level="8.3.3" data-path="id_120006-aed.html"><a href="id_120006-aed.html#variables-cualitativas-y-cuantitativas"><i class="fa fa-check"></i><b>8.3.3</b> Variables cualitativas y cuantitativas</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Preparación de datos: evaluación de la calidad de los datos. Integración, limpieza y transformación</b></span></li>
<li class="chapter" data-level="9" data-path="DGDQM.html"><a href="DGDQM.html"><i class="fa fa-check"></i><b>9</b> Gobierno y gestión de calidad de Datos</a>
<ul>
<li class="chapter" data-level="9.1" data-path="DGDQM.html"><a href="DGDQM.html#introducción-4"><i class="fa fa-check"></i><b>9.1</b> Introducción</a></li>
<li class="chapter" data-level="9.2" data-path="DGDQM.html"><a href="DGDQM.html#concepto-de-gobierno-de-datos"><i class="fa fa-check"></i><b>9.2</b> Concepto de Gobierno de datos</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="DGDQM.html"><a href="DGDQM.html#beneficiosDG"><i class="fa fa-check"></i><b>9.2.1</b> Beneficios del Gobierno de Datos</a></li>
<li class="chapter" data-level="9.2.2" data-path="DGDQM.html"><a href="DGDQM.html#artefactosDG"><i class="fa fa-check"></i><b>9.2.2</b> Artefactos de un sistema de Gobierno de Datos</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="DGDQM.html"><a href="DGDQM.html#marcos-y-metodologías-existentes-de-gobierno-de-datos"><i class="fa fa-check"></i><b>9.3</b> Marcos y metodologías existentes de Gobierno de Datos</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="DGDQM.html"><a href="DGDQM.html#modelo-alarcos-de-mejora-de-datos-mamd"><i class="fa fa-check"></i><b>9.3.1</b> Modelo Alarcos de Mejora de Datos (MAMD)</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="DGDQM.html"><a href="DGDQM.html#gestión-de-calidad-de-datos"><i class="fa fa-check"></i><b>9.4</b> Gestión de calidad de datos</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="DGDQM.html"><a href="DGDQM.html#medición-de-calidad-de-datos-vs-perfilado-de-datos"><i class="fa fa-check"></i><b>9.4.1</b> Medición de calidad de datos vs perfilado de datos</a></li>
<li class="chapter" data-level="9.4.2" data-path="DGDQM.html"><a href="DGDQM.html#mejora-de-datos"><i class="fa fa-check"></i><b>9.4.2</b> Mejora de datos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="id_130009.html"><a href="id_130009.html"><i class="fa fa-check"></i><b>10</b> Integración y limpieza de datos</a>
<ul>
<li class="chapter" data-level="10.1" data-path="id_130009.html"><a href="id_130009.html#introducción-5"><i class="fa fa-check"></i><b>10.1</b> Introducción</a></li>
<li class="chapter" data-level="10.2" data-path="id_130009.html"><a href="id_130009.html#problemas-de-calidad-de-datos"><i class="fa fa-check"></i><b>10.2</b> Problemas de calidad de datos</a></li>
<li class="chapter" data-level="10.3" data-path="id_130009.html"><a href="id_130009.html#niveles-inadecuados-de-completitud-valores-missing"><i class="fa fa-check"></i><b>10.3</b> Niveles inadecuados de completitud: Valores <em>missing</em></a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="id_130009.html"><a href="id_130009.html#visualización"><i class="fa fa-check"></i><b>10.3.1</b> Visualización</a></li>
<li class="chapter" data-level="10.3.2" data-path="id_130009.html"><a href="id_130009.html#imputacion"><i class="fa fa-check"></i><b>10.3.2</b> Técnicas de Imputación</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="id_130009.html"><a href="id_130009.html#mejorando-la-exactitud-y-la-precisión-eliminación-del-ruido-estadístico"><i class="fa fa-check"></i><b>10.4</b> Mejorando la exactitud y la precisión: eliminación del ruido estadístico</a></li>
<li class="chapter" data-level="10.5" data-path="id_130009.html"><a href="id_130009.html#integración-de-datos"><i class="fa fa-check"></i><b>10.5</b> Integración de datos</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="id_130010.html"><a href="id_130010.html"><i class="fa fa-check"></i><b>11</b> Feature Selection and Engineering</a>
<ul>
<li class="chapter" data-level="11.1" data-path="id_130010.html"><a href="id_130010.html#introducción-6"><i class="fa fa-check"></i><b>11.1</b> Introducción</a></li>
<li class="chapter" data-level="11.2" data-path="id_130010.html"><a href="id_130010.html#feature-selection-selección-de-variables"><i class="fa fa-check"></i><b>11.2</b> <em>Feature Selection</em> (Selección de variables)</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="id_130010.html"><a href="id_130010.html#métodos-de-selección-tipo-filtro"><i class="fa fa-check"></i><b>11.2.1</b> Métodos de selección tipo Filtro</a></li>
<li class="chapter" data-level="11.2.2" data-path="id_130010.html"><a href="id_130010.html#métodos-de-selección-de-variables-tipo-wrapper"><i class="fa fa-check"></i><b>11.2.2</b> Métodos de selección de variables tipo <em>wrapper</em></a></li>
<li class="chapter" data-level="11.2.3" data-path="id_130010.html"><a href="id_130010.html#métodos-de-selección-tipo-embedded"><i class="fa fa-check"></i><b>11.2.3</b> Métodos de selección tipo Embedded</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="id_130010.html"><a href="id_130010.html#transformaciones-de-escala-y-de-la-distribución-de-la-variable-objetivo"><i class="fa fa-check"></i><b>11.3</b> Transformaciones de escala y de la distribución de la variable objetivo</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="id_130010.html"><a href="id_130010.html#id_31"><i class="fa fa-check"></i><b>11.3.1</b> Transformaciones de la variable objetivo</a></li>
<li class="chapter" data-level="11.3.2" data-path="id_130010.html"><a href="id_130010.html#escalado-de-datos"><i class="fa fa-check"></i><b>11.3.2</b> Escalado de datos</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="id_130010.html"><a href="id_130010.html#feature-engineering"><i class="fa fa-check"></i><b>11.4</b> <em>Feature engineering</em></a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="id_130010.html"><a href="id_130010.html#binning"><i class="fa fa-check"></i><b>11.4.1</b> <em>Binning</em></a></li>
<li class="chapter" data-level="11.4.2" data-path="id_130010.html"><a href="id_130010.html#codificación"><i class="fa fa-check"></i><b>11.4.2</b> Codificación</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="id_130010.html"><a href="id_130010.html#reducción-de-dimensionalidad"><i class="fa fa-check"></i><b>11.5</b> Reducción de dimensionalidad</a></li>
<li class="chapter" data-level="11.6" data-path="id_130010.html"><a href="id_130010.html#otras-transformaciones"><i class="fa fa-check"></i><b>11.6</b> Otras transformaciones</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="id_130010.html"><a href="id_130010.html#particionado-de-datos"><i class="fa fa-check"></i><b>11.6.1</b> Particionado de datos</a></li>
<li class="chapter" data-level="11.6.2" data-path="id_130010.html"><a href="id_130010.html#técnicas-para-manejar-datos-no-balanceados"><i class="fa fa-check"></i><b>11.6.2</b> Técnicas para manejar datos no balanceados</a></li>
<li class="chapter" data-level="11.6.3" data-path="id_130010.html"><a href="id_130010.html#métodos-de-remuestreo"><i class="fa fa-check"></i><b>11.6.3</b> Métodos de remuestreo</a></li>
<li class="chapter" data-level="11.6.4" data-path="id_130010.html"><a href="id_130010.html#ajuste-de-hiperparámetros"><i class="fa fa-check"></i><b>11.6.4</b> Ajuste de hiperparámetros</a></li>
<li class="chapter" data-level="11.6.5" data-path="id_130010.html"><a href="id_130010.html#evaluación-de-modelos"><i class="fa fa-check"></i><b>11.6.5</b> Evaluación de modelos</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Técnicas de modelización estadísticas avanzadas</b></span></li>
<li class="chapter" data-level="12" data-path="Funda-probab.html"><a href="Funda-probab.html"><i class="fa fa-check"></i><b>12</b> Fundamentos de probabilidad</a>
<ul>
<li class="chapter" data-level="12.1" data-path="Funda-probab.html"><a href="Funda-probab.html#introducción-a-la-probabilidad"><i class="fa fa-check"></i><b>12.1</b> Introducción a la probabilidad</a></li>
<li class="chapter" data-level="12.2" data-path="Funda-probab.html"><a href="Funda-probab.html#probabilidad-elementos-básicos-definición-y-teoremas"><i class="fa fa-check"></i><b>12.2</b> Probabilidad: elementos básicos, definición y teoremas</a></li>
<li class="chapter" data-level="12.3" data-path="Funda-probab.html"><a href="Funda-probab.html#variable-aleatoria-y-su-distribución-tipos-de-variables-aleatorias"><i class="fa fa-check"></i><b>12.3</b> Variable aleatoria y su distribución: tipos de variables aleatorias</a></li>
<li class="chapter" data-level="12.4" data-path="Funda-probab.html"><a href="Funda-probab.html#modelos-de-distribución-de-probabilidad"><i class="fa fa-check"></i><b>12.4</b> Modelos de distribución de probabilidad</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="Funda-probab.html"><a href="Funda-probab.html#modelos-discretos"><i class="fa fa-check"></i><b>12.4.1</b> Modelos discretos</a></li>
<li class="chapter" data-level="12.4.2" data-path="Funda-probab.html"><a href="Funda-probab.html#modelos-continuos"><i class="fa fa-check"></i><b>12.4.2</b> Modelos continuos</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="Funda-probab.html"><a href="Funda-probab.html#tcl"><i class="fa fa-check"></i><b>12.5</b> Teorema central del límite (TCL)</a></li>
<li class="chapter" data-level="12.6" data-path="Funda-probab.html"><a href="Funda-probab.html#ejemplo-de-distribuciones-usando-r"><i class="fa fa-check"></i><b>12.6</b> Ejemplo de distribuciones usando <strong>R</strong></a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="Fundainfer.html"><a href="Fundainfer.html"><i class="fa fa-check"></i><b>13</b> Fundamentos de Inferencia Estadística</a>
<ul>
<li class="chapter" data-level="13.1" data-path="Fundainfer.html"><a href="Fundainfer.html#introinfer"><i class="fa fa-check"></i><b>13.1</b> Introducción a la Inferencia Estadística</a></li>
<li class="chapter" data-level="13.2" data-path="Fundainfer.html"><a href="Fundainfer.html#mas"><i class="fa fa-check"></i><b>13.2</b> Muestreo aleatorio simple</a></li>
<li class="chapter" data-level="13.3" data-path="Fundainfer.html"><a href="Fundainfer.html#estimpuntual"><i class="fa fa-check"></i><b>13.3</b> Estimación puntual</a></li>
<li class="chapter" data-level="13.4" data-path="Fundainfer.html"><a href="Fundainfer.html#estimintervalos"><i class="fa fa-check"></i><b>13.4</b> Estimación por intervalos</a></li>
<li class="chapter" data-level="13.5" data-path="Fundainfer.html"><a href="Fundainfer.html#contrhip"><i class="fa fa-check"></i><b>13.5</b> Contrastes de hipótesis</a></li>
<li class="chapter" data-level="13.6" data-path="Fundainfer.html"><a href="Fundainfer.html#pobnormales"><i class="fa fa-check"></i><b>13.6</b> Inferencia estadística paramétrica sobre poblaciones normales</a></li>
<li class="chapter" data-level="13.7" data-path="Fundainfer.html"><a href="Fundainfer.html#ejemplopobnorm"><i class="fa fa-check"></i><b>13.7</b> Inferencia sobre poblaciones normales con <strong>R</strong></a></li>
<li class="chapter" data-level="13.8" data-path="Fundainfer.html"><a href="Fundainfer.html#contrnormalidad"><i class="fa fa-check"></i><b>13.8</b> Inferencia estadística no paramétrica: contrastes de normalidad</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="muestreo.html"><a href="muestreo.html"><i class="fa fa-check"></i><b>14</b> Métodos de muestreo y remuestreo</a>
<ul>
<li class="chapter" data-level="14.1" data-path="muestreo.html"><a href="muestreo.html#introducción-al-muestreo"><i class="fa fa-check"></i><b>14.1</b> Introducción al muestreo</a></li>
<li class="chapter" data-level="14.2" data-path="muestreo.html"><a href="muestreo.html#muestreo-aleatorio-simple-1"><i class="fa fa-check"></i><b>14.2</b> Muestreo aleatorio simple</a></li>
<li class="chapter" data-level="14.3" data-path="muestreo.html"><a href="muestreo.html#muestestra"><i class="fa fa-check"></i><b>14.3</b> Muestreo estratificado</a></li>
<li class="chapter" data-level="14.4" data-path="muestreo.html"><a href="muestreo.html#otros-tipos-de-muestreo-probabilístico"><i class="fa fa-check"></i><b>14.4</b> Otros tipos de muestreo probabilístico</a></li>
<li class="chapter" data-level="14.5" data-path="muestreo.html"><a href="muestreo.html#técnicas-de-remuestreo-bootstrap."><i class="fa fa-check"></i><b>14.5</b> Técnicas de remuestreo: Bootstrap.</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="modelización-lineal.html"><a href="modelización-lineal.html"><i class="fa fa-check"></i><b>15</b> Modelización lineal</a>
<ul>
<li class="chapter" data-level="15.1" data-path="modelización-lineal.html"><a href="modelización-lineal.html#modelización"><i class="fa fa-check"></i><b>15.1</b> Modelización</a></li>
<li class="chapter" data-level="15.2" data-path="modelización-lineal.html"><a href="modelización-lineal.html#procedimiento-de-modelización"><i class="fa fa-check"></i><b>15.2</b> Procedimiento de modelización</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="modelización-lineal.html"><a href="modelización-lineal.html#Bondad"><i class="fa fa-check"></i><b>15.2.1</b> Estimación del modelo</a></li>
<li class="chapter" data-level="15.2.2" data-path="modelización-lineal.html"><a href="modelización-lineal.html#validación-del-modelo"><i class="fa fa-check"></i><b>15.2.2</b> Validación del modelo</a></li>
<li class="chapter" data-level="15.2.3" data-path="modelización-lineal.html"><a href="modelización-lineal.html#interpretación-de-los-coeficientes"><i class="fa fa-check"></i><b>15.2.3</b> Interpretación de los coeficientes</a></li>
<li class="chapter" data-level="15.2.4" data-path="modelización-lineal.html"><a href="modelización-lineal.html#predicción"><i class="fa fa-check"></i><b>15.2.4</b> Predicción</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="modelización-lineal.html"><a href="modelización-lineal.html#procedimiento-con-r-la-función-lm"><i class="fa fa-check"></i><b>15.3</b> Procedimiento con R: la función <code>lm</code></a></li>
<li class="chapter" data-level="15.4" data-path="modelización-lineal.html"><a href="modelización-lineal.html#Casos"><i class="fa fa-check"></i><b>15.4</b> Casos prácticos</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="modelización-lineal.html"><a href="modelización-lineal.html#estimación-de-los-coeficientes"><i class="fa fa-check"></i><b>15.4.1</b> Estimación de los coeficientes</a></li>
<li class="chapter" data-level="15.4.2" data-path="modelización-lineal.html"><a href="modelización-lineal.html#validación"><i class="fa fa-check"></i><b>15.4.2</b> Validación</a></li>
<li class="chapter" data-level="15.4.3" data-path="modelización-lineal.html"><a href="modelización-lineal.html#interpretación-de-los-coeficientes-1"><i class="fa fa-check"></i><b>15.4.3</b> Interpretación de los coeficientes</a></li>
<li class="chapter" data-level="15.4.4" data-path="modelización-lineal.html"><a href="modelización-lineal.html#predicción-1"><i class="fa fa-check"></i><b>15.4.4</b> Predicción</a></li>
<li class="chapter" data-level="15.4.5" data-path="modelización-lineal.html"><a href="modelización-lineal.html#nuevo-ajuste-con-logozone"><i class="fa fa-check"></i><b>15.4.5</b> Nuevo ajuste con <code>log(Ozone)</code></a></li>
<li class="chapter" data-level="15.4.6" data-path="modelización-lineal.html"><a href="modelización-lineal.html#coeficientes-de-variables-categóricas"><i class="fa fa-check"></i><b>15.4.6</b> Coeficientes de variables categóricas</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="modelización-lineal.html"><a href="modelización-lineal.html#comentarios-finales"><i class="fa fa-check"></i><b>15.5</b> Comentarios finales</a>
<ul>
<li class="chapter" data-level="" data-path="modelización-lineal.html"><a href="modelización-lineal.html#resumen"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html"><i class="fa fa-check"></i><b>16</b> Modelos lineales generalizados</a>
<ul>
<li class="chapter" data-level="16.1" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#motivación"><i class="fa fa-check"></i><b>16.1</b> Motivación</a></li>
<li class="chapter" data-level="16.2" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#modelo-y-sus-componentes"><i class="fa fa-check"></i><b>16.2</b> Modelo y sus componentes</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#función-enlace"><i class="fa fa-check"></i><b>16.2.1</b> Función enlace </a></li>
<li class="chapter" data-level="16.2.2" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#glms-en-r"><i class="fa fa-check"></i><b>16.2.2</b> GLMs en <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#regresión-logística"><i class="fa fa-check"></i><b>16.3</b> Regresión logística</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#procedimiento-de-ajuste"><i class="fa fa-check"></i><b>16.3.1</b> Procedimiento de ajuste</a></li>
<li class="chapter" data-level="16.3.2" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#adecuación-del-modelo"><i class="fa fa-check"></i><b>16.3.2</b> Adecuación del modelo</a></li>
<li class="chapter" data-level="16.3.3" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#SECCinterp"><i class="fa fa-check"></i><b>16.3.3</b> Interpretación de resultados</a></li>
<li class="chapter" data-level="16.3.4" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#predicción.-curva-roc-y-auc"><i class="fa fa-check"></i><b>16.3.4</b> Predicción. Curva ROC y AUC</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#regresión-de-poisson"><i class="fa fa-check"></i><b>16.4</b> Regresión de Poisson</a></li>
<li class="chapter" data-level="16.5" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#casos-prácticos"><i class="fa fa-check"></i><b>16.5</b> Casos prácticos</a>
<ul>
<li class="chapter" data-level="16.5.1" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#ejemplos-de-regresión-logística"><i class="fa fa-check"></i><b>16.5.1</b> Ejemplos de regresión logística</a></li>
<li class="chapter" data-level="16.5.2" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#ejemplo-de-regresión-de-poisson"><i class="fa fa-check"></i><b>16.5.2</b> Ejemplo de regresión de Poisson</a></li>
<li class="chapter" data-level="" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#resumen-1"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html"><i class="fa fa-check"></i><b>17</b> Modelos aditivos generalizados</a>
<ul>
<li class="chapter" data-level="17.1" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#introducción-7"><i class="fa fa-check"></i><b>17.1</b> Introducción</a></li>
<li class="chapter" data-level="17.2" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#splines-con-penalizaciones"><i class="fa fa-check"></i><b>17.2</b> Splines con penalizaciones</a></li>
<li class="chapter" data-level="17.3" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#aspectos-metodológicos"><i class="fa fa-check"></i><b>17.3</b> Aspectos metodológicos</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#estimación-de-los-paraámetros-del-modelo"><i class="fa fa-check"></i><b>17.3.1</b> Estimación de los paraámetros del modelo</a></li>
<li class="chapter" data-level="17.3.2" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#inferencia-sobre-las-funciones-suaves"><i class="fa fa-check"></i><b>17.3.2</b> Inferencia sobre las funciones suaves</a></li>
<li class="chapter" data-level="17.3.3" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#suavizado-mutidimensional-y-para-datos-no-gaussianos"><i class="fa fa-check"></i><b>17.3.3</b> Suavizado mutidimensional y para datos no Gaussianos</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#la-función-gam-del-paquete-mgcv"><i class="fa fa-check"></i><b>17.4</b> La función <code>gam</code> del paquete <code>mgcv</code></a></li>
<li class="chapter" data-level="17.5" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#casos-prácticos-1"><i class="fa fa-check"></i><b>17.5</b> Casos prácticos</a>
<ul>
<li class="chapter" data-level="17.5.1" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#modelo-unidimensional-con-fossil"><i class="fa fa-check"></i><b>17.5.1</b> Modelo unidimensional con <code>fossil</code></a></li>
<li class="chapter" data-level="17.5.2" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#modelo-aditivo-con-airquality"><i class="fa fa-check"></i><b>17.5.2</b> Modelo aditivo con <code>airquality</code></a></li>
<li class="chapter" data-level="17.5.3" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#modelo-semiparamétrico-con-onions"><i class="fa fa-check"></i><b>17.5.3</b> Modelo semiparamétrico con <code>onions</code></a></li>
<li class="chapter" data-level="17.5.4" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#modelo-aditivo-generalizado-y-multidimensional-con-smacker"><i class="fa fa-check"></i><b>17.5.4</b> Modelo aditivo generalizado y multidimensional, con <code>smacker</code></a></li>
<li class="chapter" data-level="" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#resumen-2"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="modelos-mixtos.html"><a href="modelos-mixtos.html"><i class="fa fa-check"></i><b>18</b> Modelos mixtos</a>
<ul>
<li class="chapter" data-level="18.1" data-path="modelos-mixtos.html"><a href="modelos-mixtos.html#conceptos-básicos"><i class="fa fa-check"></i><b>18.1</b> Conceptos básicos</a>
<ul>
<li class="chapter" data-level="18.1.1" data-path="modelos-mixtos.html"><a href="modelos-mixtos.html#tipo-y-estructura-de-los-datos"><i class="fa fa-check"></i><b>18.1.1</b> Tipo y estructura de los datos</a></li>
<li class="chapter" data-level="18.1.2" data-path="modelos-mixtos.html"><a href="modelos-mixtos.html#efectos-fijos-o-aleatorios"><i class="fa fa-check"></i><b>18.1.2</b> ¿Efectos fijos o aleatorios?</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="modelos-mixtos.html"><a href="modelos-mixtos.html#formulación-del-modelo-con-efectos-aleatorios-o-modelos-mixtos"><i class="fa fa-check"></i><b>18.2</b> Formulación del modelo con efectos aleatorios o modelos mixtos</a>
<ul>
<li class="chapter" data-level="18.2.1" data-path="modelos-mixtos.html"><a href="modelos-mixtos.html#formulación-general"><i class="fa fa-check"></i><b>18.2.1</b> Formulación general</a></li>
<li class="chapter" data-level="18.2.2" data-path="modelos-mixtos.html"><a href="modelos-mixtos.html#inferencia-y-selección-del-modelo"><i class="fa fa-check"></i><b>18.2.2</b> Inferencia y selección del modelo</a></li>
<li class="chapter" data-level="18.2.3" data-path="modelos-mixtos.html"><a href="modelos-mixtos.html#diagnosis-del-modelo"><i class="fa fa-check"></i><b>18.2.3</b> Diagnosis del modelo</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="modelos-mixtos.html"><a href="modelos-mixtos.html#funciones-de-r-para-ajustar-modelos-mixtos"><i class="fa fa-check"></i><b>18.3</b> Funciones de <code>R</code> para ajustar modelos mixtos</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="modelos-mixtos.html"><a href="modelos-mixtos.html#la-función-lmer"><i class="fa fa-check"></i><b>18.3.1</b> La función <code>lmer()</code></a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="modelos-mixtos.html"><a href="modelos-mixtos.html#caso-práctico"><i class="fa fa-check"></i><b>18.4</b> Caso práctico</a>
<ul>
<li class="chapter" data-level="18.4.1" data-path="modelos-mixtos.html"><a href="modelos-mixtos.html#modelo-con-ordenada-en-el-origen-aleatoria"><i class="fa fa-check"></i><b>18.4.1</b> Modelo con ordenada en el origen aleatoria</a></li>
<li class="chapter" data-level="18.4.2" data-path="modelos-mixtos.html"><a href="modelos-mixtos.html#modelo-con-pendiente-aleatoria"><i class="fa fa-check"></i><b>18.4.2</b> Modelo con pendiente aleatoria</a></li>
<li class="chapter" data-level="18.4.3" data-path="modelos-mixtos.html"><a href="modelos-mixtos.html#cómo-construir-el-modelo-en-la-práctica"><i class="fa fa-check"></i><b>18.4.3</b> ¿Cómo construir el modelo en la práctica?</a></li>
<li class="chapter" data-level="" data-path="modelos-mixtos.html"><a href="modelos-mixtos.html#resumen-3"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="modelos-sparse-y-métodos-penalizados-de-regresión.html"><a href="modelos-sparse-y-métodos-penalizados-de-regresión.html"><i class="fa fa-check"></i><b>19</b> Modelos sparse y métodos penalizados de regresión</a>
<ul>
<li class="chapter" data-level="19.1" data-path="modelos-sparse-y-métodos-penalizados-de-regresión.html"><a href="modelos-sparse-y-métodos-penalizados-de-regresión.html#introducción-8"><i class="fa fa-check"></i><b>19.1</b> Introducción</a></li>
<li class="chapter" data-level="19.2" data-path="modelos-sparse-y-métodos-penalizados-de-regresión.html"><a href="modelos-sparse-y-métodos-penalizados-de-regresión.html#selección-del-mejor-subconjunto"><i class="fa fa-check"></i><b>19.2</b> Selección del mejor subconjunto</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="modelos-sparse-y-métodos-penalizados-de-regresión.html"><a href="modelos-sparse-y-métodos-penalizados-de-regresión.html#ejemplo-sueldo-de-jugadores-de-béisbol"><i class="fa fa-check"></i><b>19.2.1</b> Ejemplo: Sueldo de jugadores de béisbol</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="modelos-sparse-y-métodos-penalizados-de-regresión.html"><a href="modelos-sparse-y-métodos-penalizados-de-regresión.html#selección-stepwise"><i class="fa fa-check"></i><b>19.3</b> Selección <em>Stepwise</em></a>
<ul>
<li class="chapter" data-level="19.3.1" data-path="modelos-sparse-y-métodos-penalizados-de-regresión.html"><a href="modelos-sparse-y-métodos-penalizados-de-regresión.html#forward-stepwise"><i class="fa fa-check"></i><b>19.3.1</b> Forward stepwise</a></li>
<li class="chapter" data-level="19.3.2" data-path="modelos-sparse-y-métodos-penalizados-de-regresión.html"><a href="modelos-sparse-y-métodos-penalizados-de-regresión.html#backward-stepwise"><i class="fa fa-check"></i><b>19.3.2</b> Backward stepwise</a></li>
<li class="chapter" data-level="19.3.3" data-path="modelos-sparse-y-métodos-penalizados-de-regresión.html"><a href="modelos-sparse-y-métodos-penalizados-de-regresión.html#ejemplo-sueldo-de-jugadores-de-béisbol-1"><i class="fa fa-check"></i><b>19.3.3</b> Ejemplo: Sueldo de jugadores de béisbol</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="modelos-sparse-y-métodos-penalizados-de-regresión.html"><a href="modelos-sparse-y-métodos-penalizados-de-regresión.html#métodos-shrinkage"><i class="fa fa-check"></i><b>19.4</b> Métodos Shrinkage</a>
<ul>
<li class="chapter" data-level="19.4.1" data-path="modelos-sparse-y-métodos-penalizados-de-regresión.html"><a href="modelos-sparse-y-métodos-penalizados-de-regresión.html#regresión-ridge"><i class="fa fa-check"></i><b>19.4.1</b> Regresión ridge</a></li>
<li class="chapter" data-level="19.4.2" data-path="modelos-sparse-y-métodos-penalizados-de-regresión.html"><a href="modelos-sparse-y-métodos-penalizados-de-regresión.html#selección-del-parámetro-de-tuneado"><i class="fa fa-check"></i><b>19.4.2</b> Selección del parámetro de tuneado</a></li>
<li class="chapter" data-level="19.4.3" data-path="modelos-sparse-y-métodos-penalizados-de-regresión.html"><a href="modelos-sparse-y-métodos-penalizados-de-regresión.html#regresión-lasso"><i class="fa fa-check"></i><b>19.4.3</b> Regresión Lasso</a></li>
<li class="chapter" data-level="19.4.4" data-path="modelos-sparse-y-métodos-penalizados-de-regresión.html"><a href="modelos-sparse-y-métodos-penalizados-de-regresión.html#elastic-net"><i class="fa fa-check"></i><b>19.4.4</b> Elastic net </a></li>
<li class="chapter" data-level="" data-path="modelos-sparse-y-métodos-penalizados-de-regresión.html"><a href="modelos-sparse-y-métodos-penalizados-de-regresión.html#resumen-4"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="20" data-path="modelización-de-series-temporales.html"><a href="modelización-de-series-temporales.html"><i class="fa fa-check"></i><b>20</b> Modelización de series temporales</a>
<ul>
<li class="chapter" data-level="20.1" data-path="modelización-de-series-temporales.html"><a href="modelización-de-series-temporales.html#conceptos-básicos-1"><i class="fa fa-check"></i><b>20.1</b> Conceptos básicos</a></li>
<li class="chapter" data-level="20.2" data-path="modelización-de-series-temporales.html"><a href="modelización-de-series-temporales.html#modelos-arima"><i class="fa fa-check"></i><b>20.2</b> Modelos ARIMA</a></li>
<li class="chapter" data-level="20.3" data-path="modelización-de-series-temporales.html"><a href="modelización-de-series-temporales.html#análisis-de-series-temporales-con-r"><i class="fa fa-check"></i><b>20.3</b> Análisis de series temporales con R</a>
<ul>
<li class="chapter" data-level="20.3.1" data-path="modelización-de-series-temporales.html"><a href="modelización-de-series-temporales.html#identificación-o-especificación-del-modelo"><i class="fa fa-check"></i><b>20.3.1</b> Identificación o especificación del modelo</a></li>
<li class="chapter" data-level="20.3.2" data-path="modelización-de-series-temporales.html"><a href="modelización-de-series-temporales.html#estimación-del-modelo"><i class="fa fa-check"></i><b>20.3.2</b> Estimación del modelo</a></li>
<li class="chapter" data-level="20.3.3" data-path="modelización-de-series-temporales.html"><a href="modelización-de-series-temporales.html#diagnosis-validación-y-contrastación"><i class="fa fa-check"></i><b>20.3.3</b> Diagnosis, validación y contrastación</a></li>
<li class="chapter" data-level="20.3.4" data-path="modelización-de-series-temporales.html"><a href="modelización-de-series-temporales.html#predicción-2"><i class="fa fa-check"></i><b>20.3.4</b> Predicción</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliografía.html"><a href="bibliografía.html"><i class="fa fa-check"></i>Bibliografía</a></li>
<li class="chapter" data-level="21" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html"><i class="fa fa-check"></i><b>21</b> Análisis de tablas de contingencia</a>
<ul>
<li class="chapter" data-level="21.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#introducción-9"><i class="fa fa-check"></i><b>21.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="21.1.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#motiv"><i class="fa fa-check"></i><b>21.1.1</b> Motivación</a></li>
<li class="chapter" data-level="21.1.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#notac"><i class="fa fa-check"></i><b>21.1.2</b> Notación</a></li>
<li class="chapter" data-level="21.1.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#diseños-experimentales-o-procedimientos-de-muestreo-que-dan-lugar-a-una-tabla-de-contingencia"><i class="fa fa-check"></i><b>21.1.3</b> Diseños experimentales o procedimientos de muestreo que dan lugar a una tabla de contingencia</a></li>
</ul></li>
<li class="chapter" data-level="21.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contraste-de-independencia-en-tablas-2times-2"><i class="fa fa-check"></i><b>21.2</b> Contraste de independencia en tablas <span class="math inline">\((2\times 2)\)</span></a>
<ul>
<li class="chapter" data-level="21.2.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#introducción-10"><i class="fa fa-check"></i><b>21.2.1</b> Introducción</a></li>
<li class="chapter" data-level="21.2.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#plantgen"><i class="fa fa-check"></i><b>21.2.2</b> Planteamiento general del contraste exacto de independencia</a></li>
<li class="chapter" data-level="21.2.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#algoritmo"><i class="fa fa-check"></i><b>21.2.3</b> Algoritmo para la realización del contraste exacto de independencia</a></li>
<li class="chapter" data-level="21.2.4" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contraste-de-independencia-diseño-tipo-1"><i class="fa fa-check"></i><b>21.2.4</b> Contraste de independencia: Diseño Tipo 1</a></li>
<li class="chapter" data-level="21.2.5" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#dise"><i class="fa fa-check"></i><b>21.2.5</b> Contraste de independencia: Diseños Tipo 2 y Tipo 3</a></li>
</ul></li>
<li class="chapter" data-level="21.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contraste-de-independencia-en-tablas-rtimes-c"><i class="fa fa-check"></i><b>21.3</b> Contraste de independencia en tablas <span class="math inline">\(R\times C\)</span></a>
<ul>
<li class="chapter" data-level="21.3.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#IntroRxC"><i class="fa fa-check"></i><b>21.3.1</b> Introducción</a></li>
<li class="chapter" data-level="21.3.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contaprox"><i class="fa fa-check"></i><b>21.3.2</b> Contrastes aproximados</a></li>
<li class="chapter" data-level="21.3.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contraste-aproximado-con-corrección-de-continuidad-1"><i class="fa fa-check"></i><b>21.3.3</b> Contraste aproximado con corrección de continuidad</a></li>
</ul></li>
<li class="chapter" data-level="21.4" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#medidas"><i class="fa fa-check"></i><b>21.4</b> Medidas de asociación en tablas <span class="math inline">\(2\times 2\)</span></a>
<ul>
<li class="chapter" data-level="21.4.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#introducción-11"><i class="fa fa-check"></i><b>21.4.1</b> Introducción</a></li>
<li class="chapter" data-level="21.4.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#la-hatq-de-yule"><i class="fa fa-check"></i><b>21.4.2</b> La <span class="math inline">\(\hat{Q}\)</span> de Yule</a></li>
<li class="chapter" data-level="21.4.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#otras-medidas-de-asociación-para-tablas-2times-2"><i class="fa fa-check"></i><b>21.4.3</b> Otras medidas de asociación para tablas <span class="math inline">\(2\times 2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="21.5" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#medidas-de-asociación-en-tablas-rtimes-c"><i class="fa fa-check"></i><b>21.5</b> Medidas de asociación en tablas <span class="math inline">\(R\times C\)</span></a>
<ul>
<li class="chapter" data-level="21.5.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#introducción-12"><i class="fa fa-check"></i><b>21.5.1</b> Introducción</a></li>
<li class="chapter" data-level="21.5.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#medidas-derivadas-del-estadístico-chi-cuadrado"><i class="fa fa-check"></i><b>21.5.2</b> Medidas derivadas del estadístico Chi-cuadrado</a></li>
<li class="chapter" data-level="21.5.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#medidas-basadas-en-la-reducción-proporcional-del-error-lambda-de-goodman-y-kruskal"><i class="fa fa-check"></i><b>21.5.3</b> Medidas basadas en la reducción proporcional del error: <span class="math inline">\(\lambda\)</span> de Goodman y Kruskal</a></li>
<li class="chapter" data-level="21.5.4" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#determinación-de-las-fuentes-de-asociación"><i class="fa fa-check"></i><b>21.5.4</b> Determinación de las fuentes de asociación</a></li>
</ul></li>
<li class="chapter" data-level="21.6" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contrastes-de-independencia-en-tablas-multidimensionales"><i class="fa fa-check"></i><b>21.6</b> Contrastes de independencia en tablas multidimensionales</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="correspondencias.html"><a href="correspondencias.html"><i class="fa fa-check"></i><b>22</b> Análisis de correspondencias</a>
<ul>
<li class="chapter" data-level="22.1" data-path="correspondencias.html"><a href="correspondencias.html#introducción-13"><i class="fa fa-check"></i><b>22.1</b> Introducción</a></li>
<li class="chapter" data-level="22.2" data-path="correspondencias.html"><a href="correspondencias.html#metodología-del-análisis-de-correspondencias"><i class="fa fa-check"></i><b>22.2</b> Metodología del análisis de correspondencias</a>
<ul>
<li class="chapter" data-level="22.2.1" data-path="correspondencias.html"><a href="correspondencias.html#proyecciones-fila-columna-y-simétrica"><i class="fa fa-check"></i><b>22.2.1</b> Proyecciones fila, columna y simétrica</a></li>
</ul></li>
<li class="chapter" data-level="22.3" data-path="correspondencias.html"><a href="correspondencias.html#ejemplos-de-análisis-de-correspondencias-con-r"><i class="fa fa-check"></i><b>22.3</b> Ejemplos de análisis de correspondencias con <strong>R</strong></a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="análisis-conjunto.html"><a href="análisis-conjunto.html"><i class="fa fa-check"></i><b>23</b> Análisis conjunto</a>
<ul>
<li class="chapter" data-level="23.1" data-path="análisis-conjunto.html"><a href="análisis-conjunto.html#introducción-conceptos-clave-y-tipos-de-análisis"><i class="fa fa-check"></i><b>23.1</b> Introducción, conceptos clave y tipos de análisis</a></li>
<li class="chapter" data-level="23.2" data-path="análisis-conjunto.html"><a href="análisis-conjunto.html#aplicación-del-análisis-conjunto-etapas"><i class="fa fa-check"></i><b>23.2</b> Aplicación del Análisis Conjunto (etapas):</a></li>
<li class="chapter" data-level="23.3" data-path="análisis-conjunto.html"><a href="análisis-conjunto.html#ejemplo-utilizando-r"><i class="fa fa-check"></i><b>23.3</b> Ejemplo utilizando R:</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="análisis-discriminante.html"><a href="análisis-discriminante.html"><i class="fa fa-check"></i><b>24</b> Análisis discriminante</a>
<ul>
<li class="chapter" data-level="24.1" data-path="análisis-discriminante.html"><a href="análisis-discriminante.html#introducción-14"><i class="fa fa-check"></i><b>24.1</b> Introducción</a></li>
<li class="chapter" data-level="24.2" data-path="análisis-discriminante.html"><a href="análisis-discriminante.html#tipos-de-análisis-discriminantes"><i class="fa fa-check"></i><b>24.2</b> Tipos de análisis discriminantes:</a></li>
<li class="chapter" data-level="24.3" data-path="análisis-discriminante.html"><a href="análisis-discriminante.html#ejemplos"><i class="fa fa-check"></i><b>24.3</b> Ejemplos:</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html"><i class="fa fa-check"></i><b>25</b> Árboles de clasificación y regresión </a>
<ul>
<li class="chapter" data-level="25.1" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#introducción-15"><i class="fa fa-check"></i><b>25.1</b> Introducción </a></li>
<li class="chapter" data-level="25.2" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#aprendizaje-con-árboles-de-decisión"><i class="fa fa-check"></i><b>25.2</b> Aprendizaje con árboles de decisión</a></li>
<li class="chapter" data-level="25.3" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#cómo-se-va-dividiendo-el-árbol"><i class="fa fa-check"></i><b>25.3</b> ¿Cómo se va dividiendo el árbol? </a>
<ul>
<li class="chapter" data-level="25.3.1" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#impureza-de-gini"><i class="fa fa-check"></i><b>25.3.1</b> Impureza de Gini</a></li>
<li class="chapter" data-level="25.3.2" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#entropía"><i class="fa fa-check"></i><b>25.3.2</b> Entropía </a></li>
<li class="chapter" data-level="25.3.3" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#ganancia-de-información"><i class="fa fa-check"></i><b>25.3.3</b> Ganancia de información</a></li>
<li class="chapter" data-level="25.3.4" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#suma-residual-de-cuadrados-mínima"><i class="fa fa-check"></i><b>25.3.4</b> Suma residual de cuadrados mínima</a></li>
</ul></li>
<li class="chapter" data-level="25.4" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#sobreajuste"><i class="fa fa-check"></i><b>25.4</b> Sobreajuste </a></li>
<li class="chapter" data-level="25.5" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#cuánto-debe-crecer-un-árbol"><i class="fa fa-check"></i><b>25.5</b> ¿Cuánto debe crecer un árbol? </a>
<ul>
<li class="chapter" data-level="25.5.1" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#la-parada-temprana"><i class="fa fa-check"></i><b>25.5.1</b> La parada temprana </a></li>
<li class="chapter" data-level="25.5.2" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#la-poda"><i class="fa fa-check"></i><b>25.5.2</b> La poda </a></li>
</ul></li>
<li class="chapter" data-level="25.6" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#el-algoritmo-id3-para-la-construcción-de-un-árbol-de-decisión"><i class="fa fa-check"></i><b>25.6</b> El algoritmo ID3 para la construcción de un árbol de decisión</a></li>
<li class="chapter" data-level="25.7" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#procedimiento-con-r-la-funcion-rpart"><i class="fa fa-check"></i><b>25.7</b> Procedimiento con R: la funcion <code>rpart</code></a></li>
<li class="chapter" data-level="25.8" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#aplicaciones-de-los-árboles-de-decisión"><i class="fa fa-check"></i><b>25.8</b> Aplicaciones de los árboles de decisión</a>
<ul>
<li class="chapter" data-level="25.8.1" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#el-caso-de-negocio"><i class="fa fa-check"></i><b>25.8.1</b> El caso de negocio</a></li>
<li class="chapter" data-level="25.8.2" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#árbol-de-clasificación-para-determinar-la-intención-de-compra"><i class="fa fa-check"></i><b>25.8.2</b> Árbol de clasificación para determinar la intención de compra</a></li>
<li class="chapter" data-level="25.8.3" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#árbol-de-regresión-para-estimar-el-número-de-días-hospitalizado"><i class="fa fa-check"></i><b>25.8.3</b> Árbol de regresión para estimar el número de días hospitalizado</a></li>
<li class="chapter" data-level="" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#resumen-5"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="26" data-path="máquinas-de-vector-soporte.html"><a href="máquinas-de-vector-soporte.html"><i class="fa fa-check"></i><b>26</b> Máquinas de Vector Soporte</a>
<ul>
<li class="chapter" data-level="26.1" data-path="máquinas-de-vector-soporte.html"><a href="máquinas-de-vector-soporte.html#introducción-16"><i class="fa fa-check"></i><b>26.1</b> Introducción</a></li>
<li class="chapter" data-level="26.2" data-path="máquinas-de-vector-soporte.html"><a href="máquinas-de-vector-soporte.html#algoritmo-svm-para-clasificación-binaria"><i class="fa fa-check"></i><b>26.2</b> Algoritmo SVM para clasificación binaria</a></li>
<li class="chapter" data-level="26.3" data-path="máquinas-de-vector-soporte.html"><a href="máquinas-de-vector-soporte.html#y-si-tengo-más-de-dos-clases"><i class="fa fa-check"></i><b>26.3</b> ¿Y si tengo más de dos clases?</a></li>
<li class="chapter" data-level="26.4" data-path="máquinas-de-vector-soporte.html"><a href="máquinas-de-vector-soporte.html#truco-del-kernel-tratando-con-la-no-linearidad"><i class="fa fa-check"></i><b>26.4</b> Truco del Kernel: Tratando con la no linearidad</a>
<ul>
<li class="chapter" data-level="26.4.1" data-path="máquinas-de-vector-soporte.html"><a href="máquinas-de-vector-soporte.html#algunos-kernels-populares"><i class="fa fa-check"></i><b>26.4.1</b> Algunos kernels populares</a></li>
</ul></li>
<li class="chapter" data-level="26.5" data-path="máquinas-de-vector-soporte.html"><a href="máquinas-de-vector-soporte.html#procedimiento-con-r-la-funcion-svm"><i class="fa fa-check"></i><b>26.5</b> Procedimiento con R: la funcion <code>svm</code></a></li>
<li class="chapter" data-level="26.6" data-path="máquinas-de-vector-soporte.html"><a href="máquinas-de-vector-soporte.html#aplicación-de-un-modelo-svm-radial-con-ajuste-automático-en-r"><i class="fa fa-check"></i><b>26.6</b> Aplicación de un modelo SVM Radial con ajuste automático en R</a>
<ul>
<li class="chapter" data-level="26.6.1" data-path="máquinas-de-vector-soporte.html"><a href="máquinas-de-vector-soporte.html#importancia-de-las-variables"><i class="fa fa-check"></i><b>26.6.1</b> Importancia de las variables</a></li>
<li class="chapter" data-level="" data-path="máquinas-de-vector-soporte.html"><a href="máquinas-de-vector-soporte.html#resumen-6"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="27" data-path="clasificador-k-vecinos-más-próximos.html"><a href="clasificador-k-vecinos-más-próximos.html"><i class="fa fa-check"></i><b>27</b> Clasificador k-vecinos más próximos</a>
<ul>
<li class="chapter" data-level="27.1" data-path="clasificador-k-vecinos-más-próximos.html"><a href="clasificador-k-vecinos-más-próximos.html#introducción-17"><i class="fa fa-check"></i><b>27.1</b> Introducción</a></li>
<li class="chapter" data-level="27.2" data-path="clasificador-k-vecinos-más-próximos.html"><a href="clasificador-k-vecinos-más-próximos.html#decisiones-a-tener-en-cuenta"><i class="fa fa-check"></i><b>27.2</b> Decisiones a tener en cuenta</a>
<ul>
<li class="chapter" data-level="27.2.1" data-path="clasificador-k-vecinos-más-próximos.html"><a href="clasificador-k-vecinos-más-próximos.html#función-de-distancia-a-utilizar"><i class="fa fa-check"></i><b>27.2.1</b> Función de distancia a utilizar</a></li>
<li class="chapter" data-level="27.2.2" data-path="clasificador-k-vecinos-más-próximos.html"><a href="clasificador-k-vecinos-más-próximos.html#número-de-vecinos-k-seleccionados"><i class="fa fa-check"></i><b>27.2.2</b> Número de vecinos (k) seleccionados</a></li>
</ul></li>
<li class="chapter" data-level="27.3" data-path="clasificador-k-vecinos-más-próximos.html"><a href="clasificador-k-vecinos-más-próximos.html#procedimiento-con-r-la-funcion-knn"><i class="fa fa-check"></i><b>27.3</b> Procedimiento con R: la funcion knn</a></li>
<li class="chapter" data-level="27.4" data-path="clasificador-k-vecinos-más-próximos.html"><a href="clasificador-k-vecinos-más-próximos.html#aplicación-del-modelo-knn-en-r"><i class="fa fa-check"></i><b>27.4</b> Aplicación del modelo KNN en R</a>
<ul>
<li class="chapter" data-level="" data-path="clasificador-k-vecinos-más-próximos.html"><a href="clasificador-k-vecinos-más-próximos.html#resumen-7"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="28" data-path="naive-bayes.html"><a href="naive-bayes.html"><i class="fa fa-check"></i><b>28</b> Naive Bayes</a>
<ul>
<li class="chapter" data-level="28.1" data-path="naive-bayes.html"><a href="naive-bayes.html#introducción-18"><i class="fa fa-check"></i><b>28.1</b> Introducción</a></li>
<li class="chapter" data-level="28.2" data-path="naive-bayes.html"><a href="naive-bayes.html#teorema-de-bayes"><i class="fa fa-check"></i><b>28.2</b> Teorema de Bayes</a></li>
<li class="chapter" data-level="28.3" data-path="naive-bayes.html"><a href="naive-bayes.html#el-algoritmo-naive-bayes"><i class="fa fa-check"></i><b>28.3</b> El algoritmo Naive Bayes</a></li>
<li class="chapter" data-level="28.4" data-path="naive-bayes.html"><a href="naive-bayes.html#procedimiento-con-r-la-funcion-naive_bayes"><i class="fa fa-check"></i><b>28.4</b> Procedimiento con R: la funcion <code>naive_bayes</code></a></li>
<li class="chapter" data-level="28.5" data-path="naive-bayes.html"><a href="naive-bayes.html#aplicación-del-modelo-naive-bayes"><i class="fa fa-check"></i><b>28.5</b> Aplicación del modelo Naive Bayes</a>
<ul>
<li class="chapter" data-level="" data-path="naive-bayes.html"><a href="naive-bayes.html#resumen-8"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="29" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html"><i class="fa fa-check"></i><b>29</b> Bagging. Random Forest </a>
<ul>
<li class="chapter" data-level="29.1" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#introducción-metodos-de-ensamble"><i class="fa fa-check"></i><b>29.1</b> Introducción: Metodos de Ensamble</a></li>
<li class="chapter" data-level="29.2" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#bagging"><i class="fa fa-check"></i><b>29.2</b> Bagging</a></li>
<li class="chapter" data-level="29.3" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#procedimiento-con-r-la-función-bagging"><i class="fa fa-check"></i><b>29.3</b> Procedimiento con R: la función <code>bagging</code> </a></li>
<li class="chapter" data-level="29.4" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#implementando-bagging-en-r"><i class="fa fa-check"></i><b>29.4</b> Implementando bagging en R</a>
<ul>
<li class="chapter" data-level="29.4.1" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#interpretación-de-variables-en-el-bagging"><i class="fa fa-check"></i><b>29.4.1</b> Interpretación de variables en el bagging</a></li>
</ul></li>
<li class="chapter" data-level="29.5" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#random-forest"><i class="fa fa-check"></i><b>29.5</b> Random Forest</a>
<ul>
<li class="chapter" data-level="29.5.1" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#número-de-árboles-k"><i class="fa fa-check"></i><b>29.5.1</b> Número de árboles (<span class="math inline">\(K\)</span>)</a></li>
<li class="chapter" data-level="29.5.2" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#número-de-variables-a-considerar-mtry"><i class="fa fa-check"></i><b>29.5.2</b> Número de variables a considerar (<span class="math inline">\(mtry\)</span>)</a></li>
<li class="chapter" data-level="29.5.3" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#complejidad-de-los-árboles"><i class="fa fa-check"></i><b>29.5.3</b> Complejidad de los árboles</a></li>
<li class="chapter" data-level="29.5.4" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#esquema-de-muestreo"><i class="fa fa-check"></i><b>29.5.4</b> Esquema de muestreo</a></li>
<li class="chapter" data-level="29.5.5" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#regla-de-división"><i class="fa fa-check"></i><b>29.5.5</b> Regla de división</a></li>
</ul></li>
<li class="chapter" data-level="29.6" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#procedimiento-con-r-la-función-randomforest"><i class="fa fa-check"></i><b>29.6</b> Procedimiento con R: la función <code>randomForest</code></a></li>
<li class="chapter" data-level="29.7" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#aplicación-del-modelo-random-forest-en-r"><i class="fa fa-check"></i><b>29.7</b> Aplicación del modelo Random Forest en R</a>
<ul>
<li class="chapter" data-level="29.7.1" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#aplicación-del-random-forest"><i class="fa fa-check"></i><b>29.7.1</b> Aplicación del Random Forest</a></li>
<li class="chapter" data-level="" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#resumen-9"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="30" data-path="boosting.-xgboost..html"><a href="boosting.-xgboost..html"><i class="fa fa-check"></i><b>30</b> Boosting. XGBoost.</a>
<ul>
<li class="chapter" data-level="30.1" data-path="boosting.-xgboost..html"><a href="boosting.-xgboost..html#introducción.-boosting."><i class="fa fa-check"></i><b>30.1</b> Introducción. Boosting.</a></li>
<li class="chapter" data-level="30.2" data-path="boosting.-xgboost..html"><a href="boosting.-xgboost..html#gradient-boosting"><i class="fa fa-check"></i><b>30.2</b> Gradient Boosting</a>
<ul>
<li class="chapter" data-level="30.2.1" data-path="boosting.-xgboost..html"><a href="boosting.-xgboost..html#hiperparámetros-del-modelo-gradient-boosting"><i class="fa fa-check"></i><b>30.2.1</b> Hiperparámetros del modelo gradient boosting</a></li>
<li class="chapter" data-level="30.2.2" data-path="boosting.-xgboost..html"><a href="boosting.-xgboost..html#estrategia-de-ajuste-de-hiperparametros"><i class="fa fa-check"></i><b>30.2.2</b> Estrategia de ajuste de hiperparametros</a></li>
</ul></li>
<li class="chapter" data-level="30.3" data-path="boosting.-xgboost..html"><a href="boosting.-xgboost..html#procedimiento-con-r-la-funcion-gbm"><i class="fa fa-check"></i><b>30.3</b> Procedimiento con R: la funcion <code>gbm</code></a></li>
<li class="chapter" data-level="30.4" data-path="boosting.-xgboost..html"><a href="boosting.-xgboost..html#aplicación-del-modelo-gbm-en-r"><i class="fa fa-check"></i><b>30.4</b> Aplicación del modelo GBM en R</a>
<ul>
<li class="chapter" data-level="30.4.1" data-path="boosting.-xgboost..html"><a href="boosting.-xgboost..html#gbm-con-ajuste-automático"><i class="fa fa-check"></i><b>30.4.1</b> GBM con ajuste automático</a></li>
</ul></li>
<li class="chapter" data-level="30.5" data-path="boosting.-xgboost..html"><a href="boosting.-xgboost..html#extreme-gradient-boosting-xgb"><i class="fa fa-check"></i><b>30.5</b> eXtreme Gradient Boosting (XGB)</a>
<ul>
<li class="chapter" data-level="30.5.1" data-path="boosting.-xgboost..html"><a href="boosting.-xgboost..html#hiperparametros-del-modelo-xgboost"><i class="fa fa-check"></i><b>30.5.1</b> Hiperparametros del modelo XGBoost</a></li>
</ul></li>
<li class="chapter" data-level="30.6" data-path="boosting.-xgboost..html"><a href="boosting.-xgboost..html#procedimiento-con-r-la-funcion-xgboost"><i class="fa fa-check"></i><b>30.6</b> Procedimiento con R: la funcion <code>xgboost</code></a></li>
<li class="chapter" data-level="30.7" data-path="boosting.-xgboost..html"><a href="boosting.-xgboost..html#aplicación-del-módelo-xgboost-en-r"><i class="fa fa-check"></i><b>30.7</b> Aplicación del módelo XGBoost en R</a>
<ul>
<li class="chapter" data-level="30.7.1" data-path="boosting.-xgboost..html"><a href="boosting.-xgboost..html#xgboost-y-ajuste-automático"><i class="fa fa-check"></i><b>30.7.1</b> XGBoost y ajuste automático</a></li>
<li class="chapter" data-level="" data-path="boosting.-xgboost..html"><a href="boosting.-xgboost..html#resumen-10"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://blog.uclm.es/tp-mbsba/"> Ciencia de datos con R </a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Fundamentos de ciencia de datos con R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="bagging.-random-forest" class="section level1 hasAnchor" number="29">
<h1><span class="header-section-number">Capítulo 29</span> Bagging. Random Forest <a href="bagging.-random-forest.html#bagging.-random-forest" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><em>Ramón A. Carrasco e Itzcóatl Bueno<a href="#fn72" class="footnote-ref" id="fnref72"><sup>72</sup></a></em></p>
<div id="introducción-metodos-de-ensamble" class="section level2 hasAnchor" number="29.1">
<h2><span class="header-section-number">29.1</span> Introducción: Metodos de Ensamble<a href="bagging.-random-forest.html#introducción-metodos-de-ensamble" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A veces puede darse el caso en que ninguno de los modelos hasta ahora presentados proporciona resultados convincentes para nuestro problema. El <em>aprendizaje ensamblado</em> es un paradigma que en lugar de entrenar un modelo muy preciso se centra en entrenar un gran número de modelos con baja precisión y después combinar sus predicciones para obtener un metamodelo una precisión más alta.</p>
<p>Los modelos de baja precisión son entrenados por algoritmos débiles, es decir, algoritmos incapaces de aprender modelos complejos; y por tanto, generalmente son rápidos tanto en tiempos de entrenamiento como de procesamiento. Existen dos paradigmas de aprendizaje ensamblado: el <em>bagging</em> y el boosting.</p>
</div>
<div id="bagging" class="section level2 hasAnchor" number="29.2">
<h2><span class="header-section-number">29.2</span> Bagging<a href="bagging.-random-forest.html#bagging" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En vez de buscar la división más eficiente en cada capa como ocurre en el árbol de decisión, una alternativa sería construir multiples árboles de decisión y combinar sus resultados. Esta técnica se conoce como bagging y consiste en hacer crecer varios árboles utilizando una selección aleatoria de los datos que se usan para cada árbol y combinando la predicción de cada uno de ellos a través de la media, en el caso de regresión, o mediante un sistema de votación, en el caso de un problema de clasificación.</p>
<p>La principal característica del bagging es el llamado muestreo bootstrap. La intuición tras esto es que para que los árboles generen una respuesta única, debe existir aleatoriedad y variación en cada árbol que conforme el modelo final; puesto que no tendría sentido construir varios árboles identicos. Este problema queda resuelto por el muestreo bootstrap, el cual extrae una variación aleatoria de los datos en cada ronda. En el caso del bagging, se ejecutan distintas muestras de datos para el entrenamiento de cada árbol. A pesar de que esto no elimina la problematica del sobreajuste, los patrones presentes en el conjunto de datos apareceran en la mayoría de los árboles entrenados y aparecerán en la predicción final. Por tanto, el bagging es una técnica de gran eficacia para el tratamiento de los valores atipicos y para la reducción de la varianza que generalmente afecta a un único árbol de decisión.</p>
</div>
<div id="procedimiento-con-r-la-función-bagging" class="section level2 hasAnchor" number="29.3">
<h2><span class="header-section-number">29.3</span> Procedimiento con R: la función <code>bagging</code> <a href="bagging.-random-forest.html#procedimiento-con-r-la-función-bagging" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En el paquete <code>ipred</code> de <strong>R</strong> se encuentra la función <code>bagging</code> que se utiliza para entrenar un modelo bagging:</p>
<div class="sourceCode" id="cb349"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb349-1"><a href="bagging.-random-forest.html#cb349-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">bagging</span>(formula, data, ...)</span></code></pre></div>
</div>
<div id="implementando-bagging-en-r" class="section level2 hasAnchor" number="29.4">
<h2><span class="header-section-number">29.4</span> Implementando bagging en R<a href="bagging.-random-forest.html#implementando-bagging-en-r" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Es posible la implementación de un modelo de predicción de agregación bootstrap en R. Para ello, se pueden utilizar multiples funciones como la ya mencionada en la sección <span class="math inline">\(\ref{rbagging}\)</span> <code>bagging</code>.</p>
<div class="sourceCode" id="cb350"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb350-1"><a href="bagging.-random-forest.html#cb350-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">library</span>(CDR)</span>
<span id="cb350-2"><a href="bagging.-random-forest.html#cb350-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">data</span>(<span class="st">&quot;dp_entr&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb351"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb351-1"><a href="bagging.-random-forest.html#cb351-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="co"># se fija una semilla para que el modelo sea reproducible</span></span>
<span id="cb351-2"><a href="bagging.-random-forest.html#cb351-2" aria-hidden="true" tabindex="-1"></a><span class="er">&gt;</span> <span class="fu">set.seed</span>(<span class="dv">101</span>)</span>
<span id="cb351-3"><a href="bagging.-random-forest.html#cb351-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> </span>
<span id="cb351-4"><a href="bagging.-random-forest.html#cb351-4" aria-hidden="true" tabindex="-1"></a><span class="er">&gt;</span> <span class="co"># Se entrena el modelo</span></span>
<span id="cb351-5"><a href="bagging.-random-forest.html#cb351-5" aria-hidden="true" tabindex="-1"></a><span class="er">&gt;</span> bag_model <span class="ot">&lt;-</span> <span class="fu">bagging</span>(</span>
<span id="cb351-6"><a href="bagging.-random-forest.html#cb351-6" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   <span class="at">formula =</span> CLS_PRO_pro13 <span class="sc">~</span> .,</span>
<span id="cb351-7"><a href="bagging.-random-forest.html#cb351-7" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   <span class="at">data =</span> dp_entr,</span>
<span id="cb351-8"><a href="bagging.-random-forest.html#cb351-8" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   <span class="at">nbagg =</span> <span class="dv">100</span>,</span>
<span id="cb351-9"><a href="bagging.-random-forest.html#cb351-9" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   <span class="at">coob =</span> <span class="cn">TRUE</span>,</span>
<span id="cb351-10"><a href="bagging.-random-forest.html#cb351-10" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   <span class="at">control =</span> <span class="fu">rpart.control</span>(<span class="at">minsplit =</span> <span class="dv">2</span>, <span class="at">cp =</span> <span class="dv">0</span>)</span>
<span id="cb351-11"><a href="bagging.-random-forest.html#cb351-11" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> )</span></code></pre></div>
<div class="sourceCode" id="cb352"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb352-1"><a href="bagging.-random-forest.html#cb352-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> bag_model</span>
<span id="cb352-2"><a href="bagging.-random-forest.html#cb352-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb352-3"><a href="bagging.-random-forest.html#cb352-3" aria-hidden="true" tabindex="-1"></a>Bagging classification trees with <span class="dv">100</span> bootstrap replications </span>
<span id="cb352-4"><a href="bagging.-random-forest.html#cb352-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb352-5"><a href="bagging.-random-forest.html#cb352-5" aria-hidden="true" tabindex="-1"></a>Call<span class="sc">:</span> <span class="fu">bagging.data.frame</span>(<span class="at">formula =</span> CLS_PRO_pro13 <span class="sc">~</span> ., <span class="at">data =</span> dp_entr, </span>
<span id="cb352-6"><a href="bagging.-random-forest.html#cb352-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">nbagg =</span> <span class="dv">100</span>, <span class="at">coob =</span> <span class="cn">TRUE</span>, <span class="at">control =</span> <span class="fu">rpart.control</span>(<span class="at">minsplit =</span> <span class="dv">2</span>, </span>
<span id="cb352-7"><a href="bagging.-random-forest.html#cb352-7" aria-hidden="true" tabindex="-1"></a>        <span class="at">cp =</span> <span class="dv">0</span>))</span>
<span id="cb352-8"><a href="bagging.-random-forest.html#cb352-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb352-9"><a href="bagging.-random-forest.html#cb352-9" aria-hidden="true" tabindex="-1"></a>Out<span class="sc">-</span>of<span class="sc">-</span>bag estimate of misclassification error<span class="sc">:</span>  <span class="fl">0.1416</span> </span></code></pre></div>
<p>Desafortunadamente, <code>bagging()</code> no proporciona el error de clasificación incorrecta por árbol, por lo que para obtener una curva de error mostrada en la figura <a href="bagging.-random-forest.html#fig:bagg-plot">29.1</a> se itera el modelo variando los valores del parametro <code>nbagg</code> entre 10 y 150, incrementandolo de cinco en cinco. Se observa que el error mínimo se obtiene al utilizar 60 árboles.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:bagg-plot"></span>
<img src="img/bagging_missclass.png" alt="Número de árboles óptimo" width="60%" />
<p class="caption">
Figura 29.1: Número de árboles óptimo
</p>
</div>
<p>El modelo se puede optimizar ajustando a sus hiperparametros óptimos. Esto se debe a que el bagging tambien está incluido en la función <code>caret</code> y por tanto podemos saber qué parametros son los que hay que ajustar. Además, se puede entrenar utilizando validación cruzada para comprobar si el modelo se puede generalizar. Se observa que si se entrena un modelo bagging con 60 árboles, la precisión del modelo es del 87%. Esto es equivalente al resultado obtenido anteriormente en el que para 60 árboles el modelo tenía un error de clasificación del 13%.</p>
<div class="sourceCode" id="cb353"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb353-1"><a href="bagging.-random-forest.html#cb353-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">set.seed</span>(<span class="dv">101</span>)</span>
<span id="cb353-2"><a href="bagging.-random-forest.html#cb353-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> model_bag <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb353-3"><a href="bagging.-random-forest.html#cb353-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   CLS_PRO_pro13 <span class="sc">~</span> .,</span>
<span id="cb353-4"><a href="bagging.-random-forest.html#cb353-4" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   <span class="at">data =</span> dp_entr,</span>
<span id="cb353-5"><a href="bagging.-random-forest.html#cb353-5" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   <span class="at">method =</span> <span class="st">&quot;treebag&quot;</span>,</span>
<span id="cb353-6"><a href="bagging.-random-forest.html#cb353-6" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">number =</span> <span class="dv">10</span>),</span>
<span id="cb353-7"><a href="bagging.-random-forest.html#cb353-7" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   <span class="at">nbagg =</span> <span class="dv">60</span>,</span>
<span id="cb353-8"><a href="bagging.-random-forest.html#cb353-8" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   <span class="at">control =</span> <span class="fu">rpart.control</span>(<span class="at">minsplit =</span> <span class="dv">2</span>, <span class="at">cp =</span> <span class="dv">0</span>)</span>
<span id="cb353-9"><a href="bagging.-random-forest.html#cb353-9" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> )</span></code></pre></div>
<div class="sourceCode" id="cb354"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb354-1"><a href="bagging.-random-forest.html#cb354-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> model_bag</span>
<span id="cb354-2"><a href="bagging.-random-forest.html#cb354-2" aria-hidden="true" tabindex="-1"></a>Bagged CART </span>
<span id="cb354-3"><a href="bagging.-random-forest.html#cb354-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb354-4"><a href="bagging.-random-forest.html#cb354-4" aria-hidden="true" tabindex="-1"></a><span class="dv">558</span> samples</span>
<span id="cb354-5"><a href="bagging.-random-forest.html#cb354-5" aria-hidden="true" tabindex="-1"></a> <span class="dv">17</span> predictor</span>
<span id="cb354-6"><a href="bagging.-random-forest.html#cb354-6" aria-hidden="true" tabindex="-1"></a>  <span class="dv">2</span> classes<span class="sc">:</span> <span class="st">&#39;S&#39;</span>, <span class="st">&#39;N&#39;</span> </span>
<span id="cb354-7"><a href="bagging.-random-forest.html#cb354-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb354-8"><a href="bagging.-random-forest.html#cb354-8" aria-hidden="true" tabindex="-1"></a>No pre<span class="sc">-</span>processing</span>
<span id="cb354-9"><a href="bagging.-random-forest.html#cb354-9" aria-hidden="true" tabindex="-1"></a>Resampling<span class="sc">:</span> Cross<span class="sc">-</span><span class="fu">Validated</span> (<span class="dv">10</span> fold) </span>
<span id="cb354-10"><a href="bagging.-random-forest.html#cb354-10" aria-hidden="true" tabindex="-1"></a>Summary of sample sizes<span class="sc">:</span> <span class="dv">502</span>, <span class="dv">502</span>, <span class="dv">502</span>, <span class="dv">503</span>, <span class="dv">503</span>, <span class="dv">502</span>, ... </span>
<span id="cb354-11"><a href="bagging.-random-forest.html#cb354-11" aria-hidden="true" tabindex="-1"></a>Resampling results<span class="sc">:</span></span>
<span id="cb354-12"><a href="bagging.-random-forest.html#cb354-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb354-13"><a href="bagging.-random-forest.html#cb354-13" aria-hidden="true" tabindex="-1"></a>  Accuracy   Kappa    </span>
<span id="cb354-14"><a href="bagging.-random-forest.html#cb354-14" aria-hidden="true" tabindex="-1"></a>  <span class="fl">0.8692532</span>  <span class="fl">0.7385449</span></span></code></pre></div>
<div id="interpretación-de-variables-en-el-bagging" class="section level3 hasAnchor" number="29.4.1">
<h3><span class="header-section-number">29.4.1</span> Interpretación de variables en el bagging<a href="bagging.-random-forest.html#interpretación-de-variables-en-el-bagging" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Una de las principales desventajas del bagging es que los modelos que son intepretables, tras el uso del bagging ya no lo son. A pesar de esto, todavía se puede hacer inferencia de como cada una de las variables influye en el modelo generado. La forma de medir la importancia de las variables incluidas en un árbol es tabular la reducción de la función de perdida atribuida en cada particióna cada variable. Una variable puede utilizarse varias veces para dividir el árbol y por tanto, se suma la reducción total en la función de perdida en todas las divisiones de esa variable, utilizandose como su importancia total. Este proceso es similar para el bagging. En este caso, para cada árbol se cácula la reducción de la función de pérdida en todas lasdivisiones. Tras esto, se agrega esta medida en todos los árboles para cada función. El paquete <code>ipred</code> en el que se encuentra la función <code>bagging</code> no captura la información requerida para calcular la importancia de las variables. Sin embargo, el paquete <code>caret</code> si lo hace y se puede construir un gráfico de importancia usando la función <code>vip</code>.</p>
<div class="sourceCode" id="cb355"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb355-1"><a href="bagging.-random-forest.html#cb355-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">library</span>(vip)</span>
<span id="cb355-2"><a href="bagging.-random-forest.html#cb355-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">vip</span>(model_bag,</span>
<span id="cb355-3"><a href="bagging.-random-forest.html#cb355-3" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   <span class="at">num_features =</span> <span class="dv">15</span>,</span>
<span id="cb355-4"><a href="bagging.-random-forest.html#cb355-4" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   <span class="at">aesthetics =</span> <span class="fu">list</span>(<span class="at">color =</span> <span class="st">&quot;skyblue&quot;</span>, <span class="at">fill =</span> <span class="st">&quot;skyblue&quot;</span>)</span>
<span id="cb355-5"><a href="bagging.-random-forest.html#cb355-5" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span> )</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:BAGGINGVIP"></span>
<img src="Ciencia_de_datos_con_r_files/figure-html/BAGGINGVIP-1.svg" alt="Importancia de las variables incluidas en el modelo bagging." width="60%" />
<p class="caption">
Figura 29.2: Importancia de las variables incluidas en el modelo bagging.
</p>
</div>
<p>La figura <span class="math inline">\(\ref{BAGGINGVIP}\)</span> muestra que las variables más importantes en el modelo bagging entrenado para predecir si un cliente comprará o no el <em>tensiómetro digital</em> son si comprará la <em>depiladora eléctrica</em> y cuánto importe gastará en ese producto, seguido de si comprará el <em>estimulador muscular</em> y el <em>smartchwatch fitness</em>.</p>
</div>
</div>
<div id="random-forest" class="section level2 hasAnchor" number="29.5">
<h2><span class="header-section-number">29.5</span> Random Forest<a href="bagging.-random-forest.html#random-forest" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El bagging es el paradigma tras el algoritmo de random forest. Este algoritmo fue desarrollado por primera vez por Tin Kam Ho en 1995 . Sin embargo, fueron Cutler y Breiman quienes desarrollaron una versión extendida del modelo y registraron <strong>random forest</strong> como marca comercial. El algoritmo básico de bagging funciona del siguiente modo: a partir del conjunto de entrenamiento, se generan <span class="math inline">\(K\)</span> muestras aleatorias <span class="math inline">\(\mathbb{S}_{k}\)</span> y se entrena un modelo de árbol de decisión <span class="math inline">\(f_k\)</span> utilizando cada muestra <span class="math inline">\(\mathbb{S}_{k}\)</span> como el conjunto de entrenamiento. Tras el entrenamiento, se dispone de <span class="math inline">\(K\)</span> árboles de decisión. La predicción de una nueva observación <span class="math inline">\(x\)</span> se obtiene como la media de las <span class="math inline">\(K\)</span> predicciones:</p>
<p><span class="math display">\[\begin{equation}
y\leftarrow\hat{f}(x)=\frac{1}{K}\sum^{K}_{k=1}f_{k}(x)
\end{equation}\]</span></p>
<p>en el caso de regresión, o por la mayoría de votación en el caso de clasificación.</p>
<p>Tanto el bagging como el random forest desarrollan multiples árboles y utilizan el muestreo bootstrap para la aleatorización de los datos. Sin embargo, el random forest establece una limitación artificial a la selección de variables al no considerar todas en cada partición.</p>
<div class="figure">
<img src="img/randomforest.png" alt="" />
<p class="caption">Ejemplo de Random Forest</p>
</div>
<p>El bagging considera las mismas variables para construir cada árbol con el objetivo de minimizar su entropía, y por tanto todos los árboles suelen tener un aspecto similar. Esto lleva a que las predicciones dadas por los árboles esten altamente correlacionadas. El modelo random forest evita este problema al establecer la obligación en cada división de utilizar un subconjunto de las variables, lo que proporciona a algunas variables mayor probabilidad de ser seleccionadas, y al generar árboles únicos y no correlacionados se consigue una estructura de decisión final más fiable.</p>
<p>En general, es mejor que el random forest esté formado por una gran cantidad de árboles (por lo menos 100) para suavizar el impacto de valores atípicos. Sin embargo, la tasa de efectividad disminuye a medida que se incorporan más árboles. Llegado a cierto punto, los nuevos árboles no aportan una mejora significativa al modelo pero si incrementan los tiempos de procesamiento.</p>
<p>El modelo random forest es rápido de entrenar y es una buena técnica para obtener un modelo de referencia. Finalmente, aunque estos modelos funcionan bien en la interpretación de patrones complejos y son versatiles, otras técnicas, como por ejemplo el gradient boosting, proporcionan una mayor precisión en las predicciones.</p>
<p>Estos modelos se han vuelto populares porque tienden a proporcionar un muy buen rendimiento con los modelos predeterminados. A pesar de tener muchos hiperparametros que pueden ser ajustados, los valores por defecto de estos tienden a ofrecer buenos resultados en la predicción. Los hiperparametros más importantes que hay que ajustar al entrenar un modelo random forest son: el número de árboles (<span class="math inline">\(K\)</span>), el numero de variables incluidos en el subconjunto aleatorio en cada división (<span class="math inline">\(mtry\)</span>), la complejidad de cada árbol, el esquema de muestreo y la regla de división a utilizar durante la construcción del árbol.</p>
<div id="número-de-árboles-k" class="section level3 hasAnchor" number="29.5.1">
<h3><span class="header-section-number">29.5.1</span> Número de árboles (<span class="math inline">\(K\)</span>)<a href="bagging.-random-forest.html#número-de-árboles-k" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El primer parametro que la lógica nos lleva a ajustar es el número de árboles que componen el modelo de random forest. Aunque no se considera un hiperparametro como tal, es necerio ajustar el número de árboles a utilizar, pues debe ser lo suficientemente grande como para que la tasa de error se estabilice. La regla general es que el valor mínimo de árboles sea igual a 10 veces el número de variables incluidas en el modelo. Sin emabrgo, cuando se tienen en cuenta otros hiperparámetros para optimizar, es posible que el número de árboles se vea afectado. El tiempo de procesamiento aumenta linealmente con la cantidad de árboles incluidos, pero cuantos más se incluyan, se obtendran estimaciones de error más estables.</p>
</div>
<div id="número-de-variables-a-considerar-mtry" class="section level3 hasAnchor" number="29.5.2">
<h3><span class="header-section-number">29.5.2</span> Número de variables a considerar (<span class="math inline">\(mtry\)</span>)<a href="bagging.-random-forest.html#número-de-variables-a-considerar-mtry" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><span class="math inline">\(mtry\)</span> se refiere al hiperparametro encargado de controlar la aleatorización de variables utilizadas para las particiones de los árboles. Este hiperparametro ayuda a equilibrar la baja correlación del árbol con una razonable fuerza predictiva. Existe un valor predeterminado para este hiperparametro el cual se puede utilizar en caso de no querer o no poder ajustarlo. En el caso de la regresión, se determina que <span class="math inline">\(mtry=\frac{p}{3}\)</span> siendo <span class="math inline">\(p\)</span> el número de variables incluidas en el modelo. Y en los problemas de clasificación, el valor predeterminado es <span class="math inline">\(mtry=\sqrt p\)</span>. Cuando hay pocas variables relevantes, es decir, los datos son muy ruidosos, tiende a funcionar mejor que el valor de <span class="math inline">\(mtry\)</span> sea alto pues hace que sea más probable seleccionar esas variables. En cambio, cuando muchas variables son importantes, funciona mejor un valor bajo de <span class="math inline">\(mtry\)</span>.</p>
</div>
<div id="complejidad-de-los-árboles" class="section level3 hasAnchor" number="29.5.3">
<h3><span class="header-section-number">29.5.3</span> Complejidad de los árboles<a href="bagging.-random-forest.html#complejidad-de-los-árboles" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La base de un random forest es que se construye con árboles de decisión, de los cuales se puede controlar su profundidad y complejidad como se vió en el capítulo <span class="math inline">\(\ref{cap_arboles}\)</span>. Esto se puede hacer ajustando los hiperparametros de profundidad máxima permitida, tamaño del nodo o la cantidad máxima de nodos terminales, por ejemplo.</p>
<p>El tamaño del nodo es probablemente el hiperparámetro más común para controlar la complejidad del árbol y la mayoría de las implementaciones usan los valores predeterminados de uno para la clasificación y cinco para la regresión, ya que estos valores tienden a producir buenos resultados. Si se quiere controlar el tiempo de procesamiento, se puede hacer reducciones significativas del tiempo aumentando el tamaño del nodo y esto solo impactará marginalmente en la estimación del error.</p>
</div>
<div id="esquema-de-muestreo" class="section level3 hasAnchor" number="29.5.4">
<h3><span class="header-section-number">29.5.4</span> Esquema de muestreo<a href="bagging.-random-forest.html#esquema-de-muestreo" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Por defecto, el random forest tiene como esquema de muestreo el bootstrapping, en el cual todas las observaciones se muestrean con reemplazo. Esto es que todas las copias de bootstrap tienen el mismo tamaño que el conjunto de datos de entrenamiento. Sin embargo, el esquema de muestreo se puede ajustar tanto en el tamaño de la muestra como en si se muestrea con o sin reposición. El parámetro de tamaño de muestra determina cuántas observaciones se extraen para el entrenamiento de cada árbol. Cuanto menor sea el tamaño muestral, menor será la correlación entre los árboles, lo cual puede llevar a mejores resultados de precisión en la predicción. La forma de determinar el tamaño muestral optimo puede hayarse evaluando tres o cuatro valores que oscilen entre el 25% y el 100% y en el caso de que haya variables no balanceadas categóricas se puede intentar muestrear sin reposición.</p>
</div>
<div id="regla-de-división" class="section level3 hasAnchor" number="29.5.5">
<h3><span class="header-section-number">29.5.5</span> Regla de división<a href="bagging.-random-forest.html#regla-de-división" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Por defecto, la regla de división que utilizan los árboles de decisión que conforman un random forest es la que se presentó en el capítulo <span class="math inline">\(\ref{cap_arboles}\)</span>. Esto es, en el caso de regresión seleccionar la división que minimiza la suma residual de cuadrados (SRC); y en el caso de clasificación la división que minimiza la impureza de Gini o la entropía.</p>
</div>
</div>
<div id="procedimiento-con-r-la-función-randomforest" class="section level2 hasAnchor" number="29.6">
<h2><span class="header-section-number">29.6</span> Procedimiento con R: la función <code>randomForest</code><a href="bagging.-random-forest.html#procedimiento-con-r-la-función-randomforest" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En el paquete <code>randomForest</code> de <strong>R</strong> se encuentra la función <code>randomForest</code> que se utiliza para entrenar un modelo random forest:</p>
<div class="sourceCode" id="cb356"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb356-1"><a href="bagging.-random-forest.html#cb356-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">randomForest</span>(formula, <span class="at">data =</span> ..., ...)</span>
<span id="cb356-2"><a href="bagging.-random-forest.html#cb356-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">randomForest</span>(x, y, xtest, ytest, <span class="at">ntree =</span> <span class="dv">500</span>, mtry, ...)</span></code></pre></div>
</div>
<div id="aplicación-del-modelo-random-forest-en-r" class="section level2 hasAnchor" number="29.7">
<h2><span class="header-section-number">29.7</span> Aplicación del modelo Random Forest en R<a href="bagging.-random-forest.html#aplicación-del-modelo-random-forest-en-r" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En esta sección se aplica el modelo random forest al ejemplo de datos de retail incluido en el paquete <code>CDR</code>. Se carga el paquete y con ello, los datos <code>dp_entr_NUM</code>. Estos datos tienen las variables categóricas de <code>dp_entr</code> ya convertidas en variables one-hot-enconding. Se busca predecir si un cliente va a comprar o no el nuevo producto de acuerdo a que productos compra, el importe que gasta en ellos y otras características como, por ejemplo, su nivel educativo.</p>
<div class="sourceCode" id="cb357"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb357-1"><a href="bagging.-random-forest.html#cb357-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">library</span>(CDR)</span>
<span id="cb357-2"><a href="bagging.-random-forest.html#cb357-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">data</span>(dp_entr_NUM)</span></code></pre></div>
<div id="aplicación-del-random-forest" class="section level3 hasAnchor" number="29.7.1">
<h3><span class="header-section-number">29.7.1</span> Aplicación del Random Forest<a href="bagging.-random-forest.html#aplicación-del-random-forest" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Este algoritmo al estar basado en árboles de clasificación tiene los mismos requisitos para el entrenamiento que tenían dicho árboles, así se contruye el modelo usando el conjunto de entrenamiento.</p>
<div class="sourceCode" id="cb358"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb358-1"><a href="bagging.-random-forest.html#cb358-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="co"># se fija una semilla común a todos los modelos</span></span>
<span id="cb358-2"><a href="bagging.-random-forest.html#cb358-2" aria-hidden="true" tabindex="-1"></a><span class="er">&gt;</span> <span class="fu">set.seed</span>(<span class="dv">101</span>)</span>
<span id="cb358-3"><a href="bagging.-random-forest.html#cb358-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> </span>
<span id="cb358-4"><a href="bagging.-random-forest.html#cb358-4" aria-hidden="true" tabindex="-1"></a><span class="er">&gt;</span> <span class="co"># se entrena el modelo</span></span>
<span id="cb358-5"><a href="bagging.-random-forest.html#cb358-5" aria-hidden="true" tabindex="-1"></a><span class="er">&gt;</span> model <span class="ot">&lt;-</span> <span class="fu">train</span>(CLS_PRO_pro13 <span class="sc">~</span> .,</span>
<span id="cb358-6"><a href="bagging.-random-forest.html#cb358-6" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   <span class="at">data =</span> dp_entr_NUM,</span>
<span id="cb358-7"><a href="bagging.-random-forest.html#cb358-7" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   <span class="at">method =</span> <span class="st">&quot;rf&quot;</span>, <span class="at">metric =</span> <span class="st">&quot;Accuracy&quot;</span>, <span class="at">ntree =</span> <span class="dv">500</span>,</span>
<span id="cb358-8"><a href="bagging.-random-forest.html#cb358-8" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   <span class="at">trControl =</span> <span class="fu">trainControl</span>(</span>
<span id="cb358-9"><a href="bagging.-random-forest.html#cb358-9" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>     <span class="at">method =</span> <span class="st">&quot;cv&quot;</span>,</span>
<span id="cb358-10"><a href="bagging.-random-forest.html#cb358-10" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>     <span class="at">number =</span> <span class="dv">10</span>,</span>
<span id="cb358-11"><a href="bagging.-random-forest.html#cb358-11" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>     <span class="at">classProbs =</span> <span class="cn">TRUE</span></span>
<span id="cb358-12"><a href="bagging.-random-forest.html#cb358-12" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   )</span>
<span id="cb358-13"><a href="bagging.-random-forest.html#cb358-13" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> )</span></code></pre></div>
<div class="sourceCode" id="cb359"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb359-1"><a href="bagging.-random-forest.html#cb359-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> model</span>
<span id="cb359-2"><a href="bagging.-random-forest.html#cb359-2" aria-hidden="true" tabindex="-1"></a>Random Forest </span>
<span id="cb359-3"><a href="bagging.-random-forest.html#cb359-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb359-4"><a href="bagging.-random-forest.html#cb359-4" aria-hidden="true" tabindex="-1"></a><span class="dv">558</span> samples</span>
<span id="cb359-5"><a href="bagging.-random-forest.html#cb359-5" aria-hidden="true" tabindex="-1"></a> <span class="dv">19</span> predictor</span>
<span id="cb359-6"><a href="bagging.-random-forest.html#cb359-6" aria-hidden="true" tabindex="-1"></a>  <span class="dv">2</span> classes<span class="sc">:</span> <span class="st">&#39;S&#39;</span>, <span class="st">&#39;N&#39;</span> </span>
<span id="cb359-7"><a href="bagging.-random-forest.html#cb359-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb359-8"><a href="bagging.-random-forest.html#cb359-8" aria-hidden="true" tabindex="-1"></a>No pre<span class="sc">-</span>processing</span>
<span id="cb359-9"><a href="bagging.-random-forest.html#cb359-9" aria-hidden="true" tabindex="-1"></a>Resampling<span class="sc">:</span> Cross<span class="sc">-</span><span class="fu">Validated</span> (<span class="dv">10</span> fold) </span>
<span id="cb359-10"><a href="bagging.-random-forest.html#cb359-10" aria-hidden="true" tabindex="-1"></a>Summary of sample sizes<span class="sc">:</span> <span class="dv">502</span>, <span class="dv">502</span>, <span class="dv">502</span>, <span class="dv">503</span>, <span class="dv">503</span>, <span class="dv">502</span>, ... </span>
<span id="cb359-11"><a href="bagging.-random-forest.html#cb359-11" aria-hidden="true" tabindex="-1"></a>Resampling results across tuning parameters<span class="sc">:</span></span>
<span id="cb359-12"><a href="bagging.-random-forest.html#cb359-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb359-13"><a href="bagging.-random-forest.html#cb359-13" aria-hidden="true" tabindex="-1"></a>  mtry  Accuracy   Kappa    </span>
<span id="cb359-14"><a href="bagging.-random-forest.html#cb359-14" aria-hidden="true" tabindex="-1"></a>   <span class="dv">2</span>    <span class="fl">0.8602922</span>  <span class="fl">0.7206238</span></span>
<span id="cb359-15"><a href="bagging.-random-forest.html#cb359-15" aria-hidden="true" tabindex="-1"></a>  <span class="dv">10</span>    <span class="fl">0.8620455</span>  <span class="fl">0.7241029</span></span>
<span id="cb359-16"><a href="bagging.-random-forest.html#cb359-16" aria-hidden="true" tabindex="-1"></a>  <span class="dv">19</span>    <span class="fl">0.8620130</span>  <span class="fl">0.7240248</span></span>
<span id="cb359-17"><a href="bagging.-random-forest.html#cb359-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb359-18"><a href="bagging.-random-forest.html#cb359-18" aria-hidden="true" tabindex="-1"></a>Accuracy was used to select the optimal model using the largest value.</span>
<span id="cb359-19"><a href="bagging.-random-forest.html#cb359-19" aria-hidden="true" tabindex="-1"></a>The final value used <span class="cf">for</span> the model was mtry <span class="ot">=</span> <span class="fl">10.</span></span></code></pre></div>
<p>Los resultados de la validación cruzada se pueden ver en el siguiente boxplot. Se observa como la precisión oscila entre el 80% y el 95%. Además, se puede ver en el resultado del modelo que el hiperparametro <span class="math inline">\(mtry\)</span> se ha ajustado a 10 variables.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:RFRESULTS"></span>
<img src="Ciencia_de_datos_con_r_files/figure-html/RFRESULTS-1.svg" alt="Resultados del modelo random forest durante el proceso de validación cruzada." width="60%" />
<p class="caption">
Figura 29.3: Resultados del modelo random forest durante el proceso de validación cruzada.
</p>
</div>
<p>Finalmente, aunque el random forest generado esta compuesto por 500 árboles, se puede acceder a cualquiera de ellos para estudiarlos en profundidad. Para ello, es necesario instalar el paquete <code>reprtree</code> el cual se encuentra en un repositorio de github.</p>
<div class="sourceCode" id="cb360"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb360-1"><a href="bagging.-random-forest.html#cb360-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">library</span>(devtools)</span>
<span id="cb360-2"><a href="bagging.-random-forest.html#cb360-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="cf">if</span> (<span class="sc">!</span>(<span class="st">&quot;reprtree&quot;</span> <span class="sc">%in%</span> <span class="fu">installed.packages</span>())) {</span>
<span id="cb360-3"><a href="bagging.-random-forest.html#cb360-3" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   devtools<span class="sc">::</span><span class="fu">install_github</span>(<span class="st">&quot;araastat/reprtree&quot;</span>)</span>
<span id="cb360-4"><a href="bagging.-random-forest.html#cb360-4" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span> }</span></code></pre></div>
<p>Se pueden observar las decisiones que se toman en el árbol de forma tabulada, indicando que variable se utiliza para la partición, cuál es el valor que decide la división, indicando si es un nodo terminal o no y la predicción del nodo, el cual es <code>NA</code> si no es un nodo terminal.</p>
<div class="sourceCode" id="cb361"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb361-1"><a href="bagging.-random-forest.html#cb361-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">set.seed</span>(<span class="dv">101</span>)</span>
<span id="cb361-2"><a href="bagging.-random-forest.html#cb361-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> rf <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(CLS_PRO_pro13 <span class="sc">~</span> .,</span>
<span id="cb361-3"><a href="bagging.-random-forest.html#cb361-3" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   <span class="at">data =</span> dp_entr_NUM, <span class="at">ntree =</span> <span class="dv">500</span>,</span>
<span id="cb361-4"><a href="bagging.-random-forest.html#cb361-4" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   <span class="at">mtry =</span> <span class="fu">unlist</span>(model<span class="sc">$</span>bestTune)</span>
<span id="cb361-5"><a href="bagging.-random-forest.html#cb361-5" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span> )</span>
<span id="cb361-6"><a href="bagging.-random-forest.html#cb361-6" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> </span>
<span id="cb361-7"><a href="bagging.-random-forest.html#cb361-7" aria-hidden="true" tabindex="-1"></a><span class="er">&gt;</span> <span class="co"># Observamos el árbol número 205</span></span>
<span id="cb361-8"><a href="bagging.-random-forest.html#cb361-8" aria-hidden="true" tabindex="-1"></a><span class="er">&gt;</span> tree205 <span class="ot">&lt;-</span> <span class="fu">getTree</span>(rf, <span class="dv">205</span>, <span class="at">labelVar =</span> <span class="cn">TRUE</span>)</span>
<span id="cb361-9"><a href="bagging.-random-forest.html#cb361-9" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> </span>
<span id="cb361-10"><a href="bagging.-random-forest.html#cb361-10" aria-hidden="true" tabindex="-1"></a><span class="er">&gt;</span> <span class="fu">head</span>(tree205[, <span class="sc">-</span><span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>)])</span>
<span id="cb361-11"><a href="bagging.-random-forest.html#cb361-11" aria-hidden="true" tabindex="-1"></a>      split var split point status prediction</span>
<span id="cb361-12"><a href="bagging.-random-forest.html#cb361-12" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> importe_pro15         <span class="dv">100</span>      <span class="dv">1</span>       <span class="sc">&lt;</span><span class="cn">NA</span><span class="sc">&gt;</span></span>
<span id="cb361-13"><a href="bagging.-random-forest.html#cb361-13" aria-hidden="true" tabindex="-1"></a><span class="dv">2</span> importe_pro12          <span class="dv">60</span>      <span class="dv">1</span>       <span class="sc">&lt;</span><span class="cn">NA</span><span class="sc">&gt;</span></span>
<span id="cb361-14"><a href="bagging.-random-forest.html#cb361-14" aria-hidden="true" tabindex="-1"></a><span class="dv">3</span> importe_pro16          <span class="dv">90</span>      <span class="dv">1</span>       <span class="sc">&lt;</span><span class="cn">NA</span><span class="sc">&gt;</span></span>
<span id="cb361-15"><a href="bagging.-random-forest.html#cb361-15" aria-hidden="true" tabindex="-1"></a><span class="dv">4</span>  ingresos_ano      <span class="dv">156500</span>      <span class="dv">1</span>       <span class="sc">&lt;</span><span class="cn">NA</span><span class="sc">&gt;</span></span>
<span id="cb361-16"><a href="bagging.-random-forest.html#cb361-16" aria-hidden="true" tabindex="-1"></a><span class="dv">5</span> importe_pro17         <span class="dv">150</span>      <span class="dv">1</span>       <span class="sc">&lt;</span><span class="cn">NA</span><span class="sc">&gt;</span></span>
<span id="cb361-17"><a href="bagging.-random-forest.html#cb361-17" aria-hidden="true" tabindex="-1"></a><span class="dv">6</span>      anos_exp          <span class="dv">33</span>      <span class="dv">1</span>       <span class="sc">&lt;</span><span class="cn">NA</span><span class="sc">&gt;</span></span></code></pre></div>
<p>Este árbol se puede mostrar de la siguiente manera. Sin embargo, el método por el que se representa gráficamente no es muy claro y puede llevar a confusión o a dificultar la interpretación del árbol. Si se desea estudiar hasta cierto nivel del árbol, se puede incluir el parametro <code>depth</code> como en el ejemplo abajo mostrado.</p>
<div class="sourceCode" id="cb362"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb362-1"><a href="bagging.-random-forest.html#cb362-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">library</span>(reprtree)</span>
<span id="cb362-2"><a href="bagging.-random-forest.html#cb362-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">plot.getTree</span>(rf, <span class="at">k =</span> <span class="dv">205</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:tree-plot"></span>
<img src="Ciencia_de_datos_con_r_files/figure-html/tree-plot-1.svg" alt="Árbol número 205 del random forest entrenado." width="60%" />
<p class="caption">
Figura 29.4: Árbol número 205 del random forest entrenado.
</p>
</div>
<div class="sourceCode" id="cb363"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb363-1"><a href="bagging.-random-forest.html#cb363-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">plot.getTree</span>(rf, <span class="at">k =</span> <span class="dv">205</span>, <span class="at">depth =</span> <span class="dv">5</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:tree-plot2"></span>
<img src="Ciencia_de_datos_con_r_files/figure-html/tree-plot2-1.svg" alt="Árbol número 205 del random forest entrenado hasta la capa 5." width="60%" />
<p class="caption">
Figura 29.5: Árbol número 205 del random forest entrenado hasta la capa 5.
</p>
</div>
<div id="aplicación-del-modelo-random-forest-con-ajuste-automático" class="section level4 hasAnchor" number="29.7.1.1">
<h4><span class="header-section-number">29.7.1.1</span> Aplicación del modelo Random Forest con ajuste automático<a href="bagging.-random-forest.html#aplicación-del-modelo-random-forest-con-ajuste-automático" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>En este segundo ejemplo, se pretenden mejorar los resultados del modelo anterior. Para ello, se va a proceder a ajustar de forma automática los parámetros más transcendentes de dicho algoritmo. De los mencionados anteriormente, solo vamos a intentar ajustar el <span class="math inline">\(mtry\)</span>, que es el que incluye el método <code>rf</code> como hiperparametro.</p>
<div class="sourceCode" id="cb364"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb364-1"><a href="bagging.-random-forest.html#cb364-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">modelLookup</span>(<span class="st">&quot;rf&quot;</span>)[, <span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>]</span>
<span id="cb364-2"><a href="bagging.-random-forest.html#cb364-2" aria-hidden="true" tabindex="-1"></a>  model parameter                         label</span>
<span id="cb364-3"><a href="bagging.-random-forest.html#cb364-3" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span>    rf      mtry <span class="co">#Randomly Selected Predictors</span></span></code></pre></div>
<p>Para ajustar el número de árboles, y el resto de hiperparametros se podría hacer iterando el modelo y cambiando sus valores. Los valores que se quieren probar para el parametro <span class="math inline">\(mtry\)</span> se incluyen en una red de opciones que se determina a continuación.</p>
<div class="sourceCode" id="cb365"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb365-1"><a href="bagging.-random-forest.html#cb365-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="co"># Se especifica un rango de valores típicos para los hiperparámetros</span></span>
<span id="cb365-2"><a href="bagging.-random-forest.html#cb365-2" aria-hidden="true" tabindex="-1"></a><span class="er">&gt;</span> tuneGrid <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="at">mtry =</span> <span class="dv">2</span><span class="sc">:</span><span class="dv">19</span>)</span></code></pre></div>
<p>A continuación se entrena el modelo para que lo ajuste a los valores de los hiperparametros que maximicen el rendimiento predictivo del modelo.</p>
<div class="sourceCode" id="cb366"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb366-1"><a href="bagging.-random-forest.html#cb366-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="co"># se fija una semilla común a todos los modelos</span></span>
<span id="cb366-2"><a href="bagging.-random-forest.html#cb366-2" aria-hidden="true" tabindex="-1"></a><span class="er">&gt;</span> <span class="fu">set.seed</span>(<span class="dv">101</span>)</span>
<span id="cb366-3"><a href="bagging.-random-forest.html#cb366-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> </span>
<span id="cb366-4"><a href="bagging.-random-forest.html#cb366-4" aria-hidden="true" tabindex="-1"></a><span class="er">&gt;</span> <span class="co"># se entrena el modelo</span></span>
<span id="cb366-5"><a href="bagging.-random-forest.html#cb366-5" aria-hidden="true" tabindex="-1"></a><span class="er">&gt;</span> model <span class="ot">&lt;-</span> <span class="fu">train</span>(CLS_PRO_pro13 <span class="sc">~</span> .,</span>
<span id="cb366-6"><a href="bagging.-random-forest.html#cb366-6" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   <span class="at">data =</span> dp_entr_NUM,</span>
<span id="cb366-7"><a href="bagging.-random-forest.html#cb366-7" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   <span class="at">method =</span> <span class="st">&quot;rf&quot;</span>, <span class="at">metric =</span> <span class="st">&quot;Accuracy&quot;</span>,</span>
<span id="cb366-8"><a href="bagging.-random-forest.html#cb366-8" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   <span class="at">tuneGrid =</span> tuneGrid,</span>
<span id="cb366-9"><a href="bagging.-random-forest.html#cb366-9" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">classProbs =</span> <span class="cn">TRUE</span>)</span>
<span id="cb366-10"><a href="bagging.-random-forest.html#cb366-10" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> )</span></code></pre></div>
<div class="sourceCode" id="cb367"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb367-1"><a href="bagging.-random-forest.html#cb367-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> model</span>
<span id="cb367-2"><a href="bagging.-random-forest.html#cb367-2" aria-hidden="true" tabindex="-1"></a>Random Forest </span>
<span id="cb367-3"><a href="bagging.-random-forest.html#cb367-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb367-4"><a href="bagging.-random-forest.html#cb367-4" aria-hidden="true" tabindex="-1"></a><span class="dv">558</span> samples</span>
<span id="cb367-5"><a href="bagging.-random-forest.html#cb367-5" aria-hidden="true" tabindex="-1"></a> <span class="dv">19</span> predictor</span>
<span id="cb367-6"><a href="bagging.-random-forest.html#cb367-6" aria-hidden="true" tabindex="-1"></a>  <span class="dv">2</span> classes<span class="sc">:</span> <span class="st">&#39;S&#39;</span>, <span class="st">&#39;N&#39;</span> </span>
<span id="cb367-7"><a href="bagging.-random-forest.html#cb367-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb367-8"><a href="bagging.-random-forest.html#cb367-8" aria-hidden="true" tabindex="-1"></a>No pre<span class="sc">-</span>processing</span>
<span id="cb367-9"><a href="bagging.-random-forest.html#cb367-9" aria-hidden="true" tabindex="-1"></a>Resampling<span class="sc">:</span> <span class="fu">Bootstrapped</span> (<span class="dv">25</span> reps) </span>
<span id="cb367-10"><a href="bagging.-random-forest.html#cb367-10" aria-hidden="true" tabindex="-1"></a>Summary of sample sizes<span class="sc">:</span> <span class="dv">558</span>, <span class="dv">558</span>, <span class="dv">558</span>, <span class="dv">558</span>, <span class="dv">558</span>, <span class="dv">558</span>, ... </span>
<span id="cb367-11"><a href="bagging.-random-forest.html#cb367-11" aria-hidden="true" tabindex="-1"></a>Resampling results across tuning parameters<span class="sc">:</span></span>
<span id="cb367-12"><a href="bagging.-random-forest.html#cb367-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb367-13"><a href="bagging.-random-forest.html#cb367-13" aria-hidden="true" tabindex="-1"></a>  mtry  Accuracy   Kappa    </span>
<span id="cb367-14"><a href="bagging.-random-forest.html#cb367-14" aria-hidden="true" tabindex="-1"></a>   <span class="dv">2</span>    <span class="fl">0.8641273</span>  <span class="fl">0.7280186</span></span>
<span id="cb367-15"><a href="bagging.-random-forest.html#cb367-15" aria-hidden="true" tabindex="-1"></a>   <span class="dv">3</span>    <span class="fl">0.8645144</span>  <span class="fl">0.7287607</span></span>
<span id="cb367-16"><a href="bagging.-random-forest.html#cb367-16" aria-hidden="true" tabindex="-1"></a>   <span class="dv">4</span>    <span class="fl">0.8618664</span>  <span class="fl">0.7234885</span></span>
<span id="cb367-17"><a href="bagging.-random-forest.html#cb367-17" aria-hidden="true" tabindex="-1"></a>   <span class="dv">5</span>    <span class="fl">0.8630134</span>  <span class="fl">0.7257459</span></span>
<span id="cb367-18"><a href="bagging.-random-forest.html#cb367-18" aria-hidden="true" tabindex="-1"></a>   <span class="dv">6</span>    <span class="fl">0.8600585</span>  <span class="fl">0.7198120</span></span>
<span id="cb367-19"><a href="bagging.-random-forest.html#cb367-19" aria-hidden="true" tabindex="-1"></a>   <span class="dv">7</span>    <span class="fl">0.8593013</span>  <span class="fl">0.7182988</span></span>
<span id="cb367-20"><a href="bagging.-random-forest.html#cb367-20" aria-hidden="true" tabindex="-1"></a>   <span class="dv">8</span>    <span class="fl">0.8629885</span>  <span class="fl">0.7256405</span></span>
<span id="cb367-21"><a href="bagging.-random-forest.html#cb367-21" aria-hidden="true" tabindex="-1"></a>   <span class="dv">9</span>    <span class="fl">0.8589407</span>  <span class="fl">0.7175065</span></span>
<span id="cb367-22"><a href="bagging.-random-forest.html#cb367-22" aria-hidden="true" tabindex="-1"></a>  <span class="dv">10</span>    <span class="fl">0.8567871</span>  <span class="fl">0.7132165</span></span>
<span id="cb367-23"><a href="bagging.-random-forest.html#cb367-23" aria-hidden="true" tabindex="-1"></a>  <span class="dv">11</span>    <span class="fl">0.8588108</span>  <span class="fl">0.7172628</span></span>
<span id="cb367-24"><a href="bagging.-random-forest.html#cb367-24" aria-hidden="true" tabindex="-1"></a>  <span class="dv">12</span>    <span class="fl">0.8595203</span>  <span class="fl">0.7187110</span></span>
<span id="cb367-25"><a href="bagging.-random-forest.html#cb367-25" aria-hidden="true" tabindex="-1"></a>  <span class="dv">13</span>    <span class="fl">0.8579929</span>  <span class="fl">0.7156347</span></span>
<span id="cb367-26"><a href="bagging.-random-forest.html#cb367-26" aria-hidden="true" tabindex="-1"></a>  <span class="dv">14</span>    <span class="fl">0.8581897</span>  <span class="fl">0.7160362</span></span>
<span id="cb367-27"><a href="bagging.-random-forest.html#cb367-27" aria-hidden="true" tabindex="-1"></a>  <span class="dv">15</span>    <span class="fl">0.8585831</span>  <span class="fl">0.7168220</span></span>
<span id="cb367-28"><a href="bagging.-random-forest.html#cb367-28" aria-hidden="true" tabindex="-1"></a>  <span class="dv">16</span>    <span class="fl">0.8581382</span>  <span class="fl">0.7159461</span></span>
<span id="cb367-29"><a href="bagging.-random-forest.html#cb367-29" aria-hidden="true" tabindex="-1"></a>  <span class="dv">17</span>    <span class="fl">0.8578179</span>  <span class="fl">0.7152923</span></span>
<span id="cb367-30"><a href="bagging.-random-forest.html#cb367-30" aria-hidden="true" tabindex="-1"></a>  <span class="dv">18</span>    <span class="fl">0.8579168</span>  <span class="fl">0.7155132</span></span>
<span id="cb367-31"><a href="bagging.-random-forest.html#cb367-31" aria-hidden="true" tabindex="-1"></a>  <span class="dv">19</span>    <span class="fl">0.8569240</span>  <span class="fl">0.7135054</span></span>
<span id="cb367-32"><a href="bagging.-random-forest.html#cb367-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb367-33"><a href="bagging.-random-forest.html#cb367-33" aria-hidden="true" tabindex="-1"></a>Accuracy was used to select the optimal model using the largest value.</span>
<span id="cb367-34"><a href="bagging.-random-forest.html#cb367-34" aria-hidden="true" tabindex="-1"></a>The final value used <span class="cf">for</span> the model was mtry <span class="ot">=</span> <span class="fl">3.</span></span></code></pre></div>
<p>Ahora que la busqueda del valor óptimo <span class="math inline">\(mtry\)</span> ha sido más exhaustiva que en el ejemplo se observa que los resultados con 3 variables seleccionadas en cada partición es suficiente, y que no son necesarias 10 como en el ejemplo anterior pues la precisión decae. Finalmente, se puede observar en el boxplot los resultados obtenidos durante la validación cruzada. Se observa cómo no solo la precisión es mayor que en el ejemplo anterior, sino que además los resultados tienen menos dispersión.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:rfresults2"></span>
<img src="Ciencia_de_datos_con_r_files/figure-html/rfresults2-1.svg" alt="Resultados obtenidos por el random forest con ajuste automático durante el proceso de validación cruzada." width="60%" />
<p class="caption">
Figura 29.6: Resultados obtenidos por el random forest con ajuste automático durante el proceso de validación cruzada.
</p>
</div>
</div>
</div>
<div id="resumen-9" class="section level3 unnumbered hasAnchor infobox_resume">
<h3>Resumen<a href="bagging.-random-forest.html#resumen-9" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En este capítulo se ha introducido al lector en el algoritmo de aprendizaje supervisado conocido como random forest, en concreto:</p>
<ul>
<li>Se ha presentado el concepto de aprendizaje ensamblado, y profundizado en uno de sus paradigmas: el bagging.</li>
<li>Se ha implementado el bagging en <code>R</code> a través de un caso de aplicación para la clasificación binaria de datos.</li>
<li>Se ha expuesto como medir la importancia de las variables incluidas en un modelo bagging para facilitar su interpretación.</li>
<li>Se ha explicado el modelo random forest, fundamentado en los árboles decisión y en el bagging. Así como los hiperparámatros más importantes para ajustar un modelo con el mejor rendimiento.</li>
<li>Se ha aplicado un ejemplo de clasificación binaria utilizando el modelo random forest en <code>R</code>.</li>
</ul>
</div>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="72">
<li id="fn72"><p>Universidad Complutense de Madrid<a href="bagging.-random-forest.html#fnref72" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="naive-bayes.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="boosting.-xgboost..html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Ciencia_de_datos_con_r.pdf", "Ciencia_de_datos_con_r.epub"],
"search": {
"engine": "lunr",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
