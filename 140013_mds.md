# Escalamiento multidimensional 

*José Luis Alfaro Navarro* $^{a}$ y *Manuel Vargas Vargas* $^{a}$

$^{a}$ Universidad de Castilla-La Mancha

## Introducción

El escalado multidimensional \index{escalamiento!multidimensional} (EMD) fue propuesto por primera vez a la Universidad de Princeton por Warren S. Torgerson a principios de la década de 1950 siendo un investigador importante en este campo Joseph Bernard Kruskal. El EMD engloba una variedad de técnicas multivariables cuya finalidad es obtener la estructura (factores o dimensiones) de los individuos (o variables) subyacente a una matriz de datos empíricos, lo que se consigue al representar dicha estructura en una forma geométrica bi o tridimensional.

Por tanto, la idea del EMD es **representar los datos en baja dimensión** (usualmente 2 dimensiones) utilizando la información proporcionada por las distancias \index{distancia} entre los datos. Esta técnica surge ya que cada vez con más frecuencia los datos particulares de los que se dispone y el objetivo del análisis hacen difícil su tratamiento con las medidas clásicas, por lo que se han ido diseñando nuevas medidas de distancia entre datos. Estas medidas se pueden utilizar para diferentes tareas: agrupamiento de casos, clasificación, detección de patrones o dimensiones subyacentes, recuperación de información, etc. Por lo tanto, EMD aborda algunas problemáticas que pueden ser analizadas con otras técnicas como, por ejemplo, análisis de componentes principales o factorial cuando el objetivo es representar muchas variables en pocas dimensiones mediante la identificación de la estructura interna de los datos, dimensiones o factores en base a la matriz de correlaciones como medida de proximidad entre las variables o el análisis cluster cuando el objetivo es analizar la proximidad entre los objetos, personas, productos, etc. estudiados.

El EMD analiza matrices de proximidad (similitud, disimililitud o distancia), \index{matriz!de proximidad} por ello, es una alternativa más flexible que otros métodos multivariantes con los que comparte objetivos, ya que sólo requiere de una matriz con las proximidades entre los datos, que pueden representar valoraciones personales, grado de acuerdo entre juicios, parecido entre objetos, frecuencias de aparición de rasgos, diferencias entre tratamientos, etc.  La idea central es que las distancias \index{distancia} que median entre los puntos se corresponden con las proximidades entre los objetos por medio de una función de ajuste resultante de un proceso iterativo de optimización, pudiendose describir las relaciones entre los objetos sobre la base de las proximidades observadas [@LopezHidalgo2010]

En **R**, existen distintas funciones para desarrollar el EMD, desde las clásicas funciones `cmdscale()` del paquete `base` e `isoMDS()` del paquete `MASS` hasta el enfoque más actual, usado en este documento, recogido en el paquete `smacof` [@Leeuw2009; @Mair2022] que proporciona al usuario una gran flexibilidad para especificar EMD. Utiliza siempre matrices de disimilaridad \index{matriz!de disimilaridad} y, desde la primera versión, se han implementado varios enfoques adicionales de EMD y despliegue, así como varias extensiones y funciones de utilidad.

A modo de ejemplo se va a usar la información relacionada con 7 variables de la sociedad de la información disponibles para 27 países europeos en la base de datos `TIC2021`,  cuatro relacionadas con el uso de las TIC por parte de las empresas y tres de aspectos relacionados con el uso por parte de las personas y la equipación de los hogares. Dicha información, así como la descripción de las variables, puede consultarse en la base de datos `TIC2021` del paquete `CDR`.

## Medición de distancias y similitudes
\index{distancia}

Tanto para el EMD como para muchas otras técnicas multivariantes, el concepto de distancia \index{distancia}, entendida como medida de diferenciación entre objetos, constituye la base fundamental de la obtención y presentación de sus resultados. También son frecuentes los conceptos de “disimilaridad”, muy parecido al de distancia, o de “similaridad”, dual en su sentido al de distancia. Se nombre como se nombre, la característica que hay que tener siempre presente es si la medida indica “alejamiento” entre los objetos (distancia o disimilaridad) \index{matriz!de disimilaridad} \index{matriz!de distancia} o “cercanía” (similaridad o proximidad) \index{matriz!de similaridad} \index{matriz!de proximidad}. 

Básicamente, se considera una medida de distancia \index{distancia} a una función que asigna a cada par de objetos ($o_i$ y $o_j$), que pueden contener mediciones de variables x e y, un número real, $d(o_i, o_j)=\delta_{ij}$, que debe cumplir las siguientes condiciones (para un análisis más detallado véase Sec. \@ref(clusterdist)):

a) No negatividad $\delta_{ij} \geq 0$
b) Simetría, $\delta_{ij} = \delta_{ji}$
c) Identificación del objeto, $\delta_{ii}=0$

Si además es semidefinida positiva y cumple la desigualdad triangular se dice que *$\delta$* es una distancia \index{distancia} métrica.

Aunque no se va a profundizar en ello, existen diferencias matemáticas en los requisitos que debe cumplir una medida para ser considerada una distancia o una distancia métrica, así como las condiciones para ser considerada una similaridad \index{matriz!de similaridad}. Básicamente, se considera una medida de similaridad a una aplicación que asigna a cada par de objetos ($o_i$ y $o_j$) un número real, $s_{ij}$, que cumple las mismas condiciones que la distancia salvo la condición *c* para la que tiene que cumplir que $s_{ij} \leq s_{ii}$.

Esta condición es más díficil de cumplir por lo que se emplean mucho más las medidas de distancia \index{distancia} al ser más sencillo formular la propiedad *c* pues simplifica mucho el poder atribuir un valor de referencia cero para definir la distancia de un individuo a sí mismo. La similitud carece de este valor de referencia, siendo posible que la similitud de un individuo a sí mismo sea diferente de unos a otros. A pesar de esta dificultad, las medidas de similitud surgen de modo natural en muchos problemas relacionados con valoraciones subjetivas de similitud. 

Para un conjunto finito de objetos, la **matriz de similaridad** \index{matriz!de similaridad} es:

\begin{equation}
\textbf{S}= \begin{pmatrix}
s_{11} & s_{12} & \dotsb & s_{1n}\\
s_{21} & s_{22} & \dotsb & s_{2n}\\
\vdots & \vdots & \ddots & \vdots\\
s_{n1} & s_{n2} & \dotsb & s_{nn}\\
\end{pmatrix}
(\#eq:eqmds1)
\end{equation}

El paso de una medida de similaridad ($s_{ji}$) a una \index{distancia} distancia ($\delta_{ij}$) se puede hacer de diversas formas. Las más usuales son:

a) $\delta_{ij} = 1-s_{ij}$

b) $\delta_{ij} = \sqrt{1-s_{ij}}$

c) Si los valores de la diagonal de S no son la unidad, $\delta_{ij} = \sqrt{s_{ii}+s_{jj}-2s_{ij}}$

En general, cuando las características que se miden sobre los objetos son variables cuantitativas p-dimensionales, las distancias más usadas son la euclídea, la city-block, la de Minkowski o la de Mahalanobis (véase Sec. \@ref(clusterdist)).

Cuando las variables son binarias (0 y 1), los coeficientes de similaridad más utilizados son el coeficiente de Jaccard o el de Sokal-Sneath; por último, en el caso más general en el que existan variables cuantitativas, binarias y/o cualitativas, se suele utilizar la distancia de Gower (véase Sec. \@ref(clusterdist)).

Como se aprecia, las características de los datos que se quieren analizar influyen determinantemente en qué tipo de medida de proximidad utilizar. A su vez, la elección de una medida concreta puede modificar la configuración de los datos y, consecuentemente, los resultados de los análisis que se hagan a partir de ellos.

## Modelo de escalamiento multidimensional

\index{escalamiento!multidimensional}

El EMD parte de una matriz de proximidades \index{matriz!de proximidad} entre $n$ objetos:

\begin{equation}
\boldsymbol{\Delta} _{nxn}=
\begin{pmatrix}
\delta_{11} & \delta_{12} & \dotsb & \delta_{1n}\\
\delta_{21} & \delta_{22} & \dotsb & \delta_{2n}\\
\vdots & \vdots & \ddots & \vdots\\
\delta_{n1} & \delta_{n2} & \dotsb & \delta_{nn}\\
\end{pmatrix}
(\#eq:eqmds2)
\end{equation}

y busca una representación de los $n$ objetos en un espacio de menor dimensión, $m$, donde $x_{ij}$ es la coordenada del objeto $i$ en la dimensión $j$:

\begin{equation}
\mathbf{X}_{nxm}=
\begin{pmatrix}
x_{11} & x_{12} & \dotsb & x_{1m}\\
x_{21} & x_{22} & \dotsb & x_{2m}\\
\vdots & \vdots & \ddots & \vdots\\
x_{n1} & x_{n2} & \dotsb & x_{nm}\\
\end{pmatrix}
(\#eq:eqmds3)
\end{equation}

de forma que se puede calcular la distancia euclídea entre cada par de objetos:

\begin{equation}
d_{ij}=\sqrt{\displaystyle\sum_{t=1}^{m}{(x_{it} - x_{jt})^2}}
(\#eq:eqmds4)
\end{equation}

y, construir una matriz de **distancias “reproducidas”** \index{Distancia!reproducida}

\begin{equation}
\mathbf{D}_{nxn}=
\begin{pmatrix}
d_{11} & d_{12} & \dotsb & d_{1n}\\
d_{21} & d_{22} & \dotsb & d_{2n}\\
\vdots & \vdots & \ddots & \vdots\\
d_{n1} & d_{n2} & \dotsb & d_{nn}\\
\end{pmatrix}
(\#eq:eqmds5)
\end{equation}

que aproxime, en la medida de lo posible, a la matriz de proximidades, $\boldsymbol{\Delta}$.

El concepto básico del EMD es que las distancias \index{distancia} entre los objetos en la configuración X, $d_{ij}$ deben corresponder a las proximidades originales, $\delta_{ij}$ mediante una transformación, $d_{ij}=f(\delta_{ij})$, donde *f* es de algún tipo determinado.

En la práctica, no se suele encontrar un ajuste perfecto, por lo que existe un cierto grado de error. Por ello, se define el **Stress de Kruskal** \index{Stress de Kruskal} como una medida de la bondad de ajuste del modelo:

\begin{equation}
Stress= \sqrt{\frac {\sum{(f(\delta_{ij})-d_{ij})^2}}{\sum d_{ij}^2}}
(\#eq:eqmds6)
\end{equation}

En caso de un ajuste perfecto, el Stress sería 0, aumentando conforme más grandes sean los errores (diferencias entre las distancias “reproducidas” y las originales). Así, la solución proporcionada por el EMD será “mejor” cuanto más pequeña sea la medida del Stress. También es frecuente utilizar una variante, llamada **S-Stress**, \index{S-Stress} definida como:

\begin{equation}
S-Stress= \sqrt{\frac {\sum{(f(\delta_{ij})^2-d_{ij}^2)^2}}{\sum (d_{ij}^2)^2}}
(\#eq:eqmds7)
\end{equation}

Otra medida que se suele utilizar como grado de ajuste es el coeficiente de **correlación al cuadrado** (RSQ), que indica la proporción de variabilidad de los datos explicada por el modelo:

\begin{equation}
RSQ=\frac{[\sum{(d_{ij}-d_{..})(f(\delta_{ij})-f(\delta_{..}))}]^2}{[\sum{(d_{ij}-d_{..})^2][\sum{(f(\delta_{ij})-f(\delta_{..}))}^2]}}
(\#eq:eqmds8)
\end{equation}

Este valor oscila entre 0 y 1, y se intrepreta de forma contraria a las medidas de Stress: mientras mayor sea el RSQ, mejor ajuste del modelo.

## Tipos de escalamiento multidimensional

La elección de la función $f$ que relaciona las proximidades originales y las distancias “reproducidas” produce dos tipos básicos de EMD, el EMD métrico (o clásico) \index{escalamiento!métrico} y el EMD no métrico \index{escalamiento!no métrico}. En el primero, se considera que los datos están medidos en escala de intervalo o de razón y existe una relación funcional entre las distancias originales y las reproducidas; mientras que el segundo se suele aplicar cuando los datos están en escala ordinal o no se asume una relación funcional entre las distancias originales y las reproducidas, sino que sólo se conserva su ordenación.

### Escalado multidimensional métrico 

En el modelo de escalamiento métrico \index{escalamiento!métrico} se asume que la relación entre las proximidades y las distancias \index{distancia} es de tipo lineal, $d_{ij}=a+b \delta_{ij}$. De esta forma, se conserva la métrica de distancia original, entre puntos, lo mejor posible, siendo adecuado para el caso de variables cuantitativas. También se conoce como EMD clásico o como análisis de coordenadas principales.

En el ejemplo introductorio, se va a aplicar un EMD métrico con un doble objetivo: por un lado se usa la matriz de correlaciones entre la variables con el objetivo de analizar la similitud entre las mismas y, por otro lado, se determina la distancia entre observaciones con el objetivo de analizar la similitud exitente entre observaciones, en este caso los países europeos.

En el primer caso, los “objetos” son las siete variables de la base de datos `TIC2021` y se ha utilizado como medida de proximidad (similitud) el coeficiente de correlación entre las variables, por lo que se plantea un EMD métrico. \index{escalamiento!métrico}


```r
library('smacof')
library('CDR')
correlacion<- cor(TIC2021)
round(correlacion[1:3,],3)
#>           ebroad esales esocmedia  eweb hbroad hiacc  iuse
#> ebroad     1.000  0.377     0.587 0.704  0.422 0.521 0.632
#> esales     0.377  1.000     0.542 0.585  0.167 0.195 0.479
#> esocmedia  0.587  0.542     1.000 0.698  0.567 0.609 0.756
```

Los pasos a seguir son:

• Calcular la matriz de disimilaridades \index{matriz!de disimilaridad} sobre la que actúa `smacof()`. En este ejemplo, se usa la matriz de correlaciones que se debe convertir en matriz de disimilaridades, mediante la función `sim2diss()`.


```r
datos<-sim2diss(correlacion,method="corr",to.dist=TRUE)
```
La conversión de similidades (correlaciones) en disimilaridades se ha hecho por el método “corr”, que utiliza la expresión general $\delta_{ij} = 1-s_{ij}$. Existen otros métodos en la función `sim2diss()` para cuando la matriz de proximidades \index{matriz!de proximidad} no sea de correlaciones. El argumento `to.dist=TRUE` permite convertir el resultado en un objeto de la clase `dist`.

• Una vez que disponemos de la matriz de disimilaridades, \index{matriz!de disimilaridad} aplicamos el EMD métrico mediante \index{escalamiento!métrico} la función `mds()`, versión equivalente a la función `smacofSym()`.


```r
res<-mds(datos,ndim=2,type="ratio")
res
#> 
#> Call:
#> mds(delta = datos, ndim = 2, type = "ratio")
#> 
#> Model: Symmetric SMACOF 
#> Number of objects: 7 
#> Stress-1 value: 0.161 
#> Number of iterations: 42
```
La Fig. \@ref(fig:graficoobjetos-ch13) que representa los objetos según sus distancias “reproducidas” muestra la configuración final de los siete objetos:


```r
plot(res)
```

<div class="figure" style="text-align: center">
<img src="140013_mds_files/figure-html/graficoobjetos-ch13-1.png" alt="Gráfico de objetos en el plano de las distancias reproducidas." width="60%" />
<p class="caption">(\#fig:graficoobjetos-ch13)Gráfico de objetos en el plano de las distancias reproducidas.</p>
</div>

La información numérica detallada se podria obtener con la información de la salidad dada por: `res$conf` que mostraría las coordenadas de los objetos en las dos dimensiones; `res$confdist` que muestra la matriz de distancias reproducidas; `res$stress` para obtener la medida de stress de Krukal \index{Stress de Kruskal} y `res$spp` con la contribución porcentual de cada objeto al stress.

En este caso los resultados muestran que la medida de stress es razonablemente baja con un valor de 0.16, indicando una buena “reproducción” de las proximidades originales. Además, la “contribución” relativa al stress de cada uno de los objetos (delitos) es bastante homogénea, siendo la variable porcentaje de empresas con banda ancha (EBROAD) la que más contribuyen al stress y el nivel de acceso a internet de los hogares (HIACC), la que menos. Para ver gráficamente el grado de ajuste, se usa el gráfico de Shepard (Fig. \@ref(fig:graficoShepard-ch13)) que compara las proximidades originales y las distancias obtenidas: \index{diagrama de Shepard}


```r
plot(res,plot.type="Shepard")
```

<div class="figure" style="text-align: center">
<img src="140013_mds_files/figure-html/graficoShepard-ch13-1.png" alt="Gráfico de Shepard con método `ratio`." width="60%" />
<p class="caption">(\#fig:graficoShepard-ch13)Gráfico de Shepard con método `ratio`.</p>
</div>

El diagrama de Shepard \index{diagrama de Shepard} incluye las proximidades originales entre pares de objetos (en gris claro) y las obtenidas por el EMD (en negro). También representa el método elegido; en este ejemplo, al usar el argumento `method=“ratio”` estamos imponiendo una relación proporcional entre ambos tipos de similitudes, por lo que aparece una recta (que pasa por el origen). Dadas las diferencias que se ven en el gráfico, quizás la elección del método `ratio` (opción por defecto), no sea la más adecuada. Probando con el método `interval`, que impone una relación lineal entre ambos tipos de similitudes (recta que no tiene que pasar necesariamente por el origen), se obtendría la Fig. \@ref(fig:graficoShepard2-ch13):\index{diagrama de Shepard}


```r
res2<-mds(datos,type="interval")
plot(res2,plot.type="Shepard")
```

<div class="figure" style="text-align: center">
<img src="140013_mds_files/figure-html/graficoShepard2-ch13-1.png" alt="Gráfico de Shepard con método `interval`." width="60%" />
<p class="caption">(\#fig:graficoShepard2-ch13)Gráfico de Shepard con método `interval`.</p>
</div>

La medida de stress se ha reducido a la mitad, 0.087, indicando mejor ajuste, y el gráfico de Shepard \index{diagrama de Shepard} muestra más concordancia entre las proximidades originales de los pares de objetos y las distancias reproducidas. Otra opción sería usar el método `mspline`, pero en este caso las diferencias son menores. Los tres métodos son métricos, \index{escalamiento!métrico} puesto que se fija una forma funcional para relacionar las proximidades originales y las disimilitudes del modelo (un ratio, una función lineal o una función spline).

• Por último, para “interpretar” el sentido de las dimensiones en las que se representan los objetos, se recurre a ver cuáles están en los extremos. En la parte izquierda de la dimensión 1 están las variables relacionadas con el uso en las empresas mientras que en la parte derecha están las relacionadas con los hogares y las personas; se podría decir, entonces, que es una dimensión relacionada con el ámbito de uso de las TIC. En la dimensión 2, con menos distancias, y una interpretación menos clara, aparecen en la parte superior las variables relacionadas con el tipo de conexión y la existencia de web en las empresas y en la parte inferior las relacionadas con las redes sociales, las ventas o la frecuencia de uso de internet por parte de los individuos; se podría decir, **que es una dimensión asociada al uso dado a las TIC**.

Los pasos para desarrollar el mismo análisis agrupando países, observaciones en lugar de variables, serían similares pero usando la matriz de distancias en lugar de la matriz de correlaciones, por lo tanto:


```r
library('factoextra')
d_euclidea <- get_dist(x = TIC2021, method = "euclidea")
res3<-mds(d_euclidea,ndim=2,type="ratio")
res3
#> 
#> Call:
#> mds(delta = d_euclidea, ndim = 2, type = "ratio")
#> 
#> Model: Symmetric SMACOF 
#> Number of objects: 27 
#> Stress-1 value: 0.112 
#> Number of iterations: 77
```


```r
plot(res3)
```

<div class="figure" style="text-align: center">
<img src="140013_mds_files/figure-html/graficodepaises-ch13-1.png" alt="Gráfico de países sobre el plano de las distancias reproducidas." width="60%" />
<p class="caption">(\#fig:graficodepaises-ch13)Gráfico de países sobre el plano de las distancias reproducidas.</p>
</div>
En la Fig. \@ref(fig:graficodepaises-ch13), la interpretación de la dimensión 1 muestra la existencia de una diferencia clara entre los países del norte y los de última adhesión a la Unión Europea mientras que en la dimensión 2, con unas diferencias menores, aparecen en la parte superior los países de Chipre y Luxemburgo y en la parte inferior Lituanía, Croacia, Irlanda y la República Checa. 

### Escalado multidimensional no métrico

En el modelo de escalamiento no métrico \index{escalamiento!no métrico} (también conocido como EMD ordinal) no se asume ninguna fórmula métrica que relacione las proximidades originales con las distancias reproducidas, sino que sólo describe un patrón creciente (o decreciente) entre ellas. No es significativo el valor de distancia, sino su relación con las distancias entre otros pares de objetos, por lo que construye distancias ajustadas que están en el mismo orden de rango que la proximidad original. Por ejemplo, si la distancia de los objetos separados A y B ocupa el tercer lugar en los datos de proximidades originales ordenadas, entonces también debería ocupar el tercer lugar en los datos de distancias reproducidas ordenadas. Así, el EMD no métrico \index{escalamiento!no métrico} busca conservar, no tanto los valores de las proximidades originales, sino la ordenación de los objetos en función de dichas proximidades; es, por tanto, un modelo que se ajusta mejor a datos cualitativos que el métrico, aunque también se utiliza cuando se busca mayor flexibilidad en el ajuste.

Se va a aplicar un MDS no métrico a la matriz de correlaciones de las tasas anuales de siete delitos en 50 estados de EE.UU. (asesinatos, violaciones, robos, asaltos, allanamiento de morada, hurtos y sustracciones de vehículos). Los datos están disponibles en la librería `smacof` bajo el nombre de `crimes`:


```r
data("crimes")
```

En este ejemplo, los *"objetos"* son los siete tipos de delito, y se ha utilizado como medida de proximidad (similitud) el coeficiente de correlación entre las tasas de delito (variables cuantitativas).

- El primer paso consiste en calcular la matriz de disimilaridades \index{matriz!de disimilaridad} sobre la que actúa `smacof`, utilizando la función `sim2diss()`.


```r
options(digits=3)
data<-sim2diss(crimes,method="corr",to.dist=FALSE)
data
#>            Murder  Rape Robbery Assault Burglary Larceny Auto.Theft
#> Murder      0.000 0.693   0.812   0.436    0.849   0.970      0.943
#> Rape        0.693 0.000   0.671   0.548    0.566   0.632      0.748
#> Robbery     0.812 0.671   0.000   0.663    0.616   0.748      0.616
#> Assault     0.436 0.548   0.663   0.000    0.693   0.825      0.819
#> Burglary    0.849 0.566   0.616   0.693    0.000   0.447      0.548
#> Larceny     0.970 0.632   0.748   0.825    0.447   0.000      0.671
#> Auto.Theft  0.943 0.748   0.616   0.819    0.548   0.671      0.000
```

La conversión de similidades (correlaciones) en disimilaridades \index{matriz!de disimilaridad} se ha hecho por el método `corr`, que utiliza la expresión general $\delta_{ij} = \sqrt {1-s_{ij}}$. Existen otros métodos en la función `sim2diss()` para cuando la matriz de proximidades no sea de correlaciones. El argumento `to.dist=TRUE` permite convertir el resultado en un objeto de la clase `dist` si fuese necesario.

Frente a los métodos métricos, que fijan una forma funcional para relacionar las proximidades originales y las disimilitudes del modelo (un ratio, una función lineal o una función spline), una alternativa más flexible es asumir una relación no métrica, donde sólo se conserve la ordenación de las proximidades originales. En este caso, se busca que las distancias reproducidas ordenen a los pares de objetos de forma idéntica a la original.

Para ello, se utiliza el método `ordinal` dentro de la función `mds()`:


```r
res4<-mds(data,ndim=2,type="ordinal")
res4
#> 
#> Call:
#> mds(delta = data, ndim = 2, type = "ordinal")
#> 
#> Model: Symmetric SMACOF 
#> Number of objects: 7 
#> Stress-1 value: 0.002 
#> Number of iterations: 15
```

Como se aprecia, la medida de stress es muy baja (0.002), indicando un muy buen ajuste, que resulta significativo como indica la Fig. \@ref(fig:140013mdsnm041) basada en la función `permtest()`:


```r
ptestnm<-permtest(res4,nrep=50)
```


```r
plot(ptestnm)
```

<div class="figure" style="text-align: center">
<img src="140013_mds_files/figure-html/140013mdsnm041-1.png" alt="Test de permutaciones para evaluación de la significatividad de la medida de stress." width="60%" />
<p class="caption">(\#fig:140013mdsnm041)Test de permutaciones para evaluación de la significatividad de la medida de stress.</p>
</div>

El gráfico de Shepard, \index{diagrama de Shepard} representado en la Fig. \@ref(fig:140013mdsnm05), incluye las proximidades originales entre pares de objetos (en gris claro) y las obtenidas por el MDS (en negro), mostrando una alta concordancia entre las ordenaciones original y reproducida:


```r
plot(res4,plot.type="Shepard")
```

<div class="figure" style="text-align: center">
<img src="140013_mds_files/figure-html/140013mdsnm05-1.png" alt="Gráfico de Shepard: concordancia entre las ordenaciones original y reproducida." width="60%" />
<p class="caption">(\#fig:140013mdsnm05)Gráfico de Shepard: concordancia entre las ordenaciones original y reproducida.</p>
</div>

La contribución porcentual de cada delito a la medida de stress y las coordenadas bidimensionales reproducidas serían:


```r
res4$spp #Contribución porcentual de cada objeto al stress
#>     Murder       Rape    Robbery    Assault   Burglary    Larceny Auto.Theft 
#>      8.064      6.443     39.270      0.104     10.618      9.023     26.478
res4$conf #Coordenadas de los objetos en dos dimensiones
#>                 D1       D2
#> Murder     -0.9673  0.01136
#> Rape       -0.1225 -0.37592
#> Robbery     0.0496  0.53424
#> Assault    -0.5630 -0.00483
#> Burglary    0.3925 -0.11326
#> Larceny     0.6015 -0.47400
#> Auto.Theft  0.6093  0.42240
```

El delito de robo (39.27%) y el de sustracción de vehículos (26.48%) son responsables del 65.75% del stress, seguidos muy de lejos por los otros cinco tipos de delito.

La Fig. \@ref(fig:140013mdsnm07) muestra la representación bidimensional de la configuración final de los siete delitos según sus distancias "reproducidas":


```r
plot(res4)
```

<div class="figure" style="text-align: center">
<img src="140013_mds_files/figure-html/140013mdsnm07-1.png" alt="Representación bidimensional de las disimilitudes entre los siete tipos de delito." width="60%" />
<p class="caption">(\#fig:140013mdsnm07)Representación bidimensional de las disimilitudes entre los siete tipos de delito.</p>
</div>

Por último, para "interpretar" el sentido de las dimensiones en las que se representan los objetos, se recurre a ver cuáles están en los extremos. En la parte izquierda de la dimensión 1 están los delitos de asesinato y asalto, mientras que en la parte derecha están los de hurto, sustracción de vehículos y allanamiento; se podría decir, entonces, que es una dimensión relacionada con el grado de *"personalización"* del delito: los que afectan a personas directamente frente a los que no. La dimensión 2, con menos distancias (véasen las escalas) y de más difícil interpretación, contrapone en la parte superior los delitos que más *"beneficios"* económicos producen (robos, sustracción de vehículos) frente a los que menos (violación o hurto); se podría decir, entonces, que es una dimensión asociada a la repercusión económica del delito.

Por último, destacar que puede ser interesante analizar la estabilidad de las soluciones del EMD (bien mediante jackknife, bootstrap, o elipses de pseudo-confianza). También puede interesar plantear un modelo de EMD que permita valorar las diferencias individuales (abordable con la función `smacofIndDiff()`). Otra alternativa puede ser abordar un desplegamiento multidimensional, que representa conjuntamente objetos e individuos.

::: {.infobox_resume data-latex=""}

**Resumen**

La aplicación del análisis EMD implica tres pasos consecutivos:

• La determinación de las proximidades originales entre los objetos. Esta fase depende de las características de los objetos y del tipo de relación que se quiera/pueda establecer entre ellos. Actualmente, **R** dispone de paquetes que permiten estimar las matrices de proximidad a partir de los datos en bruto.

• La conversión de las proximidades en similaridades (si fuese necesario) y el ajuste entre las originales y las reproducidas por el EMD. Se debe elegir el tipo de EMD a utilizar, que depende de la función de ajuste: se puede optar por funciones de tipo `ratio`, `interval` o `mspline` (EMD métricos) \index{escalamiento!métrico} o `ordinal` (EMD no métrico) \index{escalamiento!no métrico}. La elección estará relacionada con el tipo de datos usados y el grado de ajuste (stress) de los modelos.

• La interpretación de los resultados a partir de la configuración obtenida, tanto del significado de las dimensiones como de la estructura de los objetos (cuáles se parecen, si existen grupos, etc.)
:::




