<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Capítulo 23 Análisis de tablas de contingencia | Fundamentos de ciencia de datos con R</title>
<meta name="author" content="Gema Fernández-Avilés y José-María Montero">
<meta name="description" content="José-María Montero Universidad de Castilla-La Mancha  23.1 Introducción  Las tablas de contingencia analizan la relación existente entre variables categóricas, o susceptibles de categorizar, con...">
<meta name="generator" content="bookdown 0.28 with bs4_book()">
<meta property="og:title" content="Capítulo 23 Análisis de tablas de contingencia | Fundamentos de ciencia de datos con R">
<meta property="og:type" content="book">
<meta property="og:image" content="/img/cover.png">
<meta property="og:description" content="José-María Montero Universidad de Castilla-La Mancha  23.1 Introducción  Las tablas de contingencia analizan la relación existente entre variables categóricas, o susceptibles de categorizar, con...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Capítulo 23 Análisis de tablas de contingencia | Fundamentos de ciencia de datos con R">
<meta name="twitter:description" content="José-María Montero Universidad de Castilla-La Mancha  23.1 Introducción  Las tablas de contingencia analizan la relación existente entre variables categóricas, o susceptibles de categorizar, con...">
<meta name="twitter:image" content="/img/cover.png">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.2/transition.js"></script><script src="libs/bs3compat-0.4.2/tabs.js"></script><script src="libs/bs3compat-0.4.2/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><link href="libs/tabwid-1.1.0/tabwid.css" rel="stylesheet">
<link href="libs/tabwid-1.1.0/scrool.css" rel="stylesheet">
<script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><link rel="stylesheet" href="bs4_style.css">
<link rel="stylesheet" href="bs4_book.css">
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Fundamentos de ciencia de datos con R</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Buscar" aria-label="Buscar">
</form>

      <nav aria-label="Contenido"><h2>Contenido</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Prefacio</a></li>
<li class="book-part">Ciencia, datos, software… y científicos</li>
<li><a class="" href="ciencia-datos.html"><span class="header-section-number">1</span> ¿Es la ciencia de datos una ciencia?</a></li>
<li><a class="" href="metodologia.html"><span class="header-section-number">2</span> Metodología en ciencia de datos</a></li>
<li><a class="" href="ch-110003.html"><span class="header-section-number">3</span> R para ciencia de datos</a></li>
<li><a class="" href="cap-etica.html"><span class="header-section-number">4</span> Ética en la ciencia de datos</a></li>
<li class="book-part">Bienvenidos a la jungla de datos</li>
<li><a class="" href="datos-sql.html"><span class="header-section-number">5</span> Gestión de bases de datos relacionales</a></li>
<li><a class="" href="cap-nosql.html"><span class="header-section-number">6</span> Gestión de bases de datos NoSQL</a></li>
<li><a class="" href="DGDQM.html"><span class="header-section-number">7</span> Gobierno, gestión y calidad del dato</a></li>
<li><a class="" href="id_130009.html"><span class="header-section-number">8</span> Integración y limpieza de datos</a></li>
<li><a class="" href="chap-feature.html"><span class="header-section-number">9</span> Selección y transformación de variables</a></li>
<li><a class="" href="chap-herramientas.html"><span class="header-section-number">10</span> Herramientas para el análisis en ciencia de datos</a></li>
<li><a class="" href="id_120006-aed.html"><span class="header-section-number">11</span> Análisis exploratorio de datos</a></li>
<li class="book-part">Fundamentos de estadística</li>
<li><a class="" href="Funda-probab.html"><span class="header-section-number">12</span> Probabilidad</a></li>
<li><a class="" href="Fundainfer.html"><span class="header-section-number">13</span> Inferencia estadística</a></li>
<li><a class="" href="muestreo.html"><span class="header-section-number">14</span> Muestreo y remuestreo</a></li>
<li class="book-part">Modelización estadística</li>
<li><a class="" href="cap-lm.html"><span class="header-section-number">15</span> Modelización lineal</a></li>
<li><a class="" href="cap-glm.html"><span class="header-section-number">16</span> Modelos lineales generalizados</a></li>
<li><a class="" href="cap-gam.html"><span class="header-section-number">17</span> Modelos aditivos generalizados</a></li>
<li><a class="" href="cap-mxm.html"><span class="header-section-number">18</span> Modelos mixtos</a></li>
<li><a class="" href="cap-sparse.html"><span class="header-section-number">19</span> Modelos sparse y métodos penalizados de regresión</a></li>
<li><a class="" href="cap-series-temp.html"><span class="header-section-number">20</span> Modelización de series temporales</a></li>
<li><a class="" href="cap-discriminante.html"><span class="header-section-number">21</span> Análisis discriminante</a></li>
<li><a class="" href="cap-conjunto.html"><span class="header-section-number">22</span> Análisis conjunto</a></li>
<li><a class="active" href="tablas-contingencia.html"><span class="header-section-number">23</span> Análisis de tablas de contingencia</a></li>
<li class="book-part">Machine learning supervisado</li>
<li><a class="" href="cap-arboles.html"><span class="header-section-number">24</span> Árboles de clasificación y regresión</a></li>
<li><a class="" href="cap-svm.html"><span class="header-section-number">25</span> Máquinas de vector soporte</a></li>
<li><a class="" href="cap-knn.html"><span class="header-section-number">26</span> Clasificador k-vecinos más próximos</a></li>
<li><a class="" href="cap-naive-bayes.html"><span class="header-section-number">27</span> Naive Bayes</a></li>
<li><a class="" href="cap-bagg-rf.html"><span class="header-section-number">28</span> Métodos ensamblados: bagging y random forest</a></li>
<li><a class="" href="cap-boosting-xgboost.html"><span class="header-section-number">29</span> Boosting y el algoritmo XGBoost</a></li>
<li class="book-part">Machine learning no supervisado</li>
<li><a class="" href="jerarquico.html"><span class="header-section-number">30</span> Análisis cluster: clusterización jerárquica</a></li>
<li><a class="" href="no-jerarquico.html"><span class="header-section-number">31</span> Análisis cluster: clusterización no jerárquica</a></li>
<li><a class="" href="acp.html"><span class="header-section-number">32</span> Análisis de componentes principales</a></li>
<li><a class="" href="an%C3%A1lisis-factorial.html"><span class="header-section-number">33</span> Análisis factorial</a></li>
<li><a class="" href="escalamiento-multidimensional.html"><span class="header-section-number">34</span> Escalamiento multidimensional</a></li>
<li><a class="" href="correspondencias.html"><span class="header-section-number">35</span> Análisis de correspondencias</a></li>
<li class="book-part">Deep learning</li>
<li><a class="" href="capNN.html"><span class="header-section-number">36</span> Redes neuronales artificiales</a></li>
<li><a class="" href="cap-redes-convol.html"><span class="header-section-number">37</span> Redes neuronales convolucionales</a></li>
<li class="book-part">Ciencia de datos de texto y redes</li>
<li><a class="" href="mineria-textos.html"><span class="header-section-number">38</span> Minería de textos</a></li>
<li><a class="" href="grafos.html"><span class="header-section-number">39</span> Análisis de grafos y redes sociales</a></li>
<li class="book-part">Ciencia de datos espaciales</li>
<li><a class="" href="datos-espaciales.html"><span class="header-section-number">40</span> Trabajando con datos espaciales</a></li>
<li><a class="" href="geo.html"><span class="header-section-number">41</span> Geoestadística</a></li>
<li><a class="" href="cap-econom-esp.html"><span class="header-section-number">42</span> Modelos econométricos espaciales</a></li>
<li><a class="" href="cap-pp.html"><span class="header-section-number">43</span> Procesos de puntos</a></li>
<li class="book-part">Comunica y colabora</li>
<li><a class="" href="id_120007-informes.html"><span class="header-section-number">44</span> Informes reproducibles con R Markdown y Quarto</a></li>
<li><a class="" href="shiny.html"><span class="header-section-number">45</span> Creación de aplicaciones web interactivas con Shiny</a></li>
<li><a class="" href="github.html"><span class="header-section-number">46</span> Git y GitHub R</a></li>
<li><a class="" href="geoproces.html"><span class="header-section-number">47</span> Geoprocesamiento en nube</a></li>
<li class="book-part">Casos de estudio en ciencia de datos</li>
<li><a class="" href="cap-crimen.html"><span class="header-section-number">48</span> Análisis de una red criminal</a></li>
<li><a class="" href="cap-publicidad.html"><span class="header-section-number">49</span> Optimización de inversiones publicitarias</a></li>
<li><a class="" href="cap-twitter.html"><span class="header-section-number">50</span> ¿Cómo twitea Elon Musk?</a></li>
<li><a class="" href="cap-periodismo.html"><span class="header-section-number">51</span> Análisis electoral: de Rstudio a su periódico</a></li>
<li><a class="" href="paro-clm.html"><span class="header-section-number">52</span> Crisis: impacto en el paro de Castilla-La Mancha</a></li>
<li><a class="" href="cap-rfm.html"><span class="header-section-number">53</span> Segmentación de clientes en el comerico minorista</a></li>
<li><a class="" href="cap-medicina.html"><span class="header-section-number">54</span> Análisis de datos en medicina</a></li>
<li><a class="" href="cap-futbol.html"><span class="header-section-number">55</span> Messi y Ronaldo: dos ídolos desde la perspectiva de los datos</a></li>
<li><a class="" href="cambioclimatico.html"><span class="header-section-number">56</span> Un dato sobre el cambio climático</a></li>
<li><a class="" href="cap-ree.html"><span class="header-section-number">57</span> Predicción de consumo eléctrico con redes neuronales</a></li>
<li><a class="" href="cap-sist-exp.html"><span class="header-section-number">58</span> Implementación de un sistema experto en el ámbito pediátrico</a></li>
<li><a class="" href="nlp-textil.html"><span class="header-section-number">59</span> El procesamiento del lenguaje natural para tendencias de moda en textil</a></li>
<li><a class="" href="cap-fraude.html"><span class="header-section-number">60</span> Detección de fraude de tarjetas de crédito</a></li>
<li class="book-part">Appendix</li>
<li><a class="" href="info-session.html"><span class="header-section-number">A</span> Información de la sesión</a></li>
<li><a class="" href="referncias.html">Referncias</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="tablas-contingencia" class="section level1" number="23">
<h1>
<span class="header-section-number">Capítulo 23</span> Análisis de tablas de contingencia<a class="anchor" aria-label="anchor" href="#tablas-contingencia"><i class="fas fa-link"></i></a>
</h1>
<p><em>José-María Montero</em></p>
<p>Universidad de Castilla-La Mancha</p>
<div id="motiv" class="section level2" number="23.1">
<h2>
<span class="header-section-number">23.1</span> Introducción<a class="anchor" aria-label="anchor" href="#motiv"><i class="fas fa-link"></i></a>
</h2>
<p></p>
<p>Las <strong>tablas de contingencia</strong> analizan la relación existente entre variables categóricas, o susceptibles de categorizar, con un número de categorías finito. Dada su naturaleza, no permiten el uso de las tradicionales operaciones aritméticas, con lo cual, en el ámbito de la Estadística Descriptiva su análisis suele basarse en diagramas de barras y porcentajes (véase Cap. <a href="#120006-aed"><strong>??</strong></a>), y en la esfera de la Inferencia Estadística (Cap. <a href="Fundainfer.html#Fundainfer">13</a>) se centra en los contrastes de hipótesis no paramétricos y, básicamente, en el contraste de independencia entre dos o más de estas variables. Una pregunta que suele hacerse toda aquella persona que se acerca por primera vez al análisis de tablas de contingencia es el significado del término “contingencia”. Pues bien, este término fue acuñado por Pearson <span class="citation">(<a href="referncias.html#ref-Pearson1904">Pearson 1904</a>)</span> al apuntar: “… Este resultado nos permite partir de la teoría matemática de la independencia probabilística, tal como se desarrolla en los libros de texto elementales, y construir a partir de ella una teoría generalizada de la <strong>asociación</strong> o, como yo la llamo, <strong>contingencia</strong>.” </p>
<p>El análisis de tablas de contingencia (o de asociación) permite dar respuesta, entre otras, a preguntas como: los factores involucrados en una tabla de contingencia, ¿son independientes o están asociados? Si están asociados, ¿qué niveles de dichos factores son los que están asociados?, ¿cuál es la intensidad de dicha asociación?</p>
<div id="notac" class="section level3" number="23.1.1">
<h3>
<span class="header-section-number">23.1.1</span> Notación<a class="anchor" aria-label="anchor" href="#notac"><i class="fas fa-link"></i></a>
</h3>
<p> </p>
<p>Sea una población (o una muestra) de <em>N</em> elementos sobre la que se pretende analizar, simultáneamente, dos (por simplicidad) <strong>atributos</strong> o <strong>factores</strong> (<em>A</em> y <em>B</em>) con <em>R</em> y <em>C</em> <strong>niveles</strong>, <strong>modalidades</strong> o <strong>categorías</strong>, respectivamente. Sean {<em>A</em><sub>1</sub>, <em>A</em><sub>2</sub>, …, <em>A<sub>R</sub></em>} y {<em>B</em><sub>1</sub>, <em>B</em><sub>2</sub>, …, <em>B<sub>C</sub></em>} los niveles anteriormente aludidos. Sea <em>n<sub>ij</sub></em> el número de elementos que presentan a la vez las modalidades <em>i</em> y <em>j</em> de los factores <em>A</em> y <em>B</em>, respectivamente. La tabla estadística que describe, conjuntamente, estos <em>N</em> elementos (en otros términos, que muestra las frecuencias conjuntas de los niveles de ambos factores) se denomina <strong>tabla de contingencia</strong>. </p>
<div class="inline-table"><table style="width:100%;" class="table table-sm">
<colgroup>
<col width="14%">
<col width="14%">
<col width="14%">
<col width="14%">
<col width="14%">
<col width="14%">
<col width="14%">
</colgroup>
<thead><tr class="header">
<th></th>
<th></th>
<th align="center"></th>
<th align="center">Factor B</th>
<th></th>
<th align="center"></th>
<th align="center"></th>
</tr></thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td align="center">Nivel <em>B</em><sub>1</sub>
</td>
<td align="center">Nivel <em>B</em><sub>2</sub>
</td>
<td>. . .</td>
<td align="center">Nivel <em>B</em><sub>C</sub>
</td>
<td align="center"><strong>Total</strong></td>
</tr>
<tr class="even">
<td></td>
<td>Nivel <em>A</em><sub>1</sub>
</td>
<td align="center">
<em>n</em><sub>11</sub>
</td>
<td align="center">
<em>n</em><sub>12</sub>
</td>
<td>. . .</td>
<td align="center">
<em>n</em><sub>1<em>C</em></sub>
</td>
<td align="center">
<em>n</em><sub>1.</sub>
</td>
</tr>
<tr class="odd">
<td></td>
<td>Nivel <em>A</em><sub>2</sub>
</td>
<td align="center">
<em>n</em><sub>21</sub>
</td>
<td align="center">
<em>n</em><sub>22</sub>
</td>
<td>. . .</td>
<td align="center">
<em>n</em><sub>2<em>C</em></sub>
</td>
<td align="center">
<em>n</em><sub>2.</sub>
</td>
</tr>
<tr class="even">
<td></td>
<td>.</td>
<td align="center">.</td>
<td align="center">.</td>
<td>.</td>
<td align="center">.</td>
<td align="center">.</td>
</tr>
<tr class="odd">
<td>Factor <em>A</em>
</td>
<td>.</td>
<td align="center">.</td>
<td align="center">.</td>
<td>.</td>
<td align="center">.</td>
<td align="center">.</td>
</tr>
<tr class="even">
<td></td>
<td>.</td>
<td align="center">.</td>
<td align="center">.</td>
<td>.</td>
<td align="center">.</td>
<td align="center">.</td>
</tr>
<tr class="odd">
<td></td>
<td>Nivel <em>A<sub>R</sub></em>
</td>
<td align="center"> <em>n<sub>R</sub></em><sub>1</sub>
</td>
<td align="center">
<em>n<sub>R</sub></em><sub>2</sub>
</td>
<td>. . .</td>
<td align="center"><em>n<sub>RC</sub></em></td>
<td align="center">
<em>n<sub>R</sub></em><sub>.</sub>
</td>
</tr>
<tr class="even">
<td></td>
<td><strong>Total</strong></td>
<td align="center">
<em>n.</em><sub>1</sub>
</td>
<td align="center">
<em>n</em><sub>.2</sub>
</td>
<td>. . .</td>
<td align="center">
<em>n</em><sub>.<em>C</em></sub>
</td>
<td align="center"><em>n</em></td>
</tr>
</tbody>
</table></div>
<!-- ::: {#ex-tablas .example name="Tabla de contingencia con dos factores y dos niveles cada factor"} --><!-- ::: --><p>A modo de ejemplo, considérese una muestra de 80 ayuntamientos de una CC.AA., anotándose en la base <code>ayuntam</code>, incluida en el paquete <code>CRD</code> del libro, el signo político del equipo gubernamental (<code>signo_gob</code>) y si prestan o no públicamente el servicio <em>X</em> (<code>serv</code>). Los resultados obtenidos fueron los siguientes:</p>
<div class="sourceCode" id="cb326"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st">"CDR"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"ayuntam"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu">summarytools</span><span class="fu">::</span><span class="fu"><a href="https://rdrr.io/pkg/summarytools/man/ctable.html">ctable</a></span><span class="op">(</span><span class="va">ayuntam</span><span class="op">$</span><span class="va">signo_gob</span>, <span class="va">ayuntam</span><span class="op">$</span><span class="va">serv</span>, headings <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">|&gt;</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#&gt; Cross-Tabulation, Row Proportions  </span></span>
<span><span class="co">#&gt; signo_gob * serv  </span></span>
<span><span class="co">#&gt; Data Frame: ayuntam  </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; ------------ ------ ------------ ------------ -------------</span></span>
<span><span class="co">#&gt;                serv           No           Sí         Total</span></span>
<span><span class="co">#&gt;    signo_gob                                               </span></span>
<span><span class="co">#&gt;    Avanzados          14 (33.3%)   28 (66.7%)   42 (100.0%)</span></span>
<span><span class="co">#&gt;   Ilustrados           6 (15.8%)   32 (84.2%)   38 (100.0%)</span></span>
<span><span class="co">#&gt;        Total          20 (25.0%)   60 (75.0%)   80 (100.0%)</span></span>
<span><span class="co">#&gt; ------------ ------ ------------ ------------ -------------</span></span></code></pre></div>
<p>Del estudio de las distribuciones marginales de ambos factores se deduce que el 52,5% de los ayuntamientos de la CC.AA. están regidos por los Avanzados y el 47,5% por los Ilustrados. Y, más interesante, que en el 75% de los ayuntamientos prestan el servicio <em>X</em>.</p>
<p>El análisis de la tabla de contingencia daría respuesta a las siguientes preguntas: ¿La prestación pública del servicio <em>X</em> es independiente del signo político del ayuntamiento o depende de dicho signo? En este último caso: ¿Qué signo político está asociado con la prestación pública y cuál no?, ¿la asociación entre los factores “Signo político del equipo gubernamental” y “Prestación pública del servicio <em>X</em>” es muy intensa? Pero dicho análisis se abordará posteriormente.</p>
<!-- |          |            |            |         |           | -->
<!-- |----------|------------|:----------:|:-------:|:---------:| -->
<!-- |          |            | Prestación | pública |           | -->
<!-- |          |            |     NO     |   SÍ    | **Total** | -->
<!-- | Signo    | Avanzados  |     14     |   28    |  **42**   | -->
<!-- | político | Ilustrados |     6      |   32    |  **38**   | -->
<!-- |          | **Total**  |   **20**   | **60**  |  **80**   | -->
<!-- Del estudio de las distribuciones marginales de ambos factores se deduce que el 52,5% de los ayuntamientos de la CC.AA. están regidos por los Avanzados y el 47,5% por los Ilustrados. Y, más interesante, que en el 75% de los ayuntamientos prestan el servicio *X*. -->
<!-- El análisis de la tabla de contingencia daría respuesta a las siguientes preguntas: ¿La prestación pública del servicio *X* es independiente del signo político del ayuntamiento o depende de dicho signo? En este último caso: ¿Qué signo político está asociado con la prestación pública y cuál no?, ¿la asociación entre los factores "Signo político del equipo gubernamental" y "Prestación pública del servicio *X*" es muy intensa? Dicho análisis se abordará posteriormente. Por el momento, la atención se centra en su construcción a partir de la base de datos de este ejemplo y en el cálculo de porcentajes (en este caso, por fila). Se procede como sigue: -->
<p>En función del número de factores involucrados en la tabla y del número de niveles de cada uno de ellos se tiene la siguiente tipología de tablas de contingencia:</p>
<ul>
<li><p>Tablas <span class="math inline">\(R\times C\)</span>: 2 factores, el primero con <em>R</em> niveles y el segundo con <em>C</em> niveles.</p></li>
<li><p>Tablas <span class="math inline">\(R\times C \times M\)</span>: 3 factores, con <em>R</em>, <em>C</em> y <em>M</em> niveles, respectivamente.</p></li>
<li><p>Y así sucesivamente.</p></li>
</ul>
<p>
</p>
<p>Dentro de las tablas <span class="math inline">\(R\times C\)</span> se distinguen las tablas <span class="math inline">\(2\times 2\)</span> de las demás, por su especial interés en la realidad y por criterios pedagógicos, al ser las más sencillas.</p>
</div>
<div id="prodecim" class="section level3" number="23.1.2">
<h3>
<span class="header-section-number">23.1.2</span> Diseños experimentales o procedimientos de muestreo que dan lugar a una tabla de contingencia<a class="anchor" aria-label="anchor" href="#prodecim"><i class="fas fa-link"></i></a>
</h3>
<p> </p>
<p>Una cuestión a la que no se le da la suficiente importancia es la forma en la que se toma la información contenida en la tabla (el diseño del experimento o procedimiento de muestreo). Dada una determinada tabla de contingencia, ésta puede haber sido obtenida mediante uno u otro diseño de experimento o procedimiento de muestreo, y esta circunstancia no es baladí, puesto que condiciona su análisis, sobre todo cuando el tamaño muestral es pequeño.</p>
<p>Sin ánimo de exhaustividad, los diseños experimentales o procedimientos de muestreo más habituales que dan lugar a una tabla de contingencia son los siguientes:<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Otros procedimientos de muestreo o diseños experimentales no habituales pueden verse en &lt;span class="citation"&gt;Ruiz-Maya et al. (&lt;a href="referncias.html#ref-Ruiz_Maya_et_al1995"&gt;1995&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;'><sup>164</sup></a></p>
<ul>
<li><strong>Tipo 1: se fijan los totales marginales de ambos factores</strong></li>
</ul>
<p></p>
<p>Ejemplo: se desea investigar si la preferencia de la larva de gorgojo por el tipo de judía es independiente de la cubierta de la semilla o depende de ésta. Para ello se toman 22 judías de tipo <em>A</em> y 18 de tipo <em>B</em>, que se introducen en un recipiente con 33 larvas. Dadas las condiciones de densidad, no entrará más de una larva por judía. Pasado un tiempo prudencial para que las larvas entren en las judías, se cuentan las que han sido atacadas de cada tipo y las que no.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Como en el resto del manual, las variables aleatorias se escriben en mayúsculas y los valores que toman en minúscula. En este caso, los totales marginales han sido fijados y son valores pero no ocurre lo mismo con las frecuencias absolutas en las cuatro celdas de las tablas, que son variables aleatorias.&lt;/p&gt;"><sup>165</sup></a></p>
<div class="inline-table"><table class="table table-sm"><tbody>
<tr class="odd">
<td></td>
<td></td>
<td align="center">Presencia de larva</td>
<td align="center">atacante</td>
<td align="center"></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td align="center">NO</td>
<td align="center">SÍ</td>
<td align="center"><strong>Total</strong></td>
</tr>
<tr class="odd">
<td>Tipo de</td>
<td>A</td>
<td align="center">
<em>N</em><sub>11</sub>
</td>
<td align="center">
<em>N</em><sub>12</sub>
</td>
<td align="center"><strong>22</strong></td>
</tr>
<tr class="even">
<td>judía</td>
<td>B</td>
<td align="center">
<em>N</em><sub>21</sub>
</td>
<td align="center">
<em>N</em><sub>22</sub>
</td>
<td align="center"><strong>18</strong></td>
</tr>
<tr class="odd">
<td></td>
<td><strong>Total</strong></td>
<td align="center"><strong>7</strong></td>
<td align="center"><strong>33</strong></td>
<td align="center"><strong>40</strong></td>
</tr>
</tbody></table></div>
<p>Como puede apreciarse, los totales marginales de ambos factores han sido fijados en el diseño del experimento.</p>
<ul>
<li><strong>Tipo 2: sólo se fijan los totales marginales de uno de los factores</strong></li>
</ul>
<p></p>
<p>Ejemplo: en un municipio se desea investigar si el desempleo es o no independiente del sexo del desempleado. Se seleccionan aleatoriamente 100 varones y 100 mujeres y se les pregunta por su situación laboral (trabajando; en paro).[^tablas_conting-marginales columnas]</p>
<p>[^tablas_conting-marginales columnas]: En este caso los totales marginales por columnas son variables.</p>
<div class="inline-table"><table class="table table-sm">
<thead><tr class="header">
<th></th>
<th></th>
<th align="center">Situación</th>
<th align="center">laboral</th>
<th align="center"></th>
</tr></thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td align="center">Trabajando</td>
<td align="center">En paro</td>
<td align="center"><strong>Total</strong></td>
</tr>
<tr class="even">
<td>Sexo</td>
<td>Varón</td>
<td align="center">
<em>N</em><sub>11</sub>
</td>
<td align="center">
<em>N</em><sub>12</sub>
</td>
<td align="center"><strong>100</strong></td>
</tr>
<tr class="odd">
<td></td>
<td>Mujer</td>
<td align="center">
<em>N</em><sub>21</sub>
</td>
<td align="center">
<em>N</em><sub>22</sub>
</td>
<td align="center"><strong>100</strong></td>
</tr>
<tr class="even">
<td></td>
<td><strong>Total</strong></td>
<td align="center">
<em>N</em><sub>.1</sub>
</td>
<td align="center">
<em>N</em><sub>.2</sub>
</td>
<td align="center"><strong>200</strong></td>
</tr>
</tbody>
</table></div>
<ul>
<li><strong>Tipo 3: únicamente se fija el tamaño muestral</strong></li>
</ul>
<p></p>
<p>Ejemplo: un estudio transversal sobre la prevalencia de osteoporosis y su relación con dietas pobres en calcio incluyó a 400 mujeres entre 50 y 54 años. Cada una de ellas realizó una densiometría de columna y rellenó un cuestionario sobre sus antecedentes dietéticos para determinar si su dieta era o no pobre en calcio.[^tablas_conting-marginales filas]</p>
<p>[^tablas_conting-marginales filas]: Ahora tanto los totales marginales por columnas como por filas son variables.</p>
<div class="inline-table"><table class="table table-sm">
<thead><tr class="header">
<th></th>
<th></th>
<th align="center">Dieta pobre</th>
<th align="center">en calcio</th>
<th align="center"></th>
</tr></thead>
<tbody>
<tr class="odd">
<td></td>
<td></td>
<td align="center">NO</td>
<td align="center">SÍ</td>
<td align="center"><strong>Total</strong></td>
</tr>
<tr class="even">
<td>Osteoporosis</td>
<td>SI</td>
<td align="center">
<em>N</em><sub>11</sub>
</td>
<td align="center">
<em>N</em><sub>12</sub>
</td>
<td align="center">
<em>N</em><sub>1.</sub>
</td>
</tr>
<tr class="odd">
<td></td>
<td>NO</td>
<td align="center">
<em>N</em><sub>21</sub>
</td>
<td align="center">
<em>N</em><sub>22</sub>
</td>
<td align="center">
<em>N</em><sub>2.</sub>
</td>
</tr>
<tr class="even">
<td></td>
<td><strong>Total</strong></td>
<td align="center">
<em>N</em><sub>.1</sub>
</td>
<td align="center">
<em>N</em><sub>.2</sub>
</td>
<td align="center"><strong>400</strong></td>
</tr>
</tbody>
</table></div>
</div>
</div>
<div id="contraste-de-independencia-en-tablas-2-times-2" class="section level2" number="23.2">
<h2>
<span class="header-section-number">23.2</span> Contraste de independencia en tablas <span class="math inline">\(2 \times 2\)</span><a class="anchor" aria-label="anchor" href="#contraste-de-independencia-en-tablas-2-times-2"><i class="fas fa-link"></i></a>
</h2>
<p>
</p>
<p>Como se avanzó en la Sec. <a href="tablas-contingencia.html#motiv">23.1</a>, la primera pregunta a la que debe dar respuesta el análisis de tablas de contingencia es si los factores involucrados en la tabla son independientes o, por el contrario, están asociados. La respuesta a esta pregunta exige llevar a cabo un contraste de independencia y, para ilustrarlo, se aborda, inicialmente, el caso de las tablas <span class="math inline">\(2\times 2\)</span>. Dicho contraste se lleva a cabo de tres formas: (<span class="math inline">\(i\)</span>) exacta, (<span class="math inline">\(ii\)</span>) aproximada, y (<span class="math inline">\(iii\)</span>) aproximada con corrección de continuidad.</p>
<p>
</p>
<div id="plantgen" class="section level3" number="23.2.1">
<h3>
<span class="header-section-number">23.2.1</span> Planteamiento general del contraste exacto de independencia<a class="anchor" aria-label="anchor" href="#plantgen"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li>
<p>Hipótesis:</p>
<ul>
<li>
<span class="math inline">\(H_0\)</span>: los factores son independientes.</li>
<li>
<span class="math inline">\(H_1\)</span>: están asociados.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;También puede establecerse como hipótesis alternativa la asociación en un determinado sentido: “el nivel 1 del factor &lt;em&gt;A&lt;/em&gt; está asociado con el 1 del &lt;em&gt;B&lt;/em&gt; y el 2 del &lt;em&gt;A&lt;/em&gt; con el 2 del &lt;em&gt;B&lt;/em&gt;” (asociación positiva); o “el nivel 1 del factor &lt;em&gt;A&lt;/em&gt; está asociado con el 2 del &lt;em&gt;B&lt;/em&gt; y el 2 del &lt;em&gt;A&lt;/em&gt; con el 1 del &lt;em&gt;B&lt;/em&gt;” (asociación negativa). En estos dos casos el contraste no sería bilateral sino unilateral.&lt;/p&gt;"><sup>166</sup></a>
</li>
</ul>
</li>
<li><p>Filosofía del contraste: se trata de un contraste de significación. Por tanto, la tabla observada será “rara” (bajo <span class="math inline">\(H_0\)</span>) si su probabilidad, más la probabilidad de obtener tablas más alejadas de H<sub>0</sub> que ella, es inferior al nivel de significación, <span class="math inline">\(\alpha\)</span>, prefijado para el contraste. En ese caso, se rechaza la hipótesis de independencia entre los factores involucrados en la tabla.</p></li>
</ul>
<p>
</p>
</div>
<div id="algoritmo" class="section level3" number="23.2.2">
<h3>
<span class="header-section-number">23.2.2</span> Algoritmo para la realización del contraste exacto de independencia<a class="anchor" aria-label="anchor" href="#algoritmo"><i class="fas fa-link"></i></a>
</h3>
<p>De acuerdo con la filosofía de los contrastes de significación (Sec. <a href="Fundainfer.html#contrhip">13.5</a>), el algoritmo para la realización del contraste de independencia en tablas de contingencia es como sigue:</p>
<ol style="list-style-type: decimal">
<li><p>Selección de la tablas del espacio muestral que se alejen de la hipótesis de independencia, en la dirección marcada por la hipótesis alternativa, tanto o más que la tabla observada, incluida esta última.</p></li>
<li><p>Cálculo, bajo la hipótesis de independencia, de la probabilidad de ocurrencia de cada una de las tablas seleccionadas en el punto 1.</p></li>
<li><p>Suma de dichas probabilidades y comparación con el <span class="math inline">\(\alpha\)</span> prefijado.</p></li>
<li><p>Toma de la decisión relativa al rechazo o no de la hipótesis de independencia.</p></li>
</ol>
<p>Nótese que <span class="math inline">\((i)\)</span> los pasos 1 y 2 dependen del diseño del experimento o procedimiento de muestreo llevado a cabo; <span class="math inline">\((ii)\)</span> en ausencia del software adecuado, la realización de un test exacto es un procedimiento laborioso (a veces un reto), con lo cual, si ese fuera el caso, los test aproximados de independencia son bienvenidos.</p>
<p>A continuación, se expone el contraste de independencia, en sus versiones exacta, aproximada y aproximada con corrección de continuidad, cuando el procedimiento de muestreo o diseño experimental es el de tipo 1. En la Sec. <a href="tablas-contingencia.html#dise">23.2.4</a> se comentan algunas cuestiones de interés cuando el diseño de muestreo es de tipo 2 o tipo 3.</p>
</div>
<div id="contraste-de-independencia-diseño-tipo-1" class="section level3" number="23.2.3">
<h3>
<span class="header-section-number">23.2.3</span> Contraste de independencia: diseño tipo 1<a class="anchor" aria-label="anchor" href="#contraste-de-independencia-dise%C3%B1o-tipo-1"><i class="fas fa-link"></i></a>
</h3>
<p></p>
<div id="contraste-exacto-test-exacto-de-fisher" class="section level4" number="23.2.3.1">
<h4>
<span class="header-section-number">23.2.3.1</span> Contraste exacto (test exacto de Fisher)<a class="anchor" aria-label="anchor" href="#contraste-exacto-test-exacto-de-fisher"><i class="fas fa-link"></i></a>
</h4>
<p>
</p>
<p>Considérese el ejemplo del diseño tipo 1 expuesto en <a href="tablas-contingencia.html#prodecim">23.1.2</a><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Se trata de un ejemplo clásico de &lt;span class="citation"&gt;Sokal and Rolf (&lt;a href="referncias.html#ref-Sokal2012"&gt;2012&lt;/a&gt;)&lt;/span&gt;.&lt;/p&gt;'><sup>167</sup></a>. Supóngase que el resultado obtenido fue el siguiente:</p>
<div class="sourceCode" id="cb327"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">datos_jud</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">6</span>,<span class="fl">21</span>,<span class="fl">12</span><span class="op">)</span></span>
<span><span class="va">tabla</span> <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/cbind.html">cbind</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html">expand.grid</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/list.html">list</a></span><span class="op">(</span>Tipo_de_judía <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"A"</span>,<span class="st">"B"</span><span class="op">)</span>, </span>
<span>                               Presencia_larva <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"No"</span>,<span class="st">"Sí"</span><span class="op">)</span><span class="op">)</span><span class="op">)</span>, </span>
<span>              count <span class="op">=</span> <span class="va">datos_jud</span><span class="op">)</span></span>
<span><span class="va">tabla_jud</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/ftable.html">ftable</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/xtabs.html">xtabs</a></span><span class="op">(</span><span class="va">count</span><span class="op">~</span><span class="va">Tipo_de_judía</span><span class="op">+</span><span class="va">Presencia_larva</span>, <span class="va">tabla</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<div class="inline-table"><table class="table table-sm"><tbody>
<tr class="odd">
<td></td>
<td></td>
<td align="center">Presencia de larva</td>
<td align="center">atacante</td>
<td align="center"></td>
</tr>
<tr class="even">
<td></td>
<td></td>
<td align="center">NO</td>
<td align="center">SI</td>
<td align="center"><strong>Total</strong></td>
</tr>
<tr class="odd">
<td>Tipo de</td>
<td>A</td>
<td align="center">1</td>
<td align="center">21</td>
<td align="center"><strong>22</strong></td>
</tr>
<tr class="even">
<td>judía</td>
<td>B</td>
<td align="center">6</td>
<td align="center">12</td>
<td align="center"><strong>18</strong></td>
</tr>
<tr class="odd">
<td></td>
<td><strong>Total</strong></td>
<td align="center"><strong>7</strong></td>
<td align="center"><strong>33</strong></td>
<td align="center"><strong>40</strong></td>
</tr>
</tbody></table></div>
<p>Según el algoritmo expuesto en la Sec. <a href="tablas-contingencia.html#algoritmo">23.2.2</a>, el contraste es como sigue:</p>
<p><strong>1</strong>. <strong>Selección de las tablas que se alejan de <span class="math inline">\(H_0\)</span> tanto o más que la observada</strong>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;El contraste se ha llevado a cabo de forma bilateral. En caso de una alternativa unilateral (asociación positiva o en el sentido de la diagonal principal; o negativa, en el sentido de la diagonal no principal), el procedimiento sería el mismo y las tablas seleccionadas serían, en el primer caso, todas menos la &lt;span class="math inline"&gt;\(T_7\)&lt;/span&gt;, y en el segundo, &lt;span class="math inline"&gt;\(T_0\)&lt;/span&gt; y &lt;span class="math inline"&gt;\(T_1\)&lt;/span&gt;.&lt;/p&gt;'><sup>168</sup></a> Como se señalaba en <span class="citation">Pearson (<a href="referncias.html#ref-Pearson1904">1904</a>)</span>, la teoría de la independencia probabilística indica que, bajo la hipótesis de independencia, el porcentaje de judías de tipo <em>A</em> y de tipo <em>B</em> no atacadas (o atacadas) por una larva de gorgojo tiene que ser el mismo. En otros términos, bajo la hipótesis de independencia, en cada una de las cuatro celdas se tiene que verificar que: <span class="math inline">\(N_{ij} = \frac{N_{i.} N_{.j}}{N}, \forall i,j\)</span>, donde <span class="math inline">\(\frac{N_{i.} N_{.j}}{N}= {E}_{ij}\)</span> se denomina frecuencia esperada bajo la hipótesis de independencia (en este caso, al estar los totales marginales fijos, <span class="math inline">\({E}_{ij}=\frac{n_{i.} n_{.j}}{n}\)</span>). Denominando <span class="math inline">\({D}_{ij}=N_{ij}-{E}_{ij}, \hspace{0,2cm}\forall i,j, \hspace{0,2cm} i=1,2,\hspace{0,2cm} j=1,2\)</span>, se puede que comprobar que en una tabla <span class="math inline">\(2\times 2\)</span>, <span class="math inline">\({D}_{11}={D} _{22}= -{D}_{12}= - {D}_{21}\)</span>, con lo cual, tomando de referencia, por ejemplo, la celda {1,1}, las tablas que se alejan tanto o más que la observada de la hipótesis de independencia son aquellas que verifican, en valor absoluto, que <span class="math inline">\({D}_{11}=N_{11}-{E}_{11}\geq n_{11}-\frac {n_{1.} n_{\cdot1}}{n}\)</span>.</p>
<p></p>
<p>En el ejemplo que se considera, las <span class="math inline">\({D}_{11}\)</span> son las siguientes (en negrita las de la tabla observada y aquellas otras que se alejan tanto o más que ella de <span class="math inline">\(H_0\)</span>):</p>
<p><strong><em>T</em></strong><sub>0</sub>: -3,85; <strong><em>T</em></strong><sub>1</sub>: -2,85; <em>T</em><sub>2</sub>: -1,85; <em>T</em><sub>3</sub>: -0,85; <em>T</em><sub>4</sub>: 0,15; <em>T</em><sub>5</sub>: 1,15; <em>T</em><sub>6</sub>: 2,15; <strong><em>T<sub>7</sub></em></strong>: 3,15,</p>
<p>donde el subíndice de <em>T</em> indica el valor de <span class="math inline">\(N_{11}\)</span> en dicha tabla.</p>
<p>
Nótese que el criterio anterior no es otro que el criterio general de seleccionar las tablas en las que la diferencia de porcentajes, por ejemplo, por fila, en valor absoluto, sea superior a la de la tabla observada, puesto que <span class="math inline">\(\left|\frac {N_{11}}{n_{1.}} -\frac {N_{21}}{n_{2.}} \right|=|{D}_{11} | \frac {n}{n_{1.} n_{2.} }\)</span>.</p>
<p><strong>2</strong>. <strong>Cálculo, bajo la hipótesis de independencia, de la probabilidad de ocurrencia de cada una de las tablas seleccionadas en 1</strong>. La probabilidad de ocurrencia de una tabla de contingencia con los totales marginales fijos se puede obtener como el cociente entre el número de disposiciones de las frecuencias observadas favorables a dicha tabla y el número de disposiciones posibles. El número de disposiciones favorables coincide con el coeficiente multinomial (maneras de que de <span class="math inline">\(n\)</span> frecuencias observadas, <span class="math inline">\(n_{11}\)</span> caigan en la celda {1,1}, <span class="math inline">\(n_{12}\)</span> lo hagan en la celda {1,2}, <span class="math inline">\(n_{21}\)</span> lo hagan en la celda {2,1} y <span class="math inline">\(n_{22}\)</span> lo hagan en la celda {2,2}:<span class="math inline">\(\frac {n!}{n_{11}! n_{12}! n_{21}! n_{22}!}\)</span>).</p>
<p>El número de disposiciones posibles, supuesta <span class="math inline">\(H_0\)</span>, es: <span class="math inline">\(\binom{n}{n_{1.}} \binom{n}{n_{\cdot1}} = \frac{n!}{(n_{1.}! n_{2.}!)} \frac {n!}{(n_{\cdot1} ! n_{\cdot2})}\)</span>.</p>
<p>Por tanto, el cociente entre ambas es: <span class="math inline">\(P=\frac {n_{1.} !n_{2.} !n_{\cdot1} !n_{\cdot2} !} {n!n_{11} !n_{12} !n_{21} !n_{22} !}\)</span>.</p>
<p>En consecuencia, las probabilidades de las tablas seleccionadas en el punto 1 son: <span class="math inline">\(T_0: 0,0017; T_1: 0,0219; T_7: 0,0091\)</span>.</p>
<p><strong>3</strong>. <strong>Suma de dichas probabilidades</strong>: 0,0327.</p>
<p><strong>4</strong>. <strong>Comparación con <span class="math inline">\(\alpha\)</span> y decisión sobre el rechazo o no de la hipótesis de independencia</strong>: La decisión depende del valor de <span class="math inline">\(\alpha\)</span>. Si fuera, por ejemplo, 0,05, se rechazaría la independencia entre el tipo de judía y si es o no atacada por la larva de gorgojo.</p>
<p>El código <strong>R</strong> necesario para tomar llevar a cabo el test exacto de Fisher anterior es: </p>
<div class="sourceCode" id="cb328"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#Ho: Los factores son independientes. </span></span>
<span><span class="co">#H1: Los factores están asociados</span></span>
<span><span class="va">fisher</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/fisher.test.html">fisher.test</a></span><span class="op">(</span><span class="va">tabla_jud</span>, alternative <span class="op">=</span> <span class="st">"two.sided"</span><span class="op">)</span> </span>
<span><span class="va">fisher</span><span class="op">$</span><span class="va">p.value</span></span>
<span><span class="co">#&gt; [1] 0.0327607</span></span></code></pre></div>
<div class="sourceCode" id="cb329"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#Ho: Los factores son independientes. </span></span>
<span><span class="co">#H1: Existe asociación negativa.</span></span>
<span><span class="va">fisher_less</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/fisher.test.html">fisher.test</a></span><span class="op">(</span><span class="va">tabla_jud</span>, alternative <span class="op">=</span> <span class="st">"less"</span><span class="op">)</span> </span>
<span><span class="va">fisher_less</span><span class="op">$</span><span class="va">p.value</span></span>
<span><span class="co">#&gt; [1] 0.02361309</span></span></code></pre></div>
<div class="sourceCode" id="cb330"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#Ho: Los factores son independientes. </span></span>
<span><span class="co">#H1: Existe asociación positiva.</span></span>
<span><span class="va">fisher_greater</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/fisher.test.html">fisher.test</a></span><span class="op">(</span><span class="va">tabla_jud</span>, alternative <span class="op">=</span> <span class="st">"greater"</span><span class="op">)</span> </span>
<span><span class="va">fisher_greater</span><span class="op">$</span><span class="va">p.value</span></span>
<span><span class="co">#&gt; [1] 0.998293</span></span></code></pre></div>
<p>Como puede apreciarse, se rechaza la hipótesis de independencia frente a la de asociación (test bilateral). Esto no significa que las larvas ataquen a un tipo de judía y no al otro. Atacan a ambos tipos, ¡y bastante! Este es el primer hecho que se constata. Sin embargo, atacan más a las judías de tipo <em>A</em> (un 95% son atacadas) que a las de tipo B (dos terceras partes son atacadas). Esa diferencia porcentual de judías atacadas se considera significativa bajo el supuesto de independencia y, en ese sentido, se dice que existe asociación entre el tipo de judía y la presencia o no de larva atacante. La asociación sería <em>A</em>-SI y <em>B</em>-NO. Sin embargo, ¡cuidado!, las larvas atacan siempre. La asociación anterior debe entenderse como “el porcentaje de ataque es muy grande en ambos casos, pero en <em>A</em> (mucho) más que en <em>B</em>. Este es el segundo hecho importante que se constata: las larvas muestran una preferencia significativa por las judías tipo <em>A</em>. Aunque ya se ha visto la dirección de la asociación (en el sentido de la diagonal ascendente), en la Sec. <a href="tablas-contingencia.html#medidas">23.4</a>, dedicada a las medidas de asociación en tablas 2x2, se cuantificará su intensidad.</p>
</div>
<div id="contraste-aproximado" class="section level4" number="23.2.3.2">
<h4>
<span class="header-section-number">23.2.3.2</span> Contraste aproximado<a class="anchor" aria-label="anchor" href="#contraste-aproximado"><i class="fas fa-link"></i></a>
</h4>
<p></p>
<p>En este caso (tipo 1), bajo <span class="math inline">\(H_0\)</span>: independencia, la frecuencia conjunta de una celda, <span class="math inline">\(N_{ij}\)</span>, cualquiera que sea, se distribuye según una ley hipergeométrica con <span class="math inline">\(E(N_{ij})=\frac{N_{ij}} {n_{i.}n_{\cdot j}}\)</span> y <span class="math inline">\(V(N_{ij})=\frac{n_{i.}n_{\cdot j}(n-n_{i.}) (n-n_{\cdot j})}{n^2 (n-1)}\)</span>. Por consiguiente,
<span class="math display">\[P\left(\left( N_{11}-\frac{n_{1.} n_{\cdot1}} {n} \right) ^2 \geq \left(n_{11} - \frac{n_{1.} n_{\cdot1}}{n}\right)^2 \right)= P\left(\frac{(N_{11}-\frac{n_{1.} n_{\cdot1}}
{n})^2}{\frac{n_{1.}n_{\cdot1}n_{2.} n_{\cdot2}}{n^2 (n-1)}}
\geq \frac{(n_{11}-\frac{n_{1.} n_{\cdot1}}{n})^2}{\frac{n_{1.}n_{\cdot1}n_{2.} n_{\cdot2})}{n^2 (n-1)}}\right).\]</span></p>
<p>Y si ninguna <span class="math inline">\(\hat{E}_{ij}=\frac{n_{ij}} {n_{i.}n_{\cdot j}}\)</span> es inferior a 5, la probabilidad anterior puede aproximarse (teorema central del límite) por:</p>
<p>
</p>
<p><span class="math display">\[P\left(\chi^2_1 \geq {\frac{\left( n_{11}-\frac{n_{1.} n_{\cdot1}}
{n}\right)^2} {\frac{n_{1.}n_{\cdot1}n_{2.} n_{\cdot2}}{n^2 (n-1)}}}\right)=P\left( \chi^2_1 \geq {\frac{ (n-1)(n_{11}n_{22}-n_{21}n_{12}
)^2} {n_{1.}n_{\cdot1}n_{2.} n_{\cdot2}}}\right),\]</span>
donde el estadístico <span class="math inline">\(\frac{ (n-1)(n_{11}n_{22}-n_{21}n_{12} )^2} {n_{1.}n_{\cdot1}n_{2.} n_{.2}}\)</span>
se denomina chi-cuadrado ajustado <span class="math inline">\((\chi^2_{ajd})\)</span> y es tal que
<span class="math inline">\(\chi^2_{ajd}= \frac {n-1} {n}\frac{ n (n_{11}n_{22}-n_{21}n_{12} )^2} {n_{1.}n_{\cdot1}n_{2.} n_{\cdot2}}\)</span>,
donde <span class="math inline">\(\frac{ n (n_{11}n_{22}-n_{21}n_{12} )^2} {n_{1.}n_{\cdot1}n_{2.} n_{\cdot2}}\)</span>
es el estadístico chi-cuadrado (<span class="math inline">\(\chi^2\)</span>) que proporcionan todos los softwares de contraste de independencia en tablas de contingencia.</p>
<p>En el ejemplo propuesto:</p>
<div class="sourceCode" id="cb331"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test</a></span><span class="op">(</span><span class="va">tabla_jud</span><span class="op">)</span><span class="op">$</span><span class="va">expected</span></span>
<span><span class="co">#&gt;      [,1]  [,2]</span></span>
<span><span class="co">#&gt; [1,] 3.85 18.15</span></span>
<span><span class="co">#&gt; [2,] 3.15 14.85</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test</a></span><span class="op">(</span><span class="va">tabla_jud</span>, correct<span class="op">=</span><span class="cn">FALSE</span><span class="op">)</span> </span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Pearson's Chi-squared test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  tabla_jud</span></span>
<span><span class="co">#&gt; X-squared = 5.6828, df = 1, p-value = 0.01713</span></span></code></pre></div>
<p>Como <span class="math inline">\(\chi^2= 5,6828\)</span>, entonces <span class="math inline">\(\chi^2_{ajd}=5,54073\)</span> y <span class="math inline">\(P\left(\chi^2_{ajd} \geq 5,54073\right)=0,0186\)</span>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Este “cálculo extra” es un pequeño peaje que hay que pagar en aras de la exactitud. Y es importante, porque pudiera hacer cambiar la decisión resultante del contraste.&lt;/p&gt;"><sup>169</sup></a></p>
<p>Nótese que la probabilidad exacta de obtener una tabla tan alejada o más de la hipótesis de independencia que la observada (incluida esta) es 0,0327, mientras que la probabilidad aproximada es 0,0186. La aproximación no es muy buena, y ello se debe a la existencia de frecuencias esperadas menores que 5.</p>
</div>
<div id="contraste-aproximado-con-corrección-de-continuidad" class="section level4" number="23.2.3.3">
<h4>
<span class="header-section-number">23.2.3.3</span> Contraste aproximado con corrección de continuidad<a class="anchor" aria-label="anchor" href="#contraste-aproximado-con-correcci%C3%B3n-de-continuidad"><i class="fas fa-link"></i></a>
</h4>
<p></p>
<p>
</p>
<p>Como se vio en la subsección anterior, al aproximar la probabilidad de obtención de tablas tanto o más alejadas de <span class="math inline">\(H_0\)</span> que la observada (que se calcula con una distribución hipergeométrica, que es discreta) mediante una distribución <span class="math inline">\(\chi^2_1\)</span> (que es continua), se comete un “error de continuización”. Dicho error se intenta corregir incluyendo en el contraste una <strong>corrección de continuidad</strong>. Hay varias correcciones que han tenido cierto éxito en la literatura. La más popular es la corrección de Yates, si bien sólo se recomienda cuando las <span class="math inline">\({E}_{ij}\)</span> sean múltiplos de 0,5.</p>
<p>En el contraste aproximado con corrección de Yates, se rechaza <span class="math inline">\(H_0\)</span> si:
<span class="math display">\[P\left( \chi^2_1 \geq {\frac{ (n-1)(|n_{11}n_{22}-n_{21}n_{12}
|-0,5n)^2} {n_{1.}n_{\cdot1}n_{2.} n_{\cdot2}}}  \right)\leq \alpha ,\]</span>
donde el estadístico <span class="math inline">\({\frac{ (n-1)(|n_{11}n_{22}-n_{21}n_{12}|-0,5n)^2} {n_{1.}n_{\cdot1}n_{2.} n_{\cdot2}}}\)</span> se denomina estadístico chi-cuadrado ajustado corregido de continuidad de Yates (<span class="math inline">\(\chi^2_{ajd,CCY}\)</span>).</p>
<p>En el ejemplo propuesto, el test chi-cuadrado con corrección de continuidad de Yates se obtiene directamente con la función <code><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test()</a></code> que, por defecto, incluye el argumento <code>correct = TRUE</code>.</p>
<div class="sourceCode" id="cb332"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test</a></span><span class="op">(</span><span class="va">tabla_jud</span><span class="op">)</span> </span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Pearson's Chi-squared test with Yates' continuity correction</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  tabla_jud</span></span>
<span><span class="co">#&gt; X-squared = 3.8637, df = 1, p-value = 0.04934</span></span></code></pre></div>
<p>Como el estadístico Chi-cuadrado corregido de continuidad <span class="math inline">\(\chi^2_{CCY}\)</span> vale 3,8337, entonces <span class="math inline">\(\chi^2_{ajd,CCY}=\frac{39}{40}\times 3,8337=3,7636\)</span>; y como <span class="math inline">\(P\left( \chi^2_1 \geq 3,7636\right)=0,0524\)</span>,
<span class="math inline">\(H_0\)</span> se rechazaría cuando <span class="math inline">\(\alpha &gt; 0,0524\)</span>. Nótese que si, por ejemplo, <span class="math inline">\(\alpha = 0,05\)</span>, la decisión sobre el rechazo o no de <span class="math inline">\(H_0\)</span> es distinta con <span class="math inline">\(\chi^2_{CCY}\)</span> y <span class="math inline">\(\chi^2_{ajd,CCY}\)</span>; de ahí la importancia de utilizar el estadístico ajustado.</p>
<p>Por tanto, la corrección de Yates ha transformado la infraestimación de la probabilidad exacta en una sobreestimación de más o menos el mismo tamaño. Ello se debe a que en la tabla observada, hay freecuencias esperadas (<span class="math inline">\({E}_{ij}\)</span>) que distan mucho de ser multiplos de 0,5. La corrección de Yates es la que incluye la librería utilizada (<code>stats</code>). Otras correcciones pueden verse en <span class="citation">Ruiz-Maya et al. (<a href="referncias.html#ref-Ruiz_Maya_et_al1995">1995</a>)</span> y <span class="citation">J. M. Montero (<a href="referncias.html#ref-Montero2002">2002</a>)</span>.</p>
</div>
</div>
<div id="dise" class="section level3" number="23.2.4">
<h3>
<span class="header-section-number">23.2.4</span> Contraste de independencia: diseños tipo 2 y tipo 3<a class="anchor" aria-label="anchor" href="#dise"><i class="fas fa-link"></i></a>
</h3>
<p>
</p>
<p>En el caso tipo 2, para la realización del test exacto, las tablas que se alejan tanto o más que la observada de la hipótesis de independencia son las que verifican: <span class="math display">\[\left| \frac {N_{11}}{n_{1.}}-\frac{N_{21}}{n_{2.}}\right|
\geq \left|\frac{n_{11}}{n_{1.}}-\frac{n_{21}}{n_{2.}}\right|,\]</span>
y la probabilidad de ocurrencia de una tabla de contingencia viene dada por:</p>
<span class="math display">\[\begin{equation}
P\left({N_{11}}={n_{11}} ;{N_{12}}={n_{12}};{N_{21}}={n_{21}};{N_{22}}={n_{22}} |N=n\right)
= \\
\binom{n_{1.}}{N_{11}} \binom {n_{2.}}{N_{21}}
\left( \frac{N_{\cdot1}}{n} \right)^{N_{\cdot1}} \left( \frac {N_{\cdot2}}{n}\right)^{N_{\cdot2}}.
\end{equation}\]</span>
<p>El estadístico de contraste en el test aproximado viene dado por <span class="math inline">\(\chi^2=\frac{ n (n_{11}n_{22}-n_{21}n_{12})^2} {n_{1.}n_{\cdot1}n_{2.} n_{\cdot2}}\)</span>, y por <span class="math inline">\(\chi^2_{CC}=\frac { n \left( \left|n_{11}n_{22}-n_{21}n_{12}\right|-\frac {f} {2}\right)^{2}} {n_{1.}n_{\cdot1}n_{2.} n_{\cdot2}}\)</span> en el caso de estar corregido de continuidad, siendo <em>f</em> el mayor factor común de los tamaños muestrales fijados.</p>
<p>En el caso tipo 3, las tablas que se alejan tanto o más que la observada de la hipótesis de independencia son las que verifican la condición expuesta en el tipo 2 (y tipo 1), siendo su probabilidad de ocurrencia:</p>
<span class="math display">\[\begin{equation}
\begin{split}
P\left({N_{11}}  ={n_{11}} ;{N_{12}}={n_{12}};{N_{21}}={n_{21}};{N_{22}}={n_{22}} |N=n \right) = \\
\frac {n!}{{n_{1.}! n_{2.}! n_{\cdot 1}! n_{\cdot2}!}}
\left(\frac {n_{1.}}{n} \frac{n_{\cdot1}}{n} \right)^{n_{11}}
\left(\frac {n_{1.}}{n} \frac{n_{\cdot2}}{n} \right)^{n_{12}}
\left(\frac {n_{2.}}{n} \frac{n_{\cdot1}}{n} \right)^{n_{21}}
\left(\frac {n_{1.}}{n} \frac{n_{\cdot2}}{n} \right)^{n_{22}}.
\end{split}
\end{equation}\]</span>
<p>El test aproximado, en este caso, es un test razón de verosimilitudes donde el estadístico de contraste, <span class="math inline">\(G=-2ln\frac {n_{1.}^{n_{1.}} n_{2.}^{n_{2.}} n_{\cdot1}^{n_{\cdot1}} n_{\cdot2}^{n_{\cdot2}}}{n_{11}^{n_{11}} n_{21}^{n_{21}} n_{12}^{n_{12}} n_{22}^{n_{22}} n^n}\)</span>, también se distribuye como una <span class="math inline">\(\chi^2_1\)</span> en caso de independencia. Apenas hay literatura sobre correcciones de continuidad en este modelo y la poca que hay sugiere la aplicación de la corrección de Yates.</p>
<div class="infobox">
<p><strong>Nota</strong></p>
<p>En el diseño de muestreo tipo 3 se recomienda no usar ninguna corrección de continuidad, salvo que el tamaño muestral sea muy pequeño y sea imprescindible la realización del test.</p>
</div>
<p>El código <strong>R</strong> para llevar a cabo estos dos contrastes aproximados puede verse en la Sec. <a href="tablas-contingencia.html#contaprox">23.3.1</a>.</p>
<p></p>
</div>
</div>
<div id="contrasteRC" class="section level2" number="23.3">
<h2>
<span class="header-section-number">23.3</span> Contraste de independencia en tablas <span class="math inline">\(R \times C\)</span><a class="anchor" aria-label="anchor" href="#contrasteRC"><i class="fas fa-link"></i></a>
</h2>
<p></p>
<p>El análisis de tablas <span class="math inline">\(R\times C\)</span> puede considerarse, en principio, una generalización del caso de tablas <span class="math inline">\(2\times 2\)</span>. Ahora bien, en el caso <span class="math inline">\(R\times C\)</span> los test exactos, recomendados en el caso de que <span class="math inline">\(E_{ij}\leq5\)</span> en más del 20% de las celdas, [<span class="citation">H. T. Reynolds (<a href="referncias.html#ref-Reynolds1984">1984</a>)</span>]<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;La razón es que, sea cual sea el diseño de muestreo, si la probabilidad de que un elemento de la tabla caiga en una determinada celda {&lt;em&gt;i&lt;/em&gt;,&lt;em&gt;j&lt;/em&gt;} es muy pequeña (se suele utilizar el límite del 5%), entonces la distribución de probabilidad de &lt;span class="math inline"&gt;\(N_{ij}\)&lt;/span&gt; es muy asimétrica, y para que se simetrice lo suficiente y se pueda aproximar por una Normal (que después, al cuadrado, participará en una chi-cuadrado), el tamaño muestral, en el tipo 3, y los totales marginales fijados, en los tipos 1 y 2, tienen que ser grandes (se suele fijar el valor de 100), de ahí el límite de &lt;span class="math inline"&gt;\(E_{ij}\leq5\)&lt;/span&gt;; por eso es recomendable que el tamaño muestral sea grande y los totales marginales no estén desequilibrados. En todo caso, lo ideal es que requisito &lt;span class="math inline"&gt;\(E_{ij}\leq5\)&lt;/span&gt; se cumpla en todas las celdas de la tabla.&lt;/p&gt;'><sup>170</sup></a> son un auténtico reto y aún no están disponibles en el software convencional.</p>
<p>Si no se cumple el requisito anterior, una solución es agrupar categorías, con sentido común y coherencia.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;En tablas &lt;span class="math inline"&gt;\(2\times 2\)&lt;/span&gt; no se pueden agrupar filas, y la única solución son los tests exactos.&lt;/p&gt;'><sup>171</sup></a> Si la agrupación de categorías no pudiese hacerse, por carecer de sentido o cualquier otro motivo, lo más honesto sería no realizar el contraste hasta disponer de una base de datos mejor.</p>
<p>A la luz de lo anteriormente expuesto, en el caso de tablas <span class="math inline">\(R\times C\)</span> la atención se centra en los tests aproximados.</p>
<div id="contaprox" class="section level3" number="23.3.1">
<h3>
<span class="header-section-number">23.3.1</span> Contrastes aproximados<a class="anchor" aria-label="anchor" href="#contaprox"><i class="fas fa-link"></i></a>
</h3>
<p>Cuando el procedimiento de muestreo o el diseño experimental es de tipo 1 o 2 el contraste aproximado de independencia es el denominado contraste Chi-cuadrado. La filosofía de dicho contraste es la siguiente: parece lógico que el contraste se base en las diferencias (cuadráticas, para que no se compensen las negativas con las positivas) entre las frecuencias observadas y las esperadas bajo la hipótesis de independencia. Si los factores son independientes, dichas diferencias serán pequeñas y atribuibles a fluctuaciones aleatorias. Si están asociados, serán grandes y atribuibles a la asociación existente entre sus niveles. Pearson propuso el siguiente estadístico de contraste: <span class="math display">\[\chi^2 =\sum_{i=1}^{R} \sum_{j=1}^{C}\frac {\left(N_{ij}-{E}_{ij}\right)^2} {{E}_{ij}},\]</span></p>
<p>
</p>
<p>que, si no se incumple el requisito expuesto en las primeras lineas de la Sec. <a href="tablas-contingencia.html#contrasteRC">23.3</a>, y bajo la hipótesis de independencia, se distribuye como una <span class="math inline">\(\chi_{(R-1)(C-1)}^2\)</span>. En caso de que <span class="math inline">\(P\left( \chi_{(R-1)(C-1)}^2 \geq \sum_{i=1}^{R} \sum_{j=1}^{C}\frac {\left(n_{ij}-\hat{E}_{ij}\right)^2} {\hat{E}_{ij}}\right )\)</span> sea inferior al nivel de significación prefijado, se rechaza la hipótesis de independencia.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;span class="math inline"&gt;\(\hat{E}_{ij}=\frac{n_{i.} n_{.j}}{n}\)&lt;/span&gt; es el valor de &lt;span class="math inline"&gt;\({E}_{ij}\)&lt;/span&gt; calculado con los datos de la tabla observada. Igualmente, &lt;span class="math inline"&gt;\(n_{ij}\)&lt;/span&gt; son las frecuencias de la tabla observada.&lt;/p&gt;'><sup>172</sup></a> Téngase en cuenta que en el caso <span class="math inline">\(R\times C\)</span> la hipótesis alternativa es “al menos un nivel de un factor está asociado con un nivel del otro factor”.</p>
<p>La razón de que las diferencias
<span class="math inline">\(\left(N_{ij}-\hat{E}_{ij}\right)^2\)</span> se dividan por <span class="math inline">\(\hat{E}_{ij}\)</span> en el estadístico chi-cuadrado de Pearson es la siguiente: la misma diferencia <span class="math inline">\(N_{ij}-\hat{E}_{ij}\)</span> puede significar cosas bien diferentes. Una diferencia de 5 no es nada si <span class="math inline">\(\hat{E}_{ij}=1000\)</span>; pero es muchísimo si <span class="math inline">\(\hat{E}_{ij}=2\)</span>. Por eso la diferencia (cuadrática) se pone en relación con la frecuencia esperada.</p>
<p></p>
<!-- -   
¿¿LO METO AQUÍ O EN MEDIDAS DE ASOCIACIÓN??
El estadístico Chi-cuadrado tiene un límite superior fijo: $N(K-1)$, donde $N$ es el tamaño de la muestra y $K$ es el número más pequeño de filas o columnas. **Por eso no se puede utilizar como medida de asociación. ¿Un valor Chi-cuadrado de 35 es grande o pequeño, es decir, indica mucha o poca asociación? Pues depende; hay que compararlo con su valor máximo.**  -->
<!-- -   Si el tamaño muestral es grande y/o el número de niveles de los factores es elevado, el test Chi-cuadrado indicará siempre "rechazo de la hipótesis de independencia". En este caso el resultado no es muy interesante porque lo que el test podría estar detectando es un alejamiento insignificante de la hipótesis de independencia en al menos una celda y, dado que el test se alimenta con mucha información (tamaño muestral grande), lo considera significativo. Sin embargo, cuando valoremos el tamaño de la asociación detectada la medida de asociación nos dirá: los factores no son independientes, pero la intensidad de su asociación es despreciable. -->
<!-- -   Más sobre lo mismo: si en una Tabla RxC se multiplican por 10 las frecuencias observadas, las diferencias de porcentajes serán las mismas, pero el estadístico de contraste se multiplica por 10 y si con el primero no se rechazaba la hipótesis de independencia, con el segundo puede ocurrir que sí, sindo las proporciones las mismas. -->
<p>En el caso de que el procedimiento de muestreo sea del tipo 3, aunque puede aplicarse el contraste chi-cuadrado, es recomendable proceder con el contraste de independencia de razón de verosimilitudes, que compara por cociente las frecuencias esperadas bajo la hipótesis de independencia y las observadas. Se basa en la razón de la verosimilitud de la hipótesis de independencia a la luz de la muestra obtenida y del máximo de la función de verosimilitud, <span class="math inline">\(\Lambda\)</span>. Bajo el supuesto de independencia la razón será cercana a la unidad, atribuyéndose la diferencia a fluctuaciones aleatorias; el logaritmo neperiano de dicha razón (negativo) estará cercano a cero. En caso contrario, el cociente de verosimilitudes (negativo) disminuye, tanto más cuanto más diferencia hay entre la verosimilitud de la hipótesis de independencia y el máximo de la función de verosimilitud. En <span class="citation">Wilks (<a href="referncias.html#ref-Wilks1935">1935</a>)</span> se demostró que, cuando la hipótesis de independencia es cierta, <span class="math inline">\(G=-2ln \Lambda\)</span>, con <span class="math inline">\(\Lambda= \prod_{i=1}^R \prod_{j=1}^C \left (\frac {{E}_{ij}} {N_{ij}}\right)^{N_{ij}}\)</span> se distribuye como una <span class="math inline">\(\chi_{(R-1)(C-1)}^2\)</span>. Ambos estadísticos de contraste, <span class="math inline">\(\chi^2\)</span> y <span class="math inline">\(G\)</span>, son asintóticamente equivalentes.</p>
<p>
</p>
<p>A modo de ejemplo, se quiere contrastar si en la Comunidad de Madrid la opinión
sobre la presidente Dña. Isabel Díaz Ayuso depende de la zona geográfica o si
por el contrario, es independiente de ella. Para ello se encuestan,
por algún procedimiento aleatorio 2795 personas con derecho a voto en la comunidad
y se eliminan las respuestas “NS/NC/me es indiferente”. Los resultados obtenidos fueron los siguientes (dataset <code>ayuso</code> del paquete <code>CDR</code>):</p>
<div class="sourceCode" id="cb333"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"ayuso"</span><span class="op">)</span></span>
<span><span class="va">tabla_ayuso</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">ayuso</span><span class="op">)</span></span>
<span><span class="va">tabla_ayuso</span></span>
<span><span class="co">#&gt;                opinion</span></span>
<span><span class="co">#&gt; zona            n1_nefasta n2_mala n3_buena n4_excelente</span></span>
<span><span class="co">#&gt;   n1_mad_muni           25     500       50         1000</span></span>
<span><span class="co">#&gt;   n2_metropol           10     280       50          460</span></span>
<span><span class="co">#&gt;   n3_extraradio          5     130       25          260</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test</a></span><span class="op">(</span><span class="va">tabla_ayuso</span><span class="op">)</span><span class="op">$</span><span class="va">expected</span></span>
<span><span class="co">#&gt;                opinion</span></span>
<span><span class="co">#&gt; zona            n1_nefasta  n2_mala n3_buena n4_excelente</span></span>
<span><span class="co">#&gt;   n1_mad_muni    22.540250 512.7907 70.43828     969.2308</span></span>
<span><span class="co">#&gt;   n2_metropol    11.449016 260.4651 35.77818     492.3077</span></span>
<span><span class="co">#&gt;   n3_extraradio   6.010733 136.7442 18.78354     258.4615</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/chisq.test.html">chisq.test</a></span><span class="op">(</span><span class="va">tabla_ayuso</span>, correct<span class="op">=</span><span class="cn">FALSE</span><span class="op">)</span> </span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Pearson's Chi-squared test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  tabla_ayuso</span></span>
<span><span class="co">#&gt; X-squared = 19.486, df = 6, p-value = 0.003418</span></span></code></pre></div>
<div class="sourceCode" id="cb334"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="https://andrisignorell.github.io/DescTools/">"DescTools"</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://andrisignorell.github.io/DescTools/reference/GTest.html">GTest</a></span><span class="op">(</span><span class="va">tabla_ayuso</span>,correct <span class="op">=</span> <span class="st">"none"</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Log likelihood ratio (G-test) test of independence without correction</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  tabla_ayuso</span></span>
<span><span class="co">#&gt; G = 19.357, X-squared df = 6, p-value = 0.003602</span></span></code></pre></div>
<p>Como puede verse, sea cual sea el estadístico de contraste, la hipótesis de independencia se rechaza para cualquiera de los valores de <span class="math inline">\(\alpha\)</span> utilizados en la práctica (1%, 2,5%, 5%, 10%).</p>
</div>
<div id="contraste-aproximado-con-corrección-de-continuidad-1" class="section level3" number="23.3.2">
<h3>
<span class="header-section-number">23.3.2</span> Contraste aproximado con corrección de continuidad<a class="anchor" aria-label="anchor" href="#contraste-aproximado-con-correcci%C3%B3n-de-continuidad-1"><i class="fas fa-link"></i></a>
</h3>
<p></p>
<p>Afortunadamente, en la mayoría de las ocasiones el tamaño muestral es grande y los totales marginales no están muy desequilibrados, con lo que los estadísticos chi-cuadrado y chi-cuadrado corregido de continuidad son prácticamente iguales, sobre todo si el número de niveles de ambos factores es elevado. En caso de utilizar una corrección de continuidad, hay unanimidad en utilizar la de Yates, sea cual sea el procedimiento de muestreo y el test (chi-cuadrado o G), si bien dicha unanimidad tiene mucho que ver con que es la única que está programada en el software convencional sobre tablas de contingencia.</p>
</div>
</div>
<div id="medidas" class="section level2" number="23.4">
<h2>
<span class="header-section-number">23.4</span> Medidas de asociación en tablas <span class="math inline">\(2\times 2\)</span><a class="anchor" aria-label="anchor" href="#medidas"><i class="fas fa-link"></i></a>
</h2>
<p>
</p>
<p>Si no se rechaza la hipótesis de independencia, el análisis de la tabla se puede dar por finalizado. En caso contrario, el nuevo objetivo es determinar la dirección de la asociación detectada (o las fuentes de asociación en el caso <span class="math inline">\(R\times C\)</span>) y su intensidad, y para ello se utilizan las denominadas medidas de asociación. Igual que en el contraste de independencia, se distinguirán los casos <span class="math inline">\(2\times 2\)</span> y <span class="math inline">\(R\times C\)</span>, en esta ocasión no tanto por motivos pedagógicos sino porque las situaciones son bien diferentes.</p>
<p>En el caso <span class="math inline">\(2\times 2\)</span>, los tipos de asociación en función de su dirección (positiva y negativa) ya se se definieron en la Sec. <a href="tablas-contingencia.html#plantgen">23.2.1</a>. Por lo que se refiere a los límites de su intensidad, se dice que la asociación es perfecta cuando al menos uno de los niveles de uno de los factores queda determinado por un nivel del otro factor. La asociación perfecta puede ser estricta o implícita de tipo 2:<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;La asociación perfecta implícita de tipo 1, que no puede darse en tablas &lt;span class="math inline"&gt;\(2\times 2\)&lt;/span&gt;, consiste en que, dado un nivel de un factor, el nivel del otro queda inmediatamente determinado; pero dado el nivel de este último no se puede determinar el nivel del primero.&lt;/p&gt;'><sup>173</sup></a></p>
<ul>
<li>Estricta: dado el nivel de un factor, el nivel del otro queda inmediatamente determinado.</li>
<li>Implícita de tipo 2: dado un nivel de un factor, el nivel del otro queda inmediatamente determinado; dado el otro nivel, no queda determinado el nivel del otro factor.</li>
</ul>
<p>
</p>
<div id="la-q-de-yule" class="section level3" number="23.4.1">
<h3>
<span class="header-section-number">23.4.1</span> La <span class="math inline">\({Q}\)</span> de Yule<a class="anchor" aria-label="anchor" href="#la-q-de-yule"><i class="fas fa-link"></i></a>
</h3>
<p></p>
<p>En caso de independencia, las frecuencias observadas coinciden con las esperadas. A medida que las primeras se separan de las segundas, se produce un alejamiento de dicha hipótesis y los niveles de los factores aumentan la intensidad de su asociación. Por consiguiente, las diferencias <span class="math inline">\({D}_{ij}\)</span> entre las frecuencias observadas y las esperadas bajo el supuesto de independencia pueden ser la base de una magnífica medida de asociación. A mayores diferencias, mayor asociación. Mas sencillo todavía: una única diferencia, por ejemplo la <span class="math inline">\({D}_{11}\)</span>, podría servir como medida de asociación porque, como bajo la hipótesis de independencia, <span class="math inline">\({D}_{ij}=0\)</span> y <span class="math inline">\({D}_{11}={D}_{22}= -{D}_{12}=-{D}_{21}\)</span>, entonces se tiene que:</p>
<ul>
<li><p>En caso de independencia: <span class="math inline">\({D}_{11}={D}_{22}= 0\)</span> y <span class="math inline">\({D}_{12}={D}_{21}=0\)</span>, o simplemente, <span class="math inline">\({D}_{11}=0\)</span>.</p></li>
<li><p>En caso de asociación positiva: <span class="math inline">\({D}_{11}={D}_{22} \geq 0\)</span> y <span class="math inline">\({D}_{12}={D}_{21}\leq 0\)</span>, o simplemente, <span class="math inline">\({D}_{11}\geq 0\)</span>.</p></li>
<li><p>En caso de asociación negativa: <span class="math inline">\({D}_{11}={D}_{22} \leq 0\)</span> y <span class="math inline">\({D}_{12}={D}_{21}\geq 0\)</span>, o simplemente, <span class="math inline">\({D}_{11}\leq 0\)</span>.</p></li>
</ul>
<p>Por tanto, <span class="math inline">\({D}_{11}\)</span> determina muy fácilmente la dirección de la asociación. Sin embargo, en cuanto a la intensidad de la misma, el campo de variación de <span class="math inline">\({D}_{11}\)</span>, <span class="math inline">\(\left[-\frac {N_{12} N_{21}} {n};\frac {N_{12} N_{21}} {n}\right]\)</span>, depende de los valores de las frecuencias observadas (esto es un problema a la hora de la interpretación) y la máxima intensidad asociativa se da cuando la diagonal descendente o la diagonal ascendente sólo contienen ceros, es decir en caso de asociación perfecta estricta (negativa o positiva).</p>
<p>Para solucionar el problema anterior, se define la <span class="math inline">\({Q}\)</span> de Yule como:</p>
<p><span class="math display">\[{Q}=\frac {n {D}_{11}} {N_{11}N_{22} - N_{12}N_{21}}=\frac{N_{11}N_{22} - N_{12}N_{21}} {N_{11}N_{22}+ N_{12}N_{21}}.\]</span></p>
<p>El campo de variación de <span class="math inline">\({Q}\)</span> es <span class="math inline">\([-1;1]\)</span> y:</p>
<ul>
<li>En caso de independencia, <span class="math inline">\({Q}=0\)</span>.</li>
<li>En caso de asociación positiva, <span class="math inline">\({Q}&lt; 0\)</span>.</li>
<li>En caso de asociación negativa, <span class="math inline">\({Q}&gt; 0\)</span>.</li>
</ul>
<p>Por tanto, cuando se sustituyen los datos de la tabla observada en <span class="math inline">\({Q}\)</span>, obteniéndose su valor muestral u observado: <span class="math inline">\(\hat{Q}=\frac{n_{11}n_{22} - n_{12}n_{21}} {n_{11}n_{22}+ n_{12}n_{21}}\)</span>, se actúa como sigue:</p>
<ul>
<li>Cuando <span class="math inline">\(\hat{Q}=0\)</span> se dice que hay independencia.</li>
<li>Cuando <span class="math inline">\(\hat{Q}&lt; 0\)</span> se dice que hay asociación negativa.</li>
<li>Cuando <span class="math inline">\(\hat{Q}&gt; 0\)</span> se dice que hay asociación positiva.</li>
</ul>
<p>Lógicamente, a mayor valor absoluto de <span class="math inline">\(\hat{Q}\)</span> mayor intensidad de la asociación.</p>
<p>En el ejemplo utilizado para ilustrar el diseño experimental de tipo 1, el valor observado de <span class="math inline">\(Q\)</span> es <span class="math inline">\(\hat{Q}=0,83\)</span>:</p>
<div class="sourceCode" id="cb335"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://andrisignorell.github.io/DescTools/reference/CramerV.html">YuleQ</a></span><span class="op">(</span><span class="va">tabla_jud</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] -0.826087</span></span></code></pre></div>
<p>A la luz del valor del valor de <span class="math inline">\(\hat{Q}\)</span> se concluye la existencia de una fuerte asociación negativa.</p>
</div>
<div id="otras-medidas-de-asociación-para-tablas-2times-2" class="section level3" number="23.4.2">
<h3>
<span class="header-section-number">23.4.2</span> Otras medidas de asociación para tablas <span class="math inline">\(2\times 2\)</span><a class="anchor" aria-label="anchor" href="#otras-medidas-de-asociaci%C3%B3n-para-tablas-2times-2"><i class="fas fa-link"></i></a>
</h3>
<div id="cmc" class="section level4" number="23.4.2.1">
<h4>
<span class="header-section-number">23.4.2.1</span> Cuadrado medio de la contingencia de Pearson<a class="anchor" aria-label="anchor" href="#cmc"><i class="fas fa-link"></i></a>
</h4>
<p>
</p>
<p>La primera medida de asociación que se nos viene a todos a la cabeza es el propio estadístico de contraste <span class="math inline">\(\chi^2\)</span>. Sin embargo, no puede utilizarse como medida de asociación porque es siempre positivo y, sobre todo, porque su valor máximo, <span class="math inline">\(n(k-1)\)</span>, depende del tamaño muestral <span class="math inline">\(N\)</span> y de <span class="math inline">\(k\)</span>, el número más pequeño de filas o columnas. En el caso <span class="math inline">\(2\times 2\)</span> depende únicamente de <span class="math inline">\(n\)</span> porque <span class="math inline">\(k-1=1\)</span>. Para eliminar el efecto tamaño muestral, se define el cuadrado medio de la contingencia de Pearson como:</p>
<p><span class="math display">\[{\phi^2}= \frac{\chi^2}{n}=\frac{\left(N_{11}N_{22} - N_{12}N_{21}\right)^2} {N_{1.} N_{2.} N_{\cdot1}N_{\cdot2}},\]</span>
y se estima como <span class="math display">\[\hat{\phi^2}=\frac{\left(n_{11}n_{22} - n_{12}n_{21}\right)^2} {n_{1.} n_{2.} n_{\cdot1}n_{\cdot2}}.\]</span> a partir de la tabla observada.</p>
<p>Su campo de variación es <span class="math inline">\([0;1]\)</span>, tomando el valor 0 en caso de independencia y 1 cuando hay asociación perfecta y estricta. Cuanto mayor sea el valor del coeficiente, mayor es intensidad de la asociación.</p>
<p>No proporciona la dirección de la asociación, si bien se puede saber por el signo de <span class="math inline">\(n_{11}n_{22}-n_{12}n_{21}\)</span>. Otra consideración importante es que, si se codifican los niveles de los factores como (0;1), <span class="math inline">\({\phi}^2\)</span> coincide con el coeficiente de determinación lineal entre los factores. Por tanto, la asociación que mide es “lineal” (de ahí que su valor suela ser más bajo que el de <span class="math inline">\({Q}\)</span>). Su raíz cuadrada es conocida como “la V de Cramer”. En el ejemplo utilizado se tiene que:</p>
<p></p>
<div class="sourceCode" id="cb336"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="op">(</span><span class="fu"><a href="https://andrisignorell.github.io/DescTools/reference/CramerV.html">Phi</a></span><span class="op">(</span><span class="va">tabla_jud</span><span class="op">)</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span></span>
<span><span class="co">#&gt; [1] 0.1420701</span></span></code></pre></div>
</div>
<div id="odds-ratio-o-cociente-de-posibilidadestablas_conting-6" class="section level4" number="23.4.2.2">
<h4>
<span class="header-section-number">23.4.2.2</span> Odds ratio o cociente de posibilidades<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Para no confundirlo con el riesgo relativo.&lt;/p&gt;"><sup>174</sup></a><a class="anchor" aria-label="anchor" href="#odds-ratio-o-cociente-de-posibilidadestablas_conting-6"><i class="fas fa-link"></i></a>
</h4>
<p>
</p>
<p>Se define como <span class="math inline">\(\alpha=\frac {P_{11}/P_{12}} {P_{21}/P_{22}}\)</span>, donde <span class="math inline">\(P_{ij}\)</span> es la probabilidad de que un elemento de la tabla pertenezca al <em>i</em>-ésimo nivel de <em>A</em> y al <em>j</em>-ésimo de <em>B</em>, y se estima como <span class="math inline">\(\hat{\alpha}=\frac {n_{11}/n_{12}} {n_{21}/n_{22}}=\frac {n_{11}n_{22}} {n_{12}n_{21}}\)</span>.</p>
<p>Su campo de variación es <span class="math inline">\([0;\infty)\)</span>, asimétrico, y por consiguiente difícil de interpretar. En todo caso:</p>
<ul>
<li>Si <span class="math inline">\(\alpha &lt; 1\)</span>, la probabilidad (aquí denominada posibilidad) de pertenecer al nivel 1 del factor B es menor en el nivel 1 del factor A que en el 2.</li>
<li>Si <span class="math inline">\(\alpha = 1\)</span>, la probabilidad de pertenecer al nivel 1 del factor B es la misma en ambos niveles del factor A.</li>
<li>Si <span class="math inline">\(\alpha &gt; 1\)</span>, la probabilidad pertenecer de al nivel 1 del factor B es mayor en el nivel 1 del factor A que en el 2.</li>
</ul>
<p>Una posible solución a la dificultad de interpretación es definir <span class="math inline">\(ln{\alpha}\)</span>, que es una medida simétrica en <span class="math inline">\((-\infty;+\infty)\)</span>. Sin embargo, su interpretación, dada la gran amplitud del campo de variación, continúa siendo muy difusa.</p>
<!-- tal que: -->
<!-- -   Si $ln\hat{\alpha} \leq 0$,la posibilidad de trabajar en el colectivo de los varones es igual que en el colectivo de las mujeres. -->
<!-- -   Si $ln\hat{\alpha}= 0$, la posibilidad de trabajar en el colectivo de los varones es mayor que en el colectivo de las mujeres. -->
<!-- -   Si $ln\hat{\alpha} \geq 0$, la posibilidad de trabajar en el colectivo de los varones es menor que en el colectivo de las mujeres. -->
<!-- Sin embargo, la interpretación, dada la gran amplitud del campo de variación, aunque simétrico, continúa siendo muy difusa. -->
<p>Una ventaja que tiene respecto a <span class="math inline">\({\alpha}\)</span> es que no cambia si las filas se convierten en columnas y las columnas en filas.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Es decir, no es necesario identificar la variable respuesta para utilizar esta medida.&lt;/p&gt;"><sup>175</sup></a> Por ello, la razón de posibilidades se puede utilizar no sólo en estudios retrospectivos, sino también en aquéllos prospectivos y transversales. Finalmente, nótese que <span class="math inline">\((i)\)</span> la razón de posibilidades y el riesgo relativo (<span class="math inline">\(P_1/P_2\)</span>) se relacionan como sigue: <span class="math inline">\(\alpha= \frac {P_1 (1-P_2)} {P_2 (1-P_1)}\)</span>; y que <span class="math inline">\((ii)\)</span> ambos son similares cuando la probabilidad de éxito <span class="math inline">\(P_i\)</span> está cerca de cero en ambos grupos.</p>
<p>El código siguiente proporciona el valor muestral de <span class="math inline">\(\alpha\)</span> (<span class="math inline">\(\hat\alpha\)</span>) en el ejemplo que nos ocupa, así como su intervalo de confianza del 95%:</p>
<div class="sourceCode" id="cb337"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="https://fvas.unimelb.edu.au/research/groups/veterinary-epidemiology-melbourne">"epiR"</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/epiR/man/epi.2by2.html">epi.2by2</a></span><span class="op">(</span><span class="va">tabla_jud</span>, method <span class="op">=</span> <span class="st">'cohort.count'</span><span class="op">)</span><span class="op">$</span><span class="va">massoc.summary</span><span class="op">[</span><span class="fl">2</span>,<span class="op">]</span></span>
<span><span class="co">#&gt;          var       est      lower     upper</span></span>
<span><span class="co">#&gt; 2 Odds ratio 0.0952381 0.01021365 0.8880565</span></span></code></pre></div>
</div>
</div>
</div>
<div id="medidas-rxc" class="section level2" number="23.5">
<h2>
<span class="header-section-number">23.5</span> Medidas de asociación en tablas <span class="math inline">\(R\times C\)</span><a class="anchor" aria-label="anchor" href="#medidas-rxc"><i class="fas fa-link"></i></a>
</h2>
<p></p>
<p>En caso de rechazo de la hipótesis de independencia en una tabla <span class="math inline">\(R\times C\)</span>, se concluye que al menos un nivel de uno de los factores está asociado con uno del otro factor. En ese caso, se utilizarán las medidas de asociación para determinar la intensidad de la misma. Las asociaciones de determinados niveles del factor A con determinados niveles del factor B que llevan al rechazo de la independencia de ambos se denominan <strong>fuentes de asociación</strong>, y se determinan mediante los residuos estandarizados ajustados.</p>
<p>
</p>
<div id="medidas-derivadas-del-estadístico-chi-cuadrado" class="section level3" number="23.5.1">
<h3>
<span class="header-section-number">23.5.1</span> Medidas derivadas del estadístico Chi-cuadrado<a class="anchor" aria-label="anchor" href="#medidas-derivadas-del-estad%C3%ADstico-chi-cuadrado"><i class="fas fa-link"></i></a>
</h3>
<p></p>
<p>Como se avanzó en la Sec. <a href="tablas-contingencia.html#cmc">23.4.2.1</a>, el estadístico <span class="math inline">\(\chi^2\)</span> no puede utilizarse como medida de asociación porque su valor máximo, <span class="math inline">\(n(k-1)\)</span>, siendo <span class="math inline">\(n\)</span> el tamaño muestral y <span class="math inline">\(k\)</span> el número más pequeño de filas o columnas, depende tanto de <span class="math inline">\(N\)</span> como del número de niveles de los factores.</p>
<p>El cuadrado medio de la contingencia, <span class="math inline">\(\phi^2\)</span>, elimina el efecto “tamaño muestral”, pero no el efecto “número de niveles de los factores”. Igual le ocurre al coeficiente de contingencia; y a la <em>T</em> de Tschuprow, salvo en las tablas cuadradas. La única medida derivada del estadístico <span class="math inline">\(\chi^2\)</span> que corrige ambos efectos es la <em>V</em> de Cramer:
<span class="math display">\[V=\sqrt\frac{\chi^2}{kn},\]</span> con <span class="math inline">\(k=min\left(R-1; C-1\right)\)</span>. Su campo de variación es <span class="math inline">\([0,1]\)</span> y alcanza su máximo en caso de asociación perfecta. En tablas cuadradas <span class="math inline">\(V=T\)</span>.</p>
<p>
</p>
<p>En el ejemplo utilizado en la Sec. <a href="tablas-contingencia.html#contaprox">23.3.1</a>:</p>
<div class="sourceCode" id="cb338"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://andrisignorell.github.io/DescTools/reference/CramerV.html">CramerV</a></span><span class="op">(</span><span class="va">tabla_ayuso</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.0590406</span></span></code></pre></div>
<p>Aunque se rechaza la hipótesis de independencia, la asociación existente entre la opinión sobre la presidente y la zona geográfica es muy pequeña. Y ello porque, sea cual sea la zona geográfica, aunque hay ligerísimas variaciones, la opinión es muy favorable: para alrededor del 60% es excelente, para la tercera parte muy buena y tan solo para el 5% es mala (alrededor del 4%) o muy mala (apenas el 1%).</p>
</div>
<div id="medidas-basadas-en-la-reducción-proporcional-del-error-lambda-de-goodman-y-kruskal" class="section level3" number="23.5.2">
<h3>
<span class="header-section-number">23.5.2</span> Medidas basadas en la reducción proporcional del error: <span class="math inline">\(\lambda\)</span> de Goodman y Kruskal<a class="anchor" aria-label="anchor" href="#medidas-basadas-en-la-reducci%C3%B3n-proporcional-del-error-lambda-de-goodman-y-kruskal"><i class="fas fa-link"></i></a>
</h3>
<p>
</p>
<p>Al contrario que las medidas basadas en el estadístico Chi-cuadrado, exigen determinar cuál es el factor explicativo y cuál el factor a explicar. Sea <em>A</em> el factor explicativo y <em>B</em> el factor a explicar: supóngase que se selecciona aleatoriamente uno de los elementos de la tabla. Este elemento pertenecerá a un nivel “<em>i</em>” de <em>A</em> y a un nivel “<em>j</em>” de <em>B</em>. Supóngase que se quiere predecir el nivel de <em>B</em> al que pertenece, <span class="math inline">\((i)\)</span> sin utilizar el hecho de saber a que nivel de <em>A</em> pertenece, y <span class="math inline">\((ii)\)</span> utilizando dicho hecho. Lógicamente, tanto en el caso <span class="math inline">\((i)\)</span> como en el <span class="math inline">\((ii)\)</span> se comete un error <span class="math inline">\((P(i)\)</span> y <span class="math inline">\(P(ii)\)</span>, respectivamente). La probabilidad de error será la misma si los factores son independientes. Sin embargo, si están asociados, el conocimiento del nivel de <em>A</em> al que pertenece el elemento seleccionado ayudará en la predicción del nivel de <em>B</em> al que pertenece (tanto más cuanto más asociados estén los factores) y la probabilidad de error disminuirá respecto al caso <span class="math inline">\((i)\)</span>. La reducción proporcional que se opera en el error es:</p>
<p><span class="math display">\[\lambda=\frac{P(i)-P(ii)} {P(i)},\]</span></p>
<p>donde <span class="math inline">\(P(i)\)</span> y <span class="math inline">\(P(ii)\)</span> se estiman como sigue: <span class="math inline">\(\hat{P}(i)= n- \max_{j} n_{\cdot j}\)</span> y <span class="math inline">\(\hat{P}(ii)= n-\sum_{j=1}^C \max_{j} n_{\cdot j}.\)</span></p>
<p>En el caso en que <em>A</em> sea el factor a explicar, <span class="math inline">\(\hat{P}(i)= n- \max_{i} n_{i.}\)</span> y <span class="math inline">\(\hat{P}(ii)= n-\sum_{i=1}^R \max_{i} n_{i.}\)</span>.</p>
<p>En caso de no tener claro cuál es el factor a explicar, se utiliza la media agregativa de las dos medidas anteriores:</p>
<p><span class="math display">\[\hat\lambda=\frac{\sum_{j=1}^C \max_i n_{i.}-max_i n_{i.}+\sum_{i=1}^R \max_j n_{\cdot j}-\max_j n_{\cdot j} }{2n-\max_i n_{i.}\max_j n_{\cdot j}}.\]</span></p>
<p>Su campo de variación es <span class="math inline">\([0,1]\)</span>. En caso de independencia, <span class="math inline">\(\lambda=0\)</span>. Ahora bien, que <span class="math inline">\(\hat\lambda=0\)</span> no implica necesariamente que <em>A</em> y <em>B</em> tengan que ser independientes, puesto que <span class="math inline">\(\lambda\)</span> también toma el valor 0 cuando en uno de los niveles del factor a explicar las frecuencias son superiores a las de los demás niveles, y ello para todos los niveles del factor explicativo, aunque los factores no sean independientes. En caso de asociación, <span class="math inline">\(0&lt; \lambda \leq 1\)</span>, alcanzándose la unidad en caso de asociación perfecta.</p>
<p>Una limitación de <span class="math inline">\(\lambda\)</span> (además de la anterior y de que exige determinar el factor explicativo y el factor a explicar) es su sensibilidad a totales marginales desequilibrados; en este caso, toma valores anormalmente bajos. Tal es el caso del ejemplo que nos ocupa, donde <span class="math inline">\(\hat\lambda=0\)</span>, con factor a explicar la opinión, y, sin embargo, los factores no son independientes. Y es que, sea cual sea la zona geográfica, las frecuencias de la categoría de opinión “excelente” son siempre las más elevadas.</p>
<div class="sourceCode" id="cb339"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://andrisignorell.github.io/DescTools/reference/Lambda.html">Lambda</a></span><span class="op">(</span><span class="va">tabla_ayuso</span>, direction <span class="op">=</span> <span class="st">"row"</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0</span></span></code></pre></div>
</div>
<div id="determinación-de-las-fuentes-de-asociación" class="section level3" number="23.5.3">
<h3>
<span class="header-section-number">23.5.3</span> Determinación de las fuentes de asociación<a class="anchor" aria-label="anchor" href="#determinaci%C3%B3n-de-las-fuentes-de-asociaci%C3%B3n"><i class="fas fa-link"></i></a>
</h3>
<p>En el caso de tablas <span class="math inline">\(R \times C\)</span>, el rechazo la hipótesis de independencia no indica que cada nivel de uno de los factores esté asociado con uno de los niveles del otro factor, como en las tablas <span class="math inline">\(2\times 2\)</span>. Lo que indica es que al menos uno de los niveles de uno de los factores está asociado con un nivel del otro. Por tanto, puede ser, y así es normalmente, que dicho rechazo se deba a que algunos niveles de uno de los factores (incluso sólo uno) están asociados con alguno de los del otro factor. Ya no hay dirección de la asociación. Hay fuentes de asociación.</p>
<p></p>
<p>Para identificar las fuentes de asociación lo lógico es fijarse en cada celda en las diferencias entre la frecuencia observada y la esperada bajo el supuesto de independencia (tales diferencias juegan el papel de un término de error). Pero su interpretación depende del tamaño de la frecuencia esperada, y por ello se estandarizan, es decir, se ponen en relación a la raíz cuadrada de las correspondientes frecuencias esperadas.</p>
<p>
</p>
<p>Como para decidir si tales diferencias estandarizadas son significativamente grandes (asociación) o no (independencia), se necesita conocer su distribución de probabilidad bajo la hipótesis de independencia, y para ello se dividen por su desviación típica porque de esta manera tienen aproximadamente una distribución N(0;1). Cuando estas diferencias estandarizadas divididas por sus desviaciones típicas se calculan (se estiman) a partir de los resultados observados y dispuestos en la tabla, se denominan residuos estandarizados ajustados (o de Haberman), y son los que se utilizan para identificar las fuentes de asociación.</p>
<p>Por tanto, la estimación de las diferencias (los residuos) son:
<span class="math display">\[\hat{R}_{ij}=n_{ij}-\hat{E}_{ij},\]</span>
y los de las diferencias estandarizadas (los residuos estandarizados) vienen dados por:</p>
<p><span class="math display">\[\hat{R}_{ij}(est)=\frac {n_{ij}-\hat{E}_{ij}}{\sqrt{\hat{E}_{ij}}},\]</span>
mientras que la siguiente expresión corresponde a las estimaciones las dierencias estandarizadas ajustadas, que no son otras que los denominados residuos estandarizados ajustados:</p>
<p><span class="math display">\[\hat{R}_{ij}(est;ajd)=\frac{\hat{R}_{ij}(est)}{\sqrt{\left(1-\frac {n_{i.}} {N}\right)\left(1-\frac {n_{\cdot j}} {N}\right)}}.\]</span></p>
<p>Habrá una fuente de asociación en cada celda {<em>i</em>;<em>j</em>} que verifique: <span class="math inline">\(|\hat{R}_{ij}(est;ajd)|\geq{k}\)</span>, con <span class="math inline">\(k= 2,33; 1,96; 1,64\)</span> para <span class="math inline">\(\alpha=0,01; 0,05; 0,10\)</span>, respectivamente.</p>
<p>En el ejemplo que nos ocupa, los residuos estandarizados ajustados son:</p>
<div class="sourceCode" id="cb340"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="va"><a href="https://juba.github.io/questionr/">questionr</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://juba.github.io/questionr/reference/chisq.residuals.html">chisq.residuals</a></span><span class="op">(</span><span class="va">tabla_ayuso</span>, digits <span class="op">=</span> <span class="fl">2</span>, std <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt;                opinion</span></span>
<span><span class="co">#&gt; zona            n1_nefasta n2_mala n3_buena n4_excelente</span></span>
<span><span class="co">#&gt;   n1_mad_muni         0.79   -1.04    -3.77         2.41</span></span>
<span><span class="co">#&gt;   n2_metropol        -0.51    1.74     2.88        -2.78</span></span>
<span><span class="co">#&gt;   n3_extraradio      -0.45   -0.76     1.59         0.17</span></span></code></pre></div>
<p>Asumiendo <span class="math inline">\(\alpha=0,05\)</span>, las fuentes de asociación son “Madrid municipio-excelente” a costa de “buena”, y “Madrid metropolitano-buena” a costa de “excelente”.</p>
</div>
</div>
<div id="contrastes-de-independencia-en-tablas-multidimensionales" class="section level2" number="23.6">
<h2>
<span class="header-section-number">23.6</span> Contrastes de independencia en tablas multidimensionales<a class="anchor" aria-label="anchor" href="#contrastes-de-independencia-en-tablas-multidimensionales"><i class="fas fa-link"></i></a>
</h2>
<p></p>
<p>En tablas con más de dos factores (el objetivo aquí es el caso <span class="math inline">\(R \times C \times M\)</span>, por simplicidad), no sólo se puede contrastar la hipótesis de independencia global sino que, en caso de ser rechazada, también se pueden contrastar las hipótesis de <span class="math inline">\((i)\)</span> independencia parcial: dos factores están asociados y el tercero es independiente de ellos, e <span class="math inline">\((ii)\)</span> independencia condicional: dos de los factores son independientes para cada nivel del tercero pero están asociados con él.</p>
<p>En los tres casos, el estadístico de contraste (contraste aproximado) es <span class="math display">\[\chi^2=\sum_{i=1}^R \sum_{j=1}^C \sum_{m=1}^M \frac{\left (N_{ijm}-{E}_{ijm}\right)^2}{{E}_{ijm})},\]</span>
con los siguientes grados de libertad (g.l.) y <span class="math inline">\({E}_{ijm}\)</span> bajo la correspondiente <span class="math inline">\(H_0\)</span>:</p>
<p>
</p>
<p><strong>Independencia global</strong>:</p>
<p><span class="math inline">\(dl=(R\times C\times M)-(R-1)-(C-1)-(M-1)-1\)</span> y
<span class="math inline">\({E}_{ijm}=\frac{N_{i..}N_{.j.}N_{..m}}{n^2}\)</span></p>
<p><strong>Independencia parcial</strong>:</p>
<p><em>A</em> y <em>B</em> asociados entre sí pero independientes de <em>C</em>:</p>
<ul>
<li>
<span class="math inline">\(g.l.=(R\times C\times M)-(R\times C-1)-(M-1)-1\)</span> y <span class="math inline">\({E}_{ijm}=\frac{N_{ij.}N_{..m}}{n}\)</span>
</li>
</ul>
<p><em>A</em> y <em>C</em> asociados entre sí pero independientes de <em>B</em>:</p>
<ul>
<li>
<span class="math inline">\(g.l.=(R\times C\times M)-(R\times M-1)-(C-1)-1\)</span> y <span class="math inline">\({E}_{ijm}=\frac{N_{i.m}N_{.j.}}{n}\)</span>
</li>
</ul>
<p><em>B</em> y <em>C</em> asociados entre sí pero independientes de <em>A</em>:</p>
<ul>
<li>
<span class="math inline">\(g.l.=(R\times C\times M)-(C\times M-1)-(R-1)-1\)</span> y <span class="math inline">\({E}_{ijm}=\frac{N_{.jm}N_{i..}}{n}\)</span>
</li>
</ul>
<p><strong>Independencia condicional</strong></p>
<p><em>A</em> y <em>B</em> son independientes entre sí, pero están asociados con <em>C</em>:</p>
<ul>
<li>
<span class="math inline">\(g.l.=(R\times C\times M)-(R\times M-1)-(C\times M-1)-1\)</span> y <span class="math inline">\({E}_{ijm}=\frac{N_{i.m}N_{.jm}} {n}\)</span>
</li>
</ul>
<p><em>A</em> y <em>C</em> son independientes entre sí, pero están asociados con <em>B</em>:</p>
<ul>
<li>
<span class="math inline">\(g.l.=(R\times C\times M)-(R\times C-1)-(M\times C-1)-1\)</span> y
<span class="math inline">\({E}_{ijm}=\frac{N_{ij.}N_{.jm}}{n}\)</span>
</li>
</ul>
<p><em>B</em> y <em>C</em> son independientes entre sí, pero están asociados con <em>A</em>:</p>
<ul>
<li>
<span class="math inline">\(g.l.=(R\times C\times M)-(C\times R-1)-(M\times R-1)-1\)</span> y
<span class="math inline">\({E}_{ij.}=\frac{N_{i.m}N_{.jm}}{n}\)</span>
</li>
</ul>
<p>Para calcular el valor muestral del estadístico de contraste para las diferentes hipótesis, basta con sustituir las <span class="math inline">\(N_{ij}\)</span> por las frecuencias observadas (las <span class="math inline">\(n_{ij}\)</span>) y los totales marginales (<span class="math inline">\(N_{i.m}\)</span>, <span class="math inline">\(N_{.j.}\)</span>, <span class="math inline">\(N_{i..}\)</span>, etc.) por los totales marginales observados y que figuran en la tabla que surge de los datos en estudio (<span class="math inline">\(n_{i.m}\)</span>, <span class="math inline">\(n_{.j.}\)</span>, <span class="math inline">\(n_{i..}\)</span>, etc.).</p>
<p>También son interesantes las relaciones de segundo orden o superior (por ejemplo, si la asociación entre dos de los factores difiere en dirección y/o intensidad para distintos niveles del tercero), pero se estudian mediante <strong>modelos logarítmico lineales</strong>.</p>
<p></p>
<div id="resumen-20" class="section level3 unnumbered infobox_resume">
<h3>Resumen<a class="anchor" aria-label="anchor" href="#resumen-20"><i class="fas fa-link"></i></a>
</h3>
<p>Las tablas de contingencia analizan la relación entre variables categóricas. Su análisis responde preguntas como: los factores involucrados en la tabla, ¿son independientes o están asociados? Si están asociados, ¿qué niveles de dichos factores son los que están asociados?, ¿cuál es la intensidad de dicha asociación? Se aborda ampliamente el caso de tablas bifactoriales y se proponen test exactos y aproximados para el contraste de la hipótesis de independencia (para tres procedimientos de muestreo diferentes) y una selección de medidas de asociación. Finalmente, se hace una breve incursión en el ámbito de las tablas multidimensionales.</p>
</div>

</div>
</div>




  <div class="chapter-nav">
<div class="prev"><a href="cap-conjunto.html"><span class="header-section-number">22</span> Análisis conjunto</a></div>
<div class="next"><a href="cap-arboles.html"><span class="header-section-number">24</span> Árboles de clasificación y regresión</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="Índice capítulo"><h2>Índice capítulo</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#tablas-contingencia"><span class="header-section-number">23</span> Análisis de tablas de contingencia</a></li>
<li>
<a class="nav-link" href="#motiv"><span class="header-section-number">23.1</span> Introducción</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#notac"><span class="header-section-number">23.1.1</span> Notación</a></li>
<li><a class="nav-link" href="#prodecim"><span class="header-section-number">23.1.2</span> Diseños experimentales o procedimientos de muestreo que dan lugar a una tabla de contingencia</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#contraste-de-independencia-en-tablas-2-times-2"><span class="header-section-number">23.2</span> Contraste de independencia en tablas \(2 \times 2\)</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#plantgen"><span class="header-section-number">23.2.1</span> Planteamiento general del contraste exacto de independencia</a></li>
<li><a class="nav-link" href="#algoritmo"><span class="header-section-number">23.2.2</span> Algoritmo para la realización del contraste exacto de independencia</a></li>
<li><a class="nav-link" href="#contraste-de-independencia-dise%C3%B1o-tipo-1"><span class="header-section-number">23.2.3</span> Contraste de independencia: diseño tipo 1</a></li>
<li><a class="nav-link" href="#dise"><span class="header-section-number">23.2.4</span> Contraste de independencia: diseños tipo 2 y tipo 3</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#contrasteRC"><span class="header-section-number">23.3</span> Contraste de independencia en tablas \(R \times C\)</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#contaprox"><span class="header-section-number">23.3.1</span> Contrastes aproximados</a></li>
<li><a class="nav-link" href="#contraste-aproximado-con-correcci%C3%B3n-de-continuidad-1"><span class="header-section-number">23.3.2</span> Contraste aproximado con corrección de continuidad</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#medidas"><span class="header-section-number">23.4</span> Medidas de asociación en tablas \(2\times 2\)</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#la-q-de-yule"><span class="header-section-number">23.4.1</span> La \({Q}\) de Yule</a></li>
<li><a class="nav-link" href="#otras-medidas-de-asociaci%C3%B3n-para-tablas-2times-2"><span class="header-section-number">23.4.2</span> Otras medidas de asociación para tablas \(2\times 2\)</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#medidas-rxc"><span class="header-section-number">23.5</span> Medidas de asociación en tablas \(R\times C\)</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#medidas-derivadas-del-estad%C3%ADstico-chi-cuadrado"><span class="header-section-number">23.5.1</span> Medidas derivadas del estadístico Chi-cuadrado</a></li>
<li><a class="nav-link" href="#medidas-basadas-en-la-reducci%C3%B3n-proporcional-del-error-lambda-de-goodman-y-kruskal"><span class="header-section-number">23.5.2</span> Medidas basadas en la reducción proporcional del error: \(\lambda\) de Goodman y Kruskal</a></li>
<li><a class="nav-link" href="#determinaci%C3%B3n-de-las-fuentes-de-asociaci%C3%B3n"><span class="header-section-number">23.5.3</span> Determinación de las fuentes de asociación</a></li>
</ul>
</li>
<li>
<a class="nav-link" href="#contrastes-de-independencia-en-tablas-multidimensionales"><span class="header-section-number">23.6</span> Contrastes de independencia en tablas multidimensionales</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#resumen-20">Resumen</a></li></ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Fundamentos de ciencia de datos con R</strong>" coordinado por <a href="https://blog.uclm.es/gemafaviles/" class="text-light">Gema Fernández-Avilés y José-María Montero</a>. Generado por última vez el día 2023-06-16.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>Este libro ha sido generado con el paquete de R <a class="text-light" href="https://bookdown.org">bookdown</a>.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
