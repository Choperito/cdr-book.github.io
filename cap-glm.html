<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Capítulo 16 Modelos lineales generalizados | Fundamentos de ciencia de datos con R</title>
<meta name="author" content="Gema Fernández-Avilés y José-María Montero">
<meta name="description" content="Víctor Casero-Alonso\(^{a}\) y María Durbán\(^{b}\) \(^{a}\)Universidad de Castilla-La Mancha\(^{b}\)Universidad Carlos III de Madrid  16.1 Introducción Como se ha mencionado en el Cap. 15 de...">
<meta name="generator" content="bookdown 0.28 with bs4_book()">
<meta property="og:title" content="Capítulo 16 Modelos lineales generalizados | Fundamentos de ciencia de datos con R">
<meta property="og:type" content="book">
<meta property="og:image" content="/img/cover.png">
<meta property="og:description" content="Víctor Casero-Alonso\(^{a}\) y María Durbán\(^{b}\) \(^{a}\)Universidad de Castilla-La Mancha\(^{b}\)Universidad Carlos III de Madrid  16.1 Introducción Como se ha mencionado en el Cap. 15 de...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Capítulo 16 Modelos lineales generalizados | Fundamentos de ciencia de datos con R">
<meta name="twitter:description" content="Víctor Casero-Alonso\(^{a}\) y María Durbán\(^{b}\) \(^{a}\)Universidad de Castilla-La Mancha\(^{b}\)Universidad Carlos III de Madrid  16.1 Introducción Como se ha mencionado en el Cap. 15 de...">
<meta name="twitter:image" content="/img/cover.png">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.2/transition.js"></script><script src="libs/bs3compat-0.4.2/tabs.js"></script><script src="libs/bs3compat-0.4.2/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><link href="libs/tabwid-1.1.0/tabwid.css" rel="stylesheet">
<link href="libs/tabwid-1.1.0/scrool.css" rel="stylesheet">
<script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><link rel="stylesheet" href="bs4_style.css">
<link rel="stylesheet" href="bs4_book.css">
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Fundamentos de ciencia de datos con R</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Buscar" aria-label="Buscar">
</form>

      <nav aria-label="Contenido"><h2>Contenido</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Prefacio</a></li>
<li class="book-part">Ciencia, datos, software… y científicos</li>
<li><a class="" href="ciencia-datos.html"><span class="header-section-number">1</span> ¿Es la ciencia de datos una ciencia?</a></li>
<li><a class="" href="metodologia.html"><span class="header-section-number">2</span> Metodología en ciencia de datos</a></li>
<li><a class="" href="ch-110003.html"><span class="header-section-number">3</span> R para ciencia de datos</a></li>
<li><a class="" href="cap-etica.html"><span class="header-section-number">4</span> Ética en la ciencia de datos</a></li>
<li class="book-part">Bienvenidos a la jungla de datos</li>
<li><a class="" href="datos-sql.html"><span class="header-section-number">5</span> Gestión de bases de datos relacionales</a></li>
<li><a class="" href="cap-nosql.html"><span class="header-section-number">6</span> Gestión de bases de datos NoSQL</a></li>
<li><a class="" href="DGDQM.html"><span class="header-section-number">7</span> Gobierno, gestión y calidad del dato</a></li>
<li><a class="" href="id_130009.html"><span class="header-section-number">8</span> Integración y limpieza de datos</a></li>
<li><a class="" href="chap-feature.html"><span class="header-section-number">9</span> Selección y transformación de variables</a></li>
<li><a class="" href="chap-herramientas.html"><span class="header-section-number">10</span> Herramientas para el análisis en ciencia de datos</a></li>
<li><a class="" href="id_120006-aed.html"><span class="header-section-number">11</span> Análisis exploratorio de datos</a></li>
<li class="book-part">Fundamentos de estadística</li>
<li><a class="" href="Funda-probab.html"><span class="header-section-number">12</span> Probabilidad</a></li>
<li><a class="" href="Fundainfer.html"><span class="header-section-number">13</span> Inferencia estadística</a></li>
<li><a class="" href="muestreo.html"><span class="header-section-number">14</span> Muestreo y remuestreo</a></li>
<li class="book-part">Modelización estadística</li>
<li><a class="" href="cap-lm.html"><span class="header-section-number">15</span> Modelización lineal</a></li>
<li><a class="active" href="cap-glm.html"><span class="header-section-number">16</span> Modelos lineales generalizados</a></li>
<li><a class="" href="cap-gam.html"><span class="header-section-number">17</span> Modelos aditivos generalizados</a></li>
<li><a class="" href="cap-mxm.html"><span class="header-section-number">18</span> Modelos mixtos</a></li>
<li><a class="" href="cap-sparse.html"><span class="header-section-number">19</span> Modelos sparse y métodos penalizados de regresión</a></li>
<li><a class="" href="cap-series-temp.html"><span class="header-section-number">20</span> Modelización de series temporales</a></li>
<li><a class="" href="cap-discriminante.html"><span class="header-section-number">21</span> Análisis discriminante</a></li>
<li><a class="" href="cap-conjunto.html"><span class="header-section-number">22</span> Análisis conjunto</a></li>
<li><a class="" href="tablas-contingencia.html"><span class="header-section-number">23</span> Análisis de tablas de contingencia</a></li>
<li class="book-part">Machine learning supervisado</li>
<li><a class="" href="cap-arboles.html"><span class="header-section-number">24</span> Árboles de clasificación y regresión</a></li>
<li><a class="" href="cap-svm.html"><span class="header-section-number">25</span> Máquinas de vector soporte</a></li>
<li><a class="" href="cap-knn.html"><span class="header-section-number">26</span> Clasificador k-vecinos más próximos</a></li>
<li><a class="" href="cap-naive-bayes.html"><span class="header-section-number">27</span> Naive Bayes</a></li>
<li><a class="" href="cap-bagg-rf.html"><span class="header-section-number">28</span> Métodos ensamblados: bagging y random forest</a></li>
<li><a class="" href="cap-boosting-xgboost.html"><span class="header-section-number">29</span> Boosting y el algoritmo XGBoost</a></li>
<li class="book-part">Machine learning no supervisado</li>
<li><a class="" href="jerarquico.html"><span class="header-section-number">30</span> Análisis cluster: clusterización jerárquica</a></li>
<li><a class="" href="no-jerarquico.html"><span class="header-section-number">31</span> Análisis cluster: clusterización no jerárquica</a></li>
<li><a class="" href="acp.html"><span class="header-section-number">32</span> Análisis de componentes principales</a></li>
<li><a class="" href="an%C3%A1lisis-factorial.html"><span class="header-section-number">33</span> Análisis factorial</a></li>
<li><a class="" href="escalamiento-multidimensional.html"><span class="header-section-number">34</span> Escalamiento multidimensional</a></li>
<li><a class="" href="correspondencias.html"><span class="header-section-number">35</span> Análisis de correspondencias</a></li>
<li class="book-part">Deep learning</li>
<li><a class="" href="capNN.html"><span class="header-section-number">36</span> Redes neuronales artificiales</a></li>
<li><a class="" href="cap-redes-convol.html"><span class="header-section-number">37</span> Redes neuronales convolucionales</a></li>
<li class="book-part">Ciencia de datos de texto y redes</li>
<li><a class="" href="mineria-textos.html"><span class="header-section-number">38</span> Minería de textos</a></li>
<li><a class="" href="grafos.html"><span class="header-section-number">39</span> Análisis de grafos y redes sociales</a></li>
<li class="book-part">Ciencia de datos espaciales</li>
<li><a class="" href="datos-espaciales.html"><span class="header-section-number">40</span> Trabajando con datos espaciales</a></li>
<li><a class="" href="geo.html"><span class="header-section-number">41</span> Geoestadística</a></li>
<li><a class="" href="cap-econom-esp.html"><span class="header-section-number">42</span> Modelos econométricos espaciales</a></li>
<li><a class="" href="cap-pp.html"><span class="header-section-number">43</span> Procesos de puntos</a></li>
<li class="book-part">Comunica y colabora</li>
<li><a class="" href="id_120007-informes.html"><span class="header-section-number">44</span> Informes reproducibles con R Markdown y Quarto</a></li>
<li><a class="" href="shiny.html"><span class="header-section-number">45</span> Creación de aplicaciones web interactivas con Shiny</a></li>
<li><a class="" href="github.html"><span class="header-section-number">46</span> Git y GitHub R</a></li>
<li><a class="" href="geoproces.html"><span class="header-section-number">47</span> Geoprocesamiento en nube</a></li>
<li class="book-part">Casos de estudio en ciencia de datos</li>
<li><a class="" href="cap-crimen.html"><span class="header-section-number">48</span> Análisis de una red criminal</a></li>
<li><a class="" href="cap-publicidad.html"><span class="header-section-number">49</span> Optimización de inversiones publicitarias</a></li>
<li><a class="" href="cap-twitter.html"><span class="header-section-number">50</span> ¿Cómo twitea Elon Musk?</a></li>
<li><a class="" href="cap-periodismo.html"><span class="header-section-number">51</span> Análisis electoral: de Rstudio a su periódico</a></li>
<li><a class="" href="paro-clm.html"><span class="header-section-number">52</span> Crisis: impacto en el paro de Castilla-La Mancha</a></li>
<li><a class="" href="cap-rfm.html"><span class="header-section-number">53</span> Segmentación de clientes en el comerico minorista</a></li>
<li><a class="" href="cap-medicina.html"><span class="header-section-number">54</span> Análisis de datos en medicina</a></li>
<li><a class="" href="cap-futbol.html"><span class="header-section-number">55</span> Messi y Ronaldo: dos ídolos desde la perspectiva de los datos</a></li>
<li><a class="" href="cambioclimatico.html"><span class="header-section-number">56</span> Un dato sobre el cambio climático</a></li>
<li><a class="" href="cap-ree.html"><span class="header-section-number">57</span> Predicción de consumo eléctrico con redes neuronales</a></li>
<li><a class="" href="cap-sist-exp.html"><span class="header-section-number">58</span> Implementación de un sistema experto en el ámbito pediátrico</a></li>
<li><a class="" href="nlp-textil.html"><span class="header-section-number">59</span> El procesamiento del lenguaje natural para tendencias de moda en textil</a></li>
<li><a class="" href="cap-fraude.html"><span class="header-section-number">60</span> Detección de fraude de tarjetas de crédito</a></li>
<li class="book-part">Appendix</li>
<li><a class="" href="info-session.html"><span class="header-section-number">A</span> Información de la sesión</a></li>
<li><a class="" href="referncias.html">Referncias</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="cap-glm" class="section level1" number="16">
<h1>
<span class="header-section-number">Capítulo 16</span> Modelos lineales generalizados<a class="anchor" aria-label="anchor" href="#cap-glm"><i class="fas fa-link"></i></a>
</h1>
<p><em>Víctor Casero-Alonso</em><span class="math inline">\(^{a}\)</span> y
<em>María Durbán</em><span class="math inline">\(^{b}\)</span></p>
<p><span class="math inline">\(^{a}\)</span>Universidad de Castilla-La Mancha<br><span class="math inline">\(^{b}\)</span>Universidad Carlos III de Madrid</p>
<div id="introducción-7" class="section level2" number="16.1">
<h2>
<span class="header-section-number">16.1</span> Introducción<a class="anchor" aria-label="anchor" href="#introducci%C3%B3n-7"><i class="fas fa-link"></i></a>
</h2>
<p>Como se ha mencionado en el Cap. <a href="cap-lm.html#cap-lm">15</a> de modelización lineal, el objetivo detrás del uso de modelos es el de intentar explicar el comportamiento de una variable en función del comportamiento de otras que se cree que influyen en él. Por ejemplo, podría interesar <strong>predecir</strong>:</p>
<ul>
<li><p>si un empleado abandonará la empresa, o no, en función de sus años de experiencia, su formación, etc.;
o si un paciente sufrirá, o no, una enfermedad en función de su edad, sexo, nivel de colesterol, etc.</p></li>
<li><p>el número de días que un empleado puede estar de baja laboral en función del tipo de enfermedad, su antigüedad, salario, etc.;
o el número de días que un paciente puede estar hospitalizado en función de la dolencia por la que acude a urgencias, su edad, sexo, etc.</p></li>
</ul>
<p>Estos casos no pueden analizarse correctamente con el modelo de regresión lineal múltiple visto en el Cap. <a href="cap-lm.html#cap-lm">15</a>, porque la <strong>variable respuesta</strong>, la que interesa predecir en cada ejemplo, no sigue una distribución de probabilidad Normal (supuesto necesario para utilizar la regresión lineal) o ni siquiera es continua. Concretamente:</p>
<ul>
<li><p>abandonar, o no, la empresa o sufrir, o no, una enfermedad se puede modelizar mediante una variable <strong>dicotómica/binaria</strong> asignando los valores 0 y 1 a las dos posibles respuestas, lo que encaja perfectamente con una distribución de probabilidad de Bernoulli (muy distinta de la Normal, ya que es discreta, aunque podría parecerse; véase Cap. <a href="Funda-probab.html#Funda-probab">12</a>.</p></li>
<li><p>el número de días de baja (en empleados), de hospitalización (en pacientes)… son variables de tipo <strong>recuento</strong> (sólo cero o valores positivos) modelizables mediante una variable discreta que podría seguir una distribución de Poisson (que es también distinta a la Normal, por ser discreta, aunque también podría parecerse).</p></li>
</ul>
<p>En este Capítulo se aborda el <strong>modelo lineal generalizado</strong> (GLM), que generaliza el caso en que la variable respuesta sea Normal a cualquier tipo de distribución de probabilidad perteneciente a la familia exponencial y que permite varianzas no constantes en los errores. En concreto, se centra en la regresión logística y la regresión de Poisson, casos particulares de este modelo, que permiten modelizar correctamente los dos casos planteados anteriormente. Un buen libro de referencia para este Capítulo es <span class="citation">G. James et al. (<a href="referncias.html#ref-james2013introduction">2013</a>)</span>.</p>
</div>
<div id="el-modelo-y-sus-componentes" class="section level2" number="16.2">
<h2>
<span class="header-section-number">16.2</span> El modelo y sus componentes<a class="anchor" aria-label="anchor" href="#el-modelo-y-sus-componentes"><i class="fas fa-link"></i></a>
</h2>
<p>El <strong>modelo lineal generalizado</strong><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Generalized linear model. Cuidado: general y generalizado no son sinónimos en este contexto.&lt;/p&gt;"><sup>122</sup></a> se puede escribir como:
<span class="math display">\[\mu = g^{-1}(\eta),\]</span>
en el que se tienen los siguientes componentes:</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(\mu=E(Y)\)</span>, el <strong>componente aleatorio</strong>: la <strong>media</strong> de la variable respuesta <span class="math inline">\(Y\)</span>, que puede seguir cualquier distribución de probabilidad de la familia exponencial. Entre ellas están las más habituales: la Normal (por tanto el modelo de regresión lineal es un caso particular del GLM), la Bernoulli/binomial (utilizada en la regresión logística), la Poisson, la gamma, etc.</p></li>
<li><p><span class="math inline">\(\eta = X \beta\)</span>, el <strong>componente sistemático</strong>, el <strong>predictor lineal</strong>, la “estructura” que aportan las variables explicativas/predictoras <span class="math inline">\(X=(X_1, \ldots , X_p)\)</span>, que intentan explicar el comportamiento de la variable respuesta, donde <span class="math inline">\(\beta=(\beta_1, \ldots , \beta_p)\)</span> es el vector de coeficientes (parámetros) a estimar del modelo.</p></li>
<li><p><span class="math inline">\(g(\cdot)\)</span>, la novedad de los GLM, la denominada <strong>función de enlace</strong>, que relaciona los dos componentes anteriores. Esta función puede tomar distintas formas, como se verá en la siguiente Sección.</p></li>
</ol>
<p>Igual que en el modelo lineal, las dos partes o etapas fundamentales del análisis de un GLM son:</p>
<ol style="list-style-type: decimal">
<li>La <strong>especificación</strong> de la relación o estructura predefinida de antemano, mediante la <em>estimación</em> de los <em>coeficientes</em> que mejor ajustan dicha relación, utilizando el <strong>método de máxima verosimilitud</strong><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;A diferencia de la regresión lineal múltiple, que utiliza el de mínimos cuadrados.&lt;/p&gt;"><sup>123</sup></a>.
Más adelante se verá cómo se interpretan tales coeficientes y cómo se puede comprobar la adecuación del modelo.</li>
<li>La utilización del modelo estimado (especificado) para <strong>predecir</strong> nuevas respuestas, según sea el caso: valores, probabilidades de ocurrencia, etc.</li>
</ol>
<p>Para la correcta aplicación de los GLM es crucial la elección tanto de la variable respuesta como de las explicativas (que podrían ser de distinto tipo: numéricas -continuas o discretas- o categóricas/cualitativas -dicotómicas o politómicas<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;En este contexto, las variables numéricas y categóricas se denominan &lt;strong&gt;factores&lt;/strong&gt; y &lt;strong&gt;covariables&lt;/strong&gt;, respectivamente.&lt;/p&gt;"><sup>124</sup></a>), así como de la distribución de probabilidad más apropiada para la respuesta.
Como se adelantó en el Cap.<a href="cap-lm.html#cap-lm">15</a>, como muestra sirva percatarse de que una misma variable podría ser explicativa o respuesta, por ejemplo “diabetes” (sí o no), según se tenga interés en explicar la influencia de la diabetes en otra variable o la influencia de otras variables en la diabetes.
También una misma variable podría considerarse y utilizarse como variable de distinto tipo; por ejemplo, la edad puede considerarse como variable discreta (años cumplidos) o como categórica ordinal (grupos de edad), aunque es una variable continua (puede tomar cualquier valor en un intervalo).</p>
<div id="función-enlace" class="section level3" number="16.2.1">
<h3>
<span class="header-section-number">16.2.1</span> Función enlace<a class="anchor" aria-label="anchor" href="#funci%C3%B3n-enlace"><i class="fas fa-link"></i></a>
</h3>
<p></p>
<p>Cada distribución de probabilidad tiene asociada una <strong>función de enlace canónica</strong><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Podrían considerarse otras para cada distribución, pero esta cuestión excede el nivel de este Capítulo.&lt;/p&gt;"><sup>125</sup></a>:</p>
<ul>
<li>Para la Normal es la identidad: <span class="math inline">\(g(\mu)=\mu\)</span>.</li>
<li>Para la Bernoulli, es la función logit: <span class="math inline">\(g(\mu)=logit(\mu)=log (\mu / (1-\mu))\)</span>.</li>
<li>Para la Poisson, es el logaritmo: <span class="math inline">\(g(\mu)=log(\mu)\)</span>.</li>
<li>Para la Gamma es la inversa: <span class="math inline">\(g(\mu)=1/\mu\)</span>, …</li>
</ul>
<p>Tanto en el caso de la regresión logística (variable respuesta tipo Bernoulli) como en la regresión de Poisson aparece el logaritmo (neperiano) en la función de enlace, lo que conduce a efectos <strong>multiplicativos</strong> de los factores o covariables <span class="math inline">\(X_i\)</span> sobre la respuesta, como se verá más claramente en la Sec. <a href="cap-glm.html#SECCinterp">16.4.3</a>. Este es un punto que las distingue de la regresión lineal, en la que los efectos son <strong>aditivos</strong>.</p>
</div>
</div>
<div id="procedimiento-con-r-la-función-glm" class="section level2" number="16.3">
<h2>
<span class="header-section-number">16.3</span> Procedimiento con <strong>R</strong>: la función <code>glm()</code><a class="anchor" aria-label="anchor" href="#procedimiento-con-r-la-funci%C3%B3n-glm"><i class="fas fa-link"></i></a>
</h2>
<p>En el paquete <code>stats</code> (de la distribución <em>base</em> de <strong>R</strong>) se encuentra la función <code><a href="https://rdrr.io/r/stats/glm.html">glm()</a></code> que se utiliza para llevar a cabo el ajuste de un GLM:</p>
<div class="sourceCode" id="cb204"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">formula</span>, family <span class="op">=</span> <span class="va">...</span>, data <span class="op">=</span> <span class="va">...</span>, <span class="va">...</span><span class="op">)</span></span></code></pre></div>
<ul>
<li>
<code>formula</code>: para definir el <em>predictor lineal</em>; por ejemplo, <code>Y ~ X1 + X2 + X3</code>.</li>
<li>
<code>family</code>: para indicar la distribución de la variable respuesta (<code>gaussian</code>, <code>binomial</code>, <code>poisson</code> …) que determina la función de enlace (<code>binomial</code> <span class="math inline">\(\rightarrow\)</span> <code>logit</code>, etc.; consúltese <code><a href="https://rdrr.io/r/stats/family.html">?family</a></code> o <code><a href="https://rdrr.io/r/stats/glm.html">?glm</a></code> para más detalles).</li>
</ul>
<p>Las “herramientas” utilizadas para <code><a href="https://rdrr.io/r/stats/lm.html">lm()</a></code> también se pueden usar para <code><a href="https://rdrr.io/r/stats/glm.html">glm()</a></code> (aunque algunas interpretaciones varían). Así, se puede usar <code><a href="https://rdrr.io/r/base/summary.html">summary()</a></code> para detectar los predictores importantes, <code><a href="https://rdrr.io/r/stats/fitted.values.html">fitted()</a></code> para obtener los valores ajustados, etc.</p>
</div>
<div id="regresión-logística" class="section level2" number="16.4">
<h2>
<span class="header-section-number">16.4</span> Regresión logística<a class="anchor" aria-label="anchor" href="#regresi%C3%B3n-log%C3%ADstica"><i class="fas fa-link"></i></a>
</h2>
<p>La <strong>regresión logística</strong> es el caso más “famoso” de GLM, de gran relevancia en distintos contextos: Medicina, Economía, etc.
Se utiliza cuando la <strong>variable respuesta</strong> es <strong>dicotómica</strong>, del tipo pertenencia, o no, a un determinado grupo (fumadores, enfermos, morosos, …).
Habitualmente se considera que toma el valor <span class="math inline">\(Y=1\)</span> si la observación pertenece al grupo de interés e <span class="math inline">\(Y=0\)</span> en caso contrario.
Tal tipo de variable se puede modelizar con una <strong>distribución de Bernoulli</strong>, caracterizada por un parámetro <span class="math inline">\(p\)</span> que indica la probabilidad de pertenecer al grupo de interés.</p>
<p>El objetivo principal suele ser predecir el grupo al que pertenece un nuevo individuo/elemento, sobre la base de la información sobre dicho elemento/individuo que proporcionan las variables explicativas. Para ello, se estima el modelo con los datos disponibles, determinándose qué variables influyen <strong>significativamente</strong> en la variable respuesta<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Desde el punto de vista estadístico, la influencia/efecto no es fruto del azar.&lt;/p&gt;"><sup>126</sup></a>.</p>
<p><strong>¿Por qué no tiene cabida aquí el uso del modelo de regresión lineal múltiple?</strong> Al ajustar un modelo del tipo: <span class="math inline">\(Y=\beta_0 + \beta_1 X_1 + \ldots + \beta_p X_p + \epsilon,\)</span>
las estimaciones <span class="math inline">\(\hat{Y}\)</span> serán números reales que rara vez
coincidirán con 0 ó 1 (que son los valores admisibles de la variable respuesta).
Dicho de otro modo, si sólo se tuviese una variable explicativa, al ajustar el modelo de regresión lineal simple, la recta sobrepasaría, o no alcanzaría, los valores posibles de respuesta (0 ó 1), como ocurre en la Fig. <a href="cap-glm.html#fig:glm-dispersionYlogit">16.1</a> (izquierda) obtenida a partir de los datos del ejemplo de enfermedad coronaria que se manejará en la Sec. <a href="cap-glm.html#secEJreglog">16.6.1</a>.</p>
<p>El <strong>modelo de regresión logística múltiple</strong> se define como:
<span class="math display" id="eq:eta">\[\begin{equation}
   \text{logit}(p)=\log{ \Big(\dfrac{p}{1-p}  \Big)}=\beta_0 + \beta_1 X_1 + \ldots + \beta_p X_p + \epsilon,
   \tag{16.1}
\end{equation}\]</span>
que permite estimar la ratio entre
la probabilidad de pertenecer al grupo de interés, <span class="math inline">\(p\)</span>,
y la de no pertenecer a dicho grupo, <span class="math inline">\(1-p\)</span>.
Utilizando la función de enlace se puede transformar el predictor lineal <span class="math inline">\(\eta=\beta_0 + \beta_1 X_1 + \ldots + \beta_p X_p\)</span> para obtener valores admisibles para una probabilidad.
La función logística, definida como
<span class="math display" id="eq:logit">\[\begin{equation}
  p = \frac{e^\eta}{1+e^\eta}
  \tag{16.2}
\end{equation}\]</span>
y representada en la Fig. <a href="cap-glm.html#fig:glm-dispersionYlogit">16.1</a> (derecha), es la más habitual, y por ello da el nombre a la regresión logística. Con ella se obtiene la probabilidad de pertenecer al grupo de interés, <span class="math inline">\(p = P[Y = 1]\)</span>, e inmediatamente la de no pertenecer a dicho grupo, <span class="math inline">\(1-p = P[Y = 0]\)</span>.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:glm-dispersionYlogit"></span>
<img src="150017_glm_files/figure-html/glm-dispersionYlogit-1.png" alt="Gráfico de dispersión del diagnóstico frente a la edad para el ejemplo de enfermedad coronaria (izquierda) y función logística (derecha)" width="60%"><p class="caption">
Figura 16.1: Gráfico de dispersión del diagnóstico frente a la edad para el ejemplo de enfermedad coronaria (izquierda) y función logística (derecha)
</p>
</div>
<p>La ventaja del modelo logístico es que la función logística tiende a cero por la izquierda y a uno por la derecha, por lo que la predicción será
siempre un valor válido para una probabilidad. Como contrapartida, a medida que las probabilidades se acercan a cero o a uno la relación entre el predictor y la probabilidad deja de ser lineal, lo que complica la interpretación de los coeficientes.</p>
<div id="procedimiento-de-ajuste" class="section level3" number="16.4.1">
<h3>
<span class="header-section-number">16.4.1</span> Procedimiento de ajuste<a class="anchor" aria-label="anchor" href="#procedimiento-de-ajuste"><i class="fas fa-link"></i></a>
</h3>
<p>A partir de los datos disponibles de las variables <em>predictoras</em> y <em>respuesta</em>:</p>
<ol style="list-style-type: decimal">
<li>Se estiman los coeficientes <span class="math inline">\(\beta_i\)</span> del modelo, para especificar la relación entre las variables, contrastando si tales estimaciones, <span class="math inline">\(\hat\beta_i\)</span>, son o no significativas.</li>
<li>Se valora la eliminación de variables no significativas, atendiendo a la significación global del modelo, al modelo teórico subyacente, etc.</li>
<li>Se comprueba la adecuación del modelo final obtenido.</li>
<li>En caso afirmativo, se interpretan los coeficientes y el modelo queda listo para hacer <strong>predicciones</strong> de probabilidades o para <strong>clasificar</strong> individuos/elementos.</li>
</ol>
<div class="infobox">
<p><strong>Nota</strong></p>
<p>Como se menciona en el Cap. <a href="cap-lm.html#cap-lm">15</a>, un coeficiente es <em>significativo</em> cuando su <em>p-valor</em> asociado es lo <em>suficientemente pequeño</em> (como norma general, inferior a 0.05). No obstante, pueden tomarse otros valores de referencia; por ejemplo, en las salidas de <strong>R</strong> aparecen otros tres niveles de referencia, 0.1, 0.01 y 0.001.</p>
</div>
</div>
<div id="secADECUACION" class="section level3" number="16.4.2">
<h3>
<span class="header-section-number">16.4.2</span> Adecuación del modelo<a class="anchor" aria-label="anchor" href="#secADECUACION"><i class="fas fa-link"></i></a>
</h3>
<p>Para comprobar si el modelo estimado es adecuado, se compara con el modelo más simple, el que solo incluye el término independiente.
Para ello, se pueden utilizar distintos contrastes basados en la <strong>deviance</strong>,<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;En ocasiones traducida como &lt;em&gt;devianza&lt;/em&gt;, aunque es habitual no traducirla.&lt;/p&gt;"><sup>127</sup></a> una medida que juega el papel de la suma de cuadrados de los residuos.
En el modelo de regresión logística, la <em>deviance</em> de un modelo es menos dos veces el logaritmo de la <strong>verosimilitud</strong> de dicho modelo.
La diferencia entre la <em>deviance</em> de un modelo más elaborado y el simple se distribuye como una <span class="math inline">\(\chi^2\)</span> con tantos grados de libertad como restricciones impuestas a los parámetros, lo que permite contrastar cuál de los dos modelos ajusta mejor los datos.
P-valores bajos indican que el modelo ajustado es inadecuado, debiendo investigarse otras posibles variables predictoras, si se incumple la hipótesis de linealidad o existe sobredispersión (por ejemplo por exceso de ceros).</p>
<p>Adicionalmente, se puede aplicar el contraste de la <strong>razón de verosimilitudes</strong>. Este test contrasta la significación de cada cada variable predictora, basándose en la <em>deviance</em> que se genera al añadir cada variable secuencialmente al modelo que contiene las anteriores, lo que ayuda a decidir si mantenerla o eliminarla del modelo.</p>
<p>Para contrastar la bondad de ajuste del modelo, el contraste más popular en la literatura es el de <em>Hosmer-Lemeshow</em>, aplicable a modelos con al menos una variable cuantitativa.
P-valores bajos indican falta de ajuste.</p>
<p>Continuando con las medidas de bondad de ajuste, en el modelo de regresión logística no tiene sentido calcular el coeficiente de determinación lineal, <span class="math inline">\(R^2\)</span>, pero existen varias alternativas equivalentes para hacerse una idea de la variabilidad de la respuesta explicada por el modelo.
Las tres más populares son el Pseudo <span class="math inline">\(R^2\)</span> de McFadden, el <span class="math inline">\(R^2\)</span> de Cox y Snell (que por construcción no puede alcanzar el 1)
y el <span class="math inline">\(R^2\)</span> de Nagelkerke (una corrección del de Cox y Snell).</p>
</div>
<div id="SECCinterp" class="section level3" number="16.4.3">
<h3>
<span class="header-section-number">16.4.3</span> Interpretación de resultados<a class="anchor" aria-label="anchor" href="#SECCinterp"><i class="fas fa-link"></i></a>
</h3>
<p>La interpretación de los coeficientes no es tan directa y sencilla como en el modelo lineal.
A partir de las estimaciones del predictor lineal <span class="math inline">\(\hat{\eta}\)</span>, modelo <a href="cap-glm.html#eq:eta">(16.1)</a>, se puede estimar la probabilidad de que un individuo pertenezca al grupo de interés utilizando la expresión <a href="cap-glm.html#eq:logit">(16.2)</a>. Alternativamente se puede estimar el <em>odds</em>, con la siguiente expresión, que se deduce de <a href="cap-glm.html#eq:eta">(16.1)</a>:
<span class="math display" id="eq:odds">\[\begin{equation}
\mathit{odds} = \frac{\hat{p}}{1-\hat{p}} =  e^{\hat{\eta}} = e^{\hat{\beta}_0 + \hat{\beta}_1 X_1 + \ldots + \hat{\beta}_k X_k}.
\tag{16.3}
\end{equation}\]</span>
El <em>odds</em> se puede explicar como cuántas veces es más probable pertenecer al grupo de interés (<span class="math inline">\(Y=1\)</span>) que al otro grupo (<span class="math inline">\(Y=0\)</span>).
Por ejemplo, si <span class="math inline">\(\hat{p} = 0.75\)</span> el <em>odds</em> es <span class="math inline">\(0.75/0.25=3\)</span>, entonces es tres veces más probable pertenecer al grupo de interés que no pertenecer<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Por esto se traduce &lt;em&gt;odds&lt;/em&gt; como &lt;em&gt;ventaja&lt;/em&gt;. Pero cuidado con su uso: si &lt;span class="math inline"&gt;\(Y=1\)&lt;/span&gt; es tener un accidente, no parece muy adecuado hablar de ventaja. Por esto mismo, a &lt;span class="math inline"&gt;\(p\)&lt;/span&gt; tampoco se le denomina aquí probabilidad de éxito.&lt;/p&gt;'><sup>128</sup></a>.</p>
<p>La ecuación <a href="cap-glm.html#eq:odds">(16.3)</a> se puede expresar, equivalentemente, como:
<span class="math display" id="eq:modds1">\[\begin{equation}
\mathit{odds}=e^{\hat{\beta}_0} \cdot e^{\hat{\beta}_1 X_1} \cdot \ldots \cdot e^{\hat{\beta}_k X_k}.  
\tag{16.4}
\end{equation}\]</span>
La interpretación de los <span class="math inline">\(\hat{\beta}_i\)</span> carece de sentido. Lo interpretable son los <span class="math inline">\(e^{\hat\beta_i}\)</span>, denominados <strong>odd ratios</strong> (OR) .
Como el modelo <a href="cap-glm.html#eq:modds1">(16.4)</a> es multiplicativo (sus términos aparecen multiplicando, no sumando), por lo que valores de <span class="math inline">\(e^{\hat{\beta}_i}\)</span> inferiores a 1 implican disminución en el valor del odds –se reduce la probabilidad de pertenecer al grupo de interés respecto a la de no pertenecer– y valores por encima de 1 implican incremento del valor del odds, <em>ceteris paribus</em><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Manteniendo constante el valor de las demás variables.&lt;/p&gt;"><sup>129</sup></a>. En concreto, <span class="math inline">\(100(e^{\hat{\beta}_i}-1)\)</span> indica la variación porcentual en el <span class="math inline">\(odds\)</span> ante un incremento unitario en la variable explicativa <span class="math inline">\(X_i\)</span>, mientras que <span class="math inline">\(100(e^{-\hat{\beta}_i}-1)\)</span> indica el cambio porcentual que se opera en el <span class="math inline">\(odds\)</span> debido a un decremento unitario de dicha variable explicativa, <span class="math inline">\(ceteris \hspace{0,1cm} paribus\)</span>.</p>
<p>El modelo de regresión logística se acompañar del denominado <strong>riesgo relativo</strong> (RR, <em>relative risk</em>). Es una razón de
probabilidades como el <em>odds</em>, pero en vez de comparar la probabilidad de pertenecer a un grupo
o a otro de la variable respuesta, compara las probabilidades de pertenecer al grupo de referencia (<span class="math inline">\(Y=1\)</span>) según los valores del predictor categórico <span class="math inline">\(X_i\)</span>.
El riesgo relativo es similar al OR de la variable <span class="math inline">\(X_i\)</span> sólo cuando la probabilidad de <span class="math inline">\(Y=1\)</span> es pequeña; se suele dar como referencia que sea inferior al 10%. Por lo tanto, OR y RR no coinciden siempre.</p>
</div>
<div id="predicción.-curva-roc-y-auc" class="section level3" number="16.4.4">
<h3>
<span class="header-section-number">16.4.4</span> Predicción. Curva ROC y AUC<a class="anchor" aria-label="anchor" href="#predicci%C3%B3n.-curva-roc-y-auc"><i class="fas fa-link"></i></a>
</h3>
<p>Como se ha mencionado anteriormente, el uso habitual de la regresión logística es la predicción, no tanto de probabilidades, sino de la clasificación en un grupo u otro de futuros individuos/elementos en base a la información conocida de ellos a través de las variables explicativas.
La regla de clasificación en los grupos depende de la elección del punto de corte de la probabilidad, por ejemplo <span class="math inline">\(\hat{Y}=1\)</span> si <span class="math inline">\(\hat p&gt;0.7\)</span> e <span class="math inline">\(\hat{Y}=0\)</span> en otro caso.
Para seleccionar dicho punto de corte, se acude al análisis de los casos clasificados correctamente o no por el modelo ajustado: análisis de la sensibilidad y la especificidad del modelo, a su visualización más popular, la <strong>curva ROC</strong> (<em>receiver operating characteristic</em>) y la medición del área bajo dicha curva, AUC (<em>area under the curve ROC</em>); véase Cap. <a href="chap-feature.html#chap-feature">9</a>.</p>
<p>La <strong>sensibilidad</strong>, o tasa de verdaderos positivos, se define como el cociente entre estos y la suma de los verdaderos positivos y los falsos negativos.
La <strong>especificidad</strong>, o tasa de verdaderos negativos, es el cociente entre estos y la suma de los verdaderos negativos y los falsos positivos. Por consiguiente, la sensibilidad es una medida de la probabilidad de que un caso real positivo (<span class="math inline">\(Y=1\)</span>) sea clasificado correctamente como positivo por el modelo (<span class="math inline">\(\hat{Y}=1\)</span>). Equivalentemente, la especificidad es la probabilidad de clasificar correctamente casos negativos.</p>
<p>Gráficamente, se pueden obtener los valores de la sensibilidad y especificidad para distintos puntos de corte (entre 0 y 1).
La Fig. <a href="cap-glm.html#fig:glm-roc">16.2</a> (izquierda) muestra este gráfico para uno de los casos prácticos<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;La interpretación del gráfico se hace en la sección donde aparece la figura.&lt;/p&gt;"><sup>130</sup></a>.
Pero la forma más popular de analizar la sensibilidad y la especificidad es
mediante la curva ROC, que representa, para los distintos puntos de corte considerados, la <em>sensibilidad</em> frente a la tasa de falsos positivos, esto es la <em>1-especificidad</em> (Fig. <a href="cap-glm.html#fig:glm-roc">16.2</a> (derecha)).
Su AUC sirve para comparar distintos modelos de regresión logística (u otros modelos con el mismo fin<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Véase el Cap. &lt;a href="chap-feature.html#chap-feature"&gt;9&lt;/a&gt;&lt;/p&gt;'><sup>131</sup></a>).
Cuanto mayor poder discriminante tenga el modelo, más próxima a la unidad estará la AUC.
Un clasificador aleatorio presentaría la curva ROC coincidente con la diagonal, con una AUC de 0.5.</p>
</div>
</div>
<div id="regresión-de-poisson" class="section level2" number="16.5">
<h2>
<span class="header-section-number">16.5</span> Regresión de Poisson<a class="anchor" aria-label="anchor" href="#regresi%C3%B3n-de-poisson"><i class="fas fa-link"></i></a>
</h2>
<p>Se utiliza cuando la <strong>variable respuesta</strong> es <strong>discreta</strong>,sólo toma valores no negativos y su distribución de probabilidad es modelizable mediante la <strong>distribución de Poisson</strong>. Por ejemplo, las variables de tipo “número de”, como la del ejemplo motivador del principio: número de días de hospitalización.
El parámetro que caracteriza la distribución de Poisson es <span class="math inline">\(\lambda\)</span>, que representa tanto la media como la varianza de la variable aleatoria (a nivel teórico).</p>
<p>Dados los anteriores condicionantes, en esta tesitura tampoco tiene cabida el modelo de regresión lineal, principalmente porque las estimaciones <span class="math inline">\(\hat{Y}\)</span> podrían arrojar valores negativos.</p>
<p>De nuevo el objetivo suele ser la predicción: en el ejemplo, el número de días que un (nuevo) paciente estará hospitalizado (<span class="math inline">\(0, 1, 2, \ldots\)</span>), en base a la información proporcionada por las variables explicativas.
Previo a la predicción, se estima el modelo, a partir de los datos disponibles, para determinar las variables explicativas que influyen significativamente sobre la variable respuesta. Y, nuevamente, los efectos serán <em>multiplicativos</em>, dado que la función de enlace es de tipo logarítmico, como se ha visto en la Sec. <a href="cap-glm.html#SECCinterp">16.4.3</a>. Por ello, todo lo visto anteriormente para la regresión logística es válido para la regresión de Poisson.</p>
</div>
<div id="casos-prácticos" class="section level2" number="16.6">
<h2>
<span class="header-section-number">16.6</span> Casos prácticos<a class="anchor" aria-label="anchor" href="#casos-pr%C3%A1cticos"><i class="fas fa-link"></i></a>
</h2>
<div id="secEJreglog" class="section level3" number="16.6.1">
<h3>
<span class="header-section-number">16.6.1</span> Ejemplos de regresión logística<a class="anchor" aria-label="anchor" href="#secEJreglog"><i class="fas fa-link"></i></a>
</h3>
<p>Para llevar a cabo estos ejemplos, se utiliza el conjunto de datos <code>cleveland</code> incluido en el paquete <code>CDR</code> que acompaña este libro. Se quiere explicar la variable <code>diag</code> (diagnóstico; dicotómica: 1, ha sufrido una enfermedad coronaria; 0, no la ha sufrido) a partir de otras variables. La variable respuesta <code>diag</code> ya aparece como factor en la base de datos.</p>
<p><strong>Estimación</strong><br>
Primeramente, se considera un primer modelo con dos variables explicativas continuas <code>edad</code> y <code>dep</code> (depresión en el segmento ST):</p>
<div class="sourceCode" id="cb205"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st">"CDR"</span><span class="op">)</span></span>
<span><span class="va">reg_log</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">diag</span> <span class="op">~</span> <span class="va">edad</span> <span class="op">+</span> <span class="va">dep</span>, </span>
<span>               family <span class="op">=</span> <span class="st">"binomial"</span>, data <span class="op">=</span> <span class="va">cleveland</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">reg_log</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; glm(formula = diag ~ edad + dep, family = "binomial", data = cleveland)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Deviance Residuals: </span></span>
<span><span class="co">#&gt;     Min       1Q   Median       3Q      Max  </span></span>
<span><span class="co">#&gt; -2.3804  -0.8905  -0.6210   1.0021   1.9644  </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    </span></span>
<span><span class="co">#&gt; (Intercept) -3.08080    0.81939  -3.760  0.00017 ***</span></span>
<span><span class="co">#&gt; edad         0.03738    0.01476   2.532  0.01134 *  </span></span>
<span><span class="co">#&gt; dep          0.86851    0.13791   6.298 3.02e-10 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; (Dispersion parameter for binomial family taken to be 1)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     Null deviance: 417.98  on 302  degrees of freedom</span></span>
<span><span class="co">#&gt; Residual deviance: 350.64  on 300  degrees of freedom</span></span>
<span><span class="co">#&gt; AIC: 356.64</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Number of Fisher Scoring iterations: 4</span></span></code></pre></div>
<p>En la salida se muestran las estimaciones de los coeficientes del modelo (columna <code>Estimate</code>) y su significatividad (columna <code>Pr(&gt;|z|)</code>). En este ejemplo, los dos coeficientes de interés (los correspondientes a <code>edad</code> y <code>dep</code>) son significativos (a un nivel de significación del 5%).</p>
<p>Puede observarse que, dicha salida, también incluye la <em>null deviance</em> y la <em>residual deviance</em>. La primera indica lo “bien” que predice el modelo sin variables explicativas (tan sólo con el término independiente o intercepto); la segunda indica lo “bien” que predice el modelo con variables explicativas. Como se avanzó anteriormente, un contraste Chi-cuadrado permitirá dilucidar si el modelo con variables explicativas predice significativamente mejor que el que solo tiene un término independiente y su predicción, sea cual sea el valor de las variables explicativas, es siempre la media de los valores de la variable respuesta.</p>
<p>Se completa el modelo anterior añadiendo variables categóricas –concretamente, <code>tdolor</code> (politómica, tipo de dolor) y <code>sexo</code> (dicotómica)– para poder incluir más adelante la interpretación de los coeficientes asociados a este tipo de variables.
Para su correcta interpretación, se deben introducir en el predictor como variables de tipo <code>factor</code><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt; En este caso ya están definidas como &lt;code&gt;factor&lt;/code&gt; en el &lt;code&gt;data.frame&lt;/code&gt;.&lt;/p&gt;"><sup>132</sup></a>. De lo contrario, el procedimiento las considera numéricas, obteniéndose una salida que llevaría a una interpretación errónea.</p>
<div class="sourceCode" id="cb206"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">reg_log2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">reg_log</span>, <span class="op">~</span> <span class="va">.</span> <span class="op">+</span> <span class="va">sexo</span> <span class="op">+</span> <span class="va">tdolor</span><span class="op">)</span></span></code></pre></div>
<p><strong>Adecuación del modelo</strong><br>
Para evaluar la bondad de ajuste de los modelos se lleva a cabo el contraste de Hosmer-Lemeshow:</p>
<div class="sourceCode" id="cb207"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="https://github.com/psolymos/ResourceSelection">"ResourceSelection"</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/ResourceSelection/man/hoslem.test.html">hoslem.test</a></span><span class="op">(</span><span class="va">reg_log</span><span class="op">$</span><span class="va">y</span>, <span class="va">reg_log</span><span class="op">$</span><span class="va">fitted.values</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Hosmer and Lemeshow goodness of fit (GOF) test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  reg_log$y, reg_log$fitted.values</span></span>
<span><span class="co">#&gt; X-squared = 5.631, df = 8, p-value = 0.6885</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/ResourceSelection/man/hoslem.test.html">hoslem.test</a></span><span class="op">(</span><span class="va">reg_log2</span><span class="op">$</span><span class="va">y</span>, <span class="va">reg_log2</span><span class="op">$</span><span class="va">fitted.values</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Hosmer and Lemeshow goodness of fit (GOF) test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  reg_log2$y, reg_log2$fitted.values</span></span>
<span><span class="co">#&gt; X-squared = 4.8171, df = 8, p-value = 0.7769</span></span></code></pre></div>
<p>En ambos casos, los p-valores son “altos”, indicando un ajuste suficiente.</p>
<p>Para realizar el test de la razón de verosimilitudes con <strong>R</strong> se acude a la función <code><a href="https://rdrr.io/r/stats/anova.html">anova()</a></code>:</p>
<div class="sourceCode" id="cb208"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">reg_log2</span>, test <span class="op">=</span> <span class="st">"Chisq"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Analysis of Deviance Table</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Model: binomial, link: logit</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Response: diag</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Terms added sequentially (first to last)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;        Df Deviance Resid. Df Resid. Dev  Pr(&gt;Chi)    </span></span>
<span><span class="co">#&gt; NULL                     302     417.98              </span></span>
<span><span class="co">#&gt; edad    1   15.447       301     402.54 8.487e-05 ***</span></span>
<span><span class="co">#&gt; dep     1   51.894       300     350.64 5.858e-13 ***</span></span>
<span><span class="co">#&gt; sexo    1   23.982       299     326.66 9.726e-07 ***</span></span>
<span><span class="co">#&gt; tdolor  3   62.153       296     264.51 2.037e-13 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span></code></pre></div>
<p>Las <em>deviances</em> correspondientes a añadir secuencialmente cada variable o factor al modelo que contiene los anteriores permite concluir que dicha inclusión secuencial de tales variables predictoras es significativa respecto a los modelos que no las incluyen.</p>
<p>Para completar, se podría contrastar también el efecto de una variable sobre la respuesta comparando la <em>deviance</em> del modelo con dicha variable y sin ella:</p>
<div class="sourceCode" id="cb209"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">## se elimina edad del segundo modelo</span></span>
<span><span class="va">reg_log3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/update.html">update</a></span><span class="op">(</span><span class="va">reg_log2</span>, <span class="op">~</span> <span class="va">.</span> <span class="op">-</span> <span class="va">edad</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/anova.html">anova</a></span><span class="op">(</span><span class="va">reg_log3</span>, <span class="va">reg_log2</span>, test <span class="op">=</span> <span class="st">"Chisq"</span><span class="op">)</span></span>
<span><span class="co">#&gt; Analysis of Deviance Table</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Model 1: diag ~ dep + sexo + tdolor</span></span>
<span><span class="co">#&gt; Model 2: diag ~ edad + dep + sexo + tdolor</span></span>
<span><span class="co">#&gt;   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)   </span></span>
<span><span class="co">#&gt; 1       297     274.45                        </span></span>
<span><span class="co">#&gt; 2       296     264.51  1   9.9488  0.00161 **</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span></code></pre></div>
<p>El resultado indica que la variable <code>edad</code> se considera un predictor significativo en el modelo.
Se deja al lector realizar este ejercicio con las restantes variables, que le llevarán a concluir que todas son predictores significativos.</p>
<p>El valor del Pseudo <span class="math inline">\(R^2\)</span> de McFadden se obtiene como sigue:</p>
<div class="sourceCode" id="cb210"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">null</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">diag</span> <span class="op">~</span> <span class="fl">1</span>, family <span class="op">=</span> <span class="st">"binomial"</span>, data <span class="op">=</span> <span class="va">cleveland</span><span class="op">)</span></span>
<span><span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/logLik.html">logLik</a></span><span class="op">(</span><span class="va">reg_log</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/stats/logLik.html">logLik</a></span><span class="op">(</span><span class="va">null</span><span class="op">)</span></span>
<span><span class="co">#&gt; 'log Lik.' 0.1611088 (df=3)</span></span>
<span><span class="fl">1</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/logLik.html">logLik</a></span><span class="op">(</span><span class="va">reg_log2</span><span class="op">)</span> <span class="op">/</span> <span class="fu"><a href="https://rdrr.io/r/stats/logLik.html">logLik</a></span><span class="op">(</span><span class="va">null</span><span class="op">)</span></span>
<span><span class="co">#&gt; 'log Lik.' 0.3671819 (df=7)</span></span></code></pre></div>
<p>Para el primer modelo el Pseudo <span class="math inline">\(R^2\)</span> de McFadden es 0.16, mientras que para el segundo es 0.37.</p>
<p><strong>Interpretación de los coeficientes</strong><br>
A continuación se muestran los coeficientes estimados del segundo modelo y sus correspondientes OR (sus exponenciales) que son los interpretables:</p>
<div class="sourceCode" id="cb211"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">reg_log2</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Call:</span></span>
<span><span class="co">#&gt; glm(formula = diag ~ edad + dep + sexo + tdolor, family = "binomial", </span></span>
<span><span class="co">#&gt;     data = cleveland)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Deviance Residuals: </span></span>
<span><span class="co">#&gt;     Min       1Q   Median       3Q      Max  </span></span>
<span><span class="co">#&gt; -2.5346  -0.6604  -0.2436   0.6568   2.3975  </span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Coefficients:</span></span>
<span><span class="co">#&gt;             Estimate Std. Error z value Pr(&gt;|z|)    </span></span>
<span><span class="co">#&gt; (Intercept) -6.67669    1.30016  -5.135 2.82e-07 ***</span></span>
<span><span class="co">#&gt; edad         0.05621    0.01828   3.075   0.0021 ** </span></span>
<span><span class="co">#&gt; dep          0.80890    0.16597   4.874 1.10e-06 ***</span></span>
<span><span class="co">#&gt; sexo1        1.69477    0.36801   4.605 4.12e-06 ***</span></span>
<span><span class="co">#&gt; tdolor2      0.65668    0.67357   0.975   0.3296    </span></span>
<span><span class="co">#&gt; tdolor3      0.19465    0.59654   0.326   0.7442    </span></span>
<span><span class="co">#&gt; tdolor4      2.58230    0.57549   4.487 7.22e-06 ***</span></span>
<span><span class="co">#&gt; ---</span></span>
<span><span class="co">#&gt; Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; (Dispersion parameter for binomial family taken to be 1)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;     Null deviance: 417.98  on 302  degrees of freedom</span></span>
<span><span class="co">#&gt; Residual deviance: 264.51  on 296  degrees of freedom</span></span>
<span><span class="co">#&gt; AIC: 278.51</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; Number of Fisher Scoring iterations: 5</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">reg_log2</span><span class="op">)</span><span class="op">)</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span></span>
<span><span class="co">#&gt;      edad       dep     sexo1   tdolor2   tdolor3   tdolor4 </span></span>
<span><span class="co">#&gt;  1.057824  2.245432  5.445391  1.928371  1.214880 13.227480</span></span></code></pre></div>
<p>Los coeficientes asociados a las variables continuas son significativos y positivos, por tanto sus OR son significativamente superiores a 1.
Indican que, <em>ceteris paribus</em>,</p>
<ul>
<li>por cada año más, el odds de padecer la enfermedad frente a no padecerla se incrementa<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Por ser el coeficiente mayor que 1.&lt;/p&gt;"><sup>133</sup></a> un 5.78% (al ser el valor del OR asociado a la edad 1.0578). ¿Y cuál sería el incremento en el <em>odds</em> ante un aumento de la edad en 20 años? En tal caso, el odds ser multiplicaría por <span class="math inline">\(e^{\hat{\beta}_1*20} =\)</span> 3.078, es decir, más que se triplica. Se debe ser cuidadoso con la interpretación: no se triplica la probabilidad sino el odds.</li>
<li>Ante un aumento de una unidad en la variable <em>dep</em> más que se duplica el <em>odds</em> del paciente, pues su OR es 2.2454.</li>
</ul>
<div class="infobox">
<p><strong>Nota</strong></p>
<p>En regresión lineal, que un coeficiente sea significativo quiere decir que es significativamente distinto de cero, por el hecho de que el modelo considera <em>efectos aditivos</em> de las variables. El modelo de regresión logística es de <em>efectos multiplicativos</em> y, por ello, el valor “neutro” es el 1. Por tanto, un coeficiente significativo se interpreta como significativamente distinto de 1.</p>
</div>
<p>¿Y cómo se interpretan los coeficientes asociados a las variables categóricas?
¿Qué significan los valores de <code>sexo1</code>, <code>tdolor2</code>…? Representan el cambio (promedio) en la variable respuesta al pasar de la categoría de referencia a la mostrada.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;En las variables definidas como &lt;code&gt;factor&lt;/code&gt; &lt;strong&gt;R&lt;/strong&gt; toma como referencia la primera categoría al ordenarse los valores de la variable, bien alfabéticamente (a, b, c…) o bien numéricamente, de menor a mayor, salvo que se haya especificado otro orden. De ahí que &lt;code&gt;sexo=0&lt;/code&gt; sea la categoría de referencia, porque esta variable toma los valores 0 y 1, y sólo aparezca en las estimaciones &lt;code&gt;sexo1&lt;/code&gt;, reflejando el cambio medio en la variable respuesta al pasar de la categoría de referencia a la categoría 1. Para &lt;code&gt;tdolor&lt;/code&gt;, al tomar los valores 1, 2, 3 y 4, la categoría de referencia es &lt;code&gt;tdolor=1&lt;/code&gt;, apareciendo coeficientes para &lt;code&gt;tdolor=2&lt;/code&gt;, &lt;code&gt;tdolor=3&lt;/code&gt; y &lt;code&gt;tdolor=4&lt;/code&gt;.&lt;/p&gt;"><sup>134</sup></a></p>
<ul>
<li>el de <code>sexo1</code> significa que el odds de padecer la enfermedad en los hombres (<code>sexo=1</code>) es más de 5 veces superior que en las mujeres (<code>sexo=0</code>).</li>
<li>el de <code>tdolor4</code> indica que los individuos con este tipo de dolor (asintomáticos) presentan un odds 13 veces superior al de los de <code>tdolor=1</code> (angina típica).<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Los coeficientes de &lt;code&gt;tdolor2&lt;/code&gt; y &lt;code&gt;tdolor3&lt;/code&gt; no son significativos.&lt;/p&gt;"><sup>135</sup></a>
</li>
</ul>
<p>Nótese que no se muestra <span class="math inline">\(e^{\beta_0}\)</span>, pues su interpretación carece de sentido práctico: sería el OR de las personas de 0 años, <code>dep=0</code>, <code>sexo=0</code> y <code>tdolor=1</code>.</p>
<p><strong>Predicciones</strong><br>
Una vez estimado el modelo y comprobada su bondad, se puede usar para obtener predicciones.
Para ello, se deben asignar valores a las variables explicativas: <code>edad</code>, <code>dep</code>, <code>sexo</code> y <code>tdolor</code> (se han escogido arbitrariamente).</p>
<div class="sourceCode" id="cb212"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">individuo</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>edad <span class="op">=</span> <span class="fl">50</span>, dep <span class="op">=</span> <span class="fl">3</span>, </span>
<span>                        sexo <span class="op">=</span> <span class="st">"1"</span>, tdolor <span class="op">=</span> <span class="st">"4"</span> <span class="co">#entre comillas por ser factores</span></span>
<span>                        <span class="op">)</span> </span></code></pre></div>
<p>Con la función <code><a href="https://rdrr.io/r/stats/predict.html">predict()</a></code> se puede obtener tanto el valor predicho para el predictor lineal (valor no interpretable), <span class="math inline">\(\eta\)</span>, como directamente la probabilidad de que dicho individuo sufra la enfermedad coronaria, <span class="math inline">\(p\)</span>:</p>
<div class="sourceCode" id="cb213"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co">#(eta &lt;- predict(reg_log2, individuo))</span></span>
<span><span class="op">(</span><span class="va">p</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">reg_log2</span>, <span class="va">individuo</span>, type <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;         1 </span></span>
<span><span class="co">#&gt; 0.9446843</span></span></code></pre></div>
<p>A partir del valor de <span class="math inline">\(p\)</span> (o de <span class="math inline">\(\eta\)</span>) se puede obtener el <em>odds</em> correspondiente:</p>
<div class="sourceCode" id="cb214"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">p</span> <span class="op">/</span> <span class="op">(</span><span class="fl">1</span> <span class="op">-</span> <span class="va">p</span><span class="op">)</span> <span class="co"># exp(eta)</span></span>
<span><span class="co">#&gt;        1 </span></span>
<span><span class="co">#&gt; 17.07805</span></span></code></pre></div>
<p>Es decir, un individuo con 50 años, <code>dep=3</code>, <code>sexo=1</code> (hombre) y <code>tdolor=4</code> (asintomático) tiene una probabilidad de padecer la enfermedad en cuestión 17 veces mayor que de no padecerla.</p>
<p><strong>Riesgo relativo</strong><br>
Se ha visto que el OR para la categoría hombre en el segundo modelo es 5.45. El riesgo relativo de sufrir la enfermedad, en el caso de los varones, para un paciente de 50 años, valor <code>dep=3</code> y <code>tdolor=4</code> (asintomático) es:</p>
<div class="sourceCode" id="cb215"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">hom</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>edad <span class="op">=</span> <span class="fl">50</span>, dep <span class="op">=</span> <span class="fl">3</span>, sexo <span class="op">=</span> <span class="st">"1"</span>, tdolor <span class="op">=</span> <span class="st">"4"</span><span class="op">)</span></span>
<span><span class="va">muj</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span>edad <span class="op">=</span> <span class="fl">50</span>, dep <span class="op">=</span> <span class="fl">3</span>, sexo <span class="op">=</span> <span class="st">"0"</span>, tdolor <span class="op">=</span> <span class="st">"4"</span><span class="op">)</span></span>
<span><span class="op">(</span><span class="va">ph</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">reg_log2</span>, <span class="va">hom</span>, type <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;         1 </span></span>
<span><span class="co">#&gt; 0.9446843</span></span>
<span><span class="op">(</span><span class="va">pm</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">reg_log2</span>, <span class="va">muj</span>, type <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;         1 </span></span>
<span><span class="co">#&gt; 0.7582346</span></span>
<span><span class="va">ph</span> <span class="op">/</span> <span class="va">pm</span> <span class="co"># riesgo relativo hombre/mujer</span></span>
<span><span class="co">#&gt;      1 </span></span>
<span><span class="co">#&gt; 1.2459</span></span></code></pre></div>
<p>El riesgo relativo de sufrir la enfermedad, en el caso de los varones, es <span class="math inline">\(RR\)</span>=0.9447/0.7582 = 1.2459, es
decir, un varón tiene un 24.6% más de posibilidades de tener la enfermedad que una mujer con sus mismos valores o categorías en las variables que se usan como predictores. En este caso, el OR y el RR no son valores cercanos; ello es debido a que el diagnóstico 1 es frecuente (concretamente lo presentan el 45.9% de los pacientes de la base de datos).</p>
<p><strong>Curva ROC</strong><br>
El análisis de sensibilidad y especificidad del modelo, así como la curva ROC y su AUC, para este ejemplo, se pueden obtener con el siguiente código:</p>
<div class="sourceCode" id="cb216"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="http://bendixcarstensen.com/Epi/">"Epi"</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/Epi/man/ROC.html">ROC</a></span><span class="op">(</span></span>
<span>  form <span class="op">=</span> <span class="va">diag</span> <span class="op">~</span> <span class="va">edad</span> <span class="op">+</span> <span class="va">dep</span> <span class="op">+</span> <span class="va">sexo</span> <span class="op">+</span> <span class="va">tdolor</span>, data <span class="op">=</span> <span class="va">cleveland</span>,</span>
<span>  plot <span class="op">=</span> <span class="st">"sp"</span></span>
<span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/pkg/Epi/man/ROC.html">ROC</a></span><span class="op">(</span></span>
<span>  form <span class="op">=</span> <span class="va">diag</span> <span class="op">~</span> <span class="va">edad</span> <span class="op">+</span> <span class="va">dep</span> <span class="op">+</span> <span class="va">sexo</span> <span class="op">+</span> <span class="va">tdolor</span>, data <span class="op">=</span> <span class="va">cleveland</span>,</span>
<span>  plot <span class="op">=</span> <span class="st">"ROC"</span>, las <span class="op">=</span> <span class="fl">1</span></span>
<span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:glm-roc"></span>
<img src="150017_glm_files/figure-html/glm-roc-1.png" alt="Gráfico de sensibilidad y especificidad según puntos de corte de discriminación (izquierda) y curva ROC (derecha) para el segundo modelo de regresión logística" width="60%"><p class="caption">
Figura 16.2: Gráfico de sensibilidad y especificidad según puntos de corte de discriminación (izquierda) y curva ROC (derecha) para el segundo modelo de regresión logística
</p>
</div>
<p>La Fig. <a href="cap-glm.html#fig:glm-roc">16.2</a> (izquierda) muestra que tomando como punto de corte una probabilidad cercana a 0.45 se obtienen valores de sensibilidad y especificidad alrededor de 0.8. No obstante, se deben evaluar los costes y riesgos de una mala clasificación (por ejemplo, dar tratamiento cuando no hace falta y no darlo cuando es necesario).</p>
<p>La Fig. <a href="cap-glm.html#fig:glm-roc">16.2</a> (derecha) representa la curva ROC de <code>reg_log2</code>. La curva está por encima de la diagonal, con lo que es mejor que un clasificador aleatorio. La AUC es de 0.878, con una sensibilidad de 78.4% y una especificidad de 84.1%.
Si se realiza el análisis para <code>reg_log</code> se comprobará que la AUC es de 0.759, por lo que el segundo modelo es mejor para discriminar.
Además, el gráfico también indica el valor del <strong>punto de corte óptimo</strong>, 0.518 (el que proporciona la mayor AUC, 0.878) junto con los correspondientes valores de sensibilidad, especificidad, etc. También muestra las estimaciones y los errores estándar (<em>s.e.</em>) de los coeficientes del modelo considerado.</p>
<p></p>
</div>
<div id="ejemplo-de-regresión-de-poisson" class="section level3" number="16.6.2">
<h3>
<span class="header-section-number">16.6.2</span> Ejemplo de regresión de Poisson<a class="anchor" aria-label="anchor" href="#ejemplo-de-regresi%C3%B3n-de-poisson"><i class="fas fa-link"></i></a>
</h3>
<p>A partir del mismo conjunto de datos, <code>cleveland</code>, ahora se considera como variable a explicar, variable respuesta, <code>dhosp</code>, el número de días de hospitalización de un paciente.
Como variables explicativas se seleccionan las siguientes: <code>diag</code>, <code>edad</code>, <code>sexo</code> y <code>tdolor</code>, que son de distinto tipo, lo que permitirá ilustrar sus distintas interpretaciones.</p>
<p><strong>Visualización ilustrativa</strong></p>
<div class="sourceCode" id="cb217"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">p1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">cleveland</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span><span class="va">dhosp</span>, fill <span class="op">=</span> <span class="va">diag</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_bar.html">geom_bar</a></span><span class="op">(</span>position <span class="op">=</span> <span class="st">"dodge"</span><span class="op">)</span></span>
<span><span class="va">p2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">cleveland</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/factor.html">factor</a></span><span class="op">(</span><span class="va">dhosp</span><span class="op">)</span>, y <span class="op">=</span> <span class="va">edad</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_boxplot.html">geom_boxplot</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="https://patchwork.data-imaginist.com">"patchwork"</a></span><span class="op">)</span></span>
<span><span class="va">p1</span> <span class="op">+</span> <span class="va">p2</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:glm-grafpois"></span>
<img src="150017_glm_files/figure-html/glm-grafpois-1.png" alt="Gráfico de barras de `dhosp` según tipo de diagnóstico (izquierda) y gráficos de cajas de 'edad' según el número de días de hospitalización (derecha)" width="60%"><p class="caption">
Figura 16.3: Gráfico de barras de <code>dhosp</code> según tipo de diagnóstico (izquierda) y gráficos de cajas de ‘edad’ según el número de días de hospitalización (derecha)
</p>
</div>
<p>A la vista de los gráficos de la Fig. <a href="cap-glm.html#fig:glm-grafpois">16.3</a>, generados con las sentencias anteriores, <code>diag</code> parece ser una buena variable predictora del número de días de hospitalización, mientras que <code>edad</code> no tiene una influencia tan clara.</p>
<p><strong>Ajuste e interpretación</strong></p>
<div class="sourceCode" id="cb218"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">reg_pois</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">dhosp</span> <span class="op">~</span> <span class="va">diag</span> <span class="op">+</span> <span class="va">edad</span> <span class="op">+</span> <span class="va">sexo</span> <span class="op">+</span> <span class="va">tdolor</span>,</span>
<span>  data <span class="op">=</span> <span class="va">cleveland</span>, family <span class="op">=</span> <span class="st">"poisson"</span><span class="op">)</span></span></code></pre></div>
<p>Al especificar <code>family = "poisson"</code>, la función <code><a href="https://rdrr.io/r/stats/glm.html">glm()</a></code> selecciona automáticamente la función de enlace apropiada: el logaritmo (efectos multiplicativos).</p>
<div class="sourceCode" id="cb219"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">reg_pois</span><span class="op">)</span><span class="op">$</span><span class="va">coef</span></span>
<span><span class="co">#&gt;                  Estimate  Std. Error     z value     Pr(&gt;|z|)</span></span>
<span><span class="co">#&gt; (Intercept) -0.2230728726 0.332125111 -0.67165314 5.018045e-01</span></span>
<span><span class="co">#&gt; diag1        1.0902902179 0.109731744  9.93595999 2.903654e-23</span></span>
<span><span class="co">#&gt; edad         0.0001026277 0.004877904  0.02103931 9.832143e-01</span></span>
<span><span class="co">#&gt; sexo1        0.2160286255 0.103297627  2.09132226 3.649919e-02</span></span>
<span><span class="co">#&gt; tdolor2      0.1408464230 0.205232539  0.68627725 4.925383e-01</span></span>
<span><span class="co">#&gt; tdolor3      0.1217757202 0.189404790  0.64293897 5.202637e-01</span></span>
<span><span class="co">#&gt; tdolor4      0.1215388103 0.178729482  0.68001546 4.964947e-01</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Log.html">exp</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/coef.html">coef</a></span><span class="op">(</span><span class="va">reg_pois</span><span class="op">)</span><span class="op">)</span><span class="op">[</span><span class="op">-</span><span class="fl">1</span><span class="op">]</span></span>
<span><span class="co">#&gt;    diag1     edad    sexo1  tdolor2  tdolor3  tdolor4 </span></span>
<span><span class="co">#&gt; 2.975137 1.000103 1.241138 1.151248 1.129501 1.129233</span></span></code></pre></div>
<p>De todas las variables introducidas en el modelo, sólo <code>diag</code> y <code>sexo</code> son significativas (al 5%). Se confirma así lo visto en la Fig. <a href="cap-glm.html#fig:glm-grafpois">16.3</a> (derecha): que <code>edad</code> no influye en la respuesta. Al ser las dos variables significativas de tipo dicotómico, su interpretación, como en la regresión logística, se hace en función de la categoría de referencia, y <em>ceteris paribus</em> (esto en cualquier caso):</p>
<ul>
<li><p>El coeficiente de <code>diag</code> es 1.0903 pero se le debe aplicar la exponencial para tener como unidades de medida días.
Así, el número medio de días de estancia en el hospital es 2.98 veces mayor con <code>diag=1</code> que con <code>diag=0</code> (categoría tomada como referencia).</p></li>
<li><p>Algo similar se puede decir para <code>sexo</code>: un hombre (<code>sexo=1</code>) se espera que esté en el hospital, en media, 1.24 días por cada día que esté una mujer.</p></li>
<li><p>De la misma manera se interpretarían los coeficientes asociados a <code>tdolor</code>, si bien no son significativos: cada uno de ellos expresaría la diferencia con los pacientes del grupo <code>tdolor=1</code>.</p></li>
<li><p>Aunque el coeficiente asociado a <code>edad</code> tampoco es significativo, y su magnitud es ínfima, se da su interpretación, al ser la única variable continua:
por cada año que aumenta la <code>edad</code>, el número medio de días en el hospital se ve multiplicado por
1.0001 (ínfimo)<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Si el incremento fuese de 20 años (como en el ejemplo de regresión logística), el incremento en los días de hospitalización seguiría siendo despreciable: 0,0021 días.&lt;/p&gt;"><sup>136</sup></a>.</p></li>
</ul>
<p>Para posteriores comparaciones, se considera otro modelo en el que se elimina <code>tdolor</code> (por no ser significativa):</p>
<div class="sourceCode" id="cb220"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">reg_pois2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/glm.html">glm</a></span><span class="op">(</span><span class="va">dhosp</span> <span class="op">~</span> <span class="va">diag</span> <span class="op">+</span> <span class="va">sexo</span> <span class="op">+</span> <span class="va">edad</span>,</span>
<span>  data <span class="op">=</span> <span class="va">cleveland</span>,   family <span class="op">=</span> <span class="st">"poisson"</span><span class="op">)</span></span></code></pre></div>
<p><strong>Adecuación</strong><br>
En los ajustes <code>reg_pois</code> y <code>reg_pois2</code> hay información sobre la <em>Null</em> y la <em>Residual deviance</em>, con las que se puede realizar el contraste de comparación de modelos (el simple frente al elaborado) mencionado en la Sec. <a href="cap-glm.html#secADECUACION">16.4.2</a>.</p>
<div class="sourceCode" id="cb221"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">pchisq</a></span><span class="op">(</span><span class="va">reg_pois</span><span class="op">$</span><span class="va">deviance</span>, <span class="va">reg_pois</span><span class="op">$</span><span class="va">df.residual</span>, lower.tail <span class="op">=</span> <span class="cn">F</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.1325654</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/Chisquare.html">pchisq</a></span><span class="op">(</span><span class="va">reg_pois2</span><span class="op">$</span><span class="va">deviance</span>, <span class="va">reg_pois2</span><span class="op">$</span><span class="va">df.residual</span>, lower.tail <span class="op">=</span> <span class="cn">F</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.155157</span></span></code></pre></div>
<p>Al ser los p-valores superiores a 0.05, ambos modelos se pueden considerar que explican “mejor” que el modelo nulo, el que únicamente contiene la constante y el término aleatorio.</p>
<p><strong>Predicción</strong><br>
Con los modelos ajustados, y comprobada su adecuación, se pueden predecir valores, que en este caso son el número medio de días de hospitalización.</p>
<div class="sourceCode" id="cb222"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">pacientes</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/data.frame.html">data.frame</a></span><span class="op">(</span></span>
<span>  diag <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"1"</span>, <span class="st">"1"</span>, <span class="st">"0"</span>, <span class="st">"0"</span><span class="op">)</span>,</span>
<span>  edad <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">50</span>, <span class="fl">50</span>, <span class="fl">50</span>, <span class="fl">50</span><span class="op">)</span>,</span>
<span>  sexo <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"1"</span>, <span class="st">"0"</span>, <span class="st">"1"</span>, <span class="st">"0"</span><span class="op">)</span>,</span>
<span>  tdolor <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"4"</span>, <span class="st">"4"</span>, <span class="st">"4"</span>, <span class="st">"4"</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">reg_pois</span>, <span class="va">pacientes</span>, type <span class="op">=</span> <span class="st">"response"</span><span class="op">)</span></span>
<span><span class="co">#&gt;         1         2         3         4 </span></span>
<span><span class="co">#&gt; 3.3532035 2.7017171 1.1270752 0.9080983</span></span></code></pre></div>
<p>Se han escogido, arbitrariamente, valores de las variables explicativas para 4 <code>pacientes</code>: los pacientes 1 y 2 presentan la enfermedad coronaria (<code>diag=1</code>) mientras que los pacientes 3 y 4 no; los pacientes 1 y 3 son hombres (<code>sexo=1</code>), mientras que el 2 y el 4 son mujeres; los cuatro tienen 50 años y son asintomáticos (<code>tdolor=4</code>).
Las predicciones obtenidas indican que el paciente 1 (hombre con enfermedad coronaria) estará hospitalizado más días, en media, que el resto, aunque le sigue de cerca la paciente 2 (mujer con enfermedad coronaria).</p>
<p>También se pueden dibujar las predicciones modelo <code>reg_pois</code> de todo el conjunto de datos, que <code><a href="https://rdrr.io/r/stats/glm.html">glm()</a></code> ha guardado como <code>fitted.values</code>.</p>
<div class="sourceCode" id="cb223"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">cleveland</span><span class="op">$</span><span class="va">hat</span> <span class="op">&lt;-</span> <span class="va">reg_pois</span><span class="op">$</span><span class="va">fitted.values</span></span>
<span><span class="va">g1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">cleveland</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">edad</span>, y <span class="op">=</span> <span class="va">hat</span>, colour <span class="op">=</span> <span class="va">diag</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Edad"</span>, y <span class="op">=</span> <span class="st">"Días hospitalización"</span><span class="op">)</span></span>
<span><span class="va">cleveland</span><span class="op">$</span><span class="va">hat2</span> <span class="op">&lt;-</span> <span class="va">reg_pois2</span><span class="op">$</span><span class="va">fitted.values</span></span>
<span><span class="va">g2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">cleveland</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">edad</span>, y <span class="op">=</span> <span class="va">hat2</span>, colour <span class="op">=</span> <span class="va">diag</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_point.html">geom_point</a></span><span class="op">(</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">labs</a></span><span class="op">(</span>x <span class="op">=</span> <span class="st">"Edad"</span>, y <span class="op">=</span> <span class="st">"Días hospitalización"</span><span class="op">)</span></span>
<span><span class="va">g1</span> <span class="op">+</span> <span class="va">g2</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:glm-predictPois"></span>
<img src="150017_glm_files/figure-html/glm-predictPois-1.png" alt="Predicciones de todo el conjunto de datos del modelo `regpois` (izquierda) y `regpois2` (derecha)" width="60%"><p class="caption">
Figura 16.4: Predicciones de todo el conjunto de datos del modelo <code>regpois</code> (izquierda) y <code>regpois2</code> (derecha)
</p>
</div>
<!-- ```{r glm-fittedvalues, eval=FALSE} -->
<!-- cleveland$hat <- reg_pois$fitted.values -->
<!-- ggplot(cleveland, aes(x = edad, y = hat, colour = diag)) + -->
<!--   geom_point() + -->
<!--   labs(x = "Edad", y = "Días hospitalización") -->
<!-- ``` -->
<!-- ```{r glm-predictPois, fig.cap="Predicciones del modelo `regpois` (izquierda) y `regpois2` (derecha) para todo el conjunto de datos", echo=FALSE} -->
<!-- # reg_pois -->
<!-- # comprobación: si valores predichos = fitted.values (valores ajustados) -->
<!-- # la suma de las diferencias será cero -->
<!-- # sum(predict(reg_pois, type = "response") - reg_pois$fitted.values) -->
<!-- # gráfico -->
<!-- cleveland$hat <- reg_pois$fitted.values -->
<!-- g1 <- ggplot(cleveland, aes(x = edad, y = hat, colour = diag)) + -->
<!--   geom_point() + -->
<!--   labs(x = "Edad", y = "Días hospitalización") -->
<!-- # reg_pois2 -->
<!-- cleveland$hat2 <- reg_pois2$fitted.values -->
<!-- g2 <- ggplot(cleveland, aes(x = edad, y = hat2, colour = sexo)) + -->
<!--   geom_point() + -->
<!--   labs(x = "Edad", y = "Días hospitalización") -->
<!-- # grid.arrange(g1, g2, ncol = 2) -->
<!-- g1 + g2 -->
<!-- ``` -->
<p>La Fig. <a href="cap-glm.html#fig:glm-predictPois">16.4</a> muestra las predicciones del número de días (promedio) de hospitalización para los 303 individuos considerados en el conjunto de datos y para cada uno de los dos modelos de regresión de Poisson considerados.</p>
<p>Cabe recordar que en el primer modelo se consideran las variables <code>diag</code>, <code>edad</code>, <code>sexo</code> y <code>tdolor</code>, mientras que en el segundo se ha eliminado la variable <code>tdolor</code>. Lo primero que hay que destacar es que los puntos se “ordenan” en forma de lineas de puntos horizontales ordenadas verticalemtne. Ello se debe a que (<strong>i</strong>) en el eje de abscisas figura la variable <code>Èdad</code>, que no influye significativamente en los días de hospitalización (lineas horizontales); y (<strong>ii</strong>) las demás variables son categóricas, por lo que desplazan las lineas verticalmente, sin modificar su pendiente. El desplazamiento vertical diferenciado por colores, mediante la variable <code>diag</code>, es claro: la predicción del número de días (promedio) de hospitalización para personas con <code>diag=1</code> es un valor en torno a 3, mientras que para aquellos con <code>diag=0</code> es un valor en torno a 1.
En ambos gráficos no se ha incluido identificación para la variable sexo, podría hacerse añadiendo apropiadamente <code>facet_wrap(vars(sexo))</code> lo que permitiría ver que es el sexo el que genera las diferencias verticales (significativas, porque la variable <code>sexo</code> es significativa) de las dos líneas horizontales tanto en torno a <code>hosp=3</code> como a <code>hosp=1</code> (apreciables claramente en el gráfico de la derecha).
Por último, como la diferencia entre el gráfico de la izquierda y el de la derecha es la inclusión o no de <code>tdolor</code> queda claro que es dicha variable la que genera las distintas líneas horizontales de puntos (gráfico de la izquierda) con poca variabilidad vertical (por no ser significativa).</p>
<!-- En el gráfico de la izquierda hay cierta variabilidad tanto en la nube de puntos azul correspondiente a `diag_1`  (en torno al 3) como en la naranja correspondiente a `diag_0`  (en torno al 1). Ello se debe al efecto en los días de hospitalización de las combinaciones de las categorías de las variables `Sexo` y `tdolor`, no representadas en los ejes del gráfico, si bien en realidad, se debe únicamente a la variable `Sexo`, puesto que `tdolor` no es significativa. De hecho, cuando se elimina del modelo (gráfico de la derecha), se puede apreciar claramente que los puntos por debajo de `diag=3` y `diag=1` en el gráfico de la izquierda correspondían a las mujeres (`Sexo_0`) y los que están por encima de tales valores a los varones (`Sexo_1`). -->
<!-- A la vista de ambos gráficos, se puede ver que la variable edad (que no es significativa) no influye en los días de hospitalización: la predicción es "horizontal" para todos los valores de edad. También se puede ver el efecto en los días de hospitalización de las combinaciones de las categorías de las variables `diag`, `sexo` y `tdolor`. Al ser variables categóricas producen desplazamientos verticales en la predicción. El desplazamiento vertical diferenciado por colores, mediante la variable `diag`, es claro: la predicción del número de días (promedio) de hospitalización para personas con `diag=1` es un valor en torno a 3, mientras que para aquellos con `diag=0` es un valor en torno a 1. -->
<!-- En ambos gráficos no se ha incluido identificación para la variable sexo, podría hacerse añadiendo apropiadamente `facet_wrap(vars(sexo))` lo que permitiría ver que es el sexo el que genera las diferencias verticales (significativas, porque la variable `sexo` es significativa) de las dos líneas horizontales tanto en torno a `hosp=3` como a `hosp=1` (apreciables claramente en el gráfico de la derecha). -->
<!-- Por último, como la diferencia entre el gráfico de la izquierda y el de la derecha es la inclusión o no de `tdolor` queda claro que es dicha variable la que genera las distintas líneas horizontales de puntos (gráfico de la izquierda) con poca variabilidad vertical (por no ser significativa). -->
</div>
<div id="resumen-14" class="section level3 unnumbered infobox_resume">
<h3>Resumen<a class="anchor" aria-label="anchor" href="#resumen-14"><i class="fas fa-link"></i></a>
</h3>
<p>En este capítulo se introduce el modelo de regresión lineal generalizado, indicado cuando las respuestas no son gaussianas (Normales). En particular:</p>
<ul>
<li>Se introduce la función de enlace, que juega un papel importante en estos modelos.</li>
<li>Se describen los casos particulares de regresión logística y de regresión de Poisson.</li>
<li>Se muestra el uso de <strong>R</strong> para el ajuste de estos modelos.</li>
<li>Se ilustra la interpretación de los coeficientes, tanto asociados a variables cuantitativas como a categóricas, y los demás resultados obtenidos con <strong>R</strong>, mediante casos prácticos.</li>
<li>Se incluye el uso de la regresión logística como clasificador y se dan indicaciones al respecto mediante la curva ROC y la AUC.</li>
</ul>
</div>

</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="cap-lm.html"><span class="header-section-number">15</span> Modelización lineal</a></div>
<div class="next"><a href="cap-gam.html"><span class="header-section-number">17</span> Modelos aditivos generalizados</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="Índice capítulo"><h2>Índice capítulo</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#cap-glm"><span class="header-section-number">16</span> Modelos lineales generalizados</a></li>
<li><a class="nav-link" href="#introducci%C3%B3n-7"><span class="header-section-number">16.1</span> Introducción</a></li>
<li>
<a class="nav-link" href="#el-modelo-y-sus-componentes"><span class="header-section-number">16.2</span> El modelo y sus componentes</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#funci%C3%B3n-enlace"><span class="header-section-number">16.2.1</span> Función enlace</a></li></ul>
</li>
<li><a class="nav-link" href="#procedimiento-con-r-la-funci%C3%B3n-glm"><span class="header-section-number">16.3</span> Procedimiento con R: la función glm()</a></li>
<li>
<a class="nav-link" href="#regresi%C3%B3n-log%C3%ADstica"><span class="header-section-number">16.4</span> Regresión logística</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#procedimiento-de-ajuste"><span class="header-section-number">16.4.1</span> Procedimiento de ajuste</a></li>
<li><a class="nav-link" href="#secADECUACION"><span class="header-section-number">16.4.2</span> Adecuación del modelo</a></li>
<li><a class="nav-link" href="#SECCinterp"><span class="header-section-number">16.4.3</span> Interpretación de resultados</a></li>
<li><a class="nav-link" href="#predicci%C3%B3n.-curva-roc-y-auc"><span class="header-section-number">16.4.4</span> Predicción. Curva ROC y AUC</a></li>
</ul>
</li>
<li><a class="nav-link" href="#regresi%C3%B3n-de-poisson"><span class="header-section-number">16.5</span> Regresión de Poisson</a></li>
<li>
<a class="nav-link" href="#casos-pr%C3%A1cticos"><span class="header-section-number">16.6</span> Casos prácticos</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#secEJreglog"><span class="header-section-number">16.6.1</span> Ejemplos de regresión logística</a></li>
<li><a class="nav-link" href="#ejemplo-de-regresi%C3%B3n-de-poisson"><span class="header-section-number">16.6.2</span> Ejemplo de regresión de Poisson</a></li>
<li><a class="nav-link" href="#resumen-14">Resumen</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Fundamentos de ciencia de datos con R</strong>" coordinado por <a href="https://blog.uclm.es/gemafaviles/" class="text-light">Gema Fernández-Avilés y José-María Montero</a>. Generado por última vez el día 2023-06-16.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>Este libro ha sido generado con el paquete de R <a class="text-light" href="https://bookdown.org">bookdown</a>.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
