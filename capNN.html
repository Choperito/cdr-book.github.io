<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 36 Redes neuronales artificiales | Ciencia de datos con R</title>
  <meta name="description" content="Falta hacer" />
  <meta name="generator" content="bookdown 0.28 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 36 Redes neuronales artificiales | Ciencia de datos con R" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Falta hacer" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 36 Redes neuronales artificiales | Ciencia de datos con R" />
  
  <meta name="twitter:description" content="Falta hacer" />
  

<meta name="author" content="Gema Fernández-Avilés y José-María Montero" />


<meta name="date" content="2022-12-22" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="correspondencias.html"/>
<link rel="next" href="cap-redes-convol.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<link href="libs/wordcloud2-0.0.1/wordcloud.css" rel="stylesheet" />
<script src="libs/wordcloud2-0.0.1/wordcloud2-all.js"></script>
<script src="libs/wordcloud2-0.0.1/hover.js"></script>
<script src="libs/wordcloud2-binding-0.2.1/wordcloud2.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-33KQ1S5ZCJ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-33KQ1S5ZCJ');
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"> Ciencia de datos con <strong>R</strong></a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="normas-cdr-book-v0.2.html"><a href="normas-cdr-book-v0.2.html"><i class="fa fa-check"></i><b>1</b> Normas CDR-book-v0.2.0</a>
<ul>
<li class="chapter" data-level="1.1" data-path="normas-cdr-book-v0.2.html"><a href="normas-cdr-book-v0.2.html#notas-importantes"><i class="fa fa-check"></i><b>1.1</b> Notas importantes</a></li>
<li class="chapter" data-level="1.2" data-path="normas-cdr-book-v0.2.html"><a href="normas-cdr-book-v0.2.html#notas-relativas-a-r"><i class="fa fa-check"></i><b>1.2</b> Notas relativas a R</a></li>
<li class="chapter" data-level="1.3" data-path="normas-cdr-book-v0.2.html"><a href="normas-cdr-book-v0.2.html#notas-de-estilo"><i class="fa fa-check"></i><b>1.3</b> Notas de estilo</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="normas-cdr-book-v0.2.html"><a href="normas-cdr-book-v0.2.html#títulos"><i class="fa fa-check"></i><b>1.3.1</b> Títulos</a></li>
<li class="chapter" data-level="1.3.2" data-path="normas-cdr-book-v0.2.html"><a href="normas-cdr-book-v0.2.html#figuras"><i class="fa fa-check"></i><b>1.3.2</b> Figuras</a></li>
<li class="chapter" data-level="1.3.3" data-path="normas-cdr-book-v0.2.html"><a href="normas-cdr-book-v0.2.html#tablas"><i class="fa fa-check"></i><b>1.3.3</b> Tablas</a></li>
<li class="chapter" data-level="1.3.4" data-path="normas-cdr-book-v0.2.html"><a href="normas-cdr-book-v0.2.html#otros"><i class="fa fa-check"></i><b>1.3.4</b> Otros</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html"><i class="fa fa-check"></i>Prefacio</a>
<ul>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html#los-autores"><i class="fa fa-check"></i>Los autores</a></li>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html#por-qué-este-libro"><i class="fa fa-check"></i>¿Por qué este libro?</a></li>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html#características"><i class="fa fa-check"></i>Características</a></li>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html#el-paquete-cdr"><i class="fa fa-check"></i>El paquete <code>CDR</code></a></li>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html#a-quién-va-dirigido"><i class="fa fa-check"></i>¿A quién va dirigido?</a></li>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html#agradecimientos"><i class="fa fa-check"></i>Agradecimientos</a></li>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html#información-del-software"><i class="fa fa-check"></i>Información del software</a></li>
</ul></li>
<li class="part"><span><b>I Ciencia, datos, software… y científicos</b></span></li>
<li class="chapter" data-level="2" data-path="ciencia-datos.html"><a href="ciencia-datos.html"><i class="fa fa-check"></i><b>2</b> ¿Es la ciencia de datos una ciencia?</a>
<ul>
<li class="chapter" data-level="2.1" data-path="ciencia-datos.html"><a href="ciencia-datos.html#ciencia"><i class="fa fa-check"></i><b>2.1</b> ¿Qué se entiende por ciencia?</a></li>
<li class="chapter" data-level="2.2" data-path="ciencia-datos.html"><a href="ciencia-datos.html#qué-diablos-es-la-ciencia-de-datos"><i class="fa fa-check"></i><b>2.2</b> ¿Qué diablos es la ciencia de datos?</a></li>
<li class="chapter" data-level="2.3" data-path="ciencia-datos.html"><a href="ciencia-datos.html#lo-científico-de-la-ciencia-de-datos"><i class="fa fa-check"></i><b>2.3</b> Lo científico de la ciencia de datos</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="metodología.html"><a href="metodología.html"><i class="fa fa-check"></i><b>3</b> Metodología en ciencia de datos</a>
<ul>
<li class="chapter" data-level="3.1" data-path="metodología.html"><a href="metodología.html#preliminares"><i class="fa fa-check"></i><b>3.1</b> Preliminares</a></li>
<li class="chapter" data-level="3.2" data-path="metodología.html"><a href="metodología.html#principales-metodologías-en-ciencia-de-datos"><i class="fa fa-check"></i><b>3.2</b> Principales metodologías en ciencia de datos</a></li>
<li class="chapter" data-level="3.3" data-path="metodología.html"><a href="metodología.html#met-crisp-dm"><i class="fa fa-check"></i><b>3.3</b> CRISP-DM para ciencia de datos</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ch-110003.html"><a href="ch-110003.html"><i class="fa fa-check"></i><b>4</b> Ciencia de datos con R</a>
<ul>
<li class="chapter" data-level="4.1" data-path="ch-110003.html"><a href="ch-110003.html#introducción"><i class="fa fa-check"></i><b>4.1</b> Introducción</a></li>
<li class="chapter" data-level="4.2" data-path="ch-110003.html"><a href="ch-110003.html#id_110003-bases"><i class="fa fa-check"></i><b>4.2</b> La sesión de <strong>R</strong></a></li>
<li class="chapter" data-level="4.3" data-path="ch-110003.html"><a href="ch-110003.html#instalación-de-r"><i class="fa fa-check"></i><b>4.3</b> Instalación de <strong>R</strong></a></li>
<li class="chapter" data-level="4.4" data-path="ch-110003.html"><a href="ch-110003.html#id_110003-proyectos"><i class="fa fa-check"></i><b>4.4</b> Trabajar con proyectos de RStudio</a></li>
<li class="chapter" data-level="4.5" data-path="ch-110003.html"><a href="ch-110003.html#tratamiento-de-datos-con-r"><i class="fa fa-check"></i><b>4.5</b> Tratamiento de datos con <strong>R</strong></a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="ch-110003.html"><a href="ch-110003.html#id_110003-estructuras"><i class="fa fa-check"></i><b>4.5.1</b> Estructuras y tipos de datos</a></li>
<li class="chapter" data-level="4.5.2" data-path="ch-110003.html"><a href="ch-110003.html#id_110003-importacion"><i class="fa fa-check"></i><b>4.5.2</b> Importación de datos</a></li>
<li class="chapter" data-level="4.5.3" data-path="ch-110003.html"><a href="ch-110003.html#exportación-y-archivos-de-datos-de-r"><i class="fa fa-check"></i><b>4.5.3</b> Exportación y archivos de datos de R</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="ch-110003.html"><a href="ch-110003.html#id_110003-tidyverse"><i class="fa fa-check"></i><b>4.6</b> Organización de datos con el <em>tidyverse</em></a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="ch-110003.html"><a href="ch-110003.html#el-tidyverse-y-su-flujo-de-trabajo"><i class="fa fa-check"></i><b>4.6.1</b> El <em>tidyverse</em> y su flujo de trabajo</a></li>
<li class="chapter" data-level="4.6.2" data-path="ch-110003.html"><a href="ch-110003.html#transformación-de-datos-con-dplyr"><i class="fa fa-check"></i><b>4.6.2</b> Transformación de datos con <code>dplyr</code></a></li>
<li class="chapter" data-level="4.6.3" data-path="ch-110003.html"><a href="ch-110003.html#combinación-de-datos"><i class="fa fa-check"></i><b>4.6.3</b> Combinación de datos</a></li>
<li class="chapter" data-level="4.6.4" data-path="ch-110003.html"><a href="ch-110003.html#reorganización-de-datos"><i class="fa fa-check"></i><b>4.6.4</b> Reorganización de datos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="cap-etica.html"><a href="cap-etica.html"><i class="fa fa-check"></i><b>5</b> Ética en la ciencia de datos</a>
<ul>
<li class="chapter" data-level="5.1" data-path="cap-etica.html"><a href="cap-etica.html#por-que-la-ética-en-la-ciencia-de-datos"><i class="fa fa-check"></i><b>5.1</b> ¿Por que la ética en la ciencia de datos?</a></li>
<li class="chapter" data-level="5.2" data-path="cap-etica.html"><a href="cap-etica.html#los-principios-éticos"><i class="fa fa-check"></i><b>5.2</b> Los principios éticos</a></li>
<li class="chapter" data-level="5.3" data-path="cap-etica.html"><a href="cap-etica.html#la-importancia-de-los-sesgos"><i class="fa fa-check"></i><b>5.3</b> La importancia de los sesgos</a></li>
<li class="chapter" data-level="5.4" data-path="cap-etica.html"><a href="cap-etica.html#es-necesaria-la-explicabilidad"><i class="fa fa-check"></i><b>5.4</b> ¿Es necesaria la explicabilidad?</a></li>
<li class="chapter" data-level="5.5" data-path="cap-etica.html"><a href="cap-etica.html#sesgos-y-explicabilidad-en-r"><i class="fa fa-check"></i><b>5.5</b> Sesgos y explicabilidad en R</a></li>
</ul></li>
<li class="part"><span><b>II Bienvenido a la jungla de datos</b></span></li>
<li class="chapter" data-level="6" data-path="datos-sql.html"><a href="datos-sql.html"><i class="fa fa-check"></i><b>6</b> Gestión de bases de datos relacionales</a>
<ul>
<li class="chapter" data-level="6.1" data-path="datos-sql.html"><a href="datos-sql.html#introducción-1"><i class="fa fa-check"></i><b>6.1</b> Introducción</a></li>
<li class="chapter" data-level="6.2" data-path="datos-sql.html"><a href="datos-sql.html#concepto-de-base-de-datos"><i class="fa fa-check"></i><b>6.2</b> Concepto de Base de datos</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="datos-sql.html"><a href="datos-sql.html#gestión-de-los-datos-en-una-base-o-repositorio-de-datos"><i class="fa fa-check"></i><b>6.2.1</b> Gestión de los datos en una base o repositorio de datos</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="datos-sql.html"><a href="datos-sql.html#el-lenguaje-estructurado-de-consulta-sql"><i class="fa fa-check"></i><b>6.3</b> El Lenguaje Estructurado de Consulta (SQL)</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="datos-sql.html"><a href="datos-sql.html#sql-como-lenguaje-de-definición-de-datos-ldd"><i class="fa fa-check"></i><b>6.3.1</b> SQL como Lenguaje de Definición de Datos (LDD)</a></li>
<li class="chapter" data-level="6.3.2" data-path="datos-sql.html"><a href="datos-sql.html#sql-como-lenguaje-de-manipulación-de-datos-lmd"><i class="fa fa-check"></i><b>6.3.2</b> SQL como Lenguaje de Manipulación de Datos (LMD)</a></li>
<li class="chapter" data-level="6.3.3" data-path="datos-sql.html"><a href="datos-sql.html#sql-como-lenguaje-de-administración-de-datos-lad"><i class="fa fa-check"></i><b>6.3.3</b> SQL como Lenguaje de Administración de Datos (LAD)</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="datos-sql.html"><a href="datos-sql.html#usando-bases-de-datos-desde-r"><i class="fa fa-check"></i><b>6.4</b> Usando bases de datos desde R</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="datos-sql.html"><a href="datos-sql.html#conexión-a-una-base-de-datos"><i class="fa fa-check"></i><b>6.4.1</b> Conexión a una base de datos</a></li>
<li class="chapter" data-level="6.4.2" data-path="datos-sql.html"><a href="datos-sql.html#operaciones-de-lectura-selección-read-de-datos"><i class="fa fa-check"></i><b>6.4.2</b> Operaciones de lectura / selección (<em>read</em>) de datos</a></li>
<li class="chapter" data-level="6.4.3" data-path="datos-sql.html"><a href="datos-sql.html#operaciones-de-inserción-create-y-actualización-update-de-datos"><i class="fa fa-check"></i><b>6.4.3</b> Operaciones de inserción (<em>create</em>) y actualización (<em>update</em>) de datos</a></li>
<li class="chapter" data-level="6.4.4" data-path="datos-sql.html"><a href="datos-sql.html#operaciones-de-borrado-de-datos-delete"><i class="fa fa-check"></i><b>6.4.4</b> Operaciones de Borrado de datos (<em>delete</em>)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="datos-no-sql.html"><a href="datos-no-sql.html"><i class="fa fa-check"></i><b>7</b> Gesitón de bases de datos NoSQL</a>
<ul>
<li class="chapter" data-level="7.1" data-path="datos-no-sql.html"><a href="datos-no-sql.html#introducción-al-big-data"><i class="fa fa-check"></i><b>7.1</b> Introducción al Big Data</a></li>
<li class="chapter" data-level="7.2" data-path="datos-no-sql.html"><a href="datos-no-sql.html#VsBigData"><i class="fa fa-check"></i><b>7.2</b> Las V’s del Big Data</a></li>
<li class="chapter" data-level="7.3" data-path="datos-no-sql.html"><a href="datos-no-sql.html#fuentes-de-datos-en-entornos-big-data"><i class="fa fa-check"></i><b>7.3</b> Fuentes de Datos en entornos Big Data</a></li>
<li class="chapter" data-level="7.4" data-path="datos-no-sql.html"><a href="datos-no-sql.html#bases-de-datos-relacionales-vs.-nosql"><i class="fa fa-check"></i><b>7.4</b> Bases de datos Relacionales vs. NoSQL</a></li>
<li class="chapter" data-level="7.5" data-path="datos-no-sql.html"><a href="datos-no-sql.html#bases-de-datos-nosql"><i class="fa fa-check"></i><b>7.5</b> Bases de datos NoSQL</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="datos-no-sql.html"><a href="datos-no-sql.html#definición-de-bases-de-datos-nosql"><i class="fa fa-check"></i><b>7.5.1</b> Definición de bases de datos NoSQL</a></li>
<li class="chapter" data-level="7.5.2" data-path="datos-no-sql.html"><a href="datos-no-sql.html#necesidades-no-cubiertas-por-las-bases-de-datos-relacionales"><i class="fa fa-check"></i><b>7.5.2</b> Necesidades no cubiertas por las bases de datos relacionales</a></li>
<li class="chapter" data-level="7.5.3" data-path="datos-no-sql.html"><a href="datos-no-sql.html#tipos-de-almacenamiento-en-bases-de-datos-nosql"><i class="fa fa-check"></i><b>7.5.3</b> Tipos de almacenamiento en bases de datos NoSQL</a></li>
<li class="chapter" data-level="7.5.4" data-path="datos-no-sql.html"><a href="datos-no-sql.html#limitaciones-de-las-bases-de-datos-nosql"><i class="fa fa-check"></i><b>7.5.4</b> Limitaciones de las bases de datos NoSQL</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="datos-no-sql.html"><a href="datos-no-sql.html#ejemplo-de-integración-de-una-base-de-datos-nosql-y-análisis-de-datos-en-r"><i class="fa fa-check"></i><b>7.6</b> Ejemplo de integración de una base de datos NoSQL y análisis de datos en R</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="datos-no-sql.html"><a href="datos-no-sql.html#introMongo"><i class="fa fa-check"></i><b>7.6.1</b> Introducción a MongoDB</a></li>
<li class="chapter" data-level="7.6.2" data-path="datos-no-sql.html"><a href="datos-no-sql.html#paquetesCaso"><i class="fa fa-check"></i><b>7.6.2</b> Plataforma tecnológica para el caso práctico</a></li>
<li class="chapter" data-level="7.6.3" data-path="datos-no-sql.html"><a href="datos-no-sql.html#conexionMongo"><i class="fa fa-check"></i><b>7.6.3</b> Conexión y acceso a MongoDB desde R</a></li>
<li class="chapter" data-level="7.6.4" data-path="datos-no-sql.html"><a href="datos-no-sql.html#consultaViajes"><i class="fa fa-check"></i><b>7.6.4</b> Obtención de datos en R desde MongoDB</a></li>
<li class="chapter" data-level="7.6.5" data-path="datos-no-sql.html"><a href="datos-no-sql.html#analisisViajes"><i class="fa fa-check"></i><b>7.6.5</b> Analizando datos de MongoDB en R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="DGDQM.html"><a href="DGDQM.html"><i class="fa fa-check"></i><b>8</b> Gobierno y gestión de calidad de datos</a>
<ul>
<li class="chapter" data-level="8.1" data-path="DGDQM.html"><a href="DGDQM.html#introducción-2"><i class="fa fa-check"></i><b>8.1</b> Introducción</a></li>
<li class="chapter" data-level="8.2" data-path="DGDQM.html"><a href="DGDQM.html#concepto-de-gobierno-de-datos"><i class="fa fa-check"></i><b>8.2</b> Concepto de Gobierno de datos</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="DGDQM.html"><a href="DGDQM.html#beneficiosDG"><i class="fa fa-check"></i><b>8.2.1</b> Beneficios del Gobierno de Datos</a></li>
<li class="chapter" data-level="8.2.2" data-path="DGDQM.html"><a href="DGDQM.html#artefactosDG"><i class="fa fa-check"></i><b>8.2.2</b> Artefactos de un sistema de Gobierno de Datos</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="DGDQM.html"><a href="DGDQM.html#marcos-y-metodologías-existentes-de-gobierno-de-datos"><i class="fa fa-check"></i><b>8.3</b> Marcos y metodologías existentes de Gobierno de Datos</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="DGDQM.html"><a href="DGDQM.html#modelo-alarcos-de-mejora-de-datos-mamd"><i class="fa fa-check"></i><b>8.3.1</b> Modelo Alarcos de Mejora de Datos (MAMD)</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="DGDQM.html"><a href="DGDQM.html#gestión-de-calidad-de-datos"><i class="fa fa-check"></i><b>8.4</b> Gestión de calidad de datos</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="DGDQM.html"><a href="DGDQM.html#medición-de-calidad-de-datos-vs-perfilado-de-datos"><i class="fa fa-check"></i><b>8.4.1</b> Medición de calidad de datos vs perfilado de datos</a></li>
<li class="chapter" data-level="8.4.2" data-path="DGDQM.html"><a href="DGDQM.html#mejora-de-datos"><i class="fa fa-check"></i><b>8.4.2</b> Mejora de datos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="id_130009.html"><a href="id_130009.html"><i class="fa fa-check"></i><b>9</b> Integración y limpieza de datos</a>
<ul>
<li class="chapter" data-level="9.1" data-path="id_130009.html"><a href="id_130009.html#introducción-3"><i class="fa fa-check"></i><b>9.1</b> Introducción</a></li>
<li class="chapter" data-level="9.2" data-path="id_130009.html"><a href="id_130009.html#problemas-de-calidad-de-datos"><i class="fa fa-check"></i><b>9.2</b> Problemas de calidad de datos</a></li>
<li class="chapter" data-level="9.3" data-path="id_130009.html"><a href="id_130009.html#niveles-inadecuados-de-completitud-valores-missing"><i class="fa fa-check"></i><b>9.3</b> Niveles inadecuados de completitud: Valores <em>missing</em></a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="id_130009.html"><a href="id_130009.html#visualización"><i class="fa fa-check"></i><b>9.3.1</b> Visualización</a></li>
<li class="chapter" data-level="9.3.2" data-path="id_130009.html"><a href="id_130009.html#imputacion"><i class="fa fa-check"></i><b>9.3.2</b> Técnicas de Imputación</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="id_130009.html"><a href="id_130009.html#mejorando-la-exactitud-y-la-precisión-eliminación-del-ruido-estadístico"><i class="fa fa-check"></i><b>9.4</b> Mejorando la exactitud y la precisión: eliminación del ruido estadístico</a></li>
<li class="chapter" data-level="9.5" data-path="id_130009.html"><a href="id_130009.html#integración-de-datos"><i class="fa fa-check"></i><b>9.5</b> Integración de datos </a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="id_120006-aed.html"><a href="id_120006-aed.html"><i class="fa fa-check"></i><b>10</b> Análisis exploratorio de datos</a>
<ul>
<li class="chapter" data-level="10.1" data-path="id_120006-aed.html"><a href="id_120006-aed.html#introducción-4"><i class="fa fa-check"></i><b>10.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="id_120006-aed.html"><a href="id_120006-aed.html#el-cuarterto-de-anscombe"><i class="fa fa-check"></i><b>10.1.1</b> El cuarterto de Anscombe</a></li>
<li class="chapter" data-level="10.1.2" data-path="id_120006-aed.html"><a href="id_120006-aed.html#conceptos-generales"><i class="fa fa-check"></i><b>10.1.2</b> Conceptos generales</a></li>
<li class="chapter" data-level="10.1.3" data-path="id_120006-aed.html"><a href="id_120006-aed.html#componentes-de-un-gráfico-y-su-representación-en-r"><i class="fa fa-check"></i><b>10.1.3</b> Componentes de un gráfico y su representación en R</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="id_120006-aed.html"><a href="id_120006-aed.html#id_120006-aeduni"><i class="fa fa-check"></i><b>10.2</b> Análisis exploratorio de una característica</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="id_120006-aed.html"><a href="id_120006-aed.html#variables-cualitativas"><i class="fa fa-check"></i><b>10.2.1</b> Variables cualitativas</a></li>
<li class="chapter" data-level="10.2.2" data-path="id_120006-aed.html"><a href="id_120006-aed.html#variables-cuantitativas"><i class="fa fa-check"></i><b>10.2.2</b> Variables cuantitativas</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="id_120006-aed.html"><a href="id_120006-aed.html#id_120006-aedmulti"><i class="fa fa-check"></i><b>10.3</b> Análisis exploratorio de varias características</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="id_120006-aed.html"><a href="id_120006-aed.html#variables-cualitativas-1"><i class="fa fa-check"></i><b>10.3.1</b> Variables cualitativas</a></li>
<li class="chapter" data-level="10.3.2" data-path="id_120006-aed.html"><a href="id_120006-aed.html#variables-cuantitativas-1"><i class="fa fa-check"></i><b>10.3.2</b> Variables cuantitativas</a></li>
<li class="chapter" data-level="10.3.3" data-path="id_120006-aed.html"><a href="id_120006-aed.html#variables-cualitativas-y-cuantitativas"><i class="fa fa-check"></i><b>10.3.3</b> Variables cualitativas y cuantitativas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="chap-feature.html"><a href="chap-feature.html"><i class="fa fa-check"></i><b>11</b> Feature selection and engineering</a>
<ul>
<li class="chapter" data-level="11.1" data-path="chap-feature.html"><a href="chap-feature.html#introducción-5"><i class="fa fa-check"></i><b>11.1</b> Introducción</a></li>
<li class="chapter" data-level="11.2" data-path="chap-feature.html"><a href="chap-feature.html#feature-selection-selección-de-variables"><i class="fa fa-check"></i><b>11.2</b> <em>Feature Selection</em> (Selección de variables)</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="chap-feature.html"><a href="chap-feature.html#métodos-de-selección-tipo-filtro"><i class="fa fa-check"></i><b>11.2.1</b> Métodos de selección tipo Filtro</a></li>
<li class="chapter" data-level="11.2.2" data-path="chap-feature.html"><a href="chap-feature.html#métodos-de-selección-de-variables-tipo-wrapper"><i class="fa fa-check"></i><b>11.2.2</b> Métodos de selección de variables tipo <em>wrapper</em></a></li>
<li class="chapter" data-level="11.2.3" data-path="chap-feature.html"><a href="chap-feature.html#métodos-de-selección-tipo-embedded"><i class="fa fa-check"></i><b>11.2.3</b> Métodos de selección tipo Embedded </a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="chap-feature.html"><a href="chap-feature.html#transformaciones-de-escala-y-de-la-distribución-de-la-variable-objetivo"><i class="fa fa-check"></i><b>11.3</b> Transformaciones de escala y de la distribución de la variable objetivo</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="chap-feature.html"><a href="chap-feature.html#id_31"><i class="fa fa-check"></i><b>11.3.1</b> Transformaciones de la variable objetivo</a></li>
<li class="chapter" data-level="11.3.2" data-path="chap-feature.html"><a href="chap-feature.html#escalado-de-datos"><i class="fa fa-check"></i><b>11.3.2</b> Escalado de datos</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="chap-feature.html"><a href="chap-feature.html#feature-engineering"><i class="fa fa-check"></i><b>11.4</b> <em>Feature engineering</em></a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="chap-feature.html"><a href="chap-feature.html#binning"><i class="fa fa-check"></i><b>11.4.1</b> <em>Binning</em> </a></li>
<li class="chapter" data-level="11.4.2" data-path="chap-feature.html"><a href="chap-feature.html#codificación"><i class="fa fa-check"></i><b>11.4.2</b> Codificación </a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="chap-feature.html"><a href="chap-feature.html#reducción-de-dimensionalidad"><i class="fa fa-check"></i><b>11.5</b> Reducción de dimensionalidad</a></li>
<li class="chapter" data-level="11.6" data-path="chap-feature.html"><a href="chap-feature.html#otras-transformaciones"><i class="fa fa-check"></i><b>11.6</b> Otras transformaciones</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="chap-feature.html"><a href="chap-feature.html#particionado-de-datos"><i class="fa fa-check"></i><b>11.6.1</b> Particionado de datos </a></li>
<li class="chapter" data-level="11.6.2" data-path="chap-feature.html"><a href="chap-feature.html#técnicas-para-manejar-datos-no-balanceados"><i class="fa fa-check"></i><b>11.6.2</b> Técnicas para manejar datos no balanceados </a></li>
<li class="chapter" data-level="11.6.3" data-path="chap-feature.html"><a href="chap-feature.html#métodos-de-remuestreo"><i class="fa fa-check"></i><b>11.6.3</b> Métodos de remuestreo </a></li>
<li class="chapter" data-level="11.6.4" data-path="chap-feature.html"><a href="chap-feature.html#ajuste-de-hiperparámetros"><i class="fa fa-check"></i><b>11.6.4</b> Ajuste de hiperparámetros</a></li>
<li class="chapter" data-level="11.6.5" data-path="chap-feature.html"><a href="chap-feature.html#evaluación-de-modelos"><i class="fa fa-check"></i><b>11.6.5</b> Evaluación de modelos</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Fundamentos de estadística</b></span></li>
<li class="chapter" data-level="12" data-path="Funda-probab.html"><a href="Funda-probab.html"><i class="fa fa-check"></i><b>12</b> Probabilidad</a>
<ul>
<li class="chapter" data-level="12.1" data-path="Funda-probab.html"><a href="Funda-probab.html#introducción-a-la-probabilidad"><i class="fa fa-check"></i><b>12.1</b> Introducción a la probabilidad</a></li>
<li class="chapter" data-level="12.2" data-path="Funda-probab.html"><a href="Funda-probab.html#probabilidad-elementos-básicos-definición-y-teoremas"><i class="fa fa-check"></i><b>12.2</b> Probabilidad: elementos básicos, definición y teoremas</a></li>
<li class="chapter" data-level="12.3" data-path="Funda-probab.html"><a href="Funda-probab.html#variable-aleatoria-y-su-distribución-tipos-de-variables-aleatorias"><i class="fa fa-check"></i><b>12.3</b> Variable aleatoria y su distribución: tipos de variables aleatorias</a></li>
<li class="chapter" data-level="12.4" data-path="Funda-probab.html"><a href="Funda-probab.html#modelos-de-distribución-de-probabilidad"><i class="fa fa-check"></i><b>12.4</b> Modelos de distribución de probabilidad</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="Funda-probab.html"><a href="Funda-probab.html#modelos-discretos"><i class="fa fa-check"></i><b>12.4.1</b> Modelos discretos</a></li>
<li class="chapter" data-level="12.4.2" data-path="Funda-probab.html"><a href="Funda-probab.html#modelos-continuos"><i class="fa fa-check"></i><b>12.4.2</b> Modelos continuos</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="Funda-probab.html"><a href="Funda-probab.html#tcl"><i class="fa fa-check"></i><b>12.5</b> Teorema central del límite</a></li>
<li class="chapter" data-level="12.6" data-path="Funda-probab.html"><a href="Funda-probab.html#distribuciones-de-probabilidad-en-r"><i class="fa fa-check"></i><b>12.6</b> Distribuciones de probabilidad en <strong>R</strong></a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="Fundainfer.html"><a href="Fundainfer.html"><i class="fa fa-check"></i><b>13</b> Inferencia estadística</a>
<ul>
<li class="chapter" data-level="13.1" data-path="Fundainfer.html"><a href="Fundainfer.html#introinfer"><i class="fa fa-check"></i><b>13.1</b> Introducción a la Inferencia Estadística</a></li>
<li class="chapter" data-level="13.2" data-path="Fundainfer.html"><a href="Fundainfer.html#mas"><i class="fa fa-check"></i><b>13.2</b> Muestreo aleatorio simple</a></li>
<li class="chapter" data-level="13.3" data-path="Fundainfer.html"><a href="Fundainfer.html#estimpuntual"><i class="fa fa-check"></i><b>13.3</b> Estimación puntual</a></li>
<li class="chapter" data-level="13.4" data-path="Fundainfer.html"><a href="Fundainfer.html#estimintervalos"><i class="fa fa-check"></i><b>13.4</b> Estimación por intervalos</a></li>
<li class="chapter" data-level="13.5" data-path="Fundainfer.html"><a href="Fundainfer.html#contrhip"><i class="fa fa-check"></i><b>13.5</b> Contrastes de hipótesis</a></li>
<li class="chapter" data-level="13.6" data-path="Fundainfer.html"><a href="Fundainfer.html#pobnormales"><i class="fa fa-check"></i><b>13.6</b> Inferencia estadística paramétrica sobre poblaciones normales</a></li>
<li class="chapter" data-level="13.7" data-path="Fundainfer.html"><a href="Fundainfer.html#ejemplopobnorm"><i class="fa fa-check"></i><b>13.7</b> Inferencia sobre poblaciones normales con <strong>R</strong></a></li>
<li class="chapter" data-level="13.8" data-path="Fundainfer.html"><a href="Fundainfer.html#contrnormalidad"><i class="fa fa-check"></i><b>13.8</b> Inferencia estadística no paramétrica: contrastes de normalidad</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="muestreo.html"><a href="muestreo.html"><i class="fa fa-check"></i><b>14</b> Muestreo y remuestreo</a>
<ul>
<li class="chapter" data-level="14.1" data-path="muestreo.html"><a href="muestreo.html#introducción-al-muestreo"><i class="fa fa-check"></i><b>14.1</b> Introducción al muestreo</a></li>
<li class="chapter" data-level="14.2" data-path="muestreo.html"><a href="muestreo.html#muestreo-aleatorio-simple-1"><i class="fa fa-check"></i><b>14.2</b> Muestreo aleatorio simple</a></li>
<li class="chapter" data-level="14.3" data-path="muestreo.html"><a href="muestreo.html#muestestra"><i class="fa fa-check"></i><b>14.3</b> Muestreo estratificado</a></li>
<li class="chapter" data-level="14.4" data-path="muestreo.html"><a href="muestreo.html#otros-tipos-de-muestreo-probabilístico"><i class="fa fa-check"></i><b>14.4</b> Otros tipos de muestreo probabilístico</a></li>
<li class="chapter" data-level="14.5" data-path="muestreo.html"><a href="muestreo.html#técnicas-de-remuestreo-bootstrap."><i class="fa fa-check"></i><b>14.5</b> Técnicas de remuestreo: Bootstrap.</a></li>
</ul></li>
<li class="part"><span><b>IV Modelización estadística</b></span></li>
<li class="chapter" data-level="15" data-path="cap-lm.html"><a href="cap-lm.html"><i class="fa fa-check"></i><b>15</b> Modelización lineal</a>
<ul>
<li class="chapter" data-level="15.1" data-path="cap-lm.html"><a href="cap-lm.html#modelización"><i class="fa fa-check"></i><b>15.1</b> Modelización</a></li>
<li class="chapter" data-level="15.2" data-path="cap-lm.html"><a href="cap-lm.html#procedimiento-de-modelización"><i class="fa fa-check"></i><b>15.2</b> Procedimiento de modelización</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="cap-lm.html"><a href="cap-lm.html#Bondad"><i class="fa fa-check"></i><b>15.2.1</b> Estimación del modelo</a></li>
<li class="chapter" data-level="15.2.2" data-path="cap-lm.html"><a href="cap-lm.html#validación-del-modelo"><i class="fa fa-check"></i><b>15.2.2</b> Validación del modelo</a></li>
<li class="chapter" data-level="15.2.3" data-path="cap-lm.html"><a href="cap-lm.html#interpretación-de-los-coeficientes"><i class="fa fa-check"></i><b>15.2.3</b> Interpretación de los coeficientes</a></li>
<li class="chapter" data-level="15.2.4" data-path="cap-lm.html"><a href="cap-lm.html#predicción"><i class="fa fa-check"></i><b>15.2.4</b> Predicción</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="cap-lm.html"><a href="cap-lm.html#procedimiento-con-r-la-función-lm"><i class="fa fa-check"></i><b>15.3</b> Procedimiento con R: la función <code>lm</code></a></li>
<li class="chapter" data-level="15.4" data-path="cap-lm.html"><a href="cap-lm.html#Casos"><i class="fa fa-check"></i><b>15.4</b> Casos prácticos</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="cap-lm.html"><a href="cap-lm.html#estimación-de-los-coeficientes"><i class="fa fa-check"></i><b>15.4.1</b> Estimación de los coeficientes</a></li>
<li class="chapter" data-level="15.4.2" data-path="cap-lm.html"><a href="cap-lm.html#validación"><i class="fa fa-check"></i><b>15.4.2</b> Validación</a></li>
<li class="chapter" data-level="15.4.3" data-path="cap-lm.html"><a href="cap-lm.html#interpretación-de-los-coeficientes-1"><i class="fa fa-check"></i><b>15.4.3</b> Interpretación de los coeficientes</a></li>
<li class="chapter" data-level="15.4.4" data-path="cap-lm.html"><a href="cap-lm.html#predicción-1"><i class="fa fa-check"></i><b>15.4.4</b> Predicción</a></li>
<li class="chapter" data-level="15.4.5" data-path="cap-lm.html"><a href="cap-lm.html#nuevo-ajuste-con-logozone"><i class="fa fa-check"></i><b>15.4.5</b> Nuevo ajuste con <code>log(Ozone)</code></a></li>
<li class="chapter" data-level="15.4.6" data-path="cap-lm.html"><a href="cap-lm.html#coeficientes-de-variables-categóricas"><i class="fa fa-check"></i><b>15.4.6</b> Coeficientes de variables categóricas</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="cap-lm.html"><a href="cap-lm.html#comentarios-finales"><i class="fa fa-check"></i><b>15.5</b> Comentarios finales</a>
<ul>
<li class="chapter" data-level="" data-path="cap-lm.html"><a href="cap-lm.html#resumen"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="cap-glm.html"><a href="cap-glm.html"><i class="fa fa-check"></i><b>16</b> Modelos lineales generalizados</a>
<ul>
<li class="chapter" data-level="16.1" data-path="cap-glm.html"><a href="cap-glm.html#motivación"><i class="fa fa-check"></i><b>16.1</b> Motivación</a></li>
<li class="chapter" data-level="16.2" data-path="cap-glm.html"><a href="cap-glm.html#modelo-y-sus-componentes"><i class="fa fa-check"></i><b>16.2</b> Modelo y sus componentes</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="cap-glm.html"><a href="cap-glm.html#función-enlace"><i class="fa fa-check"></i><b>16.2.1</b> Función enlace </a></li>
<li class="chapter" data-level="16.2.2" data-path="cap-glm.html"><a href="cap-glm.html#glms-en-r"><i class="fa fa-check"></i><b>16.2.2</b> GLMs en <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="cap-glm.html"><a href="cap-glm.html#regresión-logística"><i class="fa fa-check"></i><b>16.3</b> Regresión logística</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="cap-glm.html"><a href="cap-glm.html#procedimiento-de-ajuste"><i class="fa fa-check"></i><b>16.3.1</b> Procedimiento de ajuste</a></li>
<li class="chapter" data-level="16.3.2" data-path="cap-glm.html"><a href="cap-glm.html#adecuación-del-modelo"><i class="fa fa-check"></i><b>16.3.2</b> Adecuación del modelo</a></li>
<li class="chapter" data-level="16.3.3" data-path="cap-glm.html"><a href="cap-glm.html#SECCinterp"><i class="fa fa-check"></i><b>16.3.3</b> Interpretación de resultados</a></li>
<li class="chapter" data-level="16.3.4" data-path="cap-glm.html"><a href="cap-glm.html#predicción.-curva-roc-y-auc"><i class="fa fa-check"></i><b>16.3.4</b> Predicción. Curva ROC y AUC</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="cap-glm.html"><a href="cap-glm.html#regresión-de-poisson"><i class="fa fa-check"></i><b>16.4</b> Regresión de Poisson</a></li>
<li class="chapter" data-level="16.5" data-path="cap-glm.html"><a href="cap-glm.html#casos-prácticos"><i class="fa fa-check"></i><b>16.5</b> Casos prácticos</a>
<ul>
<li class="chapter" data-level="16.5.1" data-path="cap-glm.html"><a href="cap-glm.html#ejemplos-de-regresión-logística"><i class="fa fa-check"></i><b>16.5.1</b> Ejemplos de regresión logística</a></li>
<li class="chapter" data-level="16.5.2" data-path="cap-glm.html"><a href="cap-glm.html#ejemplo-de-regresión-de-poisson"><i class="fa fa-check"></i><b>16.5.2</b> Ejemplo de regresión de Poisson</a></li>
<li class="chapter" data-level="" data-path="cap-glm.html"><a href="cap-glm.html#resumen-1"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="cap-gam.html"><a href="cap-gam.html"><i class="fa fa-check"></i><b>17</b> Modelos aditivos generalizados</a>
<ul>
<li class="chapter" data-level="17.1" data-path="cap-gam.html"><a href="cap-gam.html#introducción-6"><i class="fa fa-check"></i><b>17.1</b> Introducción</a></li>
<li class="chapter" data-level="17.2" data-path="cap-gam.html"><a href="cap-gam.html#splines-con-penalizaciones"><i class="fa fa-check"></i><b>17.2</b> Splines con penalizaciones</a></li>
<li class="chapter" data-level="17.3" data-path="cap-gam.html"><a href="cap-gam.html#aspectos-metodológicos"><i class="fa fa-check"></i><b>17.3</b> Aspectos metodológicos</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="cap-gam.html"><a href="cap-gam.html#estimación-de-los-paraámetros-del-modelo"><i class="fa fa-check"></i><b>17.3.1</b> Estimación de los paraámetros del modelo</a></li>
<li class="chapter" data-level="17.3.2" data-path="cap-gam.html"><a href="cap-gam.html#inferencia-sobre-las-funciones-suaves"><i class="fa fa-check"></i><b>17.3.2</b> Inferencia sobre las funciones suaves</a></li>
<li class="chapter" data-level="17.3.3" data-path="cap-gam.html"><a href="cap-gam.html#suavizado-mutidimensional-y-para-datos-no-gaussianos"><i class="fa fa-check"></i><b>17.3.3</b> Suavizado mutidimensional y para datos no Gaussianos</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="cap-gam.html"><a href="cap-gam.html#la-función-gam-del-paquete-mgcv"><i class="fa fa-check"></i><b>17.4</b> La función <code>gam</code> del paquete <code>mgcv</code></a></li>
<li class="chapter" data-level="17.5" data-path="cap-gam.html"><a href="cap-gam.html#casos-prácticos-1"><i class="fa fa-check"></i><b>17.5</b> Casos prácticos</a>
<ul>
<li class="chapter" data-level="17.5.1" data-path="cap-gam.html"><a href="cap-gam.html#modelo-unidimensional-con-fossil"><i class="fa fa-check"></i><b>17.5.1</b> Modelo unidimensional con <code>fossil</code></a></li>
<li class="chapter" data-level="17.5.2" data-path="cap-gam.html"><a href="cap-gam.html#modelo-aditivo-con-airquality"><i class="fa fa-check"></i><b>17.5.2</b> Modelo aditivo con <code>airquality</code></a></li>
<li class="chapter" data-level="17.5.3" data-path="cap-gam.html"><a href="cap-gam.html#modelo-semiparamétrico-con-onions"><i class="fa fa-check"></i><b>17.5.3</b> Modelo semiparamétrico con <code>onions</code></a></li>
<li class="chapter" data-level="17.5.4" data-path="cap-gam.html"><a href="cap-gam.html#modelo-aditivo-generalizado-y-multidimensional-con-smacker"><i class="fa fa-check"></i><b>17.5.4</b> Modelo aditivo generalizado y multidimensional, con <code>smacker</code></a></li>
<li class="chapter" data-level="" data-path="cap-gam.html"><a href="cap-gam.html#resumen-2"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="cap-mxm.html"><a href="cap-mxm.html"><i class="fa fa-check"></i><b>18</b> Modelos mixtos</a>
<ul>
<li class="chapter" data-level="18.1" data-path="cap-mxm.html"><a href="cap-mxm.html#conceptos-básicos"><i class="fa fa-check"></i><b>18.1</b> Conceptos básicos</a>
<ul>
<li class="chapter" data-level="18.1.1" data-path="cap-mxm.html"><a href="cap-mxm.html#tipo-y-estructura-de-los-datos"><i class="fa fa-check"></i><b>18.1.1</b> Tipo y estructura de los datos</a></li>
<li class="chapter" data-level="18.1.2" data-path="cap-mxm.html"><a href="cap-mxm.html#efectos-fijos-o-aleatorios"><i class="fa fa-check"></i><b>18.1.2</b> ¿Efectos fijos o aleatorios?</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="cap-mxm.html"><a href="cap-mxm.html#formulación-del-modelo-con-efectos-aleatorios-o-modelos-mixtos"><i class="fa fa-check"></i><b>18.2</b> Formulación del modelo con efectos aleatorios o modelos mixtos</a>
<ul>
<li class="chapter" data-level="18.2.1" data-path="cap-mxm.html"><a href="cap-mxm.html#formulación-general"><i class="fa fa-check"></i><b>18.2.1</b> Formulación general</a></li>
<li class="chapter" data-level="18.2.2" data-path="cap-mxm.html"><a href="cap-mxm.html#inferencia-y-selección-del-modelo"><i class="fa fa-check"></i><b>18.2.2</b> Inferencia y selección del modelo</a></li>
<li class="chapter" data-level="18.2.3" data-path="cap-mxm.html"><a href="cap-mxm.html#diagnosis-del-modelo"><i class="fa fa-check"></i><b>18.2.3</b> Diagnosis del modelo</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="cap-mxm.html"><a href="cap-mxm.html#funciones-de-r-para-ajustar-modelos-mixtos"><i class="fa fa-check"></i><b>18.3</b> Funciones de <code>R</code> para ajustar modelos mixtos</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="cap-mxm.html"><a href="cap-mxm.html#la-función-lmer"><i class="fa fa-check"></i><b>18.3.1</b> La función <code>lmer()</code></a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="cap-mxm.html"><a href="cap-mxm.html#caso-práctico"><i class="fa fa-check"></i><b>18.4</b> Caso práctico</a>
<ul>
<li class="chapter" data-level="18.4.1" data-path="cap-mxm.html"><a href="cap-mxm.html#modelo-con-ordenada-en-el-origen-aleatoria"><i class="fa fa-check"></i><b>18.4.1</b> Modelo con ordenada en el origen aleatoria</a></li>
<li class="chapter" data-level="18.4.2" data-path="cap-mxm.html"><a href="cap-mxm.html#modelo-con-pendiente-aleatoria"><i class="fa fa-check"></i><b>18.4.2</b> Modelo con pendiente aleatoria</a></li>
<li class="chapter" data-level="18.4.3" data-path="cap-mxm.html"><a href="cap-mxm.html#cómo-construir-el-modelo-en-la-práctica"><i class="fa fa-check"></i><b>18.4.3</b> ¿Cómo construir el modelo en la práctica?</a></li>
<li class="chapter" data-level="" data-path="cap-mxm.html"><a href="cap-mxm.html#resumen-3"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="cap-sparse.html"><a href="cap-sparse.html"><i class="fa fa-check"></i><b>19</b> Modelos sparse y métodos penalizados de regresión</a>
<ul>
<li class="chapter" data-level="19.1" data-path="cap-sparse.html"><a href="cap-sparse.html#introducción-7"><i class="fa fa-check"></i><b>19.1</b> Introducción</a></li>
<li class="chapter" data-level="19.2" data-path="cap-sparse.html"><a href="cap-sparse.html#selección-del-mejor-subconjunto"><i class="fa fa-check"></i><b>19.2</b> Selección del mejor subconjunto</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="cap-sparse.html"><a href="cap-sparse.html#ejemplo-sueldo-de-jugadores-de-béisbol"><i class="fa fa-check"></i><b>19.2.1</b> Ejemplo: Sueldo de jugadores de béisbol</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="cap-sparse.html"><a href="cap-sparse.html#selección-stepwise"><i class="fa fa-check"></i><b>19.3</b> Selección <em>Stepwise</em></a>
<ul>
<li class="chapter" data-level="19.3.1" data-path="cap-sparse.html"><a href="cap-sparse.html#forward-stepwise"><i class="fa fa-check"></i><b>19.3.1</b> Forward stepwise</a></li>
<li class="chapter" data-level="19.3.2" data-path="cap-sparse.html"><a href="cap-sparse.html#backward-stepwise"><i class="fa fa-check"></i><b>19.3.2</b> Backward stepwise</a></li>
<li class="chapter" data-level="19.3.3" data-path="cap-sparse.html"><a href="cap-sparse.html#ejemplo-sueldo-de-jugadores-de-béisbol-1"><i class="fa fa-check"></i><b>19.3.3</b> Ejemplo: Sueldo de jugadores de béisbol</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="cap-sparse.html"><a href="cap-sparse.html#métodos-shrinkage"><i class="fa fa-check"></i><b>19.4</b> Métodos Shrinkage</a>
<ul>
<li class="chapter" data-level="19.4.1" data-path="cap-sparse.html"><a href="cap-sparse.html#regresión-ridge"><i class="fa fa-check"></i><b>19.4.1</b> Regresión ridge</a></li>
<li class="chapter" data-level="19.4.2" data-path="cap-sparse.html"><a href="cap-sparse.html#selección-del-parámetro-de-tuneado"><i class="fa fa-check"></i><b>19.4.2</b> Selección del parámetro de tuneado</a></li>
<li class="chapter" data-level="19.4.3" data-path="cap-sparse.html"><a href="cap-sparse.html#regresión-lasso"><i class="fa fa-check"></i><b>19.4.3</b> Regresión Lasso</a></li>
<li class="chapter" data-level="19.4.4" data-path="cap-sparse.html"><a href="cap-sparse.html#elastic-net"><i class="fa fa-check"></i><b>19.4.4</b> Elastic net </a></li>
<li class="chapter" data-level="" data-path="cap-sparse.html"><a href="cap-sparse.html#resumen-4"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="20" data-path="cap-series-temp.html"><a href="cap-series-temp.html"><i class="fa fa-check"></i><b>20</b> Modelización de series temporales</a>
<ul>
<li class="chapter" data-level="20.1" data-path="cap-series-temp.html"><a href="cap-series-temp.html#conceptos-básicos-1"><i class="fa fa-check"></i><b>20.1</b> Conceptos básicos</a></li>
<li class="chapter" data-level="20.2" data-path="cap-series-temp.html"><a href="cap-series-temp.html#modelos-arima"><i class="fa fa-check"></i><b>20.2</b> Modelos ARIMA</a></li>
<li class="chapter" data-level="20.3" data-path="cap-series-temp.html"><a href="cap-series-temp.html#análisis-de-series-temporales-con-r"><i class="fa fa-check"></i><b>20.3</b> Análisis de series temporales con <strong>R</strong></a>
<ul>
<li class="chapter" data-level="20.3.1" data-path="cap-series-temp.html"><a href="cap-series-temp.html#identificación-o-especificación-del-modelo"><i class="fa fa-check"></i><b>20.3.1</b> Identificación o especificación del modelo</a></li>
<li class="chapter" data-level="20.3.2" data-path="cap-series-temp.html"><a href="cap-series-temp.html#estimación-del-modelo"><i class="fa fa-check"></i><b>20.3.2</b> Estimación del modelo</a></li>
<li class="chapter" data-level="20.3.3" data-path="cap-series-temp.html"><a href="cap-series-temp.html#diagnosis-validación-y-contrastación"><i class="fa fa-check"></i><b>20.3.3</b> Diagnosis, validación y contrastación</a></li>
<li class="chapter" data-level="20.3.4" data-path="cap-series-temp.html"><a href="cap-series-temp.html#predicción-2"><i class="fa fa-check"></i><b>20.3.4</b> Predicción</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="cap-discriminante.html"><a href="cap-discriminante.html"><i class="fa fa-check"></i><b>21</b> Análisis discriminante</a>
<ul>
<li class="chapter" data-level="21.1" data-path="cap-discriminante.html"><a href="cap-discriminante.html#introducción-8"><i class="fa fa-check"></i><b>21.1</b> Introducción</a></li>
<li class="chapter" data-level="21.2" data-path="cap-discriminante.html"><a href="cap-discriminante.html#tipos-de-análisis-discriminantes"><i class="fa fa-check"></i><b>21.2</b> Tipos de análisis discriminantes:</a></li>
<li class="chapter" data-level="21.3" data-path="cap-discriminante.html"><a href="cap-discriminante.html#procedimiento-con-r-las-funciones-lda-qda-y-mda"><i class="fa fa-check"></i><b>21.3</b> Procedimiento con <strong>R</strong>: las funciones <code>lda()</code>, <code>qda()</code> y <code>mda()</code></a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="cap-conjunto.html"><a href="cap-conjunto.html"><i class="fa fa-check"></i><b>22</b> Análisis conjunto</a>
<ul>
<li class="chapter" data-level="22.1" data-path="cap-conjunto.html"><a href="cap-conjunto.html#introducción-conceptos-clave-y-tipos-de-análisis"><i class="fa fa-check"></i><b>22.1</b> Introducción, conceptos clave y tipos de análisis</a></li>
<li class="chapter" data-level="22.2" data-path="cap-conjunto.html"><a href="cap-conjunto.html#aplicación-del-análisis-conjunto-etapas"><i class="fa fa-check"></i><b>22.2</b> Aplicación del Análisis Conjunto (etapas):</a></li>
<li class="chapter" data-level="22.3" data-path="cap-conjunto.html"><a href="cap-conjunto.html#procedimiento-con-r-la-función-conjoint"><i class="fa fa-check"></i><b>22.3</b> Procedimiento con <strong>R</strong>: la función <code>Conjoint()</code></a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html"><i class="fa fa-check"></i><b>23</b> Análisis de tablas de contingencia</a>
<ul>
<li class="chapter" data-level="23.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#introducción-9"><i class="fa fa-check"></i><b>23.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="23.1.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#motiv"><i class="fa fa-check"></i><b>23.1.1</b> Motivación</a></li>
<li class="chapter" data-level="23.1.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#notac"><i class="fa fa-check"></i><b>23.1.2</b> Notación</a></li>
<li class="chapter" data-level="23.1.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#diseños-experimentales-o-procedimientos-de-muestreo-que-dan-lugar-a-una-tabla-de-contingencia"><i class="fa fa-check"></i><b>23.1.3</b> Diseños experimentales o procedimientos de muestreo que dan lugar a una tabla de contingencia</a></li>
</ul></li>
<li class="chapter" data-level="23.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contraste-de-independencia-en-tablas-2times-2"><i class="fa fa-check"></i><b>23.2</b> Contraste de independencia en tablas <span class="math inline">\(2\times 2\)</span></a>
<ul>
<li class="chapter" data-level="23.2.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#introducción-10"><i class="fa fa-check"></i><b>23.2.1</b> Introducción</a></li>
<li class="chapter" data-level="23.2.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#plantgen"><i class="fa fa-check"></i><b>23.2.2</b> Planteamiento general del contraste exacto de independencia</a></li>
<li class="chapter" data-level="23.2.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#algoritmo"><i class="fa fa-check"></i><b>23.2.3</b> Algoritmo para la realización del contraste exacto de independencia</a></li>
<li class="chapter" data-level="23.2.4" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contraste-de-independencia-diseño-tipo-1"><i class="fa fa-check"></i><b>23.2.4</b> Contraste de independencia: Diseño Tipo 1</a></li>
<li class="chapter" data-level="23.2.5" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#dise"><i class="fa fa-check"></i><b>23.2.5</b> Contraste de independencia: Diseños Tipo 2 y Tipo 3</a></li>
</ul></li>
<li class="chapter" data-level="23.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contraste-de-independencia-en-tablas-rtimes-c"><i class="fa fa-check"></i><b>23.3</b> Contraste de independencia en tablas <span class="math inline">\(R\times C\)</span></a>
<ul>
<li class="chapter" data-level="23.3.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#IntroRxC"><i class="fa fa-check"></i><b>23.3.1</b> Introducción</a></li>
<li class="chapter" data-level="23.3.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contaprox"><i class="fa fa-check"></i><b>23.3.2</b> Contrastes aproximados</a></li>
<li class="chapter" data-level="23.3.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contraste-aproximado-con-corrección-de-continuidad-1"><i class="fa fa-check"></i><b>23.3.3</b> Contraste aproximado con corrección de continuidad</a></li>
</ul></li>
<li class="chapter" data-level="23.4" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#medidas"><i class="fa fa-check"></i><b>23.4</b> Medidas de asociación en tablas <span class="math inline">\(2\times 2\)</span></a>
<ul>
<li class="chapter" data-level="23.4.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#introducción-11"><i class="fa fa-check"></i><b>23.4.1</b> Introducción</a></li>
<li class="chapter" data-level="23.4.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#la-hatq-de-yule"><i class="fa fa-check"></i><b>23.4.2</b> La <span class="math inline">\(\hat{Q}\)</span> de Yule</a></li>
<li class="chapter" data-level="23.4.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#otras-medidas-de-asociación-para-tablas-2times-2"><i class="fa fa-check"></i><b>23.4.3</b> Otras medidas de asociación para tablas <span class="math inline">\(2\times 2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="23.5" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#medidas-de-asociación-en-tablas-rtimes-c"><i class="fa fa-check"></i><b>23.5</b> Medidas de asociación en tablas <span class="math inline">\(R\times C\)</span></a>
<ul>
<li class="chapter" data-level="23.5.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#introducción-12"><i class="fa fa-check"></i><b>23.5.1</b> Introducción</a></li>
<li class="chapter" data-level="23.5.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#medidas-derivadas-del-estadístico-chi-cuadrado"><i class="fa fa-check"></i><b>23.5.2</b> Medidas derivadas del estadístico Chi-cuadrado</a></li>
<li class="chapter" data-level="23.5.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#medidas-basadas-en-la-reducción-proporcional-del-error-lambda-de-goodman-y-kruskal"><i class="fa fa-check"></i><b>23.5.3</b> Medidas basadas en la reducción proporcional del error: <span class="math inline">\(\lambda\)</span> de Goodman y Kruskal</a></li>
<li class="chapter" data-level="23.5.4" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#determinación-de-las-fuentes-de-asociación"><i class="fa fa-check"></i><b>23.5.4</b> Determinación de las fuentes de asociación</a></li>
</ul></li>
<li class="chapter" data-level="23.6" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contrastes-de-independencia-en-tablas-multidimensionales"><i class="fa fa-check"></i><b>23.6</b> Contrastes de independencia en tablas multidimensionales</a></li>
</ul></li>
<li class="part"><span><b>V Machine learning supervisado</b></span></li>
<li class="chapter" data-level="24" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html"><i class="fa fa-check"></i><b>24</b> Árboles de clasificación y regresión </a>
<ul>
<li class="chapter" data-level="24.1" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#introducción-13"><i class="fa fa-check"></i><b>24.1</b> Introducción </a></li>
<li class="chapter" data-level="24.2" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#aprendizaje-con-árboles-de-decisión"><i class="fa fa-check"></i><b>24.2</b> Aprendizaje con árboles de decisión</a></li>
<li class="chapter" data-level="24.3" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#cómo-se-va-dividiendo-el-árbol"><i class="fa fa-check"></i><b>24.3</b> ¿Cómo se va dividiendo el árbol? </a>
<ul>
<li class="chapter" data-level="24.3.1" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#impureza-de-gini"><i class="fa fa-check"></i><b>24.3.1</b> Impureza de Gini</a></li>
<li class="chapter" data-level="24.3.2" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#entropía"><i class="fa fa-check"></i><b>24.3.2</b> Entropía </a></li>
<li class="chapter" data-level="24.3.3" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#ganancia-de-información"><i class="fa fa-check"></i><b>24.3.3</b> Ganancia de información</a></li>
<li class="chapter" data-level="24.3.4" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#suma-residual-de-cuadrados-mínima"><i class="fa fa-check"></i><b>24.3.4</b> Suma residual de cuadrados mínima</a></li>
</ul></li>
<li class="chapter" data-level="24.4" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#sobreajuste"><i class="fa fa-check"></i><b>24.4</b> Sobreajuste </a></li>
<li class="chapter" data-level="24.5" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#cuánto-debe-crecer-un-árbol"><i class="fa fa-check"></i><b>24.5</b> ¿Cuánto debe crecer un árbol? </a>
<ul>
<li class="chapter" data-level="24.5.1" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#la-parada-temprana"><i class="fa fa-check"></i><b>24.5.1</b> La parada temprana </a></li>
<li class="chapter" data-level="24.5.2" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#la-poda"><i class="fa fa-check"></i><b>24.5.2</b> La poda </a></li>
</ul></li>
<li class="chapter" data-level="24.6" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#el-algoritmo-id3-para-la-construcción-de-un-árbol-de-decisión"><i class="fa fa-check"></i><b>24.6</b> El algoritmo ID3 para la construcción de un árbol de decisión</a></li>
<li class="chapter" data-level="24.7" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#procedimiento-con-r-la-funcion-rpart"><i class="fa fa-check"></i><b>24.7</b> Procedimiento con R: la funcion <code>rpart</code></a></li>
<li class="chapter" data-level="24.8" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#aplicaciones-de-los-árboles-de-decisión"><i class="fa fa-check"></i><b>24.8</b> Aplicaciones de los árboles de decisión</a>
<ul>
<li class="chapter" data-level="24.8.1" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#el-caso-de-negocio"><i class="fa fa-check"></i><b>24.8.1</b> El caso de negocio</a></li>
<li class="chapter" data-level="24.8.2" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#árbol-de-clasificación-para-determinar-la-intención-de-compra"><i class="fa fa-check"></i><b>24.8.2</b> Árbol de clasificación para determinar la intención de compra</a></li>
<li class="chapter" data-level="24.8.3" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#árbol-de-regresión-para-estimar-el-número-de-días-hospitalizado"><i class="fa fa-check"></i><b>24.8.3</b> Árbol de regresión para estimar el número de días hospitalizado</a></li>
<li class="chapter" data-level="" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#resumen-5"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="25" data-path="cap-svm.html"><a href="cap-svm.html"><i class="fa fa-check"></i><b>25</b> Máquinas de vector soporte</a>
<ul>
<li class="chapter" data-level="25.1" data-path="cap-svm.html"><a href="cap-svm.html#introducción-14"><i class="fa fa-check"></i><b>25.1</b> Introducción</a></li>
<li class="chapter" data-level="25.2" data-path="cap-svm.html"><a href="cap-svm.html#algoritmo-svm-para-clasificación-binaria"><i class="fa fa-check"></i><b>25.2</b> Algoritmo SVM para clasificación binaria</a></li>
<li class="chapter" data-level="25.3" data-path="cap-svm.html"><a href="cap-svm.html#y-si-tengo-más-de-dos-clases"><i class="fa fa-check"></i><b>25.3</b> ¿Y si tengo más de dos clases?</a></li>
<li class="chapter" data-level="25.4" data-path="cap-svm.html"><a href="cap-svm.html#truco-del-kernel-tratando-con-la-no-linearidad"><i class="fa fa-check"></i><b>25.4</b> Truco del Kernel: Tratando con la no linearidad</a>
<ul>
<li class="chapter" data-level="25.4.1" data-path="cap-svm.html"><a href="cap-svm.html#algunos-kernels-populares"><i class="fa fa-check"></i><b>25.4.1</b> Algunos kernels populares</a></li>
</ul></li>
<li class="chapter" data-level="25.5" data-path="cap-svm.html"><a href="cap-svm.html#procedimiento-con-r-la-funcion-svm"><i class="fa fa-check"></i><b>25.5</b> Procedimiento con R: la funcion <code>svm</code></a></li>
<li class="chapter" data-level="25.6" data-path="cap-svm.html"><a href="cap-svm.html#aplicación-de-un-modelo-svm-radial-con-ajuste-automático-en-r"><i class="fa fa-check"></i><b>25.6</b> Aplicación de un modelo SVM Radial con ajuste automático en R</a>
<ul>
<li class="chapter" data-level="25.6.1" data-path="cap-svm.html"><a href="cap-svm.html#importancia-de-las-variables"><i class="fa fa-check"></i><b>25.6.1</b> Importancia de las variables</a></li>
<li class="chapter" data-level="" data-path="cap-svm.html"><a href="cap-svm.html#resumen-6"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="26" data-path="cap-knn.html"><a href="cap-knn.html"><i class="fa fa-check"></i><b>26</b> Clasificador k-vecinos más próximos</a>
<ul>
<li class="chapter" data-level="26.1" data-path="cap-knn.html"><a href="cap-knn.html#introducción-15"><i class="fa fa-check"></i><b>26.1</b> Introducción</a></li>
<li class="chapter" data-level="26.2" data-path="cap-knn.html"><a href="cap-knn.html#decisiones-a-tener-en-cuenta"><i class="fa fa-check"></i><b>26.2</b> Decisiones a tener en cuenta</a>
<ul>
<li class="chapter" data-level="26.2.1" data-path="cap-knn.html"><a href="cap-knn.html#función-de-distancia-a-utilizar"><i class="fa fa-check"></i><b>26.2.1</b> Función de distancia a utilizar</a></li>
<li class="chapter" data-level="26.2.2" data-path="cap-knn.html"><a href="cap-knn.html#número-de-vecinos-k-seleccionados"><i class="fa fa-check"></i><b>26.2.2</b> Número de vecinos (k) seleccionados</a></li>
</ul></li>
<li class="chapter" data-level="26.3" data-path="cap-knn.html"><a href="cap-knn.html#procedimiento-con-r-la-funcion-knn"><i class="fa fa-check"></i><b>26.3</b> Procedimiento con R: la funcion knn</a></li>
<li class="chapter" data-level="26.4" data-path="cap-knn.html"><a href="cap-knn.html#aplicación-del-modelo-knn-en-r"><i class="fa fa-check"></i><b>26.4</b> Aplicación del modelo KNN en R</a>
<ul>
<li class="chapter" data-level="" data-path="cap-knn.html"><a href="cap-knn.html#resumen-7"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="27" data-path="cap-naive-bayes.html"><a href="cap-naive-bayes.html"><i class="fa fa-check"></i><b>27</b> Naive Bayes</a>
<ul>
<li class="chapter" data-level="27.1" data-path="cap-naive-bayes.html"><a href="cap-naive-bayes.html#introducción-16"><i class="fa fa-check"></i><b>27.1</b> Introducción</a></li>
<li class="chapter" data-level="27.2" data-path="cap-naive-bayes.html"><a href="cap-naive-bayes.html#teorema-de-bayes"><i class="fa fa-check"></i><b>27.2</b> Teorema de Bayes</a></li>
<li class="chapter" data-level="27.3" data-path="cap-naive-bayes.html"><a href="cap-naive-bayes.html#el-algoritmo-naive-bayes"><i class="fa fa-check"></i><b>27.3</b> El algoritmo Naive Bayes</a></li>
<li class="chapter" data-level="27.4" data-path="cap-naive-bayes.html"><a href="cap-naive-bayes.html#procedimiento-con-r-la-funcion-naive_bayes"><i class="fa fa-check"></i><b>27.4</b> Procedimiento con R: la funcion <code>naive_bayes</code></a></li>
<li class="chapter" data-level="27.5" data-path="cap-naive-bayes.html"><a href="cap-naive-bayes.html#aplicación-del-modelo-naive-bayes"><i class="fa fa-check"></i><b>27.5</b> Aplicación del modelo Naive Bayes</a>
<ul>
<li class="chapter" data-level="" data-path="cap-naive-bayes.html"><a href="cap-naive-bayes.html#resumen-8"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="28" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html"><i class="fa fa-check"></i><b>28</b> Bagging. Random Forest </a>
<ul>
<li class="chapter" data-level="28.1" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#introducción-metodos-de-ensamble"><i class="fa fa-check"></i><b>28.1</b> Introducción: Metodos de Ensamble</a></li>
<li class="chapter" data-level="28.2" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#bagging"><i class="fa fa-check"></i><b>28.2</b> Bagging</a></li>
<li class="chapter" data-level="28.3" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#procedimiento-con-r-la-función-bagging"><i class="fa fa-check"></i><b>28.3</b> Procedimiento con R: la función <code>bagging</code> </a></li>
<li class="chapter" data-level="28.4" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#implementando-bagging-en-r"><i class="fa fa-check"></i><b>28.4</b> Implementando bagging en R</a>
<ul>
<li class="chapter" data-level="28.4.1" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#interpretación-de-variables-en-el-bagging"><i class="fa fa-check"></i><b>28.4.1</b> Interpretación de variables en el bagging</a></li>
</ul></li>
<li class="chapter" data-level="28.5" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#random-forest"><i class="fa fa-check"></i><b>28.5</b> Random Forest</a>
<ul>
<li class="chapter" data-level="28.5.1" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#número-de-árboles-k"><i class="fa fa-check"></i><b>28.5.1</b> Número de árboles (<span class="math inline">\(K\)</span>)</a></li>
<li class="chapter" data-level="28.5.2" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#número-de-variables-a-considerar-mtry"><i class="fa fa-check"></i><b>28.5.2</b> Número de variables a considerar (<span class="math inline">\(mtry\)</span>)</a></li>
<li class="chapter" data-level="28.5.3" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#complejidad-de-los-árboles"><i class="fa fa-check"></i><b>28.5.3</b> Complejidad de los árboles</a></li>
<li class="chapter" data-level="28.5.4" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#esquema-de-muestreo"><i class="fa fa-check"></i><b>28.5.4</b> Esquema de muestreo</a></li>
<li class="chapter" data-level="28.5.5" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#regla-de-división"><i class="fa fa-check"></i><b>28.5.5</b> Regla de división</a></li>
</ul></li>
<li class="chapter" data-level="28.6" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#procedimiento-con-r-la-función-randomforest"><i class="fa fa-check"></i><b>28.6</b> Procedimiento con R: la función <code>randomForest</code></a></li>
<li class="chapter" data-level="28.7" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#aplicación-del-modelo-random-forest-en-r"><i class="fa fa-check"></i><b>28.7</b> Aplicación del modelo Random Forest en R</a>
<ul>
<li class="chapter" data-level="28.7.1" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#aplicación-del-random-forest"><i class="fa fa-check"></i><b>28.7.1</b> Aplicación del Random Forest</a></li>
<li class="chapter" data-level="" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#resumen-9"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="29" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html"><i class="fa fa-check"></i><b>29</b> Boosting. XGBoost</a>
<ul>
<li class="chapter" data-level="29.1" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#introducción.-boosting."><i class="fa fa-check"></i><b>29.1</b> Introducción. Boosting.</a></li>
<li class="chapter" data-level="29.2" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#gradient-boosting"><i class="fa fa-check"></i><b>29.2</b> Gradient Boosting</a>
<ul>
<li class="chapter" data-level="29.2.1" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#hiperparámetros-del-modelo-gradient-boosting"><i class="fa fa-check"></i><b>29.2.1</b> Hiperparámetros del modelo gradient boosting</a></li>
<li class="chapter" data-level="29.2.2" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#estrategia-de-ajuste-de-hiperparametros"><i class="fa fa-check"></i><b>29.2.2</b> Estrategia de ajuste de hiperparametros</a></li>
</ul></li>
<li class="chapter" data-level="29.3" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#procedimiento-con-r-la-funcion-gbm"><i class="fa fa-check"></i><b>29.3</b> Procedimiento con R: la funcion <code>gbm</code></a></li>
<li class="chapter" data-level="29.4" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#aplicación-del-modelo-gbm-en-r"><i class="fa fa-check"></i><b>29.4</b> Aplicación del modelo GBM en R</a>
<ul>
<li class="chapter" data-level="29.4.1" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#gbm-con-ajuste-automático"><i class="fa fa-check"></i><b>29.4.1</b> GBM con ajuste automático</a></li>
</ul></li>
<li class="chapter" data-level="29.5" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#extreme-gradient-boosting-xgb"><i class="fa fa-check"></i><b>29.5</b> eXtreme Gradient Boosting (XGB)</a>
<ul>
<li class="chapter" data-level="29.5.1" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#hiperparametros-del-modelo-xgboost"><i class="fa fa-check"></i><b>29.5.1</b> Hiperparametros del modelo XGBoost</a></li>
</ul></li>
<li class="chapter" data-level="29.6" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#procedimiento-con-r-la-funcion-xgboost"><i class="fa fa-check"></i><b>29.6</b> Procedimiento con R: la funcion <code>xgboost</code></a></li>
<li class="chapter" data-level="29.7" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#aplicación-del-módelo-xgboost-en-r"><i class="fa fa-check"></i><b>29.7</b> Aplicación del módelo XGBoost en R</a>
<ul>
<li class="chapter" data-level="29.7.1" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#xgboost-y-ajuste-automático"><i class="fa fa-check"></i><b>29.7.1</b> XGBoost y ajuste automático</a></li>
<li class="chapter" data-level="" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#resumen-10"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>VI Machine learning no supervisado</b></span></li>
<li class="chapter" data-level="30" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html"><i class="fa fa-check"></i><b>30</b> Análisis cluster: clusterización jerárquica</a>
<ul>
<li class="chapter" data-level="30.1" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#origen-cluster"><i class="fa fa-check"></i><b>30.1</b> Introducción</a></li>
<li class="chapter" data-level="30.2" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#selección-de-las-variables"><i class="fa fa-check"></i><b>30.2</b> Selección de las variables</a></li>
<li class="chapter" data-level="30.3" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#elección-de-la-distancia-entre-elementos"><i class="fa fa-check"></i><b>30.3</b> Elección de la distancia entre elementos</a></li>
<li class="chapter" data-level="30.4" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#técnicas-de-agrupación-jerárquicas"><i class="fa fa-check"></i><b>30.4</b> Técnicas de agrupación jerárquicas</a>
<ul>
<li class="chapter" data-level="30.4.1" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#introac"><i class="fa fa-check"></i><b>30.4.1</b> Introducción</a></li>
<li class="chapter" data-level="30.4.2" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#técnicas-jerárquicas-aglomerativas"><i class="fa fa-check"></i><b>30.4.2</b> Técnicas jerárquicas aglomerativas</a></li>
<li class="chapter" data-level="30.4.3" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#técnicas-jerárquicas-divisivas"><i class="fa fa-check"></i><b>30.4.3</b> Técnicas jerárquicas divisivas</a></li>
</ul></li>
<li class="chapter" data-level="30.5" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#calidad-de-la-agrupación-y-número-de-clusters"><i class="fa fa-check"></i><b>30.5</b> Calidad de la agrupación y número de clusters</a>
<ul>
<li class="chapter" data-level="30.5.1" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#el-coeficiente-de-correlación-lineal-cofenético"><i class="fa fa-check"></i><b>30.5.1</b> El coeficiente de correlación lineal cofenético</a></li>
<li class="chapter" data-level="30.5.2" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#número-óptimo-de-clusters"><i class="fa fa-check"></i><b>30.5.2</b> Número óptimo de clusters</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="31" data-path="no-jerarquico.html"><a href="no-jerarquico.html"><i class="fa fa-check"></i><b>31</b> Análisis cluster: clusterización no jerárquica</a>
<ul>
<li class="chapter" data-level="31.1" data-path="no-jerarquico.html"><a href="no-jerarquico.html#métodos-de-reasignación"><i class="fa fa-check"></i><b>31.1</b> Métodos de reasignación</a>
<ul>
<li class="chapter" data-level="31.1.1" data-path="no-jerarquico.html"><a href="no-jerarquico.html#técnicas-basadas-en-centroides-métodos-de-forgy-y-bf-k-medias"><i class="fa fa-check"></i><b>31.1.1</b> Técnicas basadas en centroides: métodos de Forgy y <span class="math inline">\(\bf k\)</span>-medias</a></li>
<li class="chapter" data-level="31.1.2" data-path="no-jerarquico.html"><a href="no-jerarquico.html#técnicas-basadas-en-medoides"><i class="fa fa-check"></i><b>31.1.2</b> Técnicas basadas en medoides</a></li>
<li class="chapter" data-level="31.1.3" data-path="no-jerarquico.html"><a href="no-jerarquico.html#técnicas-basadas-en-medianas-bf-k-medianas"><i class="fa fa-check"></i><b>31.1.3</b> Técnicas basadas en medianas: <span class="math inline">\(\bf k\)</span>-medianas</a></li>
</ul></li>
<li class="chapter" data-level="31.2" data-path="no-jerarquico.html"><a href="no-jerarquico.html#métodos-basados-en-la-densidad-de-puntos"><i class="fa fa-check"></i><b>31.2</b> Métodos basados en la densidad de puntos</a></li>
<li class="chapter" data-level="31.3" data-path="no-jerarquico.html"><a href="no-jerarquico.html#otros-métodos"><i class="fa fa-check"></i><b>31.3</b> Otros métodos</a></li>
<li class="chapter" data-level="31.4" data-path="no-jerarquico.html"><a href="no-jerarquico.html#nota-final"><i class="fa fa-check"></i><b>31.4</b> Nota final</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="acp.html"><a href="acp.html"><i class="fa fa-check"></i><b>32</b> Análisis de componentes principales</a>
<ul>
<li class="chapter" data-level="32.1" data-path="acp.html"><a href="acp.html#introducción-17"><i class="fa fa-check"></i><b>32.1</b> Introducción</a></li>
<li class="chapter" data-level="32.2" data-path="acp.html"><a href="acp.html#obtención-de-las-componentes-principales"><i class="fa fa-check"></i><b>32.2</b> Obtención de las componentes principales</a>
<ul>
<li class="chapter" data-level="32.2.1" data-path="acp.html"><a href="acp.html#descripción-formal-del-proceso"><i class="fa fa-check"></i><b>32.2.1</b> Descripción formal del proceso</a></li>
<li class="chapter" data-level="32.2.2" data-path="acp.html"><a href="acp.html#cuestiones-importantes-en-el-acp"><i class="fa fa-check"></i><b>32.2.2</b> Cuestiones importantes en el ACP</a></li>
</ul></li>
<li class="chapter" data-level="32.3" data-path="acp.html"><a href="acp.html#estimación-de-las-componentes-principales"><i class="fa fa-check"></i><b>32.3</b> Estimación de las componentes principales</a></li>
<li class="chapter" data-level="32.4" data-path="acp.html"><a href="acp.html#numcomp"><i class="fa fa-check"></i><b>32.4</b> Número de componentes a retener</a></li>
<li class="chapter" data-level="32.5" data-path="acp.html"><a href="acp.html#interpretación-de-las-cp"><i class="fa fa-check"></i><b>32.5</b> Interpretación de las CP</a></li>
<li class="chapter" data-level="32.6" data-path="acp.html"><a href="acp.html#reproducción-de-los-datos-tipificados-y-de-r-a-partir-de-las-cp"><i class="fa fa-check"></i><b>32.6</b> Reproducción de los datos tipificados y de R a partir de las CP</a></li>
<li class="chapter" data-level="32.7" data-path="acp.html"><a href="acp.html#limitaciones-del-acp"><i class="fa fa-check"></i><b>32.7</b> Limitaciones del ACP</a></li>
</ul></li>
<li class="chapter" data-level="33" data-path="análisis-factorial.html"><a href="análisis-factorial.html"><i class="fa fa-check"></i><b>33</b> Análisis factorial</a>
<ul>
<li class="chapter" data-level="33.1" data-path="análisis-factorial.html"><a href="análisis-factorial.html#introaf"><i class="fa fa-check"></i><b>33.1</b> Introducción</a></li>
<li class="chapter" data-level="33.2" data-path="análisis-factorial.html"><a href="análisis-factorial.html#elementos-teóricos-del-análisis-factorial"><i class="fa fa-check"></i><b>33.2</b> Elementos teóricos del análisis factorial</a>
<ul>
<li class="chapter" data-level="33.2.1" data-path="análisis-factorial.html"><a href="análisis-factorial.html#modelobasicoaf"><i class="fa fa-check"></i><b>33.2.1</b> Modelo básico y terminología</a></li>
<li class="chapter" data-level="33.2.2" data-path="análisis-factorial.html"><a href="análisis-factorial.html#patrón-y-estructura-factoriales"><i class="fa fa-check"></i><b>33.2.2</b> Patrón y estructura factoriales</a></li>
</ul></li>
<li class="chapter" data-level="33.3" data-path="análisis-factorial.html"><a href="análisis-factorial.html#el-análisis-factorial-en-la-práctica"><i class="fa fa-check"></i><b>33.3</b> El análisis factorial en la práctica</a>
<ul>
<li class="chapter" data-level="33.3.1" data-path="análisis-factorial.html"><a href="análisis-factorial.html#pre-análisis-factorial"><i class="fa fa-check"></i><b>33.3.1</b> Pre-análisis factorial</a></li>
<li class="chapter" data-level="33.3.2" data-path="análisis-factorial.html"><a href="análisis-factorial.html#análisis-factorial-1"><i class="fa fa-check"></i><b>33.3.2</b> Análisis factorial</a></li>
<li class="chapter" data-level="33.3.3" data-path="análisis-factorial.html"><a href="análisis-factorial.html#postanalisis"><i class="fa fa-check"></i><b>33.3.3</b> Post-análisis factorial</a></li>
<li class="chapter" data-level="33.3.4" data-path="análisis-factorial.html"><a href="análisis-factorial.html#puntuaciones-factoriales."><i class="fa fa-check"></i><b>33.3.4</b> Puntuaciones factoriales.</a></li>
</ul></li>
<li class="chapter" data-level="33.4" data-path="análisis-factorial.html"><a href="análisis-factorial.html#relaciones-y-diferencias-entre-el-af-y-el-acp"><i class="fa fa-check"></i><b>33.4</b> Relaciones y diferencias entre el AF y el ACP</a></li>
</ul></li>
<li class="chapter" data-level="34" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html"><i class="fa fa-check"></i><b>34</b> Escalamiento multidimensional</a>
<ul>
<li class="chapter" data-level="34.1" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html#introducción-18"><i class="fa fa-check"></i><b>34.1</b> Introducción</a></li>
<li class="chapter" data-level="34.2" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html#medición-de-distancias-y-similitudes"><i class="fa fa-check"></i><b>34.2</b> Medición de distancias y similitudes</a></li>
<li class="chapter" data-level="34.3" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html#modelo-escalamiento-multidimensional."><i class="fa fa-check"></i><b>34.3</b> Modelo escalamiento multidimensional.</a></li>
<li class="chapter" data-level="34.4" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html#tipos-de-escalamiento-multidimensional"><i class="fa fa-check"></i><b>34.4</b> Tipos de escalamiento multidimensional</a>
<ul>
<li class="chapter" data-level="34.4.1" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html#escalado-multidimensional-métrico"><i class="fa fa-check"></i><b>34.4.1</b> Escalado multidimensional métrico</a></li>
<li class="chapter" data-level="34.4.2" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html#escalado-multidimensional-no-métrico"><i class="fa fa-check"></i><b>34.4.2</b> Escalado multidimensional no-métrico</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="35" data-path="correspondencias.html"><a href="correspondencias.html"><i class="fa fa-check"></i><b>35</b> Análisis de correspondencias</a>
<ul>
<li class="chapter" data-level="35.1" data-path="correspondencias.html"><a href="correspondencias.html#introducción-19"><i class="fa fa-check"></i><b>35.1</b> Introducción</a></li>
<li class="chapter" data-level="35.2" data-path="correspondencias.html"><a href="correspondencias.html#metodología-del-análisis-de-correspondencias"><i class="fa fa-check"></i><b>35.2</b> Metodología del análisis de correspondencias</a>
<ul>
<li class="chapter" data-level="35.2.1" data-path="correspondencias.html"><a href="correspondencias.html#proyecciones-fila-columna-y-simétrica"><i class="fa fa-check"></i><b>35.2.1</b> Proyecciones fila, columna y simétrica</a></li>
</ul></li>
<li class="chapter" data-level="35.3" data-path="correspondencias.html"><a href="correspondencias.html#procedimiento-con-r-la-función-ca"><i class="fa fa-check"></i><b>35.3</b> Procedimiento con <strong>R</strong>: la función <code>ca()</code></a></li>
</ul></li>
<li class="part"><span><b>VII Deep learning</b></span></li>
<li class="chapter" data-level="36" data-path="capNN.html"><a href="capNN.html"><i class="fa fa-check"></i><b>36</b> Redes neuronales artificiales</a>
<ul>
<li class="chapter" data-level="36.1" data-path="capNN.html"><a href="capNN.html#qué-es-el-deep-learning"><i class="fa fa-check"></i><b>36.1</b> ¿Qué es el <em>deep learning</em>?</a>
<ul>
<li class="chapter" data-level="36.1.1" data-path="capNN.html"><a href="capNN.html#diferencias-entre-las-técnicas-de-machine-learning-tradicional-y-el-deep-learning"><i class="fa fa-check"></i><b>36.1.1</b> Diferencias entre las técnicas de <em>machine learning</em> tradicional y el <em>deep learning</em></a></li>
</ul></li>
<li class="chapter" data-level="36.2" data-path="capNN.html"><a href="capNN.html#aplicaciones-del-deep-learning"><i class="fa fa-check"></i><b>36.2</b> Aplicaciones del <em>deep learning</em></a></li>
<li class="chapter" data-level="36.3" data-path="capNN.html"><a href="capNN.html#redes-neuronales"><i class="fa fa-check"></i><b>36.3</b> Redes Neuronales</a></li>
<li class="chapter" data-level="36.4" data-path="capNN.html"><a href="capNN.html#perceptrón-o-neurona"><i class="fa fa-check"></i><b>36.4</b> Perceptrón o Neurona</a>
<ul>
<li class="chapter" data-level="36.4.1" data-path="capNN.html"><a href="capNN.html#aprendizaje"><i class="fa fa-check"></i><b>36.4.1</b> Aprendizaje</a></li>
<li class="chapter" data-level="36.4.2" data-path="capNN.html"><a href="capNN.html#convergencia"><i class="fa fa-check"></i><b>36.4.2</b> Convergencia</a></li>
</ul></li>
<li class="chapter" data-level="36.5" data-path="capNN.html"><a href="capNN.html#perceptrón-multiclase"><i class="fa fa-check"></i><b>36.5</b> Perceptrón Multiclase</a></li>
<li class="chapter" data-level="36.6" data-path="capNN.html"><a href="capNN.html#funciones-de-activación"><i class="fa fa-check"></i><b>36.6</b> Funciones de activación</a></li>
<li class="chapter" data-level="36.7" data-path="capNN.html"><a href="capNN.html#perceptrón-multicapa"><i class="fa fa-check"></i><b>36.7</b> Perceptrón Multicapa</a>
<ul>
<li class="chapter" data-level="36.7.1" data-path="capNN.html"><a href="capNN.html#aprendizaje-1"><i class="fa fa-check"></i><b>36.7.1</b> Aprendizaje</a></li>
</ul></li>
<li class="chapter" data-level="36.8" data-path="capNN.html"><a href="capNN.html#instalación-de-librerías-de-deep-learning-en-r-tensorflowkeras"><i class="fa fa-check"></i><b>36.8</b> Instalación de librerías de <em>deep learning</em> en <strong>R</strong>: Tensorflow/Keras</a></li>
<li class="chapter" data-level="36.9" data-path="capNN.html"><a href="capNN.html#ejemplo-de-red-para-clasificación"><i class="fa fa-check"></i><b>36.9</b> Ejemplo de red para clasificación</a>
<ul>
<li class="chapter" data-level="36.9.1" data-path="capNN.html"><a href="capNN.html#carga-y-visualización-de-los-datos"><i class="fa fa-check"></i><b>36.9.1</b> Carga y visualización de los datos</a></li>
<li class="chapter" data-level="36.9.2" data-path="capNN.html"><a href="capNN.html#preprocesamiento"><i class="fa fa-check"></i><b>36.9.2</b> Preprocesamiento</a></li>
<li class="chapter" data-level="36.9.3" data-path="capNN.html"><a href="capNN.html#nngen"><i class="fa fa-check"></i><b>36.9.3</b> Generación de la red neuronal</a></li>
<li class="chapter" data-level="36.9.4" data-path="capNN.html"><a href="capNN.html#nntrain"><i class="fa fa-check"></i><b>36.9.4</b> Entrenamiento</a></li>
<li class="chapter" data-level="36.9.5" data-path="capNN.html"><a href="capNN.html#test"><i class="fa fa-check"></i><b>36.9.5</b> Test</a></li>
<li class="chapter" data-level="36.9.6" data-path="capNN.html"><a href="capNN.html#guardado-y-reutilización-del-modelo"><i class="fa fa-check"></i><b>36.9.6</b> Guardado y reutilización del modelo</a></li>
</ul></li>
<li class="chapter" data-level="36.10" data-path="capNN.html"><a href="capNN.html#ejemplo-de-red-para-regresión"><i class="fa fa-check"></i><b>36.10</b> Ejemplo de red para regresión</a>
<ul>
<li class="chapter" data-level="36.10.1" data-path="capNN.html"><a href="capNN.html#carga-y-visualización-de-los-datos-1"><i class="fa fa-check"></i><b>36.10.1</b> Carga y visualización de los datos</a></li>
<li class="chapter" data-level="36.10.2" data-path="capNN.html"><a href="capNN.html#preprocesamiento-1"><i class="fa fa-check"></i><b>36.10.2</b> Preprocesamiento</a></li>
<li class="chapter" data-level="36.10.3" data-path="capNN.html"><a href="capNN.html#generación-de-la-red-neuronal"><i class="fa fa-check"></i><b>36.10.3</b> Generación de la red neuronal</a></li>
<li class="chapter" data-level="36.10.4" data-path="capNN.html"><a href="capNN.html#entrenamiento"><i class="fa fa-check"></i><b>36.10.4</b> Entrenamiento</a></li>
<li class="chapter" data-level="36.10.5" data-path="capNN.html"><a href="capNN.html#test-1"><i class="fa fa-check"></i><b>36.10.5</b> Test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="37" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html"><i class="fa fa-check"></i><b>37</b> Redes neuronales convolucionales</a>
<ul>
<li class="chapter" data-level="37.1" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#introducción-20"><i class="fa fa-check"></i><b>37.1</b> Introducción</a></li>
<li class="chapter" data-level="37.2" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#convolución"><i class="fa fa-check"></i><b>37.2</b> Convolución</a></li>
<li class="chapter" data-level="37.3" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#neuronas-convolucionales"><i class="fa fa-check"></i><b>37.3</b> Neuronas convolucionales</a></li>
<li class="chapter" data-level="37.4" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#relleno-del-borde"><i class="fa fa-check"></i><b>37.4</b> Relleno del borde</a>
<ul>
<li class="chapter" data-level="37.4.1" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#desplazamiento"><i class="fa fa-check"></i><b>37.4.1</b> Desplazamiento</a></li>
</ul></li>
<li class="chapter" data-level="37.5" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#capas-de-agrupación"><i class="fa fa-check"></i><b>37.5</b> Capas de agrupación</a></li>
<li class="chapter" data-level="37.6" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#desvanecimiento-del-gradiente"><i class="fa fa-check"></i><b>37.6</b> Desvanecimiento del gradiente</a></li>
<li class="chapter" data-level="37.7" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#sobreajuste-1"><i class="fa fa-check"></i><b>37.7</b> Sobreajuste</a></li>
<li class="chapter" data-level="37.8" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#generación-de-datos-de-entrenamiento-artificiales"><i class="fa fa-check"></i><b>37.8</b> Generación de datos de entrenamiento artificiales</a></li>
<li class="chapter" data-level="37.9" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#ejemplo-para-el-conjunto-de-datos-cifar10"><i class="fa fa-check"></i><b>37.9</b> Ejemplo para el conjunto de datos <code>CIFAR10</code></a>
<ul>
<li class="chapter" data-level="37.9.1" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#visualizacion"><i class="fa fa-check"></i><b>37.9.1</b> Carga y visualización de los datos</a></li>
<li class="chapter" data-level="37.9.2" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#preprocesamiento-2"><i class="fa fa-check"></i><b>37.9.2</b> Preprocesamiento</a></li>
<li class="chapter" data-level="37.9.3" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#generación-de-la-red-neuronal-1"><i class="fa fa-check"></i><b>37.9.3</b> Generación de la red neuronal</a></li>
<li class="chapter" data-level="37.9.4" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#entrenamiento-1"><i class="fa fa-check"></i><b>37.9.4</b> Entrenamiento</a></li>
<li class="chapter" data-level="37.9.5" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#test-2"><i class="fa fa-check"></i><b>37.9.5</b> Test</a></li>
<li class="chapter" data-level="37.9.6" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#otros-ejemplos-de-interés"><i class="fa fa-check"></i><b>37.9.6</b> Otros ejemplos de interés</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>VIII Ciencia de datos de texto y redes</b></span></li>
<li class="chapter" data-level="38" data-path="mineria-textos.html"><a href="mineria-textos.html"><i class="fa fa-check"></i><b>38</b> Minería de textos</a>
<ul>
<li class="chapter" data-level="38.1" data-path="mineria-textos.html"><a href="mineria-textos.html#introducción-21"><i class="fa fa-check"></i><b>38.1</b> Introducción</a></li>
<li class="chapter" data-level="38.2" data-path="mineria-textos.html"><a href="mineria-textos.html#secCONCEPTOS"><i class="fa fa-check"></i><b>38.2</b> Conceptos y tareas fundamentales</a>
<ul>
<li class="chapter" data-level="38.2.1" data-path="mineria-textos.html"><a href="mineria-textos.html#preparación-de-los-datos"><i class="fa fa-check"></i><b>38.2.1</b> Preparación de los datos</a></li>
<li class="chapter" data-level="38.2.2" data-path="mineria-textos.html"><a href="mineria-textos.html#secTOKEN"><i class="fa fa-check"></i><b>38.2.2</b> Segmentación del texto: tokenización</a></li>
<li class="chapter" data-level="38.2.3" data-path="mineria-textos.html"><a href="mineria-textos.html#secESTILOM"><i class="fa fa-check"></i><b>38.2.3</b> Campos de aplicación de la minería de textos</a></li>
<li class="chapter" data-level="38.2.4" data-path="mineria-textos.html"><a href="mineria-textos.html#minería-de-textos-en-r"><i class="fa fa-check"></i><b>38.2.4</b> Minería de textos en <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="38.3" data-path="mineria-textos.html"><a href="mineria-textos.html#secSENTIM"><i class="fa fa-check"></i><b>38.3</b> Análisis de sentimientos</a></li>
<li class="chapter" data-level="38.4" data-path="mineria-textos.html"><a href="mineria-textos.html#caso-de-aplicación"><i class="fa fa-check"></i><b>38.4</b> Caso de aplicación</a>
<ul>
<li class="chapter" data-level="38.4.1" data-path="mineria-textos.html"><a href="mineria-textos.html#declaración-institucional-del-estado-de-alarma-2020"><i class="fa fa-check"></i><b>38.4.1</b> Declaración institucional del estado de alarma 2020</a></li>
<li class="chapter" data-level="38.4.2" data-path="mineria-textos.html"><a href="mineria-textos.html#segmentación-en-palabras-y-oraciones"><i class="fa fa-check"></i><b>38.4.2</b> Segmentación en palabras y oraciones</a></li>
<li class="chapter" data-level="38.4.3" data-path="mineria-textos.html"><a href="mineria-textos.html#análisis-exploratorio"><i class="fa fa-check"></i><b>38.4.3</b> Análisis exploratorio</a></li>
<li class="chapter" data-level="38.4.4" data-path="mineria-textos.html"><a href="mineria-textos.html#secSENTYEMO"><i class="fa fa-check"></i><b>38.4.4</b> Análisis de sentimientos y detección de emociones</a></li>
<li class="chapter" data-level="38.4.5" data-path="mineria-textos.html"><a href="mineria-textos.html#n-gramas"><i class="fa fa-check"></i><b>38.4.5</b> <em>N-gramas</em></a></li>
<li class="chapter" data-level="38.4.6" data-path="mineria-textos.html"><a href="mineria-textos.html#análisis-de-redes"><i class="fa fa-check"></i><b>38.4.6</b> Análisis de redes</a></li>
<li class="chapter" data-level="" data-path="mineria-textos.html"><a href="mineria-textos.html#resumen-11"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="39" data-path="grafos.html"><a href="grafos.html"><i class="fa fa-check"></i><b>39</b> Análisis de grafos y redes sociales</a>
<ul>
<li class="chapter" data-level="39.1" data-path="grafos.html"><a href="grafos.html#introducción-22"><i class="fa fa-check"></i><b>39.1</b> Introducción</a></li>
<li class="chapter" data-level="39.2" data-path="grafos.html"><a href="grafos.html#teoría-de-grafos"><i class="fa fa-check"></i><b>39.2</b> Teoría de grafos</a></li>
<li class="chapter" data-level="39.3" data-path="grafos.html"><a href="grafos.html#elementos-de-un-grafo"><i class="fa fa-check"></i><b>39.3</b> Elementos de un grafo</a></li>
<li class="chapter" data-level="39.4" data-path="grafos.html"><a href="grafos.html#el-paquete-igraph"><i class="fa fa-check"></i><b>39.4</b> El paquete <code>igraph</code></a></li>
<li class="chapter" data-level="39.5" data-path="grafos.html"><a href="grafos.html#análisis-de-influencia-en-un-grafo-aplicado-a-redes-sociales"><i class="fa fa-check"></i><b>39.5</b> Análisis de influencia en un grafo aplicado a redes sociales</a></li>
<li class="chapter" data-level="39.6" data-path="grafos.html"><a href="grafos.html#otras-utilidades-de-grafos"><i class="fa fa-check"></i><b>39.6</b> Otras utilidades de grafos</a></li>
</ul></li>
<li class="part"><span><b>IX Ciencia de datos espaciales</b></span></li>
<li class="chapter" data-level="40" data-path="datos-espaciales.html"><a href="datos-espaciales.html"><i class="fa fa-check"></i><b>40</b> Trabajando con datos espaciales</a>
<ul>
<li class="chapter" data-level="40.1" data-path="datos-espaciales.html"><a href="datos-espaciales.html#conceptos-clave"><i class="fa fa-check"></i><b>40.1</b> Conceptos clave</a>
<ul>
<li class="chapter" data-level="40.1.1" data-path="datos-espaciales.html"><a href="datos-espaciales.html#CRS"><i class="fa fa-check"></i><b>40.1.1</b> Sistema de Referencia de Coordenadas</a></li>
<li class="chapter" data-level="40.1.2" data-path="datos-espaciales.html"><a href="datos-espaciales.html#formatos"><i class="fa fa-check"></i><b>40.1.2</b> Formatos de datos espaciales</a></li>
</ul></li>
<li class="chapter" data-level="40.2" data-path="datos-espaciales.html"><a href="datos-espaciales.html#primer-mapa"><i class="fa fa-check"></i><b>40.2</b> Mi primer mapa</a></li>
<li class="chapter" data-level="40.3" data-path="datos-espaciales.html"><a href="datos-espaciales.html#no-mentir"><i class="fa fa-check"></i><b>40.3</b> ¿Cómo (no) mentir con la visualización?</a></li>
<li class="chapter" data-level="40.4" data-path="datos-espaciales.html"><a href="datos-espaciales.html#mapas-espacio-temporales"><i class="fa fa-check"></i><b>40.4</b> Mapas espacio-temporales</a></li>
<li class="chapter" data-level="40.5" data-path="datos-espaciales.html"><a href="datos-espaciales.html#mapas-interactivos"><i class="fa fa-check"></i><b>40.5</b> Mapas interactivos</a></li>
<li class="chapter" data-level="40.6" data-path="datos-espaciales.html"><a href="datos-espaciales.html#estadística-para-datos-espaciales"><i class="fa fa-check"></i><b>40.6</b> Estadística para datos espaciales</a></li>
</ul></li>
<li class="chapter" data-level="41" data-path="geo.html"><a href="geo.html"><i class="fa fa-check"></i><b>41</b> Geoestadística</a>
<ul>
<li class="chapter" data-level="41.1" data-path="geo.html"><a href="geo.html#introducción-23"><i class="fa fa-check"></i><b>41.1</b> Introducción</a></li>
<li class="chapter" data-level="41.2" data-path="geo.html"><a href="geo.html#preliminares-geo"><i class="fa fa-check"></i><b>41.2</b> Preliminares</a></li>
<li class="chapter" data-level="41.3" data-path="geo.html"><a href="geo.html#ana-estructural"><i class="fa fa-check"></i><b>41.3</b> Análisis estructural de la dependencia espacial</a>
<ul>
<li class="chapter" data-level="41.3.1" data-path="geo.html"><a href="geo.html#semivariograma"><i class="fa fa-check"></i><b>41.3.1</b> Semivariograma</a></li>
<li class="chapter" data-level="41.3.2" data-path="geo.html"><a href="geo.html#modelos-de-semivariogramas-válidos"><i class="fa fa-check"></i><b>41.3.2</b> Modelos de semivariogramas válidos</a></li>
<li class="chapter" data-level="41.3.3" data-path="geo.html"><a href="geo.html#semivariograma-empírico"><i class="fa fa-check"></i><b>41.3.3</b> Semivariograma empírico</a></li>
<li class="chapter" data-level="41.3.4" data-path="geo.html"><a href="geo.html#ajuste-semivariográfico"><i class="fa fa-check"></i><b>41.3.4</b> Ajuste semivariográfico</a></li>
</ul></li>
<li class="chapter" data-level="41.4" data-path="geo.html"><a href="geo.html#kriging"><i class="fa fa-check"></i><b>41.4</b> Kriging</a></li>
</ul></li>
<li class="chapter" data-level="42" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html"><i class="fa fa-check"></i><b>42</b> Modelos econométricos espaciales</a>
<ul>
<li class="chapter" data-level="42.1" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#la-dependencia-espacial"><i class="fa fa-check"></i><b>42.1</b> La dependencia espacial </a>
<ul>
<li class="chapter" data-level="42.1.1" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#modelización-del-espacio-la-matriz-w"><i class="fa fa-check"></i><b>42.1.1</b> Modelización del espacio: La matriz W</a></li>
</ul></li>
<li class="chapter" data-level="42.2" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#medidas-de-autocorrelación"><i class="fa fa-check"></i><b>42.2</b> Medidas de Autocorrelación </a>
<ul>
<li class="chapter" data-level="42.2.1" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#el-indicador-i-de-moran"><i class="fa fa-check"></i><b>42.2.1</b> El indicador <em>I</em> de Moran</a></li>
</ul></li>
<li class="chapter" data-level="42.3" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#modelos-econométricos-espaciales-de-corte-transversal"><i class="fa fa-check"></i><b>42.3</b> Modelos econométricos espaciales de corte transversal </a>
<ul>
<li class="chapter" data-level="42.3.1" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#estimación-sar"><i class="fa fa-check"></i><b>42.3.1</b> Estimación SAR</a></li>
<li class="chapter" data-level="42.3.2" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#comparando-sar-contra-sdm"><i class="fa fa-check"></i><b>42.3.2</b> Comparando SAR contra SDM</a></li>
<li class="chapter" data-level="42.3.3" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#interpretación-de-los-estimadores-de-los-modelos-de-autocorrelación-espacial"><i class="fa fa-check"></i><b>42.3.3</b> Interpretación de los estimadores de los modelos de autocorrelación espacial </a></li>
<li class="chapter" data-level="42.3.4" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#impacto-del-sar"><i class="fa fa-check"></i><b>42.3.4</b> Impacto del SAR</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="43" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html"><i class="fa fa-check"></i><b>43</b> Procesos de punto</a>
<ul>
<li class="chapter" data-level="43.1" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html#spatial-point-patterns-on-mathbb-r2"><i class="fa fa-check"></i><b>43.1</b> Spatial point patterns on <span class="math inline">\(\mathbb R^2\)</span></a>
<ul>
<li class="chapter" data-level="43.1.1" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html#kernel-based-intensity-estimation"><i class="fa fa-check"></i><b>43.1.1</b> Kernel-based intensity estimation</a></li>
<li class="chapter" data-level="43.1.2" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html#practical-examples"><i class="fa fa-check"></i><b>43.1.2</b> Practical examples</a></li>
<li class="chapter" data-level="43.1.3" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html#kernel-based-intensity-estimation-over-irregular-domains"><i class="fa fa-check"></i><b>43.1.3</b> Kernel-based intensity estimation over irregular domains</a></li>
<li class="chapter" data-level="43.1.4" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html#voronoi-based-intensity-estimators"><i class="fa fa-check"></i><b>43.1.4</b> Voronoi-based intensity estimators</a></li>
<li class="chapter" data-level="43.1.5" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html#second-order-summary-statistics"><i class="fa fa-check"></i><b>43.1.5</b> Second-order summary statistics</a></li>
</ul></li>
<li class="chapter" data-level="43.2" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html#spatial-point-patterns-on-linear-networks"><i class="fa fa-check"></i><b>43.2</b> Spatial point patterns on linear networks</a></li>
</ul></li>
<li class="part"><span><b>X Cómunica y colabora</b></span></li>
<li class="chapter" data-level="44" data-path="id_120007-informes.html"><a href="id_120007-informes.html"><i class="fa fa-check"></i><b>44</b> Informes reproducibles con R Markdown y Quarto</a>
<ul>
<li class="chapter" data-level="44.1" data-path="id_120007-informes.html"><a href="id_120007-informes.html#introducción-24"><i class="fa fa-check"></i><b>44.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="44.1.1" data-path="id_120007-informes.html"><a href="id_120007-informes.html#por-qué-informes-reproducibles"><i class="fa fa-check"></i><b>44.1.1</b> ¿Por qué informes reproducibles?</a></li>
<li class="chapter" data-level="44.1.2" data-path="id_120007-informes.html"><a href="id_120007-informes.html#markdown-r-markdown-quarto-y-rstudio"><i class="fa fa-check"></i><b>44.1.2</b> Markdown, R Markdown, Quarto y RStudio</a></li>
</ul></li>
<li class="chapter" data-level="44.2" data-path="id_120007-informes.html"><a href="id_120007-informes.html#documentos-quarto"><i class="fa fa-check"></i><b>44.2</b> Documentos Quarto</a>
<ul>
<li class="chapter" data-level="44.2.1" data-path="id_120007-informes.html"><a href="id_120007-informes.html#encabezado-yaml-y-configuración"><i class="fa fa-check"></i><b>44.2.1</b> Encabezado YAML y configuración</a></li>
<li class="chapter" data-level="44.2.2" data-path="id_120007-informes.html"><a href="id_120007-informes.html#formateado-de-texto"><i class="fa fa-check"></i><b>44.2.2</b> Formateado de texto</a></li>
<li class="chapter" data-level="44.2.3" data-path="id_120007-informes.html"><a href="id_120007-informes.html#inclusión-de-código-en-el-documento"><i class="fa fa-check"></i><b>44.2.3</b> Inclusión de código en el documento</a></li>
<li class="chapter" data-level="44.2.4" data-path="id_120007-informes.html"><a href="id_120007-informes.html#opciones-de-los-bloques-de-código-chunks"><i class="fa fa-check"></i><b>44.2.4</b> Opciones de los bloques de código (<em>chunks</em>)</a></li>
<li class="chapter" data-level="44.2.5" data-path="id_120007-informes.html"><a href="id_120007-informes.html#referencias-cruzadas-y-formateo-de-tablas"><i class="fa fa-check"></i><b>44.2.5</b> Referencias cruzadas y formateo de tablas</a></li>
</ul></li>
<li class="chapter" data-level="44.3" data-path="id_120007-informes.html"><a href="id_120007-informes.html#otros-formatos"><i class="fa fa-check"></i><b>44.3</b> Otros formatos</a></li>
</ul></li>
<li class="chapter" data-level="45" data-path="shiny.html"><a href="shiny.html"><i class="fa fa-check"></i><b>45</b> Aplicaciones webs interactivas con Shiny</a>
<ul>
<li class="chapter" data-level="45.1" data-path="shiny.html"><a href="shiny.html#introducción-25"><i class="fa fa-check"></i><b>45.1</b> Introducción</a></li>
<li class="chapter" data-level="45.2" data-path="shiny.html"><a href="shiny.html#partes-mínimas-de-una-aplicación-shiny-y-disposición-básica"><i class="fa fa-check"></i><b>45.2</b> Partes mínimas de una aplicación <code>Shiny</code> y disposición básica</a></li>
<li class="chapter" data-level="45.3" data-path="shiny.html"><a href="shiny.html#diseño-de-una-aplicación-shiny"><i class="fa fa-check"></i><b>45.3</b> Diseño de una aplicación <code>Shiny</code></a>
<ul>
<li class="chapter" data-level="45.3.1" data-path="shiny.html"><a href="shiny.html#diseño-de-las-páginas-fluidpage"><i class="fa fa-check"></i><b>45.3.1</b> Diseño de las páginas: fluidPage()</a></li>
<li class="chapter" data-level="45.3.2" data-path="shiny.html"><a href="shiny.html#segmentación-de-diseños-tabsetpanel-y-navlistpanel"><i class="fa fa-check"></i><b>45.3.2</b> Segmentación de diseños: tabsetPanel() y navlistPanel()</a></li>
</ul></li>
<li class="chapter" data-level="45.4" data-path="shiny.html"><a href="shiny.html#elementos-para-entrada-de-datos"><i class="fa fa-check"></i><b>45.4</b> Elementos para entrada de datos</a>
<ul>
<li class="chapter" data-level="45.4.1" data-path="shiny.html"><a href="shiny.html#lectura-de-ficheros-de-datos"><i class="fa fa-check"></i><b>45.4.1</b> Lectura de ficheros de datos</a></li>
</ul></li>
<li class="chapter" data-level="45.5" data-path="shiny.html"><a href="shiny.html#elementos-para-visualización-salida"><i class="fa fa-check"></i><b>45.5</b> Elementos para visualización (salida)</a></li>
<li class="chapter" data-level="45.6" data-path="shiny.html"><a href="shiny.html#reactividad"><i class="fa fa-check"></i><b>45.6</b> Reactividad</a>
<ul>
<li class="chapter" data-level="45.6.1" data-path="shiny.html"><a href="shiny.html#conductores-reactivos-y-control-de-la-reactividad"><i class="fa fa-check"></i><b>45.6.1</b> Conductores reactivos y control de la reactividad</a></li>
</ul></li>
<li class="chapter" data-level="45.7" data-path="shiny.html"><a href="shiny.html#publicación-de-la-aplicación-en-la-web"><i class="fa fa-check"></i><b>45.7</b> Publicación de la aplicación en la web</a></li>
<li class="chapter" data-level="45.8" data-path="shiny.html"><a href="shiny.html#extensiones-de-shiny"><i class="fa fa-check"></i><b>45.8</b> Extensiones de <code>Shiny</code></a></li>
</ul></li>
<li class="chapter" data-level="46" data-path="github.html"><a href="github.html"><i class="fa fa-check"></i><b>46</b> Git y GitHub en R</a>
<ul>
<li class="chapter" data-level="46.1" data-path="github.html"><a href="github.html#qué-es-git"><i class="fa fa-check"></i><b>46.1</b> ¿Qué es Git?</a></li>
<li class="chapter" data-level="46.2" data-path="github.html"><a href="github.html#qué-es-github"><i class="fa fa-check"></i><b>46.2</b> ¿Qué es GitHub?</a></li>
<li class="chapter" data-level="46.3" data-path="github.html"><a href="github.html#por-qué-usar-git-y-github"><i class="fa fa-check"></i><b>46.3</b> ¿Por qué usar Git y GitHub?</a></li>
<li class="chapter" data-level="46.4" data-path="github.html"><a href="github.html#configuración"><i class="fa fa-check"></i><b>46.4</b> Configuración</a></li>
<li class="chapter" data-level="46.5" data-path="github.html"><a href="github.html#configurar-git"><i class="fa fa-check"></i><b>46.5</b> Configurar git</a></li>
<li class="chapter" data-level="46.6" data-path="github.html"><a href="github.html#workflow"><i class="fa fa-check"></i><b>46.6</b> Workflow</a></li>
</ul></li>
<li class="chapter" data-level="47" data-path="cap-geoprocesamiento.html"><a href="cap-geoprocesamiento.html"><i class="fa fa-check"></i><b>47</b> Geoprocesamiento en nube</a>
<ul>
<li class="chapter" data-level="47.1" data-path="cap-geoprocesamiento.html"><a href="cap-geoprocesamiento.html#sintaxis-de-google-earth-engine"><i class="fa fa-check"></i><b>47.1</b> Sintaxis de Google Earth Engine</a></li>
<li class="chapter" data-level="47.2" data-path="cap-geoprocesamiento.html"><a href="cap-geoprocesamiento.html#primeros-pasos"><i class="fa fa-check"></i><b>47.2</b> Primeros pasos</a></li>
<li class="chapter" data-level="47.3" data-path="cap-geoprocesamiento.html"><a href="cap-geoprocesamiento.html#cálculo-de-anomalias"><i class="fa fa-check"></i><b>47.3</b> Cálculo de anomalias</a>
<ul>
<li class="chapter" data-level="47.3.1" data-path="cap-geoprocesamiento.html"><a href="cap-geoprocesamiento.html#definiciones-previas"><i class="fa fa-check"></i><b>47.3.1</b> Definiciones previas</a></li>
<li class="chapter" data-level="47.3.2" data-path="cap-geoprocesamiento.html"><a href="cap-geoprocesamiento.html#promedio-estival"><i class="fa fa-check"></i><b>47.3.2</b> Promedio estival</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>XI Casos de estudio en ciencia de datos</b></span></li>
<li class="chapter" data-level="48" data-path="cap-crimen.html"><a href="cap-crimen.html"><i class="fa fa-check"></i><b>48</b> Análisis de una red criminal</a>
<ul>
<li class="chapter" data-level="48.1" data-path="cap-crimen.html"><a href="cap-crimen.html#el-dataset-oversize"><i class="fa fa-check"></i><b>48.1</b> El <em>dataset Oversize</em></a></li>
<li class="chapter" data-level="48.2" data-path="cap-crimen.html"><a href="cap-crimen.html#creación-del-grafo"><i class="fa fa-check"></i><b>48.2</b> Creación del grafo</a></li>
<li class="chapter" data-level="48.3" data-path="cap-crimen.html"><a href="cap-crimen.html#visualización-del-grafo"><i class="fa fa-check"></i><b>48.3</b> Visualización del grafo</a></li>
<li class="chapter" data-level="48.4" data-path="cap-crimen.html"><a href="cap-crimen.html#importancia-de-los-actores"><i class="fa fa-check"></i><b>48.4</b> Importancia de los actores</a></li>
<li class="chapter" data-level="48.5" data-path="cap-crimen.html"><a href="cap-crimen.html#identificación-de-comunidades"><i class="fa fa-check"></i><b>48.5</b> Identificación de comunidades</a></li>
<li class="chapter" data-level="48.6" data-path="cap-crimen.html"><a href="cap-crimen.html#visualización-de-comunidades"><i class="fa fa-check"></i><b>48.6</b> Visualización de comunidades</a></li>
</ul></li>
<li class="chapter" data-level="49" data-path="cap-publidiad.html"><a href="cap-publidiad.html"><i class="fa fa-check"></i><b>49</b> Optimización de inversiones publicitarias</a>
<ul>
<li class="chapter" data-level="49.1" data-path="cap-publidiad.html"><a href="cap-publidiad.html#metodologías-para-optimizar-las-inversiones-publicitarias"><i class="fa fa-check"></i><b>49.1</b> Metodologías para optimizar las inversiones publicitarias</a></li>
<li class="chapter" data-level="49.2" data-path="cap-publidiad.html"><a href="cap-publidiad.html#robyn-como-alternativa-open-source-en-r"><i class="fa fa-check"></i><b>49.2</b> Robyn como alternativa open-source en R</a></li>
</ul></li>
<li class="chapter" data-level="50" data-path="cap-periodismo.html"><a href="cap-periodismo.html"><i class="fa fa-check"></i><b>50</b> Análisis electoral: de Rstudio a su periódico</a>
<ul>
<li class="chapter" data-level="50.1" data-path="cap-periodismo.html"><a href="cap-periodismo.html#obtención-de-los-datos"><i class="fa fa-check"></i><b>50.1</b> Obtención de los datos</a></li>
<li class="chapter" data-level="50.2" data-path="cap-periodismo.html"><a href="cap-periodismo.html#transformación-y-primeros-gráficos"><i class="fa fa-check"></i><b>50.2</b> Transformación y primeros gráficos</a></li>
</ul></li>
<li class="chapter" data-level="51" data-path="paro-clm.html"><a href="paro-clm.html"><i class="fa fa-check"></i><b>51</b> Evolución del paro registrado en Castilla-La Mancha</a>
<ul>
<li class="chapter" data-level="51.1" data-path="paro-clm.html"><a href="paro-clm.html#planteamiento"><i class="fa fa-check"></i><b>51.1</b> Planteamiento</a></li>
<li class="chapter" data-level="51.2" data-path="paro-clm.html"><a href="paro-clm.html#evolución-del-número-total-de-parados"><i class="fa fa-check"></i><b>51.2</b> Evolución del número total de parados</a></li>
<li class="chapter" data-level="51.3" data-path="paro-clm.html"><a href="paro-clm.html#evolución-de-la-edad-y-el-sexo-en-la-población-parada"><i class="fa fa-check"></i><b>51.3</b> Evolución de la edad y el sexo en la población parada</a></li>
<li class="chapter" data-level="51.4" data-path="paro-clm.html"><a href="paro-clm.html#evolución-del-tiempo-de-búsqueda-de-empleo-en-la-población-parada"><i class="fa fa-check"></i><b>51.4</b> Evolución del tiempo de búsqueda de empleo en la población parada</a></li>
<li class="chapter" data-level="51.5" data-path="paro-clm.html"><a href="paro-clm.html#evolución-del-paro-registrado-según-sexo-edad-y-sector-de-procedencia"><i class="fa fa-check"></i><b>51.5</b> Evolución del paro registrado según sexo, edad y sector de procedencia</a></li>
<li class="chapter" data-level="51.6" data-path="paro-clm.html"><a href="paro-clm.html#conclusiones"><i class="fa fa-check"></i><b>51.6</b> Conclusiones</a></li>
</ul></li>
<li class="chapter" data-level="52" data-path="cap-idealista.html"><a href="cap-idealista.html"><i class="fa fa-check"></i><b>52</b> Valoración del precio de la vivienda</a>
<ul>
<li class="chapter" data-level="52.1" data-path="cap-idealista.html"><a href="cap-idealista.html#introducción-26"><i class="fa fa-check"></i><b>52.1</b> Introducción</a></li>
<li class="chapter" data-level="52.2" data-path="cap-idealista.html"><a href="cap-idealista.html#conjunto-de-datos"><i class="fa fa-check"></i><b>52.2</b> Conjunto de datos</a></li>
<li class="chapter" data-level="52.3" data-path="cap-idealista.html"><a href="cap-idealista.html#estimación-del-modelo-1"><i class="fa fa-check"></i><b>52.3</b> Estimación del Modelo</a></li>
</ul></li>
<li class="chapter" data-level="53" data-path="cap-rfm.html"><a href="cap-rfm.html"><i class="fa fa-check"></i><b>53</b> Segmentación de clientes en retail</a>
<ul>
<li class="chapter" data-level="53.1" data-path="cap-rfm.html"><a href="cap-rfm.html#motivación-y-conceptos-clave"><i class="fa fa-check"></i><b>53.1</b> Motivación y conceptos clave</a></li>
<li class="chapter" data-level="53.2" data-path="cap-rfm.html"><a href="cap-rfm.html#del-modelo-rfm-tradicional-al-modelo-rfm-extendido-mejoras-propuestas"><i class="fa fa-check"></i><b>53.2</b> Del Modelo RFM tradicional al Modelo RFM extendido, mejoras propuestas</a></li>
<li class="chapter" data-level="53.3" data-path="cap-rfm.html"><a href="cap-rfm.html#modelo-rfm-extendido"><i class="fa fa-check"></i><b>53.3</b> Modelo RFM extendido</a>
<ul>
<li class="chapter" data-level="53.3.1" data-path="cap-rfm.html"><a href="cap-rfm.html#recopilación-y-comprensión-de-los-datos"><i class="fa fa-check"></i><b>53.3.1</b> Recopilación y comprensión de los datos</a></li>
<li class="chapter" data-level="53.3.2" data-path="cap-rfm.html"><a href="cap-rfm.html#cálculo-de-las-variables-del-modelo-rfm"><i class="fa fa-check"></i><b>53.3.2</b> Cálculo de las variables del Modelo RFM</a></li>
<li class="chapter" data-level="53.3.3" data-path="cap-rfm.html"><a href="cap-rfm.html#breve-análisis-exploratorio-de-las-variables-del-modelo-rfm"><i class="fa fa-check"></i><b>53.3.3</b> Breve análisis exploratorio de las variables del Modelo RFM</a></li>
<li class="chapter" data-level="53.3.4" data-path="cap-rfm.html"><a href="cap-rfm.html#cálculo-del-ranking-de-percentiles"><i class="fa fa-check"></i><b>53.3.4</b> Cálculo del Ranking de percentiles</a></li>
<li class="chapter" data-level="53.3.5" data-path="cap-rfm.html"><a href="cap-rfm.html#modelado-rfm-mediante-k-means"><i class="fa fa-check"></i><b>53.3.5</b> Modelado: RFM mediante k-means</a></li>
<li class="chapter" data-level="53.3.6" data-path="cap-rfm.html"><a href="cap-rfm.html#descriptivos-e-interpretación-de-los-segmentos"><i class="fa fa-check"></i><b>53.3.6</b> Descriptivos e interpretación de los segmentos</a></li>
<li class="chapter" data-level="53.3.7" data-path="cap-rfm.html"><a href="cap-rfm.html#puesta-en-producción"><i class="fa fa-check"></i><b>53.3.7</b> Puesta en producción</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="54" data-path="cap-medicina.html"><a href="cap-medicina.html"><i class="fa fa-check"></i><b>54</b> Ciencia de datos para la investigación y ensayos clínicos</a>
<ul>
<li class="chapter" data-level="54.1" data-path="cap-medicina.html"><a href="cap-medicina.html#justificación"><i class="fa fa-check"></i><b>54.1</b> Justificación</a></li>
<li class="chapter" data-level="54.2" data-path="cap-medicina.html"><a href="cap-medicina.html#introducción-al-uso-de-datos-en-investigación-clínica-y-ensayos-clínicos"><i class="fa fa-check"></i><b>54.2</b> Introducción al uso de datos en investigación clínica y ensayos clínicos</a>
<ul>
<li class="chapter" data-level="54.2.1" data-path="cap-medicina.html"><a href="cap-medicina.html#qué-es-un-ensayo-clínico"><i class="fa fa-check"></i><b>54.2.1</b> ¿Qué es un ensayo clínico?</a></li>
<li class="chapter" data-level="54.2.2" data-path="cap-medicina.html"><a href="cap-medicina.html#limitaciones-de-los-estudios-observacionales"><i class="fa fa-check"></i><b>54.2.2</b> Limitaciones de los estudios observacionales</a></li>
<li class="chapter" data-level="54.2.3" data-path="cap-medicina.html"><a href="cap-medicina.html#propensity-score"><i class="fa fa-check"></i><b>54.2.3</b> Propensity Score</a></li>
</ul></li>
<li class="chapter" data-level="54.3" data-path="cap-medicina.html"><a href="cap-medicina.html#ejemplo-práctico-de-un-estudio-observacional"><i class="fa fa-check"></i><b>54.3</b> Ejemplo práctico de un estudio observacional</a>
<ul>
<li class="chapter" data-level="54.3.1" data-path="cap-medicina.html"><a href="cap-medicina.html#análisis-de-supervivencia"><i class="fa fa-check"></i><b>54.3.1</b> Análisis de supervivencia</a></li>
<li class="chapter" data-level="54.3.2" data-path="cap-medicina.html"><a href="cap-medicina.html#estimación-y-comparación-de-curvas-de-supervivencia"><i class="fa fa-check"></i><b>54.3.2</b> Estimación y comparación de curvas de supervivencia</a></li>
<li class="chapter" data-level="54.3.3" data-path="cap-medicina.html"><a href="cap-medicina.html#regresión-de-cox"><i class="fa fa-check"></i><b>54.3.3</b> Regresión de COX</a></li>
</ul></li>
<li class="chapter" data-level="54.4" data-path="cap-medicina.html"><a href="cap-medicina.html#conclusión"><i class="fa fa-check"></i><b>54.4</b> Conclusión</a></li>
</ul></li>
<li class="chapter" data-level="55" data-path="cap-climatico.html"><a href="cap-climatico.html"><i class="fa fa-check"></i><b>55</b> Lo que nos cuentan los datos sobre el cambio climático</a>
<ul>
<li class="chapter" data-level="55.1" data-path="cap-climatico.html"><a href="cap-climatico.html#consideraciones-iniciales"><i class="fa fa-check"></i><b>55.1</b> Consideraciones iniciales</a></li>
<li class="chapter" data-level="55.2" data-path="cap-climatico.html"><a href="cap-climatico.html#paquetes"><i class="fa fa-check"></i><b>55.2</b> Paquetes</a></li>
<li class="chapter" data-level="55.3" data-path="cap-climatico.html"><a href="cap-climatico.html#visualización-de-mapas-de-pequeños-múltiples"><i class="fa fa-check"></i><b>55.3</b> Visualización de mapas de pequeños múltiples</a>
<ul>
<li class="chapter" data-level="55.3.1" data-path="cap-climatico.html"><a href="cap-climatico.html#datos"><i class="fa fa-check"></i><b>55.3.1</b> Datos</a></li>
<li class="chapter" data-level="55.3.2" data-path="cap-climatico.html"><a href="cap-climatico.html#preparar-los-datos"><i class="fa fa-check"></i><b>55.3.2</b> Preparar los datos</a></li>
<li class="chapter" data-level="55.3.3" data-path="cap-climatico.html"><a href="cap-climatico.html#construir-el-gráfico-de-múltiples-mapas"><i class="fa fa-check"></i><b>55.3.3</b> Construir el gráfico de múltiples mapas</a></li>
<li class="chapter" data-level="55.3.4" data-path="cap-climatico.html"><a href="cap-climatico.html#mapa-de-orientación"><i class="fa fa-check"></i><b>55.3.4</b> Mapa de orientación</a></li>
<li class="chapter" data-level="55.3.5" data-path="cap-climatico.html"><a href="cap-climatico.html#exportar-mapa-final"><i class="fa fa-check"></i><b>55.3.5</b> Exportar mapa final</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="56" data-path="cap-ree.html"><a href="cap-ree.html"><i class="fa fa-check"></i><b>56</b> Predicción de demanda eléctrica con deep learning</a>
<ul>
<li class="chapter" data-level="56.1" data-path="cap-ree.html"><a href="cap-ree.html#introducción-27"><i class="fa fa-check"></i><b>56.1</b> Introducción</a></li>
<li class="chapter" data-level="56.2" data-path="cap-ree.html"><a href="cap-ree.html#datos-de-entrada"><i class="fa fa-check"></i><b>56.2</b> Datos de entrada</a></li>
<li class="chapter" data-level="56.3" data-path="cap-ree.html"><a href="cap-ree.html#caso-de-estudio"><i class="fa fa-check"></i><b>56.3</b> Caso de estudio</a></li>
</ul></li>
<li class="chapter" data-level="57" data-path="cap-sist-experto.html"><a href="cap-sist-experto.html"><i class="fa fa-check"></i><b>57</b> Sistemas expertos en el ámbito pediátrico</a>
<ul>
<li class="chapter" data-level="57.1" data-path="cap-sist-experto.html"><a href="cap-sist-experto.html#introducción-28"><i class="fa fa-check"></i><b>57.1</b> Introducción</a></li>
<li class="chapter" data-level="57.2" data-path="cap-sist-experto.html"><a href="cap-sist-experto.html#marco-teórico"><i class="fa fa-check"></i><b>57.2</b> Marco teórico</a>
<ul>
<li class="chapter" data-level="57.2.1" data-path="cap-sist-experto.html"><a href="cap-sist-experto.html#razonamiento"><i class="fa fa-check"></i><b>57.2.1</b> Razonamiento</a></li>
</ul></li>
<li class="chapter" data-level="57.3" data-path="cap-sist-experto.html"><a href="cap-sist-experto.html#sistema-experto-para-el-ámbito-pediátrico-en-atención-primaria"><i class="fa fa-check"></i><b>57.3</b> Sistema experto para el ámbito pediátrico en atención primaria</a></li>
</ul></li>
<li class="chapter" data-level="58" data-path="nlp-textil.html"><a href="nlp-textil.html"><i class="fa fa-check"></i><b>58</b> El NLP y las tendencias en el mundo de la moda</a>
<ul>
<li class="chapter" data-level="58.1" data-path="nlp-textil.html"><a href="nlp-textil.html#introducción-29"><i class="fa fa-check"></i><b>58.1</b> Introducción</a></li>
<li class="chapter" data-level="58.2" data-path="nlp-textil.html"><a href="nlp-textil.html#nlp-para-tendencias-de-moda-en-textil"><i class="fa fa-check"></i><b>58.2</b> NLP para tendencias de moda en textil</a></li>
</ul></li>
<li class="chapter" data-level="59" data-path="cap-fraude.html"><a href="cap-fraude.html"><i class="fa fa-check"></i><b>59</b> Detección de fraude de tarjetas de crédito</a>
<ul>
<li class="chapter" data-level="59.1" data-path="cap-fraude.html"><a href="cap-fraude.html#introducción-30"><i class="fa fa-check"></i><b>59.1</b> Introducción</a></li>
<li class="chapter" data-level="59.2" data-path="cap-fraude.html"><a href="cap-fraude.html#modelización-del-fraude-en-la-compra-con-tarjetas-de-crérdito"><i class="fa fa-check"></i><b>59.2</b> Modelización del fraude en la compra con tarjetas de crérdito</a></li>
</ul></li>
<li class="chapter" data-level="" data-path=""><a href="#appendix-appendix"><i class="fa fa-check"></i>(APPENDIX) Appendix</a>
<ul>
<li class="chapter" data-level="59.3" data-path="cap-fraude.html"><a href="cap-fraude.html#información-de-la-sesión"><i class="fa fa-check"></i><b>59.3</b> Información de la sesión</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://cdr-book.github.io/"> Ciencia de datos con R </a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Ciencia de datos con R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="capNN" class="section level1 hasAnchor" number="36">
<h1><span class="header-section-number">Capítulo 36</span> Redes neuronales artificiales<a href="capNN.html#capNN" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><em>Noelia Vállez Enano y José Luis Espinosa Aranda</em></p>
<div id="qué-es-el-deep-learning" class="section level2 hasAnchor" number="36.1">
<h2><span class="header-section-number">36.1</span> ¿Qué es el <em>deep learning</em>?<a href="capNN.html#qué-es-el-deep-learning" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La inteligencia artificial es el conjunto de técnicas que hacen que cualquier elemento controlado por un computador sea capaz de realizar acciones similares a las que haría un humano en situaciones determinadas. Entre otros ejemplos podemos encontrar en la actualidad tanto robots que son capaces de realizar tareas de manera similar a un humano en una fábrica, las denominadas como casas inteligentes o los vehículos autónomos.</p>
<p>Dentro de las técnicas utilizadas para la inteligencia artificial, se encuentran las técnicas clásicas de <em>machine learning</em>, ya explicadas en capítulos anteriores de este libro, las cuales tienen la habilidad de aprender sin haber sido explícitamente programadas para una tarea en particular, pudiendo ser utilizadas para varios fines y aplicaciones.</p>
<p>A su vez, dentro de estos algoritmos, se pueden enmarcar como un subconjunto de las mismas las técnicas de <em>deep learning</em>, las cuales intentan simular tanto la arquitectura como el comportamiento del sistema nervioso humano, en particular, de las redes de neuronas que componen el encéfalo y que se encargan de realizar tareas específicas (Fig. <a href="capNN.html#fig:iaMLDL">36.1</a>). Para ello, estas técnicas se basan en el concepto de redes neuronales, que intentan emular la forma de aprendizaje de los humanos <span class="citation">(<a href="#ref-goodfellow2016deep" role="doc-biblioref">Goodfellow, Bengio, and Courville 2016</a>)</span>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:iaMLDL"></span>
<img src="img/conc_dl_01_iaMLDL.png" alt="Inteligencia Artificial vs Machine learning vs Deep Learning" width="90%" />
<p class="caption">
Figura 36.1: Inteligencia Artificial vs Machine learning vs Deep Learning
</p>
</div>
<div id="diferencias-entre-las-técnicas-de-machine-learning-tradicional-y-el-deep-learning" class="section level3 hasAnchor" number="36.1.1">
<h3><span class="header-section-number">36.1.1</span> Diferencias entre las técnicas de <em>machine learning</em> tradicional y el <em>deep learning</em><a href="capNN.html#diferencias-entre-las-técnicas-de-machine-learning-tradicional-y-el-deep-learning" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Como se vio en capítulos anteriores, las técnicas de <em>machine learning</em> tradicional requieren al inicio realizar una selección de las mejores características que representen el problema a resolver, y que puedan ser comprendidas por el algoritmo seleccionado de tal forma que sea capaz de solucionar el problema planteado.</p>
<p>Por ejemplo, en el caso de querer detectar una cara dentro de una imagen, sería necesario definir qué tipo de características servirían para detectar la misma, como podrían ser, a bajo nivel, determinados tipos de bordes de la imagen (Fig. <a href="capNN.html#fig:scharrpitu">36.2</a>). Estas características proporcionarían la base para detectar a medio nivel elementos de la cara como ojos, narices, orejas, etc. y, definitivamente a alto nivel, reconocer donde hay una cara dentro de la imagen.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:scharrpitu"></span>
<img src="img/conc_dl_02_Pitu.png" alt="Detección de bordes de una imagen mediante el método de Scharr" width="100%" />
<p class="caption">
Figura 36.2: Detección de bordes de una imagen mediante el método de Scharr
</p>
</div>
<p>Esta elección de características requiere en muchas ocasiones de la intervención humana, por lo que puede llevar mucho tiempo y diversos experimentos de prueba y error hasta poder encontrar una combinación de características y algoritmos que permita resolver el problema planteado.</p>
<p>Debido a esto, nacen las técnicas de <em>deep learning</em>, las cuales tratan de simular el comportamiento de aprendizaje humano. Esto implica que, a diferencia de las técnicas de <em>machine learning</em> tradicional, son capaces de aprender cuales son las mejores características que permitirán representar el problema que se quiere resolver sin necesidad de la interacción humana a la misma vez que buscan la solución al mismo.</p>
<p>Por ejemplo, continuando con el ejemplo anterior de la detección de caras, mientras que en las técnicas de <em>machine learning</em> sería necesario explicarle al algoritmo que características base componen una cara para que sea capaz de reconocerlas, al utilizar <em>deep learning</em> únicamente sería necesario mostrarle suficientes imágenes de caras para conseguir que el algoritmo sea capaz de aprender a identificar una cara por si mismo.</p>
<p>La capacidad de aprender las mejores características necesarias por sí mismo hace que a nivel teórico las técnicas de <em>deep learning</em> puedan llegar a ser más potentes que el <em>machine learning</em> clásico, pero debido a la mayor complejidad del problema y, por consiguiente, al proceso de entrenamiento, también lleva a que que sean necesarios muchos más datos iniciales y una mayor potencia de cómputo.</p>
<p>Este hecho explica que, aunque las bases de las técnicas de <em>deep learning</em> como el algoritmo del descenso del gradiente <span class="citation">(<a href="#ref-kiefer1952stochastic" role="doc-biblioref">Kiefer and Wolfowitz 1952</a>)</span>, el perceptrón <span class="citation">(<a href="#ref-rosenblatt1958perceptron" role="doc-biblioref">Rosenblatt 1958</a>)</span>, los algoritmos de retropropagación y el perceptrón multicapa <span class="citation">(<a href="#ref-rumelhart1986learning" role="doc-biblioref">Rumelhart, Hinton, and Williams 1986</a>)</span> y la primera red neuronal convolucional <span class="citation">(<a href="#ref-lecun1995convolutional" role="doc-biblioref">LeCun, Bengio, et al. 1995</a>)</span>, datan de varios años atrás, no sea hasta hace relativamente poco tiempo cuando ha podido empezar a utilizar estas técnicas gracias a:</p>
<ol style="list-style-type: decimal">
<li><p><strong>La evolución en el hardware de procesamiento.</strong> En particular, debido a la mejora de la capacidad de paralelismo masivo durante el cómputo que proporcionaron las nuevas tarjetas gráficas al incorporar una gran cantidad de microprocesadores específicos, inicialmente, para representar modelos complejos 3D en los monitores, pero que han podido ser utilizadas para las técnicas de <em>deep learning</em>, llevando recientemente al desarrollo de tarjetas específicas para este fin .</p></li>
<li><p><strong>Big data.</strong> La gran cantidad de datos que se generan y almacenan en la actualidad en el día a día, así como la mayor facilidad a la hora de trabajar con esos conjuntos de datos, han permitido cubrir la necesidad de datos iniciales necesarios.</p></li>
<li><p><strong>La evolución del sofware.</strong> Recientemente ha habido un amplio interés tanto en buscar nuevos modelos para resolver todo tipo de problemas, como para mejorar las técnicas utilizadas para entrenar dichas redes neuronales, lo cual ha llevado a la creación y mejora de diversos frameworks y aplicaciones relacionadas con el entrenamiento y despliegue de redes neuronales. Entre ellos, serían destacables Keras, Tensorflow, Pytorch, Caffe2, Matlab y OpenVINO.</p></li>
</ol>
</div>
</div>
<div id="aplicaciones-del-deep-learning" class="section level2 hasAnchor" number="36.2">
<h2><span class="header-section-number">36.2</span> Aplicaciones del <em>deep learning</em><a href="capNN.html#aplicaciones-del-deep-learning" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Las posibles aplicaciones de las técnicas de <em>deep learning</em> son muy diversas y, gracias a la continua investigación desarrollada en el área en la actualidad, no hacen más que aumentar. A continuación se comentan algunas de ellas:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Clasificación de imágenes.</strong> Aunque la clasificación de imágenes dentro del área de la visión por computador lleva años presente, es con las técnicas de <em>deep learning</em> con las que se han logrado los mayores avances, en particular, utilizando las redes neuronales convolucionales. Estas redes permiten determinar a que clase, perteneciente al conjunto de clases utilizado para entrenar, pertenece una determinada imagen.</p></li>
<li><p><strong>Detección de objetos.</strong> Permite localizar los objetos contenidos en una imagen y su tipología marcándose con un rectángulo. Por ejemplo, utilizando una cámara de seguridad instalada en una calle con este tipo de modelos sería posible localizar y diferenciar entre peatones y vehículos (Fig. <a href="capNN.html#fig:camaraTermica">36.3</a>).</p></li>
</ol>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:camaraTermica"></span>
<img src="img/conc_dl_04_camaraTermica.png" alt="Detección de peatones y vehículos utilizando una cámara térmica y técnicas de deep learning" width="90%" />
<p class="caption">
Figura 36.3: Detección de peatones y vehículos utilizando una cámara térmica y técnicas de deep learning
</p>
</div>
<ol start="3" style="list-style-type: decimal">
<li><p><strong>Segmentación semántica/de instancias.</strong> De forma similar a la detección de objetos, la segmentación permite localizar objetos contenidos en una imagen, además de su tipología, pero en este caso se marcan utilizando una máscara a nivel de píxel. La segmentación de instancias además es capaz de diferenciar entre diferentes instancias de una misma clase aún cuando se encuentren situadas de forma contigua.</p></li>
<li><p><strong>Reconocimiento del habla.</strong> Permite a un computador procesar el habla humana en formato escrito. En la actualidad existen varios asistentes inteligentes basados en esta tecnología que además son capaces de interpretar órdenes o instrucciones sencillas y actuar en consecuencia.</p></li>
<li><p><strong>Traducción automática.</strong> Consiste en utilizar las técnicas de <em>deep learning</em> para traducir un texto automáticamente de una lengua a otra sin la necesidad de intervención humana. En la actualidad, no se limita únicamente a la traducción literal, palabra por palabra, del texto, si no que también tiene en cuenta el significado que tendría en el idioma original para adaptarlo al idioma destino (Fig. <a href="capNN.html#fig:deepL">36.4</a>).</p></li>
</ol>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:deepL"></span>
<img src="img/conc_dl_05_deepL.png" alt="Traductor automático basado en Deep Learning" width="100%" />
<p class="caption">
Figura 36.4: Traductor automático basado en Deep Learning
</p>
</div>
<ol start="6" style="list-style-type: decimal">
<li><strong>Generación automática de imágenes/texto.</strong> Permite obtener desde una imagen un texto descriptivo que indique el contenido de la imagen, o al contrario, a partir de un texto descriptivo generar una imagen basada en dicho texto. Un ejemplo de este último caso sería Dall-E <span class="citation">(<a href="#ref-borji2022generated" role="doc-biblioref">Borji 2022</a>)</span> (Fig. <a href="capNN.html#fig:DallE">36.5</a>).</li>
</ol>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:DallE"></span>
<img src="img/conc_dl_06_DallE.png" alt="Algunas salidas posibles del generador de imágentes a partir de texto Dall-E, para el texto a $``$cat with glasses studying computer vision in the space with the Earth in the background$&quot;$" width="100%" />
<p class="caption">
Figura 36.5: Algunas salidas posibles del generador de imágentes a partir de texto Dall-E, para el texto a <span class="math inline">\(``\)</span>cat with glasses studying computer vision in the space with the Earth in the background<span class="math inline">\(&quot;\)</span>
</p>
</div>
<ol start="7" style="list-style-type: decimal">
<li><strong>Automóvil autónomo.</strong> Las técnicas de <em>deep learning</em> están siendo claves para el desarrollo del vehículo autónomo, capaz de viajar sin la necesidad de la interacción de un conductor humano. Para lograr definitivamente un vehículo con estas características, es necesario que sea capaz de ver, tomar decisiones y conducir al mismo tiempo. Esto se consigue en la actualidad integrando la información de gran cantidad de sensores que obtienen datos en tiempo real sobre el entorno, como serían cámaras, LIDAR, radares o ultrasónicos entre otros, y que son procesados por varias redes neuronales con el fin de que sea capaz de tomar una decisión en cuestión de milisegundos (Fig. <a href="capNN.html#fig:camaraTermica">36.3</a>).</li>
</ol>
</div>
<div id="redes-neuronales" class="section level2 hasAnchor" number="36.3">
<h2><span class="header-section-number">36.3</span> Redes Neuronales<a href="capNN.html#redes-neuronales" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Las redes neuronales artificiales (en inglés Artificial Neural Network (ANN)) tienen su origen a finales de los años 50 a partir del diseño del perceptrón por parte de Frank Rosenblatt <span class="citation">(<a href="#ref-rosenblatt1958perceptron" role="doc-biblioref">Rosenblatt 1958</a>)</span>. Cada ANN está formada por un conjunto de elementos conocidos como ``neuronas” cuya organización está inspirada en la que siguen las redes neuronales de los seres vivos. Entre dos neuronas adyacentes existe una serie de conexiones a través de las cuales se envía la información como si de pulsos eléctricos se tratase. De forma aislada, cada neurona procesa la información recibida para producir un resultado que será utilizado por las siguientes neuronas con las que está conectada</p>
<p>Cada ANN tiene como objetivo resolver una tarea concreta. Por ejemplo, una ANN podría estar diseñada para reconocer un dígito o una letra a partir de una imagen. Para conseguir resolver dicha tarea, la red sigue un proceso de aprendizaje automático. Este proceso se conoce como ``entrenamiento” y requiere que se disponga de un conjunto de datos representativos de la tarea a resolver.</p>
</div>
<div id="perceptrón-o-neurona" class="section level2 hasAnchor" number="36.4">
<h2><span class="header-section-number">36.4</span> Perceptrón o Neurona<a href="capNN.html#perceptrón-o-neurona" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El elemento básico de toda ANN es el perceptrón o neurona. Se trata de un modelo artificial basado en las neuronas biológicas. Cada neurona tiene una serie de entradas y produce una única salida. Las entradas pueden ser variables extraídas de la tarea que se debe resolver o salidas de otras neuronas de la red.</p>
<p>Para calcular la salida, cada neurona realiza una suma ponderada de sus entradas utilizando una serie de pesos, <span class="math inline">\(\boldsymbol w\)</span> donde <span class="math inline">\(w_i\in \mathbb{R}\)</span>, y añade un término constante,<span class="math inline">\(w_0\in \mathbb{R}\)</span>. Por tanto, cada neurona actúa como un clasificador lineal que puede separar dos conjuntos diferentes dependiendo de si la salida es positiva o negativa (Figura <a href="capNN.html#fig:perceptron">36.6</a>).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:perceptron"></span>
<img src="img/perceptron.png" alt="Estructura del perceptrón o neurona" width="80%" />
<p class="caption">
Figura 36.6: Estructura del perceptrón o neurona
</p>
</div>
<p>Para cada vector de entrada, <span class="math inline">\(\boldsymbol x\)</span>, la neurona aplicará los pesos, <span class="math inline">\(\boldsymbol w\)</span>, como el producto escalar de ambos vectores:</p>
<p><span class="math display">\[\begin{equation}
\boldsymbol w^{\prime}    \boldsymbol x  = w_0\cdot 1+w_1 \cdot x_1+w_2 \cdot x_2+\dots+w_n \cdot x_n .
\end{equation}\]</span></p>
<p>Una vez obtenida la suma ponderada, se puede separar las entradas en dos conjuntos, obteniéndose como salida final un valor binario, siguiendo la fórmula:</p>
<p><span class="math display">\[\begin{equation}
f (\boldsymbol w^{\prime}   \boldsymbol x) = \begin{cases}
1 &amp; \text{si $\boldsymbol w^{\prime}   \boldsymbol x&gt;0$}\\
0 &amp; \text{en otro caso}
\end{cases} .
\end{equation}\]</span></p>
<div id="aprendizaje" class="section level3 hasAnchor" number="36.4.1">
<h3><span class="header-section-number">36.4.1</span> Aprendizaje<a href="capNN.html#aprendizaje" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El proceso de aprendizaje del perceptrón busca el ajuste automático de los valores de los pesos. Estos pesos deben seleccionarse de forma que minimicen el error de clasificación cometido sobre un conjunto de entrenamiento. El conjunto de entrenamiento estará compuesto por un conjunto de muestras del que se conoce su clase:</p>
<p><span class="math display">\[\begin{equation}
D = \{ (\boldsymbol x_1 , y_1 ), (\boldsymbol x_2 , y_2 ), \dots, (\boldsymbol x_m , y_m ) \},
\end{equation}\]</span></p>
<p>donde cada muestra, <span class="math inline">\(\boldsymbol x_i = (x_{i1},x_{i2},\dots,x_{in})\)</span>, pertenece a una de las 2 clases, <span class="math inline">\(y_j = \{ 0,1 \}\)</span> .</p>
<p>El primer paso del aprendizaje o entrenamiento consiste en la inicialización de cada peso <span class="math inline">\(w_j\)</span> a 0 o a algún otro valor aleatorio.</p>
<p>Tras ello, se calcula la clase estimada, <span class="math inline">\(\hat y\)</span>, en un momento determinado, <span class="math inline">\(t\)</span>, para cada muestra <span class="math inline">\(\boldsymbol x_i\)</span> del conjunto de datos:
<span class="math display">\[\begin{equation}
\hat y_i(t) = f(\boldsymbol w(t)^{T}  \boldsymbol x_i) = f(w_0(t) + w_1(t) \cdot x_{i1} + \dots + w_n(t) \cdot x_{in}) .
\end{equation}\]</span></p>
<p>Tras obtener la salida para todas las muestras de entrenamiento, cada uno de los pesos, <span class="math inline">\(w_j\)</span>, de la neurona se actualiza siguiendo la fórmula:
<span class="math display">\[\begin{equation}
w_j(t+1) = w_j(t) + \lambda \cdot |y_i-\hat y_i(t)|\cdot x_{ij} .
\end{equation}\]</span></p>
<p>donde <span class="math inline">\(|y_i-\hat y_i(t)|\)</span> será 0 cuando la clase predicha coincida con la clase real de la muestra y <span class="math inline">\(\lambda\)</span> es la tasa de aprendizaje. La tasa de aprendizaje debe seleccionarse de antemano y controla la variación de los pesos entre iteraciones. En algunos casos el valor de <span class="math inline">\(r\)</span> es 0.</p>
<p>Los dos pasos anteriores se repiten hasta que el error de clasificación es menor que un cierto umbral o el número de iteraciones alcanza un cierto valor fijado. Normalmente se suele utilizar el número de iteraciones como criterio de paro puesto que no siempre es posible alcanzar una tasa de error más baja que la deseada.</p>
</div>
<div id="convergencia" class="section level3 hasAnchor" number="36.4.2">
<h3><span class="header-section-number">36.4.2</span> Convergencia<a href="capNN.html#convergencia" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El teorema de la convergencia del perceptrón dice que, en los problemas en los que haya dos clases linealmente separables, es siempre posible encontrar unos pesos que realicen la separación en un número finito de iteraciones <span class="citation">(<a href="#ref-novikoff62convergence" role="doc-biblioref">Novikoff 1962</a>)</span>. Sin embargo, en la mayoría de los casos no es posible obtener un conjunto de variables que separen perfectamente las muestras de ambas clases. Por ello, es necesario el uso de ciertas estrategias que solucionen el problema de convergencia en estos casos. Algunas de las estrategias más utilizadas son:</p>
<ul>
<li><p>Algoritmo Pocket: Guarda la mejor solución obtenida hasta el final del entrenamiento.</p></li>
<li><p>Algoritmo Maxover: Halla el margen de separación máximo permitiendo clasificaciones incorrectas.</p></li>
<li><p>Algoritmo de Voto: Se utilizan múltiples perceptrones combinando sus salidas.</p></li>
</ul>
</div>
</div>
<div id="perceptrón-multiclase" class="section level2 hasAnchor" number="36.5">
<h2><span class="header-section-number">36.5</span> Perceptrón Multiclase<a href="capNN.html#perceptrón-multiclase" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Una extensión lógica del uso del perceptrón es su empleo en la resolución de tareas de clasificación donde existan más de dos clases <span class="citation">(<a href="#ref-haykin1999" role="doc-biblioref">Haykin 1999</a>)</span>. En ese caso se tendrá un conjunto de entrenamiento, <span class="math inline">\(D\)</span>, de <span class="math inline">\(m\)</span> muestras:</p>
<p><span class="math display">\[\begin{equation}
D = \{ (\boldsymbol x_1 , y_1 ), (\boldsymbol x_2 , y_2 ), \dots, (\boldsymbol x_m , y_m ) \},
\end{equation}\]</span></p>
<p>donde cada muestra <span class="math inline">\(\boldsymbol x_i = (x_{i1},x_{i2},\dots,x_{in})\)</span> pertenezca a una de las <span class="math inline">\(c\)</span> clases posibles:</p>
<p><span class="math display">\[\begin{equation}
y_j = \{ 0,1,\dots,c-1 \} .
\end{equation}\]</span></p>
<p>A diferencia del problema binario, en su versión multiclase lo que se definen son varios modelos, <span class="math inline">\(F\)</span>, uno para cada una de las <span class="math inline">\(c\)</span> clases:</p>
<p><span class="math display">\[\begin{equation}
F=\{f_0,f_1,\dots,f_{c-1}\}\\
f_j: \mathbb{R}^n \rightarrow \mathbb{R} .
\end{equation}\]</span></p>
<p>En este caso la salida no se selecciona en función de si el valor obtenido es positivo o negativo, sino que se asigna la clase del modelo que obtenga el valor más alto tras aplicar los pesos a la muestra. Esta estrategia recibe el nombre de ``uno contra todos”:</p>
<p><span class="math display">\[\begin{equation}
\hat y_i = argmax_j(f_j(\boldsymbol x_i))\\
j\in\{0,1,\dots ,c-1\} .
\end{equation}\]</span></p>
<p>En muchas ocasiones lo que se obtiene no es un único valor con la clase asignada como salida, sino que se obtiene un vector con las salidas binarias de cada uno de los modelos empleados. En ese caso, el vector contendrá un 1 en la posición de la clase asignada y un 0 en el resto de clases. Por ejemplo, el vector <span class="math inline">\([0,1,0,0,0]\)</span> representaría que una muestra ha sido asignada a la segunda clase en un problema de clasificación donde existen 5 clases posibles:</p>
<p><span class="math display">\[\begin{equation}
[(f_1(\boldsymbol x_i)),(f_2(\boldsymbol x_i)),\dots,(f_c(\boldsymbol x_i))] .
\end{equation}\]</span></p>
</div>
<div id="funciones-de-activación" class="section level2 hasAnchor" number="36.6">
<h2><span class="header-section-number">36.6</span> Funciones de activación<a href="capNN.html#funciones-de-activación" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Además de los pesos, toda neurona tiene asociada una función de activación. Esta función se encarga de transformar la suma ponderada de las entradas en el resultado final. En las secciones anteriores se ha utilizado una función de activación con umbral 0, pero existen muchas otras. Algunas de las más utilizadas se enumeran a continuación.</p>
<p>Para algunas de ellas, se ha implementado una función, <em>plot_activation_function</em>, que permite dibujarlas en <strong>R</strong>, y que se puede ver a continuación:</p>
<div class="sourceCode" id="cb423"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb423-1"><a href="capNN.html#cb423-1" aria-hidden="true" tabindex="-1"></a><span class="fu">require</span>(ggplot2)</span>
<span id="cb423-2"><a href="capNN.html#cb423-2" aria-hidden="true" tabindex="-1"></a>plot_activation_function <span class="ot">&lt;-</span> <span class="cf">function</span>(f, title, range) {</span>
<span id="cb423-3"><a href="capNN.html#cb423-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggplot</span>(<span class="fu">data.frame</span>(<span class="at">x =</span> range), <span class="at">mapping =</span> <span class="fu">aes</span>(<span class="at">x =</span> x)) <span class="sc">+</span></span>
<span id="cb423-4"><a href="capNN.html#cb423-4" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">alpha =</span> <span class="dv">3</span> <span class="sc">/</span> <span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb423-5"><a href="capNN.html#cb423-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="dv">0</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">alpha =</span> <span class="dv">3</span> <span class="sc">/</span> <span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb423-6"><a href="capNN.html#cb423-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">stat_function</span>(<span class="at">fun =</span> f, <span class="at">colour =</span> <span class="st">&quot;red&quot;</span>) <span class="sc">+</span></span>
<span id="cb423-7"><a href="capNN.html#cb423-7" aria-hidden="true" tabindex="-1"></a>    <span class="fu">ggtitle</span>(title) <span class="sc">+</span></span>
<span id="cb423-8"><a href="capNN.html#cb423-8" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_x_continuous</span>(<span class="at">name =</span> <span class="st">&quot;x&quot;</span>) <span class="sc">+</span></span>
<span id="cb423-9"><a href="capNN.html#cb423-9" aria-hidden="true" tabindex="-1"></a>    <span class="fu">scale_y_continuous</span>(<span class="at">name =</span> <span class="st">&quot;f(x)&quot;</span>) <span class="sc">+</span></span>
<span id="cb423-10"><a href="capNN.html#cb423-10" aria-hidden="true" tabindex="-1"></a>    <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>))</span>
<span id="cb423-11"><a href="capNN.html#cb423-11" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<ul>
<li><strong>Función lineal.</strong> Se trata de una función identidad donde la salida tiene el mismo valor que la entrada. Normalmente se aplica en problemas de regresión lineal. Por ejemplo, si se quiere predecir el número de días que lloverá en un mes determinado.</li>
</ul>
<p><span class="math display">\[\begin{equation}
f(x)=x
\end{equation}\]</span></p>
<p>Y se representa gráficamente de la siguiente forma:</p>
<div class="sourceCode" id="cb424"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb424-1"><a href="capNN.html#cb424-1" aria-hidden="true" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb424-2"><a href="capNN.html#cb424-2" aria-hidden="true" tabindex="-1"></a>  x</span>
<span id="cb424-3"><a href="capNN.html#cb424-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb424-4"><a href="capNN.html#cb424-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_activation_function</span>(f, <span class="st">&quot;Lineal&quot;</span>, <span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="dv">4</span>))</span></code></pre></div>
<p><img src="Ciencia_de_datos_con_r_files/figure-html/unnamed-chunk-146-1.png" width="60%" style="display: block; margin: auto;" /></p>
<ul>
<li><strong>Función umbral.</strong> Esta función recibe también el nombre de función escalón. Si el valor de entrada es menor que el umbral la salida será 0. En caso contrario, la salida será 1. Si el umbral es 0, la función se reduce a mirar el signo del valor analizado.</li>
</ul>
<p><span class="math display">\[\begin{equation}
f(x)=\begin{cases}
0 &amp; \text{si $x&lt;u$}\\
1 &amp; \text{en otro caso}
\end{cases}
\end{equation}\]</span></p>
<p>Se representa gráficamente mediante el siguiente código, el cual se corresponde con una modificación de la función <em>plot_activation_function</em>, ya que la versión original no mostraría de forma correcta la gráfica al requerir representar dos valores en la posición 0, el valor 0 y el valor 1 del escalón:</p>
<div class="sourceCode" id="cb425"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb425-1"><a href="capNN.html#cb425-1" aria-hidden="true" tabindex="-1"></a>df <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="sc">-</span><span class="dv">3</span>, <span class="sc">-</span><span class="dv">2</span>, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">2</span>, <span class="dv">3</span>, <span class="dv">4</span>), <span class="at">f =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>))</span>
<span id="cb425-2"><a href="capNN.html#cb425-2" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> df, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> f, <span class="at">group =</span> <span class="dv">1</span>)) <span class="sc">+</span></span>
<span id="cb425-3"><a href="capNN.html#cb425-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">theme</span>(<span class="at">plot.title =</span> <span class="fu">element_text</span>(<span class="at">hjust =</span> <span class="fl">0.5</span>)) <span class="sc">+</span></span>
<span id="cb425-4"><a href="capNN.html#cb425-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Umbral&quot;</span>) <span class="sc">+</span></span>
<span id="cb425-5"><a href="capNN.html#cb425-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_y_continuous</span>(<span class="at">name =</span> <span class="st">&quot;f(x)&quot;</span>) <span class="sc">+</span></span>
<span id="cb425-6"><a href="capNN.html#cb425-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="dv">0</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">alpha =</span> <span class="dv">3</span> <span class="sc">/</span> <span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb425-7"><a href="capNN.html#cb425-7" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_vline</span>(<span class="at">xintercept =</span> <span class="dv">0</span>, <span class="at">color =</span> <span class="st">&quot;black&quot;</span>, <span class="at">alpha =</span> <span class="dv">3</span> <span class="sc">/</span> <span class="dv">4</span>) <span class="sc">+</span></span>
<span id="cb425-8"><a href="capNN.html#cb425-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_step</span>(<span class="at">color =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="Ciencia_de_datos_con_r_files/figure-html/unnamed-chunk-147-1.png" width="60%" style="display: block; margin: auto;" /></p>
<ul>
<li><strong>Función sigmoide.</strong> También conocida como función logística, se trata de una de las funciones más utilizadas para asignar una clase. Si el punto de evaluación de la función es un valor negativo muy bajo, la función dará como resultado un valor muy cercano a 0, si se evalúa en 0, el resultado es 0,5 y si se evalúa en un valor positivo alto el resultado será aproximadamente 1.</li>
</ul>
<p><span class="math display">\[\begin{equation}
f(x)=\frac{1}{1-e^{-x}}
\end{equation}\]</span></p>
<p>Representándose gráficamente de la siguiente forma:</p>
<div class="sourceCode" id="cb426"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb426-1"><a href="capNN.html#cb426-1" aria-hidden="true" tabindex="-1"></a>f <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb426-2"><a href="capNN.html#cb426-2" aria-hidden="true" tabindex="-1"></a>  <span class="dv">1</span> <span class="sc">/</span> (<span class="dv">1</span> <span class="sc">+</span> <span class="fu">exp</span>(<span class="sc">-</span>x))</span>
<span id="cb426-3"><a href="capNN.html#cb426-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb426-4"><a href="capNN.html#cb426-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_activation_function</span>(f, <span class="st">&quot;Sigmoide&quot;</span>, <span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="dv">4</span>))</span></code></pre></div>
<p><img src="Ciencia_de_datos_con_r_files/figure-html/unnamed-chunk-148-1.png" width="60%" style="display: block; margin: auto;" />
- <strong>Función tangente hiperbólica.</strong> El rango de valores de salida es [-1, 1], donde los valores altos tienden de manera asintótica a 1 y los valores muy bajos tienden de manera asintótica a -1 de forma similar a la sigmoide.</p>
<p><span class="math display">\[\begin{equation}
f(x)=\frac{e^x-e^{-x}}{e^x+e^{-x}}
\end{equation}\]</span></p>
<p>Siendo su representación gráfica de la siguiente forma:</p>
<div class="sourceCode" id="cb427"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb427-1"><a href="capNN.html#cb427-1" aria-hidden="true" tabindex="-1"></a>tanh_func <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb427-2"><a href="capNN.html#cb427-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">tanh</span>(x)</span>
<span id="cb427-3"><a href="capNN.html#cb427-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb427-4"><a href="capNN.html#cb427-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_activation_function</span>(tanh_func, <span class="st">&quot;Tangente Hiperbólica&quot;</span>, <span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="dv">4</span>))</span></code></pre></div>
<p><img src="Ciencia_de_datos_con_r_files/figure-html/unnamed-chunk-149-1.png" width="60%" style="display: block; margin: auto;" />
- <strong>Función ReLU.</strong> Se trata de la unidad lineal rectificada (del inglés Rectified Linear Unit). Es posiblemente la función de activación más utilizada actualmente en redes neuronales <span class="citation">(<a href="#ref-nair2010rectified" role="doc-biblioref">Nair and Hinton 2010</a>)</span>.</p>
<p><span class="math display">\[\begin{equation}
f(x)=\begin{cases}
0 &amp; \text{si $x\leq 0$}\\
x &amp; \text{en otro caso}
\end{cases}
\end{equation}\]</span></p>
<p>Y se representaría gráficamente de la siguiente manera:</p>
<div class="sourceCode" id="cb428"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb428-1"><a href="capNN.html#cb428-1" aria-hidden="true" tabindex="-1"></a>rec_lu_func <span class="ot">&lt;-</span> <span class="cf">function</span>(x) {</span>
<span id="cb428-2"><a href="capNN.html#cb428-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ifelse</span>(x <span class="sc">&lt;</span> <span class="dv">0</span>, <span class="dv">0</span>, x)</span>
<span id="cb428-3"><a href="capNN.html#cb428-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb428-4"><a href="capNN.html#cb428-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot_activation_function</span>(rec_lu_func, <span class="st">&quot;ReLU&quot;</span>, <span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="dv">4</span>))</span></code></pre></div>
<p><img src="Ciencia_de_datos_con_r_files/figure-html/unnamed-chunk-150-1.png" width="60%" style="display: block; margin: auto;" /></p>
</div>
<div id="perceptrón-multicapa" class="section level2 hasAnchor" number="36.7">
<h2><span class="header-section-number">36.7</span> Perceptrón Multicapa<a href="capNN.html#perceptrón-multicapa" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Aunque el perceptrón puede representar muchos tipos de lógica, no es posible realizar con él la operación XOR (o exclusiva) que asigna un 1 a la salida cuando las dos entradas son distintas <span class="citation">(<a href="#ref-minsky1969introduction" role="doc-biblioref">Minsky and Papert 1969</a>)</span>. El perceptrón multicapa o, en inglés, Multilayer Perceptron (MLP) surge para dar una solución a este problema.</p>
<p>Un MLP está compuesto por varias capas con neuronas. La primera capa será la capa de entrada, que recibirá la variables que representan los elementos del problema a resolver. Por otro lado, la última capa será, de forma similar a cada neurona individual, la salida del MLP. Entre ambas capas existirán una o más capas ``ocultas”. Las neuronas de una capa intermedia tienen como entrada la salida de la capa anterior y su salida es la entrada de las neuronas de la siguiente capa (Figura <a href="capNN.html#fig:ann">36.7</a>). Este tipo de capas también son llamadas <em>densas</em> o <em>totalmente conectadas</em>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:ann"></span>
<img src="img/ann.png" alt="Estructura del perceptrón multicapa (MLP)" width="100%" />
<p class="caption">
Figura 36.7: Estructura del perceptrón multicapa (MLP)
</p>
</div>
<div id="aprendizaje-1" class="section level3 hasAnchor" number="36.7.1">
<h3><span class="header-section-number">36.7.1</span> Aprendizaje<a href="capNN.html#aprendizaje-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El MLP entra en la categoría de los algoritmos de propagación hacia adelante o <em>feedforward</em> ya que las entradas de las neuronas de una capa se combinan mediante la suma ponderada, pasan por una función de activación y el resultado es propagado a las neuronas de la capa siguiente. Este proceso se lleva a cabo desde la capa de entrada hasta la capa de salida.</p>
<p>Dado un conjunto de muestras de entrenamiento <span class="math inline">\(\{(\boldsymbol x_1, y_1), (\boldsymbol x_2, y_2), \ldots, (\boldsymbol x_n, y_n)\}\)</span> donde cada <span class="math inline">\(\boldsymbol x_i \in \mathbb{R}^d\)</span> e <span class="math inline">\(y_i \in \{0, 1\}\)</span>, la salida de la primera capa, <span class="math inline">\(\boldsymbol z_1\)</span>, para una entrada <span class="math inline">\(\boldsymbol x\)</span> vendrá dada por la expresión:</p>
<p><span class="math display">\[\begin{equation}
\boldsymbol z_1 = \boldsymbol W_{(1)}^{\prime}   \boldsymbol x + \boldsymbol b_1 ,
\end{equation}\]</span></p>
<p>donde <span class="math inline">\(\boldsymbol b_1 \in \mathbb{R}^{h}\)</span> es un vector con las constantes de la primera capa y <span class="math inline">\(\boldsymbol{W}_{(1)} \in \mathbb{R}^{h \times d}\)</span> son los pesos de la capa. Tras aplicar la función de activación, <span class="math inline">\(g(\cdot)\)</span>, al vector intermedio, <span class="math inline">\(\boldsymbol{z}\in \mathbb{R}^h\)</span>, se obtiene:</p>
<p><span class="math display">\[\begin{equation}
\boldsymbol{h_1}= g(\mathbf{z_1}) .
\end{equation}\]</span></p>
<p>La salida de una capa intermedia, <span class="math inline">\(\boldsymbol{h_i}\in \mathbb{R}^h\)</span>, también está formada por variables intermedias que sirven de entrada a la siguiente capa. La función a calcular en la siguiente capa será por tanto:</p>
<p><span class="math display">\[\begin{equation}
\boldsymbol h_2 = g ( \boldsymbol W_{(2)}^{\prime}   \boldsymbol h_1 + \boldsymbol b_2) .
\end{equation}\]</span></p>
<p>Siguiendo el mismo razonamiento, la salida de la última capa, <span class="math inline">\(\hat y\)</span>, y por tanto de la red, vendrá dada por:</p>
<p><span class="math display">\[\begin{equation}
\hat y = g ( \boldsymbol W_{(n)}^{\prime}   \boldsymbol h_{n-1} + \boldsymbol b_n ) .
\end{equation}\]</span></p>
<p>Por ejemplo, si se tiene una red de tres capas la salida podrá calcularse como:</p>
<p><span class="math display">\[\begin{equation}
\hat y = g ( \boldsymbol W_{(3)}^{\prime}   \boldsymbol g ( \boldsymbol W_{(2)}^{\prime}   \boldsymbol g ( \boldsymbol W_{(1)}^{\prime}   \boldsymbol x + \boldsymbol b_1)+ \boldsymbol b_2 )+ \boldsymbol b_3  ) .
\end{equation}\]</span></p>
<p>Para entrenar y ajustar los pesos de este tipo de redes es necesario realizar el ajuste de la combinación de todos los pesos de la red. De forma similar a la búsqueda de los pesos de una sola neurona, será necesario encontrar la combinación de valores que clasifiquen bien todas las muestras del conjunto de entrenamiento o, en su defecto, que fallen en el menor número de muestras posible o minimicen alguna otra función de coste. En este punto es donde entra en juego la propagación hacia atrás o <em>backpropagation</em>.</p>
<p>La propagación hacia atrás es el mecanismo por el que el MLP ajusta de forma iterativa los pesos de la red con el objetivo de minimizar una función de coste que mide lo bueno o malo que es el resultado obtenido en un momento determinado <span class="citation">(<a href="#ref-rumelhart1986learning" role="doc-biblioref">Rumelhart, Hinton, and Williams 1986</a>)</span>. Su único requisito de aplicación es que todas las operaciones de la red (incluidas las funciones de activación) sean diferenciables ya que se utiliza el algoritmo del descenso del gradiente para optimizar la función de coste.</p>
<p>El MLP utiliza diferentes funciones de coste según el tipo de problema a resolver. Para los problemas de clasificación, la función de coste más utilizada es la Entropía Cruzada Media (en inglés Average Cross-Entropy). Para un problema binario esta función de coste se calcula como;</p>
<p><span class="math display">\[\begin{equation}
C(\hat{y},y,\boldsymbol W) = -\dfrac{1}{n}\sum_{i=0}^n(y_i \ln {\hat{y_i}} + (1-y_i) \ln{(1-\hat{y_i})}) + \dfrac{\alpha}{2n} ||\boldsymbol W||_2^2 ,
\end{equation}\]</span></p>
<p>donde <span class="math inline">\(\alpha ||W||_2^2\)</span> con <span class="math inline">\(\alpha &gt; 0\)</span> es un término de regularización, L2, también conocido como penalización ya que penaliza los modelos complejos. <span class="math inline">\(\alpha\)</span> es un hiperparámetro cuyo valor se establece manualmente.</p>
<p>Para los problemas de regresión, la función de coste se basa en el Error Cuadrático Medio:</p>
<p><span class="math display">\[\begin{equation}
C(\hat{y},y,\boldsymbol W) = \frac{1}{2n}\sum_{i=0}^n||\hat{y}_i - y_i ||_2^2 + \frac{\alpha}{2n} ||\boldsymbol W||_2^2 .
\end{equation}\]</span></p>
<p>Cada iteración en el proceso de aprendizaje estará compuesta entonces por dos etapas, una de propagación hacia adelante y otra de propagación hacia atrás. En la primera etapa se introducen los valores de entrada a la red y se propagan las operaciones y los resultados hasta obtener la salida final de la red. En la segunda, el gradiente de la función de coste es propagado hacia atrás para actualizar los valores de los pesos de todas las capas y acercarse más a los valores que minimizan la función de coste.</p>
<p>En el algoritmo del descenso del gradiente, <span class="math inline">\(\nabla C_{\boldsymbol W}\)</span> se calcula y deduce de <span class="math inline">\(\boldsymbol W\)</span>.
Formalmente esto puede expresarse como:</p>
<p><span class="math display">\[\begin{equation}
\boldsymbol W^{t+1} = \boldsymbol W^{\prime}   - \lambda \nabla {C}_{\boldsymbol W}^{t} ,
\end{equation}\]</span></p>
<p>donde <span class="math inline">\(t\)</span> es el estado de la red en una iteración determinada y <span class="math inline">\(\lambda\)</span> es la tasa de aprendizaje cuyo valor debe ser superior a 0.</p>
<p>Al igual que en el caso del perceptrón único, el entrenamiento terminará cuando se alcance un número máximo de iteraciones o la mejora en la función de coste entre dos iteraciones consecutivas no supere cierto umbral.</p>
<p>Durante el proceso de aprendizaje, es necesario guardar en memoria los resultados de cada una de las muestras del conjunto de entrenamiento. Si el número de muestras o el tamaño de la red son grandes, es posible que no se disponga del suficiente espacio. Para resolver este problema, en una iteración no se utiliza todo el conjunto de entrenamiento, sino que se utiliza un subconjunto de él llamado <em>batch</em>. El conjunto de entrenamiento se divide, por tanto, en un número de <em>batches</em> con un número de muestras por <em>batch</em>. Atendiendo a esta división, es posible definir una serie de hiperparámetros:</p>
<ul>
<li>Tamaño del <em>batch</em>. Número de muestras utilizadas en cada iteración para actualizar los pesos.</li>
<li>Número de épocas. Número de pasadas completas sobre el conjunto de entrenamiento hasta terminar el proceso de aprendizaje.</li>
<li>Número de iteraciones por época. Será el resultado de dividir el número total de muestras por el tamaño del <em>batch</em>.</li>
</ul>
<p>Por ejemplo, si se tiene un conjunto de 55000 muestras y el tamaño del <em>batch</em> es de 100, cada época tendrá 550 iteraciones.</p>
</div>
</div>
<div id="instalación-de-librerías-de-deep-learning-en-r-tensorflowkeras" class="section level2 hasAnchor" number="36.8">
<h2><span class="header-section-number">36.8</span> Instalación de librerías de <em>deep learning</em> en <strong>R</strong>: Tensorflow/Keras<a href="capNN.html#instalación-de-librerías-de-deep-learning-en-r-tensorflowkeras" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El framework que se va a utilizar en este libro para trabajar con técnicas de <em>deep learning</em> será Tensorflow/Keras, debido a que es uno de los más completos en la actualidad, permitiendo realizar una configuración completa del proceso de entrenamiento y trabajar con diversos tipos de redes neuronales.</p>
<p>Para poder utilizar Tensorflow/Keras en <strong>R</strong>, es necesario realizar la instalación de la librería fuera de <strong>R</strong>. Por ello, si ya se dispone de una instalación del mismo sería posible utilizarla. No obstante, se recomienda seguir los pasos indicados a continuación para tener una instalación nativa de Tensorflow/Keras asociada directamente a R.</p>
<ul>
<li><strong>Paso 1</strong> - Librería de Tensorflow en <strong>R</strong></li>
</ul>
<p>El primer paso será instalar el paquete de <strong>tensorflow</strong> en <strong>R</strong> [].</p>
<div class="sourceCode" id="cb429"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb429-1"><a href="capNN.html#cb429-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;tensorflow&quot;</span>)</span></code></pre></div>
<p>A continuación, será necesario tener una instalación de Conda en el sistema. Los usuarios tanto de Windows como de Linux/Mac podrán realizar directamente la instalación de una versión de Conda denominada Mini-Conda en el instalador del siguiente paso, la cual sería la opción recomendada para no tener que realizar una instalación externa de manera adicional.</p>
<div class="infobox">
<p><strong>NOTA</strong></p>
<p>Otra manera disponible para los usuarios de Windows, pero no recomendada por los autores de este libro salvo que ya se disponga de Anaconda instalado, sería la de utilizar el programa y la librería directamente dentro de Anaconda, instalando una versión de R directamente en el sistema a través del siguiente link:</p>
<p><a href="https://docs.anaconda.com/anaconda/install/windows/" class="uri">https://docs.anaconda.com/anaconda/install/windows/</a></p>
</div>
<ul>
<li><strong>Paso 2</strong> - Instalación de <strong>tensorflow</strong> y <strong>keras</strong></li>
</ul>
<p>Para continuar la instalación se activará la librería de Tensorflow y se ejecutará la función <em>install_tensorflow</em></p>
<div class="sourceCode" id="cb430"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb430-1"><a href="capNN.html#cb430-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb430-2"><a href="capNN.html#cb430-2" aria-hidden="true" tabindex="-1"></a><span class="fu">install_tensorflow</span>()</span></code></pre></div>
<p>Al ejecutar esta función, los usuarios deberán marcar “Y” para aceptar la instalación de Mini-Conda, descartando aceptar la utilización de cualquier otro sistema Conda que pueda estar instalado previamente.</p>
<p>También se puede ejecutar la función <em>install_keras</em> del paquete <strong>keras</strong> para instalar Tensorflow [].</p>
<div class="sourceCode" id="cb431"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb431-1"><a href="capNN.html#cb431-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;keras&quot;</span>)</span>
<span id="cb431-2"><a href="capNN.html#cb431-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb431-3"><a href="capNN.html#cb431-3" aria-hidden="true" tabindex="-1"></a><span class="fu">install_keras</span>()</span></code></pre></div>
<ul>
<li><strong>Paso 3</strong> - Confirmar la instalación</li>
</ul>
<p>Para confirmar la instalación, se puede comprobar con los siguientes comandos (la salida puede variar según el equipo, pero la línea final tiene que ser similar a la indicada):</p>
<div class="sourceCode" id="cb432"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb432-1"><a href="capNN.html#cb432-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tensorflow)</span>
<span id="cb432-2"><a href="capNN.html#cb432-2" aria-hidden="true" tabindex="-1"></a>tf<span class="sc">$</span><span class="fu">constant</span>(<span class="st">&quot;Hellow Tensorflow&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb433"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb433-1"><a href="capNN.html#cb433-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tf.Tensor</span>(b<span class="st">&#39;Hellow Tensorflow&#39;</span>, <span class="at">shape=</span>(), <span class="at">dtype=</span>string)</span></code></pre></div>
</div>
<div id="ejemplo-de-red-para-clasificación" class="section level2 hasAnchor" number="36.9">
<h2><span class="header-section-number">36.9</span> Ejemplo de red para clasificación<a href="capNN.html#ejemplo-de-red-para-clasificación" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En esta sección se entrena una red neuronal artificial para reconocer o clasificar los dígitos manuscritos del conjunto de datos MNIST (<a href="https://en.wikipedia.org/wiki/MNIST_database" class="uri">https://en.wikipedia.org/wiki/MNIST_database</a>). Cada una de las imágenes de este conjunto de datos tiene un tamaño de <span class="math inline">\(28\times28\)</span> píxeles en escala de grises. En vez de extraer una serie de variables a partir de cada imagen, en este caso se utilizan cada uno de los <span class="math inline">\(28\times28=784\)</span> píxeles como variable de entrada (Figura <a href="capNN.html#fig:mlpmnhist">36.8</a>).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:mlpmnhist"></span>
<img src="img/mlpmnhist.png" alt="MLP para reconocimiento de dígitos manuscritos" width="100%" />
<p class="caption">
Figura 36.8: MLP para reconocimiento de dígitos manuscritos
</p>
</div>
<div id="carga-y-visualización-de-los-datos" class="section level3 hasAnchor" number="36.9.1">
<h3><span class="header-section-number">36.9.1</span> Carga y visualización de los datos<a href="capNN.html#carga-y-visualización-de-los-datos" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El primer paso será cargar la librería <strong>keras</strong> que permite crear redes neuronales y conjunto de imágenes que se encuentra disponible públicamente:</p>
<div class="sourceCode" id="cb434"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb434-1"><a href="capNN.html#cb434-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(keras)</span>
<span id="cb434-2"><a href="capNN.html#cb434-2" aria-hidden="true" tabindex="-1"></a>mnist <span class="ot">&lt;-</span> <span class="fu">dataset_mnist</span>()</span></code></pre></div>
<p>A continuación, se puede ver el contenido de las variables generadas, donde cabe destacar que el conjunto de datos MNIST ya viene separado en dos subconjuntos, uno para entrenamiento y otro para test, compuestos por 60000 y 10000 imágenes respectivamente. En ambos casos, estos datos se almacenan en la variable <em>x</em>.</p>
<div class="sourceCode" id="cb435"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb435-1"><a href="capNN.html#cb435-1" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(mnist)</span>
<span id="cb435-2"><a href="capNN.html#cb435-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] &quot;train&quot; &quot;test&quot;</span></span>
<span id="cb435-3"><a href="capNN.html#cb435-3" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(mnist<span class="sc">$</span>train<span class="sc">$</span>x)</span>
<span id="cb435-4"><a href="capNN.html#cb435-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 60000    28    28</span></span>
<span id="cb435-5"><a href="capNN.html#cb435-5" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(mnist<span class="sc">$</span>train<span class="sc">$</span>y)</span>
<span id="cb435-6"><a href="capNN.html#cb435-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 60000</span></span>
<span id="cb435-7"><a href="capNN.html#cb435-7" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(mnist<span class="sc">$</span>test<span class="sc">$</span>x)</span>
<span id="cb435-8"><a href="capNN.html#cb435-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 10000    28    28</span></span>
<span id="cb435-9"><a href="capNN.html#cb435-9" aria-hidden="true" tabindex="-1"></a><span class="fu">dim</span>(mnist<span class="sc">$</span>test<span class="sc">$</span>y)</span>
<span id="cb435-10"><a href="capNN.html#cb435-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 10000</span></span></code></pre></div>
<p>Además, las imágenes de cada subconjunto vienen acompañadas de la clase a la que pertenecen (dígito contenido en la imagen). En ambos casos, esta etiqueta se almacena en la variable <em>y</em>. A continuación se muestra un pequeño ejemplo que permitirá mostrar alguna de las imágenes contenidas en el conjunto de datos de entrenamiento junto con la etiqueta representando el dígito contenido:</p>
<div class="sourceCode" id="cb436"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb436-1"><a href="capNN.html#cb436-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfcol =</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">4</span>))</span>
<span id="cb436-2"><a href="capNN.html#cb436-2" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mar =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">0</span>), <span class="at">xaxs =</span> <span class="st">&quot;i&quot;</span>, <span class="at">yaxs =</span> <span class="st">&quot;i&quot;</span>)</span>
<span id="cb436-3"><a href="capNN.html#cb436-3" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">16</span>) {</span>
<span id="cb436-4"><a href="capNN.html#cb436-4" aria-hidden="true" tabindex="-1"></a>  im <span class="ot">&lt;-</span> mnist<span class="sc">$</span>train<span class="sc">$</span>x[j, , ]</span>
<span id="cb436-5"><a href="capNN.html#cb436-5" aria-hidden="true" tabindex="-1"></a>  im <span class="ot">&lt;-</span> <span class="fu">t</span>(<span class="fu">apply</span>(im, <span class="dv">2</span>, rev))</span>
<span id="cb436-6"><a href="capNN.html#cb436-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">image</span>(</span>
<span id="cb436-7"><a href="capNN.html#cb436-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">28</span>, <span class="at">y =</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">28</span>, <span class="at">z =</span> im, <span class="at">col =</span> <span class="fu">gray</span>((<span class="dv">0</span><span class="sc">:</span><span class="dv">255</span>) <span class="sc">/</span> <span class="dv">255</span>),</span>
<span id="cb436-8"><a href="capNN.html#cb436-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">xaxt =</span> <span class="st">&quot;n&quot;</span>, <span class="at">main =</span> <span class="fu">paste</span>(mnist<span class="sc">$</span>train<span class="sc">$</span>y[j])</span>
<span id="cb436-9"><a href="capNN.html#cb436-9" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb436-10"><a href="capNN.html#cb436-10" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-158"></span>
<img src="Ciencia_de_datos_con_r_files/figure-html/unnamed-chunk-158-1.png" alt="Algunas imágenes del conjunto de entrenamiento" width="60%" />
<p class="caption">
Figura 36.9: Algunas imágenes del conjunto de entrenamiento
</p>
</div>
</div>
<div id="preprocesamiento" class="section level3 hasAnchor" number="36.9.2">
<h3><span class="header-section-number">36.9.2</span> Preprocesamiento<a href="capNN.html#preprocesamiento" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Una vez cargados los datos y comprobado su contenido, es posible realizar algún tipo de preprocesado. Dependiendo del tipo de problema se podrán realizar unas operaciones u otras. Por ejemplo, cuando se trabaja con imágenes es muy típico estandarizar los valores de color de las imágenes para mitigar las diferencias producidas por las diferentes condiciones de iluminación.</p>
<p>En este caso, solo se va a transformar los valores originales de la imagen (en rango de 0 a 255) a valores entre 0 y 1 dividiendo cada valor por el máximo, 255:</p>
<div class="sourceCode" id="cb437"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb437-1"><a href="capNN.html#cb437-1" aria-hidden="true" tabindex="-1"></a>mnist<span class="sc">$</span>train<span class="sc">$</span>x <span class="ot">&lt;-</span> mnist<span class="sc">$</span>train<span class="sc">$</span>x <span class="sc">/</span> <span class="dv">255</span></span>
<span id="cb437-2"><a href="capNN.html#cb437-2" aria-hidden="true" tabindex="-1"></a>mnist<span class="sc">$</span>test<span class="sc">$</span>x <span class="ot">&lt;-</span> mnist<span class="sc">$</span>test<span class="sc">$</span>x <span class="sc">/</span> <span class="dv">255</span></span></code></pre></div>
</div>
<div id="nngen" class="section level3 hasAnchor" number="36.9.3">
<h3><span class="header-section-number">36.9.3</span> Generación de la red neuronal<a href="capNN.html#nngen" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El siguiente paso consiste en la generación de la red neuronal. Para ello, se define primero la estructura utilizando la interfaz <em>sequential</em> proporcionada por Tensorflow/Keras a través de la función <em>keras_model_sequential</em>:</p>
<div class="sourceCode" id="cb438"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb438-1"><a href="capNN.html#cb438-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">keras_model_sequential</span>() <span class="sc">|&gt;</span></span>
<span id="cb438-2"><a href="capNN.html#cb438-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_flatten</span>(<span class="at">input_shape =</span> <span class="fu">c</span>(<span class="dv">28</span>, <span class="dv">28</span>)) <span class="sc">|&gt;</span></span>
<span id="cb438-3"><a href="capNN.html#cb438-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">15</span>, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb438-4"><a href="capNN.html#cb438-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="dv">10</span>, <span class="at">activation =</span> <span class="st">&quot;softmax&quot;</span>)</span></code></pre></div>
<p>Como se puede observar, la red definida está compuesta por una capa de tipo <em>flatten</em> que se encarga de transformar los 28x28 valores a un vector de 784 elementos, para que a continuación una capa oculta <em>dense</em> de 15 neuronas con activación <em>relu</em> se encargue de realizar las primeras operaciones con esos datos. Al final, una última capa <em>dense</em> se encarga de obtener la probabilidad de que la imagen represente cada una de las posibles clases mediante una activación <em>softmax</em><a href="#fn106" class="footnote-ref" id="fnref106"><sup>106</sup></a>:</p>
<div class="sourceCode" id="cb439"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb439-1"><a href="capNN.html#cb439-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model, <span class="at">line_length =</span> <span class="dv">64</span>)</span>
<span id="cb439-2"><a href="capNN.html#cb439-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Model: &quot;sequential&quot;</span></span>
<span id="cb439-3"><a href="capNN.html#cb439-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ________________________________________________________________</span></span>
<span id="cb439-4"><a href="capNN.html#cb439-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  Layer (type)               Output Shape              Param #   </span></span>
<span id="cb439-5"><a href="capNN.html#cb439-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ================================================================</span></span>
<span id="cb439-6"><a href="capNN.html#cb439-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  flatten (Flatten)          (None, 784)               0         </span></span>
<span id="cb439-7"><a href="capNN.html#cb439-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  dense_1 (Dense)            (None, 15)                11775     </span></span>
<span id="cb439-8"><a href="capNN.html#cb439-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  dense (Dense)              (None, 10)                160       </span></span>
<span id="cb439-9"><a href="capNN.html#cb439-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ================================================================</span></span>
<span id="cb439-10"><a href="capNN.html#cb439-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Total params: 11,935</span></span>
<span id="cb439-11"><a href="capNN.html#cb439-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Trainable params: 11,935</span></span>
<span id="cb439-12"><a href="capNN.html#cb439-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Non-trainable params: 0</span></span>
<span id="cb439-13"><a href="capNN.html#cb439-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ________________________________________________________________</span></span></code></pre></div>
<p>Finalmente, es necesario compilar el modelo, indicando algunos de los parámetros de configuración necesarios para el proceso de entrenamiento, como la función de coste o pérdida, el optimizador a utilizar y las métricas a obtener:</p>
<div class="sourceCode" id="cb440"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb440-1"><a href="capNN.html#cb440-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">|&gt;</span></span>
<span id="cb440-2"><a href="capNN.html#cb440-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(</span>
<span id="cb440-3"><a href="capNN.html#cb440-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">loss =</span> <span class="st">&quot;sparse_categorical_crossentropy&quot;</span>, <span class="co"># función utilizada para problemas de clasificación con varias clases</span></span>
<span id="cb440-4"><a href="capNN.html#cb440-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer =</span> <span class="st">&quot;sgd&quot;</span>, <span class="co"># stochastic gradient descent</span></span>
<span id="cb440-5"><a href="capNN.html#cb440-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">metrics =</span> <span class="st">&quot;accuracy&quot;</span> <span class="co"># Precisión</span></span>
<span id="cb440-6"><a href="capNN.html#cb440-6" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
</div>
<div id="nntrain" class="section level3 hasAnchor" number="36.9.4">
<h3><span class="header-section-number">36.9.4</span> Entrenamiento<a href="capNN.html#nntrain" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Una vez generada la estructura de la red neuronal y definida la anterior configuración, es posible entrenarla mediante la función <em>fit()</em>. Para ello, se le debe indicar el conjunto de imágenes de entrenamiento, <em>x</em>, que debe utilizar y sus clases correspondientes, <em>y</em>. Además de otros parámetros, se podrá configurar el número de <em>epochs</em> a entrenar (pasadas sobre el conjunto completo de entrenamiento), el tamaño del batch que se utilizará en cada iteración con <em>batch_size</em> (número de imágenes por iteración), qué porcentaje de elementos del conjunto de datos se utilizarán para validar el modelo con <em>validation_split</em> (imágenes utilizadas durante el entrenamiento pero solo para obtener una estimación real del error cometido) o la tasa de aprendizaje, <em>learning_rate</em>.</p>
<div class="sourceCode" id="cb441"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb441-1"><a href="capNN.html#cb441-1" aria-hidden="true" tabindex="-1"></a>training_evolution <span class="ot">&lt;-</span> model <span class="sc">|&gt;</span></span>
<span id="cb441-2"><a href="capNN.html#cb441-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(</span>
<span id="cb441-3"><a href="capNN.html#cb441-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> mnist<span class="sc">$</span>train<span class="sc">$</span>x, <span class="at">y =</span> mnist<span class="sc">$</span>train<span class="sc">$</span>y,</span>
<span id="cb441-4"><a href="capNN.html#cb441-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">epochs =</span> <span class="dv">10</span>, <span class="at">batch_size =</span> <span class="dv">128</span>,</span>
<span id="cb441-5"><a href="capNN.html#cb441-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">validation_split =</span> <span class="fl">0.2</span>,</span>
<span id="cb441-6"><a href="capNN.html#cb441-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">learning_rate =</span> <span class="fl">0.1</span>,</span>
<span id="cb441-7"><a href="capNN.html#cb441-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">verbose =</span> <span class="dv">2</span></span>
<span id="cb441-8"><a href="capNN.html#cb441-8" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<div class="sourceCode" id="cb442"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb442-1"><a href="capNN.html#cb442-1" aria-hidden="true" tabindex="-1"></a>Epoch <span class="dv">1</span><span class="sc">/</span><span class="dv">10</span></span>
<span id="cb442-2"><a href="capNN.html#cb442-2" aria-hidden="true" tabindex="-1"></a><span class="dv">375</span><span class="sc">/</span><span class="dv">375</span> <span class="sc">-</span> 2s <span class="sc">-</span> loss<span class="sc">:</span> <span class="fl">1.6313</span> <span class="sc">-</span> accuracy<span class="sc">:</span> <span class="fl">0.5266</span> <span class="sc">-</span> val_loss<span class="sc">:</span> <span class="fl">1.0455</span> <span class="sc">-</span> val_accuracy<span class="sc">:</span> <span class="fl">0.7510</span> <span class="sc">-</span> 2s<span class="sc">/</span>epoch <span class="sc">-</span> 6ms<span class="sc">/</span>step</span>
<span id="cb442-3"><a href="capNN.html#cb442-3" aria-hidden="true" tabindex="-1"></a>Epoch <span class="dv">2</span><span class="sc">/</span><span class="dv">10</span></span>
<span id="cb442-4"><a href="capNN.html#cb442-4" aria-hidden="true" tabindex="-1"></a><span class="dv">375</span><span class="sc">/</span><span class="dv">375</span> <span class="sc">-</span> 1s <span class="sc">-</span> loss<span class="sc">:</span> <span class="fl">0.8433</span> <span class="sc">-</span> accuracy<span class="sc">:</span> <span class="fl">0.7881</span> <span class="sc">-</span> val_loss<span class="sc">:</span> <span class="fl">0.6409</span> <span class="sc">-</span> val_accuracy<span class="sc">:</span> <span class="fl">0.8434</span> <span class="sc">-</span> 1s<span class="sc">/</span>epoch <span class="sc">-</span> 3ms<span class="sc">/</span>step</span>
<span id="cb442-5"><a href="capNN.html#cb442-5" aria-hidden="true" tabindex="-1"></a>Epoch <span class="dv">3</span><span class="sc">/</span><span class="dv">10</span></span>
<span id="cb442-6"><a href="capNN.html#cb442-6" aria-hidden="true" tabindex="-1"></a><span class="dv">375</span><span class="sc">/</span><span class="dv">375</span> <span class="sc">-</span> 1s <span class="sc">-</span> loss<span class="sc">:</span> <span class="fl">0.6022</span> <span class="sc">-</span> accuracy<span class="sc">:</span> <span class="fl">0.8427</span> <span class="sc">-</span> val_loss<span class="sc">:</span> <span class="fl">0.5031</span> <span class="sc">-</span> val_accuracy<span class="sc">:</span> <span class="fl">0.8712</span> <span class="sc">-</span> 1s<span class="sc">/</span>epoch <span class="sc">-</span> 3ms<span class="sc">/</span>step</span>
<span id="cb442-7"><a href="capNN.html#cb442-7" aria-hidden="true" tabindex="-1"></a>Epoch <span class="dv">4</span><span class="sc">/</span><span class="dv">10</span></span>
<span id="cb442-8"><a href="capNN.html#cb442-8" aria-hidden="true" tabindex="-1"></a><span class="dv">375</span><span class="sc">/</span><span class="dv">375</span> <span class="sc">-</span> 1s <span class="sc">-</span> loss<span class="sc">:</span> <span class="fl">0.5047</span> <span class="sc">-</span> accuracy<span class="sc">:</span> <span class="fl">0.8656</span> <span class="sc">-</span> val_loss<span class="sc">:</span> <span class="fl">0.4381</span> <span class="sc">-</span> val_accuracy<span class="sc">:</span> <span class="fl">0.8830</span> <span class="sc">-</span> 1s<span class="sc">/</span>epoch <span class="sc">-</span> 3ms<span class="sc">/</span>step</span>
<span id="cb442-9"><a href="capNN.html#cb442-9" aria-hidden="true" tabindex="-1"></a>Epoch <span class="dv">5</span><span class="sc">/</span><span class="dv">10</span></span>
<span id="cb442-10"><a href="capNN.html#cb442-10" aria-hidden="true" tabindex="-1"></a><span class="dv">375</span><span class="sc">/</span><span class="dv">375</span> <span class="sc">-</span> 1s <span class="sc">-</span> loss<span class="sc">:</span> <span class="fl">0.4526</span> <span class="sc">-</span> accuracy<span class="sc">:</span> <span class="fl">0.8767</span> <span class="sc">-</span> val_loss<span class="sc">:</span> <span class="fl">0.4019</span> <span class="sc">-</span> val_accuracy<span class="sc">:</span> <span class="fl">0.8909</span> <span class="sc">-</span> 1s<span class="sc">/</span>epoch <span class="sc">-</span> 3ms<span class="sc">/</span>step</span>
<span id="cb442-11"><a href="capNN.html#cb442-11" aria-hidden="true" tabindex="-1"></a>Epoch <span class="dv">6</span><span class="sc">/</span><span class="dv">10</span></span>
<span id="cb442-12"><a href="capNN.html#cb442-12" aria-hidden="true" tabindex="-1"></a><span class="dv">375</span><span class="sc">/</span><span class="dv">375</span> <span class="sc">-</span> 1s <span class="sc">-</span> loss<span class="sc">:</span> <span class="fl">0.4201</span> <span class="sc">-</span> accuracy<span class="sc">:</span> <span class="fl">0.8854</span> <span class="sc">-</span> val_loss<span class="sc">:</span> <span class="fl">0.3764</span> <span class="sc">-</span> val_accuracy<span class="sc">:</span> <span class="fl">0.8959</span> <span class="sc">-</span> 1s<span class="sc">/</span>epoch <span class="sc">-</span> 3ms<span class="sc">/</span>step</span>
<span id="cb442-13"><a href="capNN.html#cb442-13" aria-hidden="true" tabindex="-1"></a>Epoch <span class="dv">7</span><span class="sc">/</span><span class="dv">10</span></span>
<span id="cb442-14"><a href="capNN.html#cb442-14" aria-hidden="true" tabindex="-1"></a><span class="dv">375</span><span class="sc">/</span><span class="dv">375</span> <span class="sc">-</span> 1s <span class="sc">-</span> loss<span class="sc">:</span> <span class="fl">0.3976</span> <span class="sc">-</span> accuracy<span class="sc">:</span> <span class="fl">0.8896</span> <span class="sc">-</span> val_loss<span class="sc">:</span> <span class="fl">0.3593</span> <span class="sc">-</span> val_accuracy<span class="sc">:</span> <span class="fl">0.8996</span> <span class="sc">-</span> 1s<span class="sc">/</span>epoch <span class="sc">-</span> 3ms<span class="sc">/</span>step</span>
<span id="cb442-15"><a href="capNN.html#cb442-15" aria-hidden="true" tabindex="-1"></a>Epoch <span class="dv">8</span><span class="sc">/</span><span class="dv">10</span></span>
<span id="cb442-16"><a href="capNN.html#cb442-16" aria-hidden="true" tabindex="-1"></a><span class="dv">375</span><span class="sc">/</span><span class="dv">375</span> <span class="sc">-</span> 1s <span class="sc">-</span> loss<span class="sc">:</span> <span class="fl">0.3809</span> <span class="sc">-</span> accuracy<span class="sc">:</span> <span class="fl">0.8939</span> <span class="sc">-</span> val_loss<span class="sc">:</span> <span class="fl">0.3463</span> <span class="sc">-</span> val_accuracy<span class="sc">:</span> <span class="fl">0.9022</span> <span class="sc">-</span> 1s<span class="sc">/</span>epoch <span class="sc">-</span> 3ms<span class="sc">/</span>step</span>
<span id="cb442-17"><a href="capNN.html#cb442-17" aria-hidden="true" tabindex="-1"></a>Epoch <span class="dv">9</span><span class="sc">/</span><span class="dv">10</span></span>
<span id="cb442-18"><a href="capNN.html#cb442-18" aria-hidden="true" tabindex="-1"></a><span class="dv">375</span><span class="sc">/</span><span class="dv">375</span> <span class="sc">-</span> 1s <span class="sc">-</span> loss<span class="sc">:</span> <span class="fl">0.3678</span> <span class="sc">-</span> accuracy<span class="sc">:</span> <span class="fl">0.8975</span> <span class="sc">-</span> val_loss<span class="sc">:</span> <span class="fl">0.3359</span> <span class="sc">-</span> val_accuracy<span class="sc">:</span> <span class="fl">0.9050</span> <span class="sc">-</span> 1s<span class="sc">/</span>epoch <span class="sc">-</span> 3ms<span class="sc">/</span>step</span>
<span id="cb442-19"><a href="capNN.html#cb442-19" aria-hidden="true" tabindex="-1"></a>Epoch <span class="dv">10</span><span class="sc">/</span><span class="dv">10</span></span>
<span id="cb442-20"><a href="capNN.html#cb442-20" aria-hidden="true" tabindex="-1"></a><span class="dv">375</span><span class="sc">/</span><span class="dv">375</span> <span class="sc">-</span> 1s <span class="sc">-</span> loss<span class="sc">:</span> <span class="fl">0.3571</span> <span class="sc">-</span> accuracy<span class="sc">:</span> <span class="fl">0.8997</span> <span class="sc">-</span> val_loss<span class="sc">:</span> <span class="fl">0.3289</span> <span class="sc">-</span> val_accuracy<span class="sc">:</span> <span class="fl">0.9064</span> <span class="sc">-</span> 1s<span class="sc">/</span>epoch <span class="sc">-</span> 3ms<span class="sc">/</span>step</span></code></pre></div>
<p>Tras el entrenamiento es posible ver su evolución mediante las gráficas de coste/pérdida y precisión:</p>
<div class="sourceCode" id="cb443"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb443-1"><a href="capNN.html#cb443-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(training_evolution)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:plot-curve1"></span>
<img src="img/curve1.png" alt="Evolución durante el entrenamiento de la precisión y la pérdida de los conjuntos de entrenamiento y validación" width="100%" />
<p class="caption">
Figura 36.10: Evolución durante el entrenamiento de la precisión y la pérdida de los conjuntos de entrenamiento y validación
</p>
</div>
<p>Como se puede observar, la red entrenada tiene alrededor de un 90% de precisión para las imágenes en los conjuntos de entrenamiento y validación.</p>
</div>
<div id="test" class="section level3 hasAnchor" number="36.9.5">
<h3><span class="header-section-number">36.9.5</span> Test<a href="capNN.html#test" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Una vez entrenado el modelo, es posible aplicarlo sobre el conjunto de test. Para ello, se puede realizar la predicción sobre cualquiera de las imágenes mediante la función <em>predict</em>, obteniendo la probabilidad de que pertenezca a una determinada clase:</p>
<div class="sourceCode" id="cb444"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb444-1"><a href="capNN.html#cb444-1" aria-hidden="true" tabindex="-1"></a>predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(model, mnist<span class="sc">$</span>test<span class="sc">$</span>x)</span>
<span id="cb444-2"><a href="capNN.html#cb444-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(<span class="fu">round</span>(predictions, <span class="at">digits =</span> <span class="dv">3</span>), <span class="dv">5</span>)</span></code></pre></div>
<pre><code>#&gt;       [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10]
#&gt; [1,] 0.000 0.000 0.000 0.003 0.000 0.000 0.000 0.995 0.000 0.002
#&gt; [2,] 0.009 0.000 0.836 0.024 0.000 0.009 0.119 0.000 0.003 0.000
#&gt; [3,] 0.000 0.962 0.013 0.006 0.001 0.001 0.003 0.002 0.010 0.002
#&gt; [4,] 0.999 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000 0.000
#&gt; [5,] 0.001 0.000 0.007 0.000 0.836 0.004 0.011 0.012 0.017 0.111</code></pre>
<p>También se puede utilizar la función <em>evaluate</em> para calcular tanto el coste o pérdida como la precisión de la red neuronal sobre el conjunto de test. Como se puede observar, se obtienen valores muy similares a los obtenidos durante el entrenamiento:</p>
<div class="sourceCode" id="cb446"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb446-1"><a href="capNN.html#cb446-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">|&gt;</span></span>
<span id="cb446-2"><a href="capNN.html#cb446-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">evaluate</span>(mnist<span class="sc">$</span>test<span class="sc">$</span>x, mnist<span class="sc">$</span>test<span class="sc">$</span>y, <span class="at">verbose =</span> <span class="dv">0</span>)</span></code></pre></div>
<pre><code>#&gt;      loss  accuracy 
#&gt; 0.3310305 0.9045000</code></pre>
<p>Con la función <em>predict</em> se puede también generar la matriz de confusión de la red para evaluar qué pares de clases está confundiendo:</p>
<div class="sourceCode" id="cb448"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb448-1"><a href="capNN.html#cb448-1" aria-hidden="true" tabindex="-1"></a>prediction_matrix <span class="ot">&lt;-</span> model <span class="sc">|&gt;</span></span>
<span id="cb448-2"><a href="capNN.html#cb448-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">predict</span>(mnist<span class="sc">$</span>test<span class="sc">$</span>x) <span class="sc">|&gt;</span></span>
<span id="cb448-3"><a href="capNN.html#cb448-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">k_argmax</span>()</span>
<span id="cb448-4"><a href="capNN.html#cb448-4" aria-hidden="true" tabindex="-1"></a>confusion_matrix <span class="ot">&lt;-</span> <span class="fu">table</span>(<span class="fu">as.array</span>(prediction_matrix), mnist<span class="sc">$</span>test<span class="sc">$</span>y)</span>
<span id="cb448-5"><a href="capNN.html#cb448-5" aria-hidden="true" tabindex="-1"></a>confusion_matrix</span></code></pre></div>
<pre><code>#&gt;    
#&gt;        0    1    2    3    4    5    6    7    8    9
#&gt;   0  953    0   11    4    2   16   16    3    8    7
#&gt;   1    0 1108   10    2    6    1    3   21   10    5
#&gt;   2    4    3  901   27    5   11   14   27   13    6
#&gt;   3    2    2   16  903    0   46    1    4   29   10
#&gt;   4    1    0   16    0  899   16   12    9   11   43
#&gt;   5    6    1    1   29    1  726    8    1   24   13
#&gt;   6    9    4   19    3   10   21  902    0   10    0
#&gt;   7    2    2   12   17    2   10    0  916   11   18
#&gt;   8    3   15   35   20   10   38    2    3  839    9
#&gt;   9    0    0   11    5   47    7    0   44   19  898</code></pre>
<p>En la diagonal principal podemos observar el número de aciertos que obtiene el modelo entrenado para el conjunto de test, mientras que el resto de valores indican en cuantas ocasiones una clase es clasificada de manera incorrecta como otra diferente. Estos resultados coinciden con el valor de <strong>accuracy</strong> calculado mediante la función <strong>evaluate</strong> previa.</p>
</div>
<div id="guardado-y-reutilización-del-modelo" class="section level3 hasAnchor" number="36.9.6">
<h3><span class="header-section-number">36.9.6</span> Guardado y reutilización del modelo<a href="capNN.html#guardado-y-reutilización-del-modelo" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Finalmente, es posible almacenar el modelo entrenado mediante la función <em>save_model_tf</em>, que genera una carpeta con la red que se puede cargar y reutilizar mediante la función <em>load_model_tf</em>.</p>
<div class="sourceCode" id="cb450"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb450-1"><a href="capNN.html#cb450-1" aria-hidden="true" tabindex="-1"></a><span class="fu">save_model_tf</span>(<span class="at">object =</span> model, <span class="at">filepath =</span> <span class="st">&quot;model&quot;</span>)</span>
<span id="cb450-2"><a href="capNN.html#cb450-2" aria-hidden="true" tabindex="-1"></a>reloaded_model <span class="ot">&lt;-</span> <span class="fu">load_model_tf</span>(<span class="st">&quot;model&quot;</span>)</span>
<span id="cb450-3"><a href="capNN.html#cb450-3" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">predict</span>(reloaded_model, mnist<span class="sc">$</span>test<span class="sc">$</span>x[<span class="dv">1</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">28</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">28</span>]), <span class="at">digits =</span> <span class="dv">4</span>)</span></code></pre></div>
<pre><code>#&gt;       [,1] [,2]  [,3]   [,4] [,5]  [,6] [,7]   [,8] [,9] [,10]
#&gt; [1,] 2e-04    0 1e-04 0.0028    0 1e-04    0 0.9948    0 0.002</code></pre>
</div>
</div>
<div id="ejemplo-de-red-para-regresión" class="section level2 hasAnchor" number="36.10">
<h2><span class="header-section-number">36.10</span> Ejemplo de red para regresión<a href="capNN.html#ejemplo-de-red-para-regresión" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En esta sección se entrena una red neuronal artificial para predecir el precio de la vivienda según sus características en Madrid. Para ello se usará el dataset de <strong>Madrid_Sale</strong> disponibles en el paquete de <em>R</em> <strong>Idealista18</strong>, con datos inmobiliaros del año 2018 y que fue utilizado en el Capítulo @ref(#chap-feature). Para ello, se tomarán las siguientes 7 variables que se usarán para realizar la estimación:</p>
<ul>
<li><em>CONSTRUCTEDAREA</em>. Metros cuadrados construidos.</li>
<li><em>ROOMNUMBER</em>. Número de habitaciones.</li>
<li><em>BATHNUMBER</em>. Número de baños.</li>
<li><em>HASLIFT</em>. Si tiene ascensor.</li>
<li><em>DISTANCE_TO_CITY_CENTER</em>. Distancia al centro de la ciudad.</li>
<li><em>DISTANCE_TO_METRO</em>. Distancia a la parada de metro más cercana.</li>
<li><em>DISTANCE_TO_CASTELLANA</em>. Distancia a la Castellana.</li>
</ul>
<div id="carga-y-visualización-de-los-datos-1" class="section level3 hasAnchor" number="36.10.1">
<h3><span class="header-section-number">36.10.1</span> Carga y visualización de los datos<a href="capNN.html#carga-y-visualización-de-los-datos-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Considerando que ya se ha cargado previamente la librería <strong>keras</strong>, se carga el conjunto de datos indicando las variables a considerar:</p>
<div class="sourceCode" id="cb452"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb452-1"><a href="capNN.html#cb452-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(idealista18)</span>
<span id="cb452-2"><a href="capNN.html#cb452-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;Madrid_Sale&quot;</span>)</span>
<span id="cb452-3"><a href="capNN.html#cb452-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb452-4"><a href="capNN.html#cb452-4" aria-hidden="true" tabindex="-1"></a>variables <span class="ot">&lt;-</span> <span class="fu">c</span>(</span>
<span id="cb452-5"><a href="capNN.html#cb452-5" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;CONSTRUCTEDAREA&quot;</span>, <span class="st">&quot;ROOMNUMBER&quot;</span>, <span class="st">&quot;BATHNUMBER&quot;</span>,</span>
<span id="cb452-6"><a href="capNN.html#cb452-6" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;HASLIFT&quot;</span>, <span class="st">&quot;DISTANCE_TO_CITY_CENTER&quot;</span>, <span class="st">&quot;DISTANCE_TO_METRO&quot;</span>,</span>
<span id="cb452-7"><a href="capNN.html#cb452-7" aria-hidden="true" tabindex="-1"></a>  <span class="st">&quot;DISTANCE_TO_CASTELLANA&quot;</span></span>
<span id="cb452-8"><a href="capNN.html#cb452-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb452-9"><a href="capNN.html#cb452-9" aria-hidden="true" tabindex="-1"></a>x_madrid <span class="ot">&lt;-</span> Madrid_Sale[variables]</span>
<span id="cb452-10"><a href="capNN.html#cb452-10" aria-hidden="true" tabindex="-1"></a>x_madrid_mat <span class="ot">&lt;-</span> <span class="fu">unname</span>(<span class="fu">data.matrix</span>(x_madrid))</span>
<span id="cb452-11"><a href="capNN.html#cb452-11" aria-hidden="true" tabindex="-1"></a>y_madrid <span class="ot">&lt;-</span> Madrid_Sale<span class="sc">$</span>PRICE</span>
<span id="cb452-12"><a href="capNN.html#cb452-12" aria-hidden="true" tabindex="-1"></a>y_madrid_mat <span class="ot">&lt;-</span> <span class="fu">matrix</span>(y_madrid, <span class="at">nrow =</span> <span class="fu">length</span>(y_madrid), <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p>El conjunto de datos contiene un total de 94815 elementos, que se dividirán en un 90% para entrenamiento y un 10% para test:</p>
<div class="sourceCode" id="cb453"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb453-1"><a href="capNN.html#cb453-1" aria-hidden="true" tabindex="-1"></a>ind <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="cn">TRUE</span>, <span class="cn">FALSE</span>), <span class="fu">length</span>(y_madrid), <span class="at">replace =</span> <span class="cn">TRUE</span>, <span class="at">prob =</span> <span class="fu">c</span>(<span class="fl">0.9</span>, <span class="fl">0.1</span>))</span>
<span id="cb453-2"><a href="capNN.html#cb453-2" aria-hidden="true" tabindex="-1"></a>madrid_dat_train_x <span class="ot">&lt;-</span> x_madrid_mat[ind, ]</span>
<span id="cb453-3"><a href="capNN.html#cb453-3" aria-hidden="true" tabindex="-1"></a>madrid_dat_test_x <span class="ot">&lt;-</span> x_madrid_mat[<span class="sc">!</span>ind, ]</span>
<span id="cb453-4"><a href="capNN.html#cb453-4" aria-hidden="true" tabindex="-1"></a>madrid_dat_train_y <span class="ot">&lt;-</span> y_madrid_mat[ind, ]</span>
<span id="cb453-5"><a href="capNN.html#cb453-5" aria-hidden="true" tabindex="-1"></a>madrid_dat_test_y <span class="ot">&lt;-</span> y_madrid_mat[<span class="sc">!</span>ind, ]</span></code></pre></div>
</div>
<div id="preprocesamiento-1" class="section level3 hasAnchor" number="36.10.2">
<h3><span class="header-section-number">36.10.2</span> Preprocesamiento<a href="capNN.html#preprocesamiento-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Una vez cargados los datos y comprobado su contenido, es recomendable la normalización de las variables contenidas en el conjunto de datos debido a su heterogeneidad. Aunque sería posible para la red neuronal el adaptarse a esta situación, ciertamente puede complicar el proceso de entrenamiento. Para ello, se utilizará la función <em>scale</em> en las variables predictoras y se dividirá la variable del precio entre 100000 para reducir su orden:</p>
<div class="sourceCode" id="cb454"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb454-1"><a href="capNN.html#cb454-1" aria-hidden="true" tabindex="-1"></a>madrid_dat_train_x <span class="ot">&lt;-</span> <span class="fu">scale</span>(madrid_dat_train_x)</span>
<span id="cb454-2"><a href="capNN.html#cb454-2" aria-hidden="true" tabindex="-1"></a>madrid_dat_test_x <span class="ot">&lt;-</span> <span class="fu">scale</span>(madrid_dat_test_x)</span>
<span id="cb454-3"><a href="capNN.html#cb454-3" aria-hidden="true" tabindex="-1"></a>madrid_dat_train_y <span class="ot">&lt;-</span> madrid_dat_train_y <span class="sc">/</span> <span class="dv">100000</span></span>
<span id="cb454-4"><a href="capNN.html#cb454-4" aria-hidden="true" tabindex="-1"></a>madrid_dat_test_y <span class="ot">&lt;-</span> madrid_dat_test_y <span class="sc">/</span> <span class="dv">100000</span></span></code></pre></div>
</div>
<div id="generación-de-la-red-neuronal" class="section level3 hasAnchor" number="36.10.3">
<h3><span class="header-section-number">36.10.3</span> Generación de la red neuronal<a href="capNN.html#generación-de-la-red-neuronal" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El siguiente paso consiste en la generación de la red neuronal. Para ello, al igual que en la sección <a href="capNN.html#nngen">36.9.3</a>, se define primero la estructura utilizando la interfaz <em>sequential</em> proporcionada por Tensorflow/Keras a través de la función <em>keras_model_sequential</em>:</p>
<div class="sourceCode" id="cb455"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb455-1"><a href="capNN.html#cb455-1" aria-hidden="true" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">keras_model_sequential</span>() <span class="sc">|&gt;</span></span>
<span id="cb455-2"><a href="capNN.html#cb455-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">128</span>, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>, <span class="at">input_shape =</span> <span class="dv">7</span>) <span class="sc">|&gt;</span></span>
<span id="cb455-3"><a href="capNN.html#cb455-3" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">64</span>, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb455-4"><a href="capNN.html#cb455-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">16</span>, <span class="at">activation =</span> <span class="st">&quot;relu&quot;</span>) <span class="sc">|&gt;</span></span>
<span id="cb455-5"><a href="capNN.html#cb455-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">layer_dense</span>(<span class="at">units =</span> <span class="dv">1</span>)</span></code></pre></div>
<p>Como se puede observar, la red está compuesta por varias capas ocultas tipo <em>dense</em>, en las que las tres primeras tienen una activación <em>relu</em>. Al final, una última capa <em>dense</em> se encarga de obtener el valor de la estimación y, al contrario que en el ejemplo previo, no incluye ningún tipo de activación debido a que el valor de la misma ya es comprensible tanto para el modelo como para su interpretación, y cualquier función de activación restringiría el rango de valores que podría obtener.</p>
<div class="sourceCode" id="cb456"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb456-1"><a href="capNN.html#cb456-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(model, <span class="at">line_length =</span> <span class="dv">64</span>)</span>
<span id="cb456-2"><a href="capNN.html#cb456-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Model: &quot;sequential_1&quot;</span></span>
<span id="cb456-3"><a href="capNN.html#cb456-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ________________________________________________________________</span></span>
<span id="cb456-4"><a href="capNN.html#cb456-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Layer (type) Output Shape Param #</span></span>
<span id="cb456-5"><a href="capNN.html#cb456-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ================================================================</span></span>
<span id="cb456-6"><a href="capNN.html#cb456-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; dense_5 (Dense) (None, 128) 1024</span></span>
<span id="cb456-7"><a href="capNN.html#cb456-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; dense_4 (Dense) (None, 64) 8256</span></span>
<span id="cb456-8"><a href="capNN.html#cb456-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; dense_3 (Dense) (None, 16) 1040</span></span>
<span id="cb456-9"><a href="capNN.html#cb456-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; dense_2 (Dense) (None, 1) 17</span></span>
<span id="cb456-10"><a href="capNN.html#cb456-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ================================================================</span></span>
<span id="cb456-11"><a href="capNN.html#cb456-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Total params: 10,337</span></span>
<span id="cb456-12"><a href="capNN.html#cb456-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Trainable params: 10,337</span></span>
<span id="cb456-13"><a href="capNN.html#cb456-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; Non-trainable params: 0</span></span>
<span id="cb456-14"><a href="capNN.html#cb456-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; ________________________________________________________________</span></span></code></pre></div>
<p>Finalmente, se compila el modelo indicando los parámetros de configuración necesarios para el proceso de entrenamiento. En este caso la función de coste o pérdida se corresponderá con el error medio cuadrático y la métrica con el error medio absoluto:</p>
<div class="sourceCode" id="cb457"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb457-1"><a href="capNN.html#cb457-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">|&gt;</span></span>
<span id="cb457-2"><a href="capNN.html#cb457-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">compile</span>(</span>
<span id="cb457-3"><a href="capNN.html#cb457-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">loss =</span> <span class="st">&quot;mse&quot;</span>, <span class="co"># mean squared error</span></span>
<span id="cb457-4"><a href="capNN.html#cb457-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">optimizer =</span> <span class="st">&quot;sgd&quot;</span>, <span class="co"># stochastic gradient descent</span></span>
<span id="cb457-5"><a href="capNN.html#cb457-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">metrics =</span> <span class="st">&quot;mae&quot;</span> <span class="co"># mean average error</span></span>
<span id="cb457-6"><a href="capNN.html#cb457-6" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
</div>
<div id="entrenamiento" class="section level3 hasAnchor" number="36.10.4">
<h3><span class="header-section-number">36.10.4</span> Entrenamiento<a href="capNN.html#entrenamiento" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Una vez generada la estructura de la red neuronal y definida la anterior configuración, se entrena la misma utilizando la función <em>fit</em>, configurando el resto de parámetros de forma similar a como se vio en la sección <a href="capNN.html#nntrain">36.9.4</a>:</p>
<div class="sourceCode" id="cb458"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb458-1"><a href="capNN.html#cb458-1" aria-hidden="true" tabindex="-1"></a>training_evolution <span class="ot">&lt;-</span> model <span class="sc">|&gt;</span></span>
<span id="cb458-2"><a href="capNN.html#cb458-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">fit</span>(</span>
<span id="cb458-3"><a href="capNN.html#cb458-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">x =</span> madrid_dat_train_x, <span class="at">y =</span> madrid_dat_train_y,</span>
<span id="cb458-4"><a href="capNN.html#cb458-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">epochs =</span> <span class="dv">50</span>, <span class="at">batch_size =</span> <span class="dv">512</span>,</span>
<span id="cb458-5"><a href="capNN.html#cb458-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">validation_split =</span> <span class="fl">0.2</span>,</span>
<span id="cb458-6"><a href="capNN.html#cb458-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">learning_rate =</span> <span class="fl">0.1</span>,</span>
<span id="cb458-7"><a href="capNN.html#cb458-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">verbose =</span> <span class="dv">2</span></span>
<span id="cb458-8"><a href="capNN.html#cb458-8" aria-hidden="true" tabindex="-1"></a>  )</span></code></pre></div>
<p>Tras el entrenamiento es posible ver su evolución mediante las gráficas de coste/pérdida y error:</p>
<div class="sourceCode" id="cb459"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb459-1"><a href="capNN.html#cb459-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(training_evolution)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:plot-curve2"></span>
<img src="img/curve2.png" alt="Evolución durante el entrenamiento de la precisión y la pérdida de los conjuntos de entrenamiento y validación" width="100%" />
<p class="caption">
Figura 36.11: Evolución durante el entrenamiento de la precisión y la pérdida de los conjuntos de entrenamiento y validación
</p>
</div>
<p>Como se puede observar, en este caso el modelo tiene aún posibilidad de mejora, ya que la pérdida sigue siendo alta y no se ha estancado, por lo que incrementando el número de épocas y el tiempo de entrenamiento se podría obtener un mejor resultado.</p>
</div>
<div id="test-1" class="section level3 hasAnchor" number="36.10.5">
<h3><span class="header-section-number">36.10.5</span> Test<a href="capNN.html#test-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Una vez entrenado el modelo, es posible aplicarlo sobre el conjunto de test mediante la función <em>predict</em>, obteniendo la estimación para cada una de las viviendas:</p>
<div class="sourceCode" id="cb460"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb460-1"><a href="capNN.html#cb460-1" aria-hidden="true" tabindex="-1"></a>predictions <span class="ot">&lt;-</span> <span class="fu">predict</span>(model, madrid_dat_test_x)</span>
<span id="cb460-2"><a href="capNN.html#cb460-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(predictions, <span class="dv">5</span>)</span>
<span id="cb460-3"><a href="capNN.html#cb460-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [,1]</span></span>
<span id="cb460-4"><a href="capNN.html#cb460-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1,] 6.669374</span></span>
<span id="cb460-5"><a href="capNN.html#cb460-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [2,] 5.895504</span></span>
<span id="cb460-6"><a href="capNN.html#cb460-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [3,] 3.887646</span></span>
<span id="cb460-7"><a href="capNN.html#cb460-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [4,] 6.390513</span></span>
<span id="cb460-8"><a href="capNN.html#cb460-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [5,] 5.721725</span></span></code></pre></div>
<p>Y mediante la función <em>evaluate</em> se calcula tanto el coste o pérdida como el error de la red neuronal sobre el conjunto de test, el cual tendremos que multiplicar por 100000 para obtener el resultado en la escala original del conjunto de datos:</p>
<div class="sourceCode" id="cb461"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb461-1"><a href="capNN.html#cb461-1" aria-hidden="true" tabindex="-1"></a>model <span class="sc">|&gt;</span></span>
<span id="cb461-2"><a href="capNN.html#cb461-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">evaluate</span>(madrid_dat_test_x, madrid_dat_test_y, <span class="at">verbose =</span> <span class="dv">0</span>)</span>
<span id="cb461-3"><a href="capNN.html#cb461-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; loss mae</span></span>
<span id="cb461-4"><a href="capNN.html#cb461-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2.4195166 0.9227165</span></span></code></pre></div>
<div class="infobox_resume">
<p><strong>RESUMEN</strong></p>
<ul>
<li><p>En este capítulo se ha explicado en detalle el concepto de redes neuronales artificiales, incluyendo los elementos que la componen, desde el perceptrón o neurona básica hasta el perceptrón multicapa, pasando el perceptron multiclase, junto al proceso de aprendizaje de los mismos.</p></li>
<li><p>Además, se han definido las funciones de activación clásicas utilizadas en las redes neuronales artificiales, las cuales se encargan de transformar la suma ponderada de las entradas en el resultado final de la capa.</p></li>
<li><p>Finalmente, se han explicado los pasos necesarios para poder entrenar una red neuronal artificial utilizando la librería Tensorflow/Keras en <strong>R</strong>, resolviendo el problema de clasificación de dígitos manuscritos representado en el conjunto de datos MNIST y un problema de regresión para estimar el precio de viviendas según sus características representado en el conjunto de datos de Idealista18.</p></li>
</ul>
</div>

</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-borji2022generated" class="csl-entry">
Borji, Ali. 2022. <span>“Generated Faces in the Wild: Quantitative Comparison of Stable Diffusion, Midjourney and Dall-e 2.”</span> <em>arXiv Preprint arXiv:2210.00586</em>.
</div>
<div id="ref-goodfellow2016deep" class="csl-entry">
Goodfellow, I., Y. Bengio, and A. Courville. 2016. <em>Deep Learning</em>. Adaptive Computation and Machine Learning. MIT Press. <a href="https://books.google.co.in/books?id=Np9SDQAAQBAJ">https://books.google.co.in/books?id=Np9SDQAAQBAJ</a>.
</div>
<div id="ref-haykin1999" class="csl-entry">
Haykin, S. 1999. <em>Neural Networks: A Comprehensive Foundation</em>. Prentice Hall.
</div>
<div id="ref-kiefer1952stochastic" class="csl-entry">
Kiefer, Jack, and Jacob Wolfowitz. 1952. <span>“Stochastic Estimation of the Maximum of a Regression Function.”</span> <em>The Annals of Mathematical Statistics</em>, 462–66.
</div>
<div id="ref-lecun1995convolutional" class="csl-entry">
LeCun, Yann, Yoshua Bengio, et al. 1995. <span>“Convolutional Networks for Images, Speech, and Time Series.”</span> <em>The Handbook of Brain Theory and Neural Networks</em> 3361 (10): 1995.
</div>
<div id="ref-minsky1969introduction" class="csl-entry">
Minsky, Marvin, and Seymour Papert. 1969. <span>“An Introduction to Computational Geometry.”</span> <em>Cambridge Tiass., HIT</em> 479: 480.
</div>
<div id="ref-nair2010rectified" class="csl-entry">
Nair, Vinod, and Geoffrey E Hinton. 2010. <span>“Rectified Linear Units Improve Restricted Boltzmann Machines.”</span> In <em>ICML 2010</em>, 807–14.
</div>
<div id="ref-novikoff62convergence" class="csl-entry">
Novikoff, A. B. 1962. <span>“On Convergence Proofs on Perceptrons.”</span> In <em>Proceedings of the Symposium on the Mathematical Theory of Automata</em>, 12:615–22. New York, NY, USA: Polytechnic Institute of Brooklyn.
</div>
<div id="ref-rosenblatt1958perceptron" class="csl-entry">
Rosenblatt, Frank. 1958. <span>“The Perceptron: A Probabilistic Model for Information Storage and Organization in the Brain.”</span> <em>Psychological Review</em> 65 (6): 386.
</div>
<div id="ref-rumelhart1986learning" class="csl-entry">
Rumelhart, David E, Geoffrey E Hinton, and Ronald J Williams. 1986. <span>“Learning Representations by Back-Propagating Errors.”</span> <em>Nature</em> 323 (6088): 533–36.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="106">
<li id="fn106"><p>La activación <em>softmax</em> convierte un vector de número reales en una distribución de probabilidad.<a href="capNN.html#fnref106" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="correspondencias.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="cap-redes-convol.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Ciencia_de_datos_con_r.pdf", "Ciencia_de_datos_con_r.epub"],
"search": {
"engine": "lunr",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
