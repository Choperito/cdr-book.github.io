<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Capítulo 10 Herramientas para el análisis en ciencia de datos | Fundamentos de ciencia de datos con R</title>
<meta name="author" content="Gema Fernández-Avilés y José-María Montero">
<meta name="description" content="José-María Montero\(^{a}\) y Jorge Velasco López\(^{b}\) \(^{a}\)Universidad de Castilla-La Mancha\(^{b}\)Instituto Nacional de Estadística de España  10.1 Introducción En este capítulo se...">
<meta name="generator" content="bookdown 0.37 with bs4_book()">
<meta property="og:title" content="Capítulo 10 Herramientas para el análisis en ciencia de datos | Fundamentos de ciencia de datos con R">
<meta property="og:type" content="book">
<meta property="og:image" content="/img/cover.png">
<meta property="og:description" content="José-María Montero\(^{a}\) y Jorge Velasco López\(^{b}\) \(^{a}\)Universidad de Castilla-La Mancha\(^{b}\)Instituto Nacional de Estadística de España  10.1 Introducción En este capítulo se...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Capítulo 10 Herramientas para el análisis en ciencia de datos | Fundamentos de ciencia de datos con R">
<meta name="twitter:description" content="José-María Montero\(^{a}\) y Jorge Velasco López\(^{b}\) \(^{a}\)Universidad de Castilla-La Mancha\(^{b}\)Instituto Nacional de Estadística de España  10.1 Introducción En este capítulo se...">
<meta name="twitter:image" content="/img/cover.png">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.6.1/transition.js"></script><script src="libs/bs3compat-0.6.1/tabs.js"></script><script src="libs/bs3compat-0.6.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><link href="libs/tabwid-1.1.3/tabwid.css" rel="stylesheet">
<script src="libs/tabwid-1.1.3/tabwid.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><link rel="stylesheet" href="bs4_style.css">
<link rel="stylesheet" href="bs4_book.css">
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Fundamentos de ciencia de datos con <strong>R</strong></a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Buscar" aria-label="Buscar">
</form>

      <nav aria-label="Contenido"><h2>Contenido</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Prefacio</a></li>
<li><a class="" href="pr%C3%B3logo-by-julia-silge.html">Prólogo (by Julia Silge)</a></li>
<li><a class="" href="pr%C3%B3logo-por-yanina-bellini.html">Prólogo (por Yanina Bellini)</a></li>
<li class="book-part">Ciencia, datos, software… y científicos</li>
<li><a class="" href="ciencia-datos.html"><span class="header-section-number">1</span> ¿Es la ciencia de datos una ciencia?</a></li>
<li><a class="" href="metodologia.html"><span class="header-section-number">2</span> Metodología en ciencia de datos</a></li>
<li><a class="" href="ch-110003.html"><span class="header-section-number">3</span> R para ciencia de datos</a></li>
<li><a class="" href="cap-etica.html"><span class="header-section-number">4</span> Ética en la ciencia de datos</a></li>
<li class="book-part">Bienvenidos a la jungla de datos</li>
<li><a class="" href="datos-sql.html"><span class="header-section-number">5</span> Gestión de bases de datos relacionales</a></li>
<li><a class="" href="cap-nosql.html"><span class="header-section-number">6</span> Gestión de bases de datos NoSQL</a></li>
<li><a class="" href="DGDQM.html"><span class="header-section-number">7</span> Gobierno, gestión y calidad del dato</a></li>
<li><a class="" href="cap-130009.html"><span class="header-section-number">8</span> Integración y limpieza de datos</a></li>
<li><a class="" href="chap-feature.html"><span class="header-section-number">9</span> Selección y transformación de variables</a></li>
<li><a class="active" href="chap-herramientas.html"><span class="header-section-number">10</span> Herramientas para el análisis en ciencia de datos</a></li>
<li><a class="" href="cap-120006-aed.html"><span class="header-section-number">11</span> Análisis exploratorio de datos</a></li>
<li class="book-part">Fundamentos de estadística</li>
<li><a class="" href="Funda-probab.html"><span class="header-section-number">12</span> Probabilidad</a></li>
<li><a class="" href="Fundainfer.html"><span class="header-section-number">13</span> Inferencia estadística</a></li>
<li><a class="" href="muestreo.html"><span class="header-section-number">14</span> Muestreo y remuestreo</a></li>
<li class="book-part">Modelización estadística</li>
<li><a class="" href="cap-lm.html"><span class="header-section-number">15</span> Modelización lineal</a></li>
<li><a class="" href="cap-glm.html"><span class="header-section-number">16</span> Modelos lineales generalizados</a></li>
<li><a class="" href="cap-gam.html"><span class="header-section-number">17</span> Modelos aditivos generalizados</a></li>
<li><a class="" href="cap-mxm.html"><span class="header-section-number">18</span> Modelos mixtos</a></li>
<li><a class="" href="cap-sparse.html"><span class="header-section-number">19</span> Modelos \(\textit{sparse}\) y métodos penalizados de regresión</a></li>
<li><a class="" href="cap-series-temp.html"><span class="header-section-number">20</span> Modelización de series temporales</a></li>
<li><a class="" href="cap-discriminante.html"><span class="header-section-number">21</span> Análisis discriminante</a></li>
<li><a class="" href="cap-conjunto.html"><span class="header-section-number">22</span> Análisis conjunto</a></li>
<li><a class="" href="tablas-contingencia.html"><span class="header-section-number">23</span> Análisis de tablas de contingencia</a></li>
<li class="book-part">Machine learning supervisado</li>
<li><a class="" href="cap-arboles.html"><span class="header-section-number">24</span> Árboles de clasificación y regresión</a></li>
<li><a class="" href="cap-svm.html"><span class="header-section-number">25</span> Máquinas de vector soporte</a></li>
<li><a class="" href="cap-knn.html"><span class="header-section-number">26</span> Clasificador \(k\)-vecinos más próximos</a></li>
<li><a class="" href="cap-naive-bayes.html"><span class="header-section-number">27</span> Naive Bayes</a></li>
<li><a class="" href="cap-bagg-rf.html"><span class="header-section-number">28</span> Métodos ensamblados: \(\bf \textit {bagging}\) y \(\bf \textit{random}\) \(\bf \textit{forest}\)</a></li>
<li><a class="" href="cap-boosting-xgboost.html"><span class="header-section-number">29</span> \(\bf \textit{Boosting}\) y el algoritmo XGBoost</a></li>
<li class="book-part">Machine learning no supervisado</li>
<li><a class="" href="cap-cluster.html"><span class="header-section-number">30</span> Análisis clúster: clusterización jerárquica</a></li>
<li><a class="" href="no-jerarquico.html"><span class="header-section-number">31</span> Análisis clúster: clusterización no jerárquica</a></li>
<li><a class="" href="acp.html"><span class="header-section-number">32</span> Análisis de componentes principales</a></li>
<li><a class="" href="af.html"><span class="header-section-number">33</span> Análisis factorial</a></li>
<li><a class="" href="mds.html"><span class="header-section-number">34</span> Escalamiento multidimensional</a></li>
<li><a class="" href="correspondencias.html"><span class="header-section-number">35</span> Análisis de correspondencias</a></li>
<li class="book-part">Deep learning</li>
<li><a class="" href="capNN.html"><span class="header-section-number">36</span> Redes neuronales artificiales</a></li>
<li><a class="" href="cap-redes-convol.html"><span class="header-section-number">37</span> Redes neuronales convolucionales</a></li>
<li class="book-part">Ciencia de datos de texto y redes</li>
<li><a class="" href="mineria-textos.html"><span class="header-section-number">38</span> Minería de textos</a></li>
<li><a class="" href="grafos.html"><span class="header-section-number">39</span> Análisis de grafos y redes sociales</a></li>
<li class="book-part">Ciencia de datos espaciales</li>
<li><a class="" href="datos-espaciales.html"><span class="header-section-number">40</span> Trabajando con datos espaciales</a></li>
<li><a class="" href="geo.html"><span class="header-section-number">41</span> Geoestadística</a></li>
<li><a class="" href="cap-econom-esp.html"><span class="header-section-number">42</span> Modelos econométricos espaciales</a></li>
<li><a class="" href="cap-pp.html"><span class="header-section-number">43</span> Procesos de puntos</a></li>
<li class="book-part">Comunica y colabora</li>
<li><a class="" href="cap-120007-informes.html"><span class="header-section-number">44</span> Informes reproducibles con R Markdown y Quarto</a></li>
<li><a class="" href="shiny.html"><span class="header-section-number">45</span> Creación de aplicaciones web interactivas con Shiny</a></li>
<li><a class="" href="github.html"><span class="header-section-number">46</span> Git y GitHub R</a></li>
<li><a class="" href="geoproces.html"><span class="header-section-number">47</span> Geoprocesamiento en nube</a></li>
<li class="book-part">Casos de estudio en ciencia de datos</li>
<li><a class="" href="cap-crimen.html"><span class="header-section-number">48</span> Análisis de una red criminal</a></li>
<li><a class="" href="cap-publicidad.html"><span class="header-section-number">49</span> Optimización de inversiones publicitarias</a></li>
<li><a class="" href="cap-twitter.html"><span class="header-section-number">50</span> ¿Cómo tuitea Elon Musk?</a></li>
<li><a class="" href="cap-periodismo.html"><span class="header-section-number">51</span> Análisis electoral: de RStudio a su periódico favorito</a></li>
<li><a class="" href="paro-clm.html"><span class="header-section-number">52</span> El impacto de las crisis financiera y de la COVID-19 en el paro de CLM</a></li>
<li><a class="" href="cap-rfm.html"><span class="header-section-number">53</span> Segmentación de clientes en el comercio minorista</a></li>
<li><a class="" href="cap-medicina.html"><span class="header-section-number">54</span> Análisis de datos en medicina</a></li>
<li><a class="" href="cap-futbol.html"><span class="header-section-number">55</span> Messi y Ronaldo: dos ídolos desde la perspectiva de los datos</a></li>
<li><a class="" href="cambioclimatico.html"><span class="header-section-number">56</span> Una nota sobre el cambio climático</a></li>
<li><a class="" href="cap-sist-exp.html"><span class="header-section-number">57</span> Implementación de un sistema experto en el ámbito pediátrico</a></li>
<li><a class="" href="cap-ree.html"><span class="header-section-number">58</span> Predicción de consumo eléctrico con redes neuronales artificiales</a></li>
<li><a class="" href="nlp-textil.html"><span class="header-section-number">59</span> El procesamiento del lenguaje natural para tendencias de moda en textil</a></li>
<li><a class="" href="cap-fraude.html"><span class="header-section-number">60</span> Detección de fraude de tarjetas de crédito</a></li>
<li class="book-part">Appendix</li>
<li><a class="" href="info-session.html"><span class="header-section-number">A</span> Información de la sesión</a></li>
<li><a class="" href="referencias.html">Referencias</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="chap-herramientas" class="section level1" number="10">
<h1>
<span class="header-section-number">Capítulo 10</span> Herramientas para el análisis en ciencia de datos<a class="anchor" aria-label="anchor" href="#chap-herramientas"><i class="fas fa-link"></i></a>
</h1>
<p><em>José-María Montero</em><span class="math inline">\(^{a}\)</span> y <em>Jorge Velasco López</em><span class="math inline">\(^{b}\)</span></p>
<p><span class="math inline">\(^{a}\)</span>Universidad de Castilla-La Mancha<br><span class="math inline">\(^{b}\)</span>Instituto Nacional de Estadística de España</p>
<div id="introducción-5" class="section level2" number="10.1">
<h2>
<span class="header-section-number">10.1</span> Introducción<a class="anchor" aria-label="anchor" href="#introducci%C3%B3n-5"><i class="fas fa-link"></i></a>
</h2>
<p>En este capítulo se describen una serie de herramientas necesarias para desarrollar proyectos de ciencia de datos. Son herramientas que se utilizan pre o postmodelado de los datos y que aumentan significativamente el rendimiento de los modelos. Tal caja de herramientas incluye el particionado del conjunto de datos, el manejo de datos no equilibrados,<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;El término inglés &lt;em&gt;unbalanced data&lt;/em&gt; se suele traducir, en español, en lenguaje formal, por “datos no equilibrados”, si bien en la jerga de ciencia de datos, a nivel de divulgación, también se utiliza la expresión “datos desbalanceados”.&lt;/p&gt;"><sup>76</sup></a> los métodos de remuestreo, el equilibrio entre sesgo y varianza, el ajuste de hiperparámetros y la evaluación de modelos, entre otras.</p>
<p>Para ilustrar el manejo de las herramientas anteriormente mencionadas, se utiliza el conjunto de datos <code>Madrid_Sale</code> (disponible en el paquete de <strong>R</strong> <code>idealista18</code>), con datos inmobiliarios del año 2018 para el municipio de Madrid. En cuanto al software <strong>R</strong>, se utiliza <code>caret</code> <span class="citation">(<a href="referencias.html#ref-kuhn2008building">Kuhn 2008</a>)</span>, para diversas tareas de preparación de datos, y <code>rsample</code>, para muestreo.</p>
<p></p>
<p>
</p>
</div>
<div id="partición-del-conjunto-de-datos" class="section level2" number="10.2">
<h2>
<span class="header-section-number">10.2</span> Partición del conjunto de datos <a class="anchor" aria-label="anchor" href="#partici%C3%B3n-del-conjunto-de-datos"><i class="fas fa-link"></i></a>
</h2>
<p>El objetivo principal del proceso de ciencia de datos es encontrar el modelo o algoritmo que mejor resuelva la pregunta de investigación o, lo que es lo mismo, que proporcione mejores resultados. Por ejemplo, en el caso de los modelos de predicción (y en general de aquellos en los que el aprendizaje es supervisado), muy populares en la ciencia de datos, hay que encontrar el que prediga con mayor exactitud los valores futuros de la variable objetivo a partir de los predictores seleccionados en el conjunto de datos disponible. En otras palabras, un algoritmo que no solo ajuste bien los datos pasados sino, lo que es más importante, que proporcione predicciones (futuras) acertadas (y precisas). Para ello, inicialmente, se dividen los datos en dos subconjuntos:</p>
<p></p>
<ul>
<li>
<strong>de entrenamiento (<em>training</em>)</strong>: se utiliza para desarrollar conjuntos de funciones, entrenar algoritmos, ajustar hiperparámetros, comparar modelos y realizar todas las demás actividades necesarias para seleccionar un modelo final.</li>
<li>
<strong>de prueba (test)</strong>: se utiliza para validar la precisión del modelo seleccionado en la fase de entrenamiento.</li>
</ul>
<p>
</p>
<p>A la hora de dividir el conjunto de datos en los dos subconjuntos anteriores, hay que tomar dos decisiones:</p>
<ul>
<li>¿Qué porcentaje de los datos (casos, observaciones) se incluye en cada subconjunto?</li>
<li>¿Cómo se seleccionan los casos u observaciones que van a cada subconjunto?</li>
</ul>
<p>Por lo que se refiere a la primera decisión, cuanto más grande sea el subconjunto de entrenamiento, mejor será el predictor (o clasificador), aunque las mejoras serán cada vez más
pequeñas. Por el contrario, cuanto más grande sea el subconjunto de prueba o test, más precisa será
la estimación del error de predicción. En otros términos, lo ideal sería tener un conjunto de datos muy grande y que ambos subconjuntos fueran grandes. De esta manera, los errores de predicción serían pequeños y tendrían poca variabilidad. Sin embargo, con frecuencia, este no es el caso en la práctica, y el dilema es elegir un buen predictor (o clasificador) o una buena estimación del error de predicción. En la práctica, lo más frecuente es incluir
el 70% de los datos en el subconjunto de entrenamiento y el 30% restante en el de test, aunque los repartos 80% - 20% y 60% - 40% también son muy populares.</p>
<p>En cuanto a la segunda decisión, la respuesta es: mediante métodos de muestreo, siendo los más utilizados el muestreo aleatorio simple y el muestreo aleatorio estratificado (véase Cap. <a href="Fundainfer.html#Fundainfer">13</a>).</p>
<div id="muestreo-aleatorio-simple" class="section level3" number="10.2.1">
<h3>
<span class="header-section-number">10.2.1</span> Muestreo aleatorio simple <a class="anchor" aria-label="anchor" href="#muestreo-aleatorio-simple"><i class="fas fa-link"></i></a>
</h3>
<p>La forma más sencilla de asignar los datos a los subconjuntos de entrenamiento y prueba es tomar una <strong>muestra aleatoria simple</strong> (m.a.s.) (véase Sec. <a href="Fundainfer.html#mas">13.2</a>) del conjunto de casos u observaciones del tamaño deseado, y asignarlos al subconjunto de entrenamiento, asignándose los restantes al conjunto de test.</p>
<p></p>
<p>Un problema que puede surgir con las m.a.s. es que, cuando el conjunto de datos es pequeño y los valores de uno (o más) de los predictores están muy desequilibrados (por ejemplo, el predictor es binario y el 95% de sus valores pertenecen a una clase o categoría y el 5% restante a la otra), hay una probabilidad nada desdeñable de que en alguno de los dos subconjuntos (sobre todo en el de test) dicho predictor no esté representado. Si esta circunstancia ocurriese en el conjunto de entrenamiento, algunos algoritmos darían error al aplicarlos al conjunto de test (donde habría datos de un predictor más). Si, por el contrario, ocurriese en el conjunto de test, los problemas surgirían por haber un predictor menos que en el conjunto de entrenamiento. Los problemas se agravarían si la desproporción anterior tuviese lugar en la variable objetivo.</p>
<p>A continuación, se realiza una división<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Por defecto, salvo que la variable sea categórica, la división se realiza mediante muestreo aleatorio simple; por tanto, a diferencia del caso de muestreo aleatorio estratificado, que se verá a continuación, no se indica el argumento de las funciones &lt;code&gt;training&lt;/code&gt; y &lt;code&gt;testing&lt;/code&gt;.&lt;/p&gt;"><sup>77</sup></a> 70% - 30% en el conjunto de datos <code>Madrid_Sale_num</code>, generado en el Cap. <a href="chap-feature.html#chap-feature">9</a>. Para que se pueda reproducir, se establece al principio una semilla determinada.</p>
<div class="sourceCode" id="cb124"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span> <span class="op">(</span><span class="st"><a href="https://github.com/topepo/caret/">"caret"</a></span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span> <span class="co"># para permitir reproducirlo</span></span>
<span><span class="va">index</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/caret/man/createDataPartition.html">createDataPartition</a></span><span class="op">(</span><span class="va">Madrid_Sale_num</span><span class="op">$</span><span class="va">PRICE</span>, p <span class="op">=</span> <span class="fl">0.7</span>, list <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="va">train</span> <span class="op">&lt;-</span> <span class="va">Madrid_Sale_num</span><span class="op">[</span><span class="va">index</span>, <span class="op">]</span></span>
<span><span class="va">test</span> <span class="op">&lt;-</span> <span class="va">Madrid_Sale_num</span><span class="op">[</span><span class="op">-</span><span class="va">index</span>, <span class="op">]</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">Madrid_Sale_num</span><span class="op">)</span> <span class="co"># 94815</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">train</span><span class="op">)</span> <span class="co"># 66373</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/dim.html">dim</a></span><span class="op">(</span><span class="va">test</span><span class="op">)</span> <span class="co"># 28442</span></span></code></pre></div>
<p>Como puede comprobarse, de los 94.815 datos que contiene <code>Madrid_Sale_num</code>, 66.373 (el 70%), pasan a formar parte del conjunto de entrenamiento y, el resto, 28.442, constituyen el conjunto de test.</p>
</div>
<div id="binning" class="section level3" number="10.2.2">
<h3>
<span class="header-section-number">10.2.2</span> Muestreo estratificado <a class="anchor" aria-label="anchor" href="#binning"><i class="fas fa-link"></i></a>
</h3>
<p>Si se desea controlar el muestreo para que los subconjuntos de entrenamiento y prueba tengan distribuciones similares en las clases de la variable objetivo,<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Es decir, que cada clase esté representada con, aproximadamente, las mismas proporciones en los dos subconjuntos.&lt;/p&gt;"><sup>78</sup></a> se puede usar <strong>muestreo estratificado</strong> (véase Sec. <a href="muestreo.html#muestestra">14.3</a>).<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;El muestreo estratificado también puede ser de utilidad en problemas de predicción cuando el conjunto de datos es pequeño y la distribución probabilística de la variable objetivo se desvía mucho de la normalidad.&lt;/p&gt;"><sup>79</sup></a> Sin embargo, este tipo de muestreo, estratificando por la variable objetivo, no garantiza que ocurra lo mismo con los predictores. Es decir, presenta la misma limitación que el muestreo aleatorio simple en caso de que algún (o algunos) predictores estén muy desequilibrados y se quiera garantizar que en ambos subconjuntos las clases de la variable respuesta estén representadas de forma similar. Una posible solución es la eliminación de dichos predictores (que tendrán varianza próxima a cero), si bien ello implica pérdida de información.</p>
<p>A continuación, se estratifica el conjunto de datos <code>Madrid_Sale_num_sample_bin</code> del Cap. <a href="chap-feature.html#chap-feature">9</a> por la variable objetivo (<code>price_bin</code>, el precio de venta con <em>binning</em>), que tiene cuatro categorías.</p>
<div class="sourceCode" id="cb125"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="https://rsample.tidymodels.org">"rsample"</a></span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span> <span class="co"># para permitir reproducirlo</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">Madrid_Sale_num_sample_bin</span><span class="op">$</span><span class="va">price_bin</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/base/proportions.html">prop.table</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#         0.4776    0.3062    0.1024    0.1116</span></span>
<span><span class="va">split_estrat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rsample.tidymodels.org/reference/initial_split.html">initial_split</a></span><span class="op">(</span><span class="va">Madrid_Sale_num_sample_bin</span>, prop <span class="op">=</span> <span class="fl">0.7</span>, strata <span class="op">=</span> <span class="st">"price_bin"</span><span class="op">)</span></span>
<span><span class="va">train_estrat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rsample.tidymodels.org/reference/initial_split.html">training</a></span><span class="op">(</span><span class="va">split_estrat</span><span class="op">)</span></span>
<span><span class="va">test_estrat</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rsample.tidymodels.org/reference/initial_split.html">testing</a></span><span class="op">(</span><span class="va">split_estrat</span><span class="op">)</span></span></code></pre></div>
<p>Como puede comprobarse debajo, al generar muestras aleatorias estratificadas por la variable objetivo, la distribución de estas en los subconjuntos de entrenamiento y de prueba es aproximadamente igual:</p>
<div class="sourceCode" id="cb126"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">train_estrat</span><span class="op">$</span><span class="va">price_bin</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/base/proportions.html">prop.table</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#   0.4777015 0.2913093 0.1132075 0.1177816</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/table.html">table</a></span><span class="op">(</span><span class="va">test_estrat</span><span class="op">$</span><span class="va">price_bin</span><span class="op">)</span> <span class="op">|&gt;</span> <span class="fu"><a href="https://rdrr.io/r/base/proportions.html">prop.table</a></span><span class="op">(</span><span class="op">)</span></span>
<span><span class="co">#   0.4799886 0.3061750 0.1023442 0.1114923</span></span></code></pre></div>
</div>
</div>
<div id="tecnicas" class="section level2" number="10.3">
<h2>
<span class="header-section-number">10.3</span> Técnicas para manejar datos no equilibrados <a class="anchor" aria-label="anchor" href="#tecnicas"><i class="fas fa-link"></i></a>
</h2>
<p>A menudo, los datos utilizados en determinadas áreas tienen menos del 1% de eventos raros, pero precisamente su rareza es lo que los hace “interesantes”: por ejemplo, estafas en operaciones bancarias o usuarios que hacen clic en anuncios. En otros términos, una de las clases de la variable objetivo es dominante, pero la clase minoritaria es la que presenta interés. Sin embargo, la mayoría de los algoritmos no funcionan bien con variables cuyas clases están desequilibradas <span class="citation">(<a href="#ref-kuhn2013applied"><strong>kuhn2013applied?</strong></a>)</span>. Hay varias técnicas para manejar este problema:</p>
<p>
</p>
<ul>
<li>
<strong><em>Downsampling</em></strong>:<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;También denominado &lt;em&gt;undersampling&lt;/em&gt;.&lt;/p&gt;"><sup>80</sup></a> equilibra el conjunto de datos reduciendo el tamaño de las clases abundantes para que coincida con el de la clase menos prevalente. Este método es de utilidad cuando el tamaño del conjunto de datos es suficientemente grande para ser aplicado.</li>
<li>
<strong><em>Upsampling</em></strong>:<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;También denominado &lt;em&gt;oversampling&lt;/em&gt;.&lt;/p&gt;"><sup>81</sup></a> equilibra el conjunto de datos aumentando el tamaño de las clases más raras. En lugar de deshacerse de datos de las clases abundantes, se generan nuevos datos para las clases raras mediante repetición o <em>bootstrapping</em>. Este procedimiento es de utilidad cuando no hay suficientes datos en la clase (o clases) rara.</li>
<li>
<strong>Creación de datos sintéticos</strong>: esta técnica consiste en equilibrar el conjunto de entrenamiento generando nuevos registros sintéticos, esto es, inventados, de la clase minoritaria. Existen diversos algoritmos que realizan esta tarea, siendo uno de los más conocidos la técnica de SMOTE (<em>Synthetic Minority Oversampling Technique</em>) <span class="citation">(<a href="referencias.html#ref-chawla2002smote">Chawla et al. 2002</a>)</span>.</li>
<li>
<strong>Otras técnicas</strong>: como que el algoritmo implemente mecanismos para dar mayor peso a los casos de la clase minoritaria, etc.</li>
</ul>
<p>A modo de ejemplo, a continuación se utiliza <em>downsampling</em> en el conjunto de datos <code>Madrid_Sale_num_sample_bin</code>, para mejorar la precisión del modelo, mediante el algoritmo <em>gradient-boosting</em>:</p>
<p></p>
<div class="sourceCode" id="cb127"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Se especifica que el modelo se entrene con downsampling</span></span>
<span><span class="va">ctrl</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/caret/man/trainControl.html">trainControl</a></span><span class="op">(</span></span>
<span>  method <span class="op">=</span> <span class="st">"repeatedcv"</span>, repeats <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  classProbs <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>  sampling <span class="op">=</span> <span class="st">"down"</span></span>
<span><span class="op">)</span></span>
<span><span class="va">Madrid_Sale_num_sample_bin_downsample</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/caret/man/train.html">train</a></span><span class="op">(</span><span class="va">price_bin</span> <span class="op">~</span> <span class="va">.</span>,</span>
<span>  data <span class="op">=</span> <span class="va">Madrid_Sale_num_sample_bin</span>,</span>
<span>  method <span class="op">=</span> <span class="st">"gbm"</span>,</span>
<span>  preProcess <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="st">"range"</span><span class="op">)</span>,</span>
<span>  verbose <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  trControl <span class="op">=</span> <span class="va">ctrl</span></span>
<span><span class="op">)</span></span></code></pre></div>
<p>No existe una ventaja absoluta de un método sobre otro. La aplicación de estos métodos depende del caso de uso al que se aplique y del conjunto de datos. La función de <code>caret</code> para implementar estas técnicas está en <code>?caret::trainControl())</code>.</p>
<p>Una alternativa a los métodos anteriores es la implementación de algoritmos que proporcionen un buen rendimiento con variables cuyas clases están desequilibradas, de tal manera que se refuerce el aprendizaje en la clase minoritaria. La idea detrás de esta segunda opción es incluir una penalización o un sesgo que pondere las clases de tal manera que se le dé más importancia a la predicción, clasificación, etc. correcta en la clase minoritaria <span class="citation">(para más detalles, véase <a href="referencias.html#ref-garcia2021comparativa">García Abad 2021</a>)</span>.</p>
</div>
<div id="enfoque-validacion" class="section level2" number="10.4">
<h2>
<span class="header-section-number">10.4</span> El enfoque de validación<a class="anchor" aria-label="anchor" href="#enfoque-validacion"><i class="fas fa-link"></i></a>
</h2>
<p>
</p>
<p>Anteriormente, se indicaba que los datos deben dividirse en dos subconjuntos, uno de entrenamiento y otro de prueba, y que no debía usarse el subconjunto de prueba para evaluar la exactitud del modelo durante la fase de entrenamiento. Si la exactitud de las predicciones (por ejemplo, porcentaje de casos bien clasificados en un problema de clasificación) en el conjunto de test es (además de elevada) similar a la que se obtiene en el conjunto de entrenamiento, entonces el modelo entrenado generalizará bien para otros conjuntos de datos y puede darse por bueno. En otro caso, el modelo no ha entrenado bien. Por ejemplo, si la exactitud de las predicciones en el conjunto de entrenamiento es del 80% y en el de test es del 25% o del 97%, entonces el modelo no puede darse por válido. En el caso del 97%, la diferencia de porcentajes está indicando un aprendizaje “excesivo” del conjunto de datos de entrenamiento, de tal manera que el modelo en cuestión puede proporcionar muy buenas predicciones para el conjunto de datos utilizado, pero no para nuevos datos, o conjuntos de datos (esta circunstancia se conoce como sobreajuste u <em>overfitting</em>).<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Subajuste o &lt;em&gt;underfitting&lt;/em&gt; indica la imposibilidad de identificar o de obtener resultados correctos debido a un insuficiente tamaño de muestra en el conjunto de entrenamiento, o un entrenamiento muy pobre.&lt;/p&gt;"><sup>82</sup></a></p>
<p>En el caso en el que la exactitud de las predicciones sea muy distinta en los subconjuntos de entrenamiento y test, hay varias opciones (no excluyentes) para salvar dicha circunstancia: mejorar el modelo, ajustar sus hiperparámetros, incluir más casos en el conjunto de datos, modificar el preprocesado de los datos, ver si hay desequilibrio entre las clases, analizar si las variables predictoras son o no las adecuadas, revisar el proceso de limpieza de datos… y, posteriormente, entrenar de nuevo el modelo y determinar si es o no válido. Otra opción más drástica es, simplemente, cambiar de modelo.</p>
<p>Una mejor opción sería utilizar desde el principio un enfoque de validación, que implica dividir el subconjunto de entrenamiento en dos partes: un subconjunto de entrenamiento propiamente dicho y un conjunto de <strong>validación</strong>. Así, se puede entrenar el modelo en el nuevo subconjunto de entrenamiento y estimar su exactitud en el conjunto de validación. Es importante tener claro que el subconjunto de validación no es un subconjunto que se deje aparte, como el de test, durante la fase de entrenamiento, sino que se utiliza en dicha fase.</p>
<p>
</p>
<p>En resumen, con el enfoque de validación, para dar por válido un modelo, se procede como sigue:</p>
<ul>
<li>Dividir el conjunto de datos en subconjunto de entrenamiento y subconjunto de test.</li>
<li>Dividir el subconjunto de entrenamiento en un subconjunto de entrenamiento propiamente dicho y un subconjunto de validación.</li>
<li>Entrenar el modelo con los datos del subconjunto de entrenamiento propiamente dicho.</li>
<li>Comprobar que la exactitud de las predicciones en dicho subconjunto de entrenamiento y en el de validación es similar (y aceptable para la exigencia que se requiere).</li>
<li>Realizar predicciones con el conjunto de test y comprobar que se obtiene un porcentaje de buenas predicciones aceptable para los requisitos exigidos.</li>
<li>Agregar el conjunto de test al de entrenamiento (global) y entrenar de nuevo el modelo (que será el definitivo); de esta manera se aprovecha el 100% de los datos. Este último entrenamiento debería mejorar el modelo final, aunque la única manera de comprobarlo es mediante su comportamiento en el entorno real.</li>
</ul>
<p>La limitación del enfoque de validación con un solo subconjunto de reserva (de validación) es que dicha validación puede ser muy variable y poco confiable, a menos que se esté trabajando con conjuntos de datos muy grandes <span class="citation">(<a href="referencias.html#ref-molinaro2005prediction">Molinaro, Simon, and Pfeiffer 2005</a>)</span>. Y aquí es donde entran en juego los procedimientos de validación que utilizan remuestreo. El procedimiento de validación con remuestreo más utilizado es la <strong>validación cruzada (VC)</strong> <em>k</em>-grupos (<em>k-fold cross validation</em>). También es muy popular el que utiliza remustreo por <em>bootstrapping</em>, que se abordará tras la VC de <em>k</em>-grupos.</p>
<p>
</p>
<p>Para llevar a cabo una VC <em>k</em>-grupos, se divide aleatoriamente el subconjunto de datos de entrenamiento en <span class="math inline">\(k\)</span> grupos (<em>folds</em>) de aproximadamente el mismo tamaño. El modelo se ajusta en los <span class="math inline">\(k-1\)</span> primeros grupos y el último se usa como conjunto de validación, para “validar” la bondad del modelo. A continuación, se separa el penúltimo grupo y se ajusta el modelo con los restantes, usándose el penúltimo grupo como subconjunto de validación para validar la bondad del modelo. Después se separa el antepenúltimo grupo, y así sucesivamente, hasta separar el primero. Como resultado, se obtienen <span class="math inline">\(k\)</span> conjuntos de errores, cuyo promedio (véase Sec. <a href="chap-herramientas.html#evaluation">10.7</a>) podría servir como estimación de la exactitud y precisión (o error<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;span class="citation"&gt;Boehmke and Greenwell (&lt;a href="referencias.html#ref-boehmke2019hands"&gt;2020&lt;/a&gt;)&lt;/span&gt; lo denominan error de generalización puesto que tiene lugar al “generalizar” el modelo entrenado a nuevos conjuntos de datos.&lt;/p&gt;'><sup>83</sup></a>) esperada en un conjunto de datos nuevo.</p>
<p>El procedimiento descrito puede repetirse varias veces (VC con repetición), mediante nuevas particiones aleatorias del conjunto de entrenamiento y procediendo igual que en la iteración anterior.</p>
<p>En la práctica, normalmente se usa <span class="math inline">\(k=5\)</span> o <span class="math inline">\(k=10\)</span> (las Fig. <a href="chap-herramientas.html#fig:kfold1">10.1</a> y <a href="chap-herramientas.html#fig:kfold2">10.2</a> ilustran el caso de VC 5-grupos). No existe una regla formal en cuanto al tamaño de <span class="math inline">\(k\)</span>, pero a medida que <span class="math inline">\(k\)</span> aumenta, la diferencia entre el rendimiento estimado y el real, así como entre la precisión estimada y la real que se obtendrá en el conjunto de test disminuirá. En el lado negativo de la balanza, un valor de <span class="math inline">\(k\)</span> demasiado grande puede aumentar notablemente la carga computacional y, además, no generar mejoras significativas. A este respecto, en <span class="citation">Molinaro, Simon, and Pfeiffer (<a href="referencias.html#ref-molinaro2005prediction">2005</a>)</span> se concluye que VC con <span class="math inline">\(k=10\)</span> funciona de manera similar a VC con <span class="math inline">\(k=n\)</span>, la VC más extrema, también conocida como VC “dejando uno fuera” (<em>leave one out cross validation</em>, LOOCV).</p>
<p></p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:kfold1"></span>
<img src="img/kfold1.png" alt="VC 5-grupos (i)." width="70%"><p class="caption">
Figura 10.1: VC 5-grupos (i).
</p>
</div>
<p>Y si la exactitud de las predicciones en el subconjunto de entrenamiento propiamente dicho y en el de validación es similar (y aceptable para la exigencia que se requiere):</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:kfold2"></span>
<img src="img/kfold2.png" alt="VC 5-grupos (ii)." width="70%"><p class="caption">
Figura 10.2: VC 5-grupos (ii).
</p>
</div>
<p>Aunque <span class="math inline">\(k\geq 10\)</span> contribuye a minimizar la variabilidad del error de predicción (es decir, tiende a aumentar la precisión de las predicciones), en general la VC <em>k</em>-grupos suele proporcionar mayores variabilidades que el <em>bootstrapping</em> (que se analiza a continuación); no ocurre lo mismo con el sesgo <span class="citation">(<a href="referencias.html#ref-boehmke2019hands">Boehmke and Greenwell 2020</a>)</span>. <span class="citation">Kim (<a href="referencias.html#ref-kim2009estimating">2009</a>)</span> demostró que repetir el VC <em>k</em>-grupos puede ayudar a reducir la estimación del error de generalización.</p>
<p>Una implementación del VC <em>k</em>-grupos, con tres repeticiones, utilizando el conjunto de datos <code>Madrid_Sale_num_sample_bin</code>, previa mejora de la precisión del modelo mediante <em>downsampling</em>, se llevó a cabo en la Sec. <a href="chap-herramientas.html#tecnicas">10.3</a> con la siguiente orden:</p>
<div class="sourceCode" id="cb128"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">control</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/caret/man/trainControl.html">trainControl</a></span><span class="op">(</span>method <span class="op">=</span> <span class="st">"repeatedcv"</span>, number <span class="op">=</span> <span class="fl">10</span>, repeats <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span></code></pre></div>
<!-- \textcolor{red}{YA SE QUE BRALEY BOHENKE PONE "TEST" EN SU FIGURA, PERO YO CREO QUE HABRÍA QUE PONER "VALIDACIÓN" PARA NO LLEVAR A EQUIVOCACIÓN AL LECTOR} -->
<!-- \textcolor{purple}{Jorge, no se si leiste que había cambiado esta parte: el resumen es el siguiente:} -->
<!-- \textcolor{purple}{En resumen, con el enfoque de validación, para dar por válido un modelo, se procede como sigue:VER EMAIL. NO ME COMPILA Y LO HE PUESTO COMO TEXTO OCULTO} -->
<!-- \textcolor{Purple}{1. Dividir el conjunto de datos en subconjunto de entrenamiento y subconjunto de test.} -->
<!-- \textcolor{Purple}{2. Dividir el subconjunto de entrenamiento en un subconjunto de entrenamiento propiamente dicho y un subconjunto de validación.} -->
<!-- \textcolor{Purple}{3. Entrenar el modelo con los datos del subconjunto de entrenamiento propiamente dicho.} -->
<!-- \textcolor{Purple}{4. Comprobar que la exactitud de las predicciones en dicho subconjunto de entrenamiento y en el de validación es similar (y aceptable para la exigencia que se requiere).} -->
<!-- \textcolor{Purple}{5. Realizar predicciones con el conjunto de test y comprobar que se obtiene un  porcentaje de buenas predicciones aceptable para los requisitos exigidos.} -->
<!-- {\textcolor{Purple}{6. Agregar el conjunto de test al de entrenamiento (global) y entrenar de nuevo el modelo (que será el definitivo). Así se aprovecha el 100% de los datos. Este último entrenamiento debería mejorar el modelo final, aunque la única manera de comprobarlo es mediante su comportamiento en el entorno real.} -->
<!-- \textcolor{Sepia}{En función de esto, habría que hacer dos figuras con un texto entre las dos:} -->
<!-- \textcolor{Sepia}{Fig. a: VC 5-grupos en el conjunto de entrenamiento} -->
<!-- \textcolor{Sepia}{Aquí, se divide el conjunto de entrenamiento en 'conjunto de entrenamiento propiamente dicho' y 'conjunto de validación', y en las cajitas sombreadas en naranja creo que debería poner "Validación".} -->
<!-- \textcolor{Sepia}{En la caja verde grande de la izquierda creo que habría que poner 'Conjunto de entrenamiento propiamente dicho' y, encima de las cajitas 'fold 1,... "fold ' habría que poner una caja que cubriera el ancho de todas ellas que pusiese "Conjunto de validación". En toda la figura hay que sustituir 'fold' por 'grupo'.} -->
<!-- \textcolor{Sepia}{Texto:y si la exactitud de las predicciones en el subconjunto de entrenamiento propiamente dicho y en el de validación es similar (y aceptable para la exigencia que se requiere)...} -->
<!-- \textcolor{Sepia}{Fig. b: VC 5-grupos en el conjunto de datos} -->
<!-- \textcolor{Sepia}{Aquí si valdría la figura de Bohenke con los siguientes cambios} -->
<!-- \textcolor{Sepia}{En la caja verde grande de la izquierda creo que habría que poner} -->
<!-- \textcolor{Sepia}{Encima de las cajitas 'fold 1,... "fold 5' habría que poner una caja que cubriera el ancho de todas ellas que pusiese "Conjunto de validación". En toda la figura hay que sustituir 'fold' por 'grupo'} -->
<!-- \textcolor{Sepia}{El título de la Figura total podría ser algo así como 'Enfoque de validación con VC 5-grupos'} -->
<p><em>Bootstrapping</em> es un procedimiento de muestreo aleatorio con reemplazamiento <span class="citation">(<a href="referencias.html#ref-efron1986bootstrap">Efron and Tibshirani 1986</a>)</span>. Esto significa que, después de seleccionar un dato para incluirlo en el subconjunto que sea, sigue disponible para una selección posterior. Una muestra <em>bootstrap</em> tiene el mismo tamaño que el conjunto de datos original a partir del cual se obtiene. Las observaciones originales seleccionadas (una o varias veces) en la muestra conforman el subconjunto de de entrenamiento, mientras que aquellas que no aparecen en ella (se las denomina <em>out-of-bag</em>) conforman el subconjunto de test.</p>
<p></p>
<p>La Fig. <a href="chap-herramientas.html#fig:bootstrap">10.3</a> (adaptada de <span class="citation">Boehmke and Greenwell (<a href="referencias.html#ref-boehmke2019hands">2020</a>)</span>), muestra un esquema de muestreo <em>bootstrap</em>, donde cada muestra contiene 12 observaciones, al igual que en el conjunto de datos original. Como puede observarse, el muestreo <em>bootstrap</em> lleva aproximadamente a la misma distribución de valores (representados por colores) que el conjunto de datos original.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:bootstrap"></span>
<img src="img/bootstrap.png" alt="Remuestreo $bootstrap$. Elaboración propia a partir de  Boehmke and Greenwell (2019)." width="70%"><p class="caption">
Figura 10.3: Remuestreo <span class="math inline">\(bootstrap\)</span>. Elaboración propia a partir de Boehmke and Greenwell (2019).
</p>
</div>
<p>El hecho de que <em>bootstrapping</em> replique el conjunto de observaciones implica, como se dijo anteriormente, que la variablidad del error es menor que en VC <em>k</em>-grupos. Sin embargo, dicha replicación puede aumentar el sesgo de la estimación de dicho error. Esto puede ser un problema con conjuntos de datos muy pequeños, pero no para la mayoría de los conjuntos de datos, que suelen ser de tamaño medio o grande (por ejemplo, <span class="math inline">\(n \geq 1000\)</span>).</p>
<p></p>
<p>Las muestras <em>bootstrap</em> pueden crearse fácilmente con <code><a href="https://rsample.tidymodels.org/reference/bootstraps.html">rsample::bootstraps()</a></code>, como se ilustra a continuación.</p>
<div class="sourceCode" id="cb129"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rsample.tidymodels.org/reference/bootstraps.html">bootstraps</a></span><span class="op">(</span><span class="va">Madrid_Sale_num_sample_bin</span>, times <span class="op">=</span> <span class="fl">10</span><span class="op">)</span></span></code></pre></div>
<p>Si se usa la función <code><a href="https://rdrr.io/pkg/caret/man/trainControl.html">trainControl()</a></code>, se debe especificar: <code>method = "boot"</code>.</p>
</div>
<div id="compensacion" class="section level2" number="10.5">
<h2>
<span class="header-section-number">10.5</span> Compensación (<em>trade off</em>) entre sesgo y varianza<a class="anchor" aria-label="anchor" href="#compensacion"><i class="fas fa-link"></i></a>
</h2>
<p>En el entorno predictivo, el objetivo es que el error de predicción, en términos generales o por término medio, sea lo más pequeño posible. Sin embargo, no se pueden promediar los errores porque se compensarían los positivos con los negativos. Por ello, se promedian elevados al cuadrado (considerando solo su magnitud), denominándose dicho promedio “error cuadrático medio”, ECM (en este caso, de predicción): <span class="math inline">\(E(y_j- \hat y_j)^2\)</span> en términos probabilísticos, o <span class="math inline">\(\sum _{j=1}^ {N}(y_j- \hat y_j)^2 \frac {n_j}{N}\)</span> en términos descriptivos. Pues bien, el ECM se puede descomponer como suma de dos componentes:</p>
<p>
</p>
<ul>
<li>Uno debido a la diferencia entre el valor correcto de la variable objetivo o respuesta y el que se espera que proporcione el modelo. Dicha diferencia se denomina sesgo (en ingés, <em>bias</em>), y aparece elevado al cuadrado en dicha descomposición.</li>
<li>Otro debido a que, dado un conjunto de valores de las variables predictoras, la respuesta del modelo no es siempre la misma. Esta variabilidad aparece en la descomposición en forma de varianza, y por ello se denomina varianza del error de predicción o, simplemente, varianza de predicción.</li>
</ul>
<p>Lógicamente, el incremento/reducción de uno de los componentes implica la reducción/incremento del otro.</p>
<!-- Los errores de predicción pueden descomponerse en el error debido al **sesgo** (*bias*)  y el error debido a la **varianza** y, a menudo, existe un equilibrio entre la capacidad de un modelo para minimizar ambos. Comprender cómo las distintas fuentes de error conducen al sesgo y la varianza, ayuda a mejorar el proceso de ajuste de los datos, lo que da lugar a modelos más precisos.  -->
<!-- El **error debido al sesgo** de un modelo es la diferencia entre el valor esperado del estimador (es decir, la predicción media del modelo) y el valor real.  -->
<p>Un sesgo muy elevado es un indicador de que el modelo es muy simple y no ha ajustado bien los datos de entrenamiento (<em>underfitting</em>), lo cual se traduce en errores de predicción elevados. Una varianza de predicción elevada (es decir, pequeños cambios en los datos de entrada que producen salidas muy distintas), es un signo de complejidad en el modelo y sobreajuste (<em>overfitting</em>) de los datos de entrenamiento.</p>
<p>
</p>
<p>Los algoritmos con tendencia a un elevado porcentaje del ECM debido al sesgo tienen, lógicamente, un porcentaje del ECM debido a la varianza de predicción pequeño; es decir, tienen los problemas que se derivan del infraajuste de los datos: malas predicciones (sesgadas) y, encima, muy precisas. Y al contrario, aquellos que tienen un porcentaje del ECM debido al sesgo pequeño, tienen un porcentaje del ECM por varianza de predicción elevado.</p>
<p>Los modelos lineales (regresión lineal, análisis discriminante lineal, regresión logística…) suelen tener errores por sesgo elevados.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Sin embargo, rara vez se ven afectados por el error introducido en el remuestreo.&lt;/p&gt;"><sup>84</sup></a> Modelos como los árboles de decisión, el <em>k</em>-vecinos más cercanos y los <em>support vector machine</em> tienen errores por sesgo pequeños (y, por tanto, varianza de predicción grande, siempre en relación al ECM total), son muy adaptables y ofrecen una flexibilidad extrema en cuanto a los patrones a los que pueden ajustarse. Sin embargo, plantean sus propios problemas, especialmente el de sobreajuste de los datos de entrenamiento, cuya consecuencia es que el modelo no se generalizará bien con datos nuevos.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Por ello, el remuestreo es clave para reducir este riesgo.&lt;/p&gt;"><sup>85</sup></a></p>
<p></p>
<p>Lógicamente, el modelo predictivo o clasificador deseado es el que tenga el menor ECM posible.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Sin embargo, hay una parte del ECM que no se puede reducir: aquel que se debe a la aleatoriedad, o a la no inclusión en el modelo de variables relevantes, entre otras.&lt;/p&gt;"><sup>86</sup></a> Si este no fuera el caso, habría que encontrar la combinación sesgo cuadrático-varianza de predicción que minimizase el ECM. La Fig. <a href="chap-herramientas.html#fig:tradeoff">10.4</a> se ha generado a partir de datos sintéticos de sesgo (al cuadrado) y varianza de predicción. En ella se puede apreciar que el valor mínimo del ECM es la suma de los valores del sesgo cuadrático y varianza de predicción determinados por la línea vertical amarilla.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:tradeoff"></span>
<img src="img/tradeoff.png" alt="Trade off entre sesgo y varianza." width="60%"><p class="caption">
Figura 10.4: Trade off entre sesgo y varianza.
</p>
</div>
</div>
<div id="ajuste-de-hiperparámetros" class="section level2" number="10.6">
<h2>
<span class="header-section-number">10.6</span> Ajuste de hiperparámetros<a class="anchor" aria-label="anchor" href="#ajuste-de-hiperpar%C3%A1metros"><i class="fas fa-link"></i></a>
</h2>
<p></p>
<p>Los denominados “hiperparámetros” de un modelo son los valores de las configuraciones utilizadas durante el proceso de entrenamiento. A diferencia de los parámetros, son valores que no se obtienen a partir de los datos, sino que los propone el científico de datos. Podría decirse que son conjeturas (buenas conjeturas) realizadas sin utilizar las observaciones disponibles.</p>
<p>Los hiperparámetros, a diferencia de los parámetros, se fijan antes del entrenamiento. Siendo más específicos, al entrenar un modelo de aprendizaje automático se fijan los valores de los hiperparámetros para que con estos se estimen los parámetros. Podría decirse que son los ajustes del modelo para que este pueda resolver de manera óptima el problema de aprendizaje automático.</p>
<p>Algunos ejemplos de hiperparámetros utilizados para entrenar los modelos son la ratio de aprendizaje en el algoritmo del descenso del gradiente, el número de vecinos en el algoritmo de <em>k</em>-vecinos más cercanos, la profundidad máxima en un árbol de decisión, el número de árboles en un bosque aleatorio (<em>random forest</em>)… Como puede apreciarse, sirven para controlar la complejidad de los algoritmos de aprendizaje automático y, por tanto, la compensación entre sesgo y varianza.</p>
<p>En conclusión, hiperparámetros y parámetros son conceptos bien diferentes.</p>
<p>A la luz de la definición de hiperparámetro, lo natural sería que el científico de datos lo fijase de acuerdo con su experiencia en el pasado en problemas similares, asignándole los mismos, o parecidos, valores. Sin embargo, existen métodos más sofisticados para resolver el problema de la “optimización de hiperparámetros”, es decir, de la obtención del conjunto óptimo de valores de los mismos que proporciona la configuración que, tras el entrenamiento, dará lugar a los mejores resultados. Entre estos procedimientos cabe destacar los siguientes por ser los que incorporan los algoritmos más populares:</p>
<ul>
<li><p>Optimización bayesiana: utiliza la moda para elegir qué hiperparámetros considerar, en función del rendimiento de las elecciones anteriores.</p></li>
<li><p>Búsqueda en cuadrícula (<em>grid search</em>): prueba con todas las combinaciones posibles de la cuadrícula.</p></li>
<li><p>Búsqueda aleatoria: muestrea y evalúa aleatoriamente conjuntos de una distribución de probabilidad específica.</p></li>
<li><p>Optimización secuencial basada en modelos: son una formalización de la optimización bayesiana.</p></li>
</ul>
<p>A modo de ejemplo, los dos hiperparámetros que más influencia tienen en un modelo de <em>random forest</em> (véase Cap. <a href="cap-bagg-rf.html#cap-bagg-rf">28</a>) son <code>mtry</code> (número de variables muestreadas aleatoriamente como candidatas en cada <em>split</em>) y <code>ntree</code> (número de
árboles). Pues bien, a continuación, como viene siendo habitual, se utiliza el conjunto de datos <code>Madrid_Sale_num_sample_bin</code> para buscar el valor óptimo de <code>mtry</code> mediante la técnica de búsqueda en cuadrícula; se usa la métrica <code>Accuracy</code> (exactitud), que hace referencia a la proporción de predicciones correctas, véase Sec. <a href="chap-herramientas.html#evaluation">10.7</a>.</p>
<div class="sourceCode" id="cb130"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">control</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/caret/man/trainControl.html">trainControl</a></span><span class="op">(</span>method <span class="op">=</span> <span class="st">"repeatedcv"</span>, number <span class="op">=</span> <span class="fl">10</span>, repeats <span class="op">=</span> <span class="fl">3</span><span class="op">)</span></span>
<span><span class="va">seed</span> <span class="op">&lt;-</span> <span class="fl">7</span></span>
<span><span class="va">metrica</span> <span class="op">&lt;-</span> <span class="st">"Accuracy"</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="va">seed</span><span class="op">)</span></span>
<span><span class="va">mtry</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/nrow.html">ncol</a></span><span class="op">(</span><span class="va">Madrid_Sale_num_sample_bin</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">tunegrid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html">expand.grid</a></span><span class="op">(</span>.mtry <span class="op">=</span> <span class="va">mtry</span><span class="op">)</span></span></code></pre></div>
<div class="infobox">
<p><strong>Nota</strong></p>
<p>La implementación del algoritmo de <em>random forest</em> del paquete <code>randomForest</code> proporciona la función <code>tuneRF()</code>, que busca valores <code>mtry</code> óptimos dados los datos disponibles.</p>
</div>
<p>Se entrena el modelo y se observa que la mayor exactitud, 68,76%, se obtiene con un <code>mtree</code> de 2,449489.</p>
<div class="sourceCode" id="cb131"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">rf_default</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/caret/man/train.html">train</a></span><span class="op">(</span><span class="va">price_bin</span> <span class="op">~</span> <span class="va">.</span>, data <span class="op">=</span> <span class="va">Madrid_Sale_num_sample_bin</span>, method <span class="op">=</span> <span class="st">"rf"</span>, metric <span class="op">=</span> <span class="va">metrica</span>, tuneGrid <span class="op">=</span> <span class="va">tunegrid</span>, trControl <span class="op">=</span> <span class="va">control</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">rf_default</span><span class="op">)</span></span>
<span><span class="co"># Accuracy   </span></span>
<span><span class="co"># 0.6876006  </span></span></code></pre></div>
</div>
<div id="evaluation" class="section level2" number="10.7">
<h2>
<span class="header-section-number">10.7</span> Evaluación de modelos<a class="anchor" aria-label="anchor" href="#evaluation"><i class="fas fa-link"></i></a>
</h2>
<!-- Tradicionalmente, el rendimiento de los modelos estadísticos se basaba en gran medida en pruebas de **bondad de ajuste** y **evaluación de residuos**. Desafortunadamente, pueden derivarse conclusiones equívocas de los modelos predictivos que pasan este tipo de evaluaciones.  -->
<!-- En la actualidad, para analizar el rendimiento del modelo, se suele evaluar la precisión predictiva a través de funciones de pérdida (*loss functions*). Las funciones de pérdida son métricas que comparan los valores predichos con el valor real. -->
<!-- Al realizar métodos de remuestreo, se evalúan los valores pronosticados para un conjunto de validación respecto al valor objetivo real. Por ejemplo, en la regresión, una forma de medir el error es tomar la diferencia entre el valor real y el predicho para una observación determinada (esta es la definición habitual de residuo en la regresión lineal ordinaria). El error de validación general del modelo, se calcula agregando los errores en todo el conjunto de datos de validación. -->
<p>La última fase del proceso de modelización contesta a las preguntas: ¿Cómo de bueno es el modelo entrenado? ¿Cómo de bien generaliza los (buenos) resultados obtenidos en la fase de entrenamiento a nuevos conjuntos de datos (datos <em>out-of-sample</em>)? Por ello, en este epígrafe se presentan las métricas más populares de rendimiento de modelos en los entornos de regresión (predicción) y clasificación.</p>
<p>En el entorno de regresión, es prácticamente imposible predecir valores exactos, y hay que conformarse con muy buenas aproximaciones a dichos valores exactos, por lo que las métricas que se utilizan para medir la bondad del modelo entrenado suelen estar basadas en la diferencia entre los valores reales y los que predice el modelo, es decir, en los errores de predicción. La medida natural sería la media de los errores de predicción, pero, para evitar la compensación de los errores positivos con los negativos, y puesto que el interés se centra en la magnitud de los errores y no en su signo, las métricas de evaluación más populares en el entorno de regresión son:</p>
<p>
</p>
<ul>
<li><p><strong>Error cuadrático medio (ECM)</strong>: es la más utilizada en tareas de regresión. Como se avanzó en la Sec. <a href="chap-herramientas.html#compensacion">10.5</a>, se define como la media de las diferencias cuadráticas de entre los valores objetivo (<span class="math inline">\(y_j\)</span>) y los predichos por el modelo (<span class="math inline">\(\hat{y}_i\)</span>), evitando así la compensación de errores positivos y negativos. Su expresión es, por tanto, <span class="math inline">\(ECM=\frac{1}{n}\sum_{i=1}^{n}(y_i-\hat{y}_i)^2\)</span>. Al considerar los errores de predicción al cuadrado, exacerba los errores grandes, por lo que hay que utilizar esta métrica con cuidado cuando se tengan valores anómalos en el conjunto de datos y no hayan sido tratados en las fases previas a la modelización y validación. En ese caso, incluso un modelo cuasiperfecto podría tener un ECM elevado. Si todos los errores son inferiores a la unidad hay un riesgo elevado de subestimar lo malo que es el modelo (en caso de que lo fuese).</p></li>
<li><p><strong>Error absoluto medio (EAM)</strong>: es una alternativa al ECM que se define como la media del valor absoluto de los errores de predicción (para evitar compensaciones): <span class="math inline">\(EAM=\frac{1}{n}\sum_{i=1}^{n}|y_i-\hat{y}_i|\)</span>. Al no elevar al cuadrado, no magnifica los errores grandes, por lo que es menos sensible que el ECM a valores anómalos, si bien tampoco es recomendable en caso de que estos no hayan sido tratados previamente. Una ventaja que tiene es que su unidad de medida es la misma que la de la variable objetivo.</p></li>
<li><p><strong>Raíz cuadrada del error cuadrático medio (RECM)</strong>: “deshace”, no en un sentido matemático, sino aproximadamente, la elevación al cuadrado de los errores en el ECM y, por consiguiente, viene dada en las mismas unidades que la salida del modelo, lo que la hace más interpretable. Su expresión es: <span class="math inline">\(RECM=+\sqrt{\frac{1}{n}\sum_{i=1}^{n}(y_i-\hat{y}_i)^2}\)</span>.</p></li>
<li><p><strong>Coeficiente de determinación (<span class="math inline">\(\bf R^2\)</span>)</strong>: se define como <span class="math inline">\(R^2=1-\frac{\sum_{i=1}^{n}(y_i-\hat y_i)^2}{\sum_{i=1}^{n}(y_i-\bar y)^2}\)</span> <span class="citation">(véanse detalles adicionales en el Cap. 5 de <a href="referencias.html#ref-lorenzo2007estadistica">José María Montero 2007</a>)</span> y su campo de variación es [<span class="math inline">\(-\infty\)</span>, 1]. En la práctica totalidad de las situaciones reales toma valores entre 0 y 1, puesto que solo toma valores negativos cuando el modelo entrenado sea muy deficiente y prediga peor que cuando se establece como predicción la media de las salidas observadas, sean cuales sean los valores de los predictores. Obviando estas situaciones, y aquellas en las que la varianza de la variable de salida no se pueda descomponer en varianza debida al modelo y varianza debida al error (por ejemplo, en el caso de una regresión potencial),<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;En estos casos es mejor utilizar otra métrica, como el ECM.&lt;/p&gt;"><sup>87</sup></a> <span class="math inline">\(R^2\)</span> se puede interpretar como la reducción proporcional en el ECM que tiene lugar al predecir las salidas del modelo mediante los predictores (cualquiera que sea la función que los ligue con la salida) en vez de mediante la media de la variable <em>output</em> (que es la predicción óptima en ausencia de predictores). Mide, por tanto, lo bueno que es disponer de predictores para predecir los valores de la variable <em>output</em> o de salida; o, en otros términos, el porcentaje de varianza de la variable salida que explican los predictores a través del modelo que liga a ambos. Cuanto más cercano esté a la unidad, mejor es el modelo a efectos predictivos.</p></li>
</ul>
<ul>
<li><p><strong>Coeficiente de determinación ajustado (<span class="math inline">\(\bf R_{ajd}^2)\)</span></strong>: una limitación importante del <span class="math inline">\(R^2\)</span> es que su valor puede aumentarse artificialmente mediante la inclusión de más y más variables predictoras, pues la inclusión de las mismas o mantiene o mejora dicha métrica. Esta circunstancia puede dar lugar a confusión, pues el hecho de que un modelo utilice más variables predictoras que otro no quiere decir que sea mejor. El <span class="math inline">\(R_{ajd}^2\)</span> corrige dicha circunstancia penalizando la complejidad del modelo, entendiéndose que un modelo es más complejo que otro si utiliza un mayor número de variables predictoras que ese otro. Su expresión viene dada por <span class="math inline">\(R_{ajd}^2=1-\left(\frac{n-1}{n-p-1}\right)\left(1-R^2\right)\)</span>, y su valor nunca supera el del <span class="math inline">\(R^2\)</span>.</p></li>
<li><p><strong><em>Deviance</em></strong>: es una métrica relacionada con la estimación de modelos (especialmente modelos lineales generalizados) por el método de la máxima verosimilitud. Compara, por cociente, la verosimilitud del modelo estimado con la del modelo saturado (aquel que tiene tantos parámetros como observaciones<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Por tanto, pasa por todas ellas.&lt;/p&gt;"><sup>88</sup></a> y que, por tanto, tiene la máxima verosimilitud alcanzable). Mide el grado en el que un modelo explica la variabilidad en un conjunto de datos cuando se utiliza la estimación de máxima verosimilitud. En términos de log-verosimilitud (<span class="math inline">\(l\)</span>) se define como <span class="math inline">\(D=2(l_{Modelo \hspace{0,1cm} saturado}-l_{Modelo \hspace{0,1cm} propuesto})\)</span>, y, lógicamente, cuanto menor es la <em>deviance</em>, mejor es el modelo.</p></li>
</ul>
<ul>
<li>
<strong>Raíz del error logarítmico cuadrático medio (RELCM)</strong>: similar a RMSE, pero tomando logaritmos en los valores reales y predichos. De especial interés cuando lo que importa es la magnitud relativa (porcentual) de los errores. No se puede utilizar cuando la variable objetivo toma valores negativos. Para salvar la problemática de que la variable objetivo tome el valor cero, generalmente se agrega una constante a los valores reales y predichos de la variable salida antes de aplicar la operación logarítmica. Dependiendo del problema, se puede elegir otro tipo de constante. Su expresión viene dada por: <span class="math inline">\(RMSLE=\sqrt{\frac{1}{n}(log(y_i+1)-log(\hat{y}_i+1))^2)}\)</span>.</li>
</ul>
<p>
</p>
<p>En este manual se usan estas medidas en repetidas ocasiones. Por ejemplo, en el Cap. <a href="cap-sparse.html#cap-sparse">19</a> se ajusta la regresión <em>ridge</em> en el subconjunto de entrenamiento y se evalúa su ECM en el subconjunto de test.</p>
<div class="sourceCode" id="cb132"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">ridge_pred</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/predict.html">predict</a></span><span class="op">(</span><span class="va">ridge.mod</span>, s <span class="op">=</span> <span class="fl">1e10</span>, newx <span class="op">=</span> <span class="va">x</span><span class="op">[</span><span class="va">test</span>, <span class="op">]</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/mean.html">mean</a></span><span class="op">(</span><span class="op">(</span><span class="va">ridge_pred</span> <span class="op">-</span> <span class="va">y.test</span><span class="op">)</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<p>En el entorno clasificatorio, las salidas del modelo pueden ser de clase (tal es el caso de los algoritmos de máquinas de vectores soporte y <em>k</em>-vecinos más cercanos, por ejemplo) o de probabilidad (caso de la regresión logística, los bosques aleatorios, el AdaBoost…). Dado que pasar de salidas probabilísticas a salidas de clase consiste únicamente en fijar umbrales de probabilidad, y que algunos algoritmos ya proporcionan el paso de salidas de clase a salidas probabilísticas, en lo que sigue no se hará distinción entre ellas.</p>
<p>En dicho entorno clasificatorio, es muy frecuente el uso de la <strong>matriz de confusión</strong>, que compara las clases (niveles categóricos) reales con las predichas en el subconjunto de test (cuyos resultados se conocen). La Fig. <a href="chap-herramientas.html#fig:iris-mat-con">10.5</a> muestra un ejemplo de clasificación multiclase (en concreto, 3 clases) basado en el famoso conjunto de datos “Flor iris” de Fisher, que considera tres especies (<em>Iris setosa</em>, <em>Iris virginica</em> e <em>Iris versicolor</em>). La predicción de la clase a la que pertenece una flor se hace en función del largo y el ancho del sépalo y del pétalo.</p>
<p>En la diagonal ascendente figura el número de flores, de cada color, cuya clase ha sido correctamente predicha. Los elementos fuera de dicha diagonal indican las flores, de cada clase, que el clasificador utilizado ha clasificado erróneamente. Como puede apreciarse, 47 de las 50 flores iris que se consideran fueron bien clasificadas. Sin embargo, dicho clasificador clasificó una flor versicolor como virgínica, y dos virgínicas como versicolores.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:iris-mat-con"></span>
<img src="img/iris_mat_confusion.png" alt="Matriz de confusión con tres clases." width="60%"><p class="caption">
Figura 10.5: Matriz de confusión con tres clases.
</p>
</div>
<p>Aunque el concepto de matriz de confusión es muy sencillo, la terminología que lo rodea no lo es tanto; incluso podría decirse que es confusa. La predicción proporcionada por el modelo puede ser (véase Fig. <a href="chap-herramientas.html#fig:matrizconfusion2">10.6</a>):</p>
<ul>
<li>Un verdadero positivo (VP): predicción de verdadero y verdadero en realidad.</li>
<li>Un verdadero negativo (VN): predicción de falso y falso en realidad.</li>
<li>Un falso positivo (FP): predicción de verdadero y falso en la realidad.</li>
<li>Un falso negativo (FN): predicción de falso y verdadero en la realidad.</li>
</ul>
<p>
</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:matrizconfusion2"></span>
<img src="img/Mat_Confusion.png" alt="Terminología de una matriz de confusión." width="70%"><p class="caption">
Figura 10.6: Terminología de una matriz de confusión.
</p>
</div>
<p>Como se avanzó anteriormente, esta terminología es confusa y, por ello, se ilustra a continuación con un ejemplo. Supóngase que se está interesado en conocer si un determinado tratamiento médico tiene efectos positivos sobre una enfermedad. Echando mano de la teoría de la contrastación de hipótesis (véase Sec. <a href="Fundainfer.html#contrhip">13.5</a>), supóngase que se toma como hipótesis nula (<span class="math inline">\(H_0\)</span>): SÍ y como hipótesis alternativa (<span class="math inline">\(H_1\)</span>): NO. Pues bien:</p>
<ul>
<li>Si es cierto que el tratamiento en cuestión tiene un efecto positivo en la enfermedad y el modelo no rechaza la hipótesis nula, se tiene un VP.</li>
<li>Si la hipótesis nula es falsa, es decir, si el tratamiento no tiene un efecto positivo sobre la enfermedad, y el modelo rechaza la hipótesis nula, entonces se tiene un VN.</li>
<li>Si la hipótesis nula es falsa y el modelo concluye que no se rechaza la hipótesis nula de que el tratamiento cura la enfermedad, entonces se tiene un FP.</li>
<li>Si es cierto que el tratamiento tiene un efecto positivo en la enfermedad y el modelo rechaza la hipótesis nula, se tiene un FN.
</li>
</ul>
<p>Las siguientes medidas se pueden calcular a partir de una matriz de confusión (es decir, a partir del número de VP, VN, FP y FN) para un clasificador binario:</p>
<p> </p>
<ul>
<li><p><strong>Exactitud</strong>. Es la proporción de predicciones correctas: <span class="math inline">\(Exactitud=\frac{VP+VN}{Total}\)</span>. Responde a la pregunta: ¿Con qué frecuencia funciona correctamente el clasificador? Lógicamente, la tasa de clasificación errónea se obtiene como <span class="math inline">\(\frac{FP+FN}{Total}\)</span>. En caso de desequilibrio notable de clase, por ejemplo, la clase A contiene 999 casos y la B tan solo 1, siendo B la clase rara, la clase positiva, la precisión no sería una métrica fiable para evaluar el rendimiento clasificatorio del modelo. Por ejemplo, el clasificador podría consistir en una regla que dijese que todos los casos pertenecen a la clase A, ¡y acertaría en el 99,9% de los casos! En estos casos, sería mejor utilizar como métricas la precisión y la sensibilidad.</p></li>
<li><p><strong>Precisión</strong>. Da respuesta a la pregunta: cuando el clasificador predice “SÍ”, ¿con qué frecuencia predice correctamente? Su expresión viene dada por: <span class="math inline">\(Precisión=\frac{VP}{VP+FP}\)</span>.</p></li>
<li><p><strong>Sensibilidad</strong>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;A veces denominada “exhaustividad”.&lt;/p&gt;"><sup>89</sup></a> Restringe el denominador de la precisión a los SÍ reales. Responde a la pregunta: ¿cuando en realidad es un SÍ, cuál es el porcentaje de aciertos del clasificador? Su expresión es <span class="math inline">\(Sensibilidad=\frac{VP}{VP+FN}\)</span>. Por consiguiente, la sensibilidad es una medida de la probabilidad de que un caso real positivo se clasifique como positivo.</p></li>
</ul>
<ul>
<li><p><strong>Especificidad</strong>. Se define como <span class="math inline">\(Especificidad=\frac{VN}{FP+VN}\)</span>. Es, por tanto, el porcentaje de verdaderos negativos respecto de todo lo que debería haber sido clasificado como negativo. Su complementario, la 1-especificidad (<span class="math inline">\(\frac{FP}{FP+VN}\)</span>) es, básicamente, una medida de la frecuencia (relativa) con la que se producirá una falsa alarma, o la frecuencia con la que un caso real negativo se clasifique como positivo.</p></li>
<li><p><strong>Puntuación F1</strong>. Es la media armónica de la precisión y la sensibilidad. Su campo de variación es [0, 1], donde 0 indica falta total de precisión y sensibilidad y 1 significa precisión y sensibilidad perfectas. La puntuación F1 penaliza los valores extremos y se suele utilizar en caso de conjuntos de datos desequilibrados. </p></li>
<li><p><strong>Área bajo la curva de características operativas del receptor (área bajo la curva ROC)</strong>. Al graficar la sensibilidad (tasa de verdaderos positivos) frente a la tasa de falsos positivos (también denominada 1-especificidad), se obtiene la curva ROC. La diagonal ascendente representa la aleatoriedad. Cuanto más grande sea el área bajo la curva ROC, mejor será la precisión obtenida. Es una medida recomendable en el caso de clases desequilibradas. Un ejemplo de área bajo la curva ROC puede verse en el Cap. <a href="cap-glm.html#cap-glm">16</a>, y se reproduce en la parte derecha de la Fig. <a href="chap-herramientas.html#fig:roc3bis">10.7</a>.</p></li>
</ul>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:roc3bis"></span>
<img src="img/roc3bis.png" alt="Ejemplo de curva ROC a partir de la estimación de un modelo lineal generalizado (parte derecha)." width="70%"><p class="caption">
Figura 10.7: Ejemplo de curva ROC a partir de la estimación de un modelo lineal generalizado (parte derecha).
</p>
</div>
<ul>
<li><p><strong>Índice de Gini</strong>. Bien conocido en la literatura estadística sobre concentración, se trata de un indicador útil en el caso de clases desequilibradas. Su campo de variación es [0, 1], donde 0 representa la igualdad perfecta y 1 la concentración en una única clase. Puede calcularse a partir del área bajo la curva ROC de la siguiente manera: <span class="math inline">\(IG=2\hspace{0,1cm} \acute{A}rea\hspace{0,1cm} bajo \hspace{0,1cm} la\hspace{0,1cm}curva\hspace{0,1cm} ROC-1\)</span>. En caso de IG = 0, el área bajo la curva ROC es 1/2 y la curva ROC coincide con la diagonal ascendente. En caso de IG = 1, el área bajo la curva ROC será 0 y dicha curva vale 0 para todos los valores del eje de abscisas, excepto para el último, para el cual vale 1. En caso de que las observaciones no se vayan acumulando de una en una para la configuración de la curva bajo ROC, o para el cálculo directo del índice de Gini, es mejor utilizar una versión del mismo denominada “índice E” <span class="citation">(IE, véase Cap. 3 de <a href="referencias.html#ref-lorenzo2007estadistica">José María Montero 2007</a>)</span>, pues el índice de Gini tan solo proporcionará una aproximación de la concentración existente; buena aproximación, pero aproximación.</p></li>
<li><p><strong>Índice de Jaccard</strong>. Mide las similitudes entre el conjunto clases reales y predichas por el clasificador. Se define como el cociente entre el número de coincidencias en los conjuntos real y predicho (clases predichas correctamente) y el tamaño de la unión de los dos conjuntos (el doble del número de clases a etiquetar menos el número de clases predichas correctamente): <span class="math inline">\(I_{Jaccard}=\frac{VP+VN}{2Total-(Fp+FN)}\)</span>.</p></li>
</ul>
<p>Otras medidas de interés son la pérdida logarítmica, el coeficiente de correlación de Matthews, el gráfico de Kolmogorov-Smirnov y el gráfico de ganancia y elevación. Estas, entre otras, pueden verse en <span class="citation">Dembla (<a href="referencias.html#ref-dembla2020intuition">2020</a>)</span>, <span class="citation">Hernández-Orallo, Flach, and Ferri (<a href="referencias.html#ref-hernandez2011brier">2011</a>)</span> y <span class="citation">Vujović (<a href="referencias.html#ref-vujovic2021classification">2021</a>)</span>, entre otros.</p>
<p>Con tantas métricas, ¿cómo decidir entre ellas? Será el conocimiento de la problemática que se esté estudiando (el negocio) el que normalmente guíe la elección de la métrica: si se trata de un problema de predicción de la producción de un determinado bien cuyo coste de almacenaje es elevado, lo más prudente sería utilizar el ECM para penalizar la sobreproducción; si lo que interesa son valores altos de la precisión y la sensibilidad (tal es el caso en numerosas situaciones del ámbito sanitario), la mejor medida sería la puntuación F1. No obstante, se habrá de tener siempre en cuenta que la exactitud, la precisión, la sensibilidad, la especificidad y el índice de Jaccard son buenas formas de evaluar clasificadores cuando las clases están equilibradas. En caso contrario, el área bajo la curva ROC y el IG (o el IE) son dos buenas alternativas.</p>
<div id="resumen-9" class="section level3 unnumbered infobox_resume">
<h3>Resumen<a class="anchor" aria-label="anchor" href="#resumen-9"><i class="fas fa-link"></i></a>
</h3>
<ul>
<li><p>En este capítulo se describen una serie de herramientas necesarias para desarrollar proyectos de ciencia de datos. Son herramientas que se utilizan se utilizan pre o postmodelado de los datos y que aumentan significativamente el rendimiento de los modelos. Tal caja de herramientas incluye el particionado del conjunto de datos, el manejo de datos no equilibrados, los métodos de remuestreo, el equilibrio entre sesgo y varianza, el ajuste de hiperparámetros y la evaluación de modelos, entre otras.</p></li>
<li><p>Se hace especial hincapié en las métricas para evaluar modelos, tanto en el entorno de regresión como en el de clasificación, y, en ambos casos, se ofrece un amplio abanico de ellas.</p></li>
<li><p>A efectos ilustrativos, se utilizan, fundamentalmente, el paquete <code>caret</code> y conjuntos de datos derivados del dataset <code>Madrid_Sale</code>.</p></li>
</ul>
</div>

</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="chap-feature.html"><span class="header-section-number">9</span> Selección y transformación de variables</a></div>
<div class="next"><a href="cap-120006-aed.html"><span class="header-section-number">11</span> Análisis exploratorio de datos</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="Índice del capítulo"><h2>Índice del capítulo</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#chap-herramientas"><span class="header-section-number">10</span> Herramientas para el análisis en ciencia de datos</a></li>
<li><a class="nav-link" href="#introducci%C3%B3n-5"><span class="header-section-number">10.1</span> Introducción</a></li>
<li>
<a class="nav-link" href="#partici%C3%B3n-del-conjunto-de-datos"><span class="header-section-number">10.2</span> Partición del conjunto de datos </a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#muestreo-aleatorio-simple"><span class="header-section-number">10.2.1</span> Muestreo aleatorio simple </a></li>
<li><a class="nav-link" href="#binning"><span class="header-section-number">10.2.2</span> Muestreo estratificado </a></li>
</ul>
</li>
<li><a class="nav-link" href="#tecnicas"><span class="header-section-number">10.3</span> Técnicas para manejar datos no equilibrados </a></li>
<li><a class="nav-link" href="#enfoque-validacion"><span class="header-section-number">10.4</span> El enfoque de validación</a></li>
<li><a class="nav-link" href="#compensacion"><span class="header-section-number">10.5</span> Compensación (trade off) entre sesgo y varianza</a></li>
<li><a class="nav-link" href="#ajuste-de-hiperpar%C3%A1metros"><span class="header-section-number">10.6</span> Ajuste de hiperparámetros</a></li>
<li>
<a class="nav-link" href="#evaluation"><span class="header-section-number">10.7</span> Evaluación de modelos</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#resumen-9">Resumen</a></li></ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Fundamentos de ciencia de datos con <strong>R</strong></strong>" coordinado por <a href="https://blog.uclm.es/gemafaviles/" class="text-light">Gema Fernández-Avilés y José-María Montero</a>. </p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>Este libro ha sido generado con el paquete de R <a class="text-light" href="https://bookdown.org">bookdown</a>.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
