<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Capítulo 12 Probabilidad | Fundamentos de ciencia de datos con R</title>
<meta name="author" content="Gema Fernández-Avilés y José-María Montero">
<meta name="description" content="Mª Leticia Meseguer Santamaría\(^{a}\) y Manuel Vargas Vargas\(^{a}\) \(^{a}\) Universidad de Castilla-La Mancha  12.1 Introducción a la probabilidad La incertidumbre es inevitable en muchos...">
<meta name="generator" content="bookdown 0.28 with bs4_book()">
<meta property="og:title" content="Capítulo 12 Probabilidad | Fundamentos de ciencia de datos con R">
<meta property="og:type" content="book">
<meta property="og:image" content="/img/cover.png">
<meta property="og:description" content="Mª Leticia Meseguer Santamaría\(^{a}\) y Manuel Vargas Vargas\(^{a}\) \(^{a}\) Universidad de Castilla-La Mancha  12.1 Introducción a la probabilidad La incertidumbre es inevitable en muchos...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Capítulo 12 Probabilidad | Fundamentos de ciencia de datos con R">
<meta name="twitter:description" content="Mª Leticia Meseguer Santamaría\(^{a}\) y Manuel Vargas Vargas\(^{a}\) \(^{a}\) Universidad de Castilla-La Mancha  12.1 Introducción a la probabilidad La incertidumbre es inevitable en muchos...">
<meta name="twitter:image" content="/img/cover.png">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.2/transition.js"></script><script src="libs/bs3compat-0.4.2/tabs.js"></script><script src="libs/bs3compat-0.4.2/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><link href="libs/tabwid-1.1.0/tabwid.css" rel="stylesheet">
<link href="libs/tabwid-1.1.0/scrool.css" rel="stylesheet">
<script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><link rel="stylesheet" href="bs4_style.css">
<link rel="stylesheet" href="bs4_book.css">
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Fundamentos de ciencia de datos con R</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Buscar" aria-label="Buscar">
</form>

      <nav aria-label="Contenido"><h2>Contenido</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Prefacio</a></li>
<li class="book-part">Ciencia, datos, software… y científicos</li>
<li><a class="" href="ciencia-datos.html"><span class="header-section-number">1</span> ¿Es la ciencia de datos una ciencia?</a></li>
<li><a class="" href="metodologia.html"><span class="header-section-number">2</span> Metodología en ciencia de datos</a></li>
<li><a class="" href="ch-110003.html"><span class="header-section-number">3</span> R para ciencia de datos</a></li>
<li><a class="" href="cap-etica.html"><span class="header-section-number">4</span> Ética en la ciencia de datos</a></li>
<li class="book-part">Bienvenidos a la jungla de datos</li>
<li><a class="" href="datos-sql.html"><span class="header-section-number">5</span> Gestión de bases de datos relacionales</a></li>
<li><a class="" href="cap-nosql.html"><span class="header-section-number">6</span> Gestión de bases de datos NoSQL</a></li>
<li><a class="" href="DGDQM.html"><span class="header-section-number">7</span> Gobierno, gestión y calidad del dato</a></li>
<li><a class="" href="id_130009.html"><span class="header-section-number">8</span> Integración y limpieza de datos</a></li>
<li><a class="" href="chap-feature.html"><span class="header-section-number">9</span> Selección y transformación de variables</a></li>
<li><a class="" href="chap-herramientas.html"><span class="header-section-number">10</span> Herramientas para el análisis en ciencia de datos</a></li>
<li><a class="" href="id_120006-aed.html"><span class="header-section-number">11</span> Análisis exploratorio de datos</a></li>
<li class="book-part">Fundamentos de estadística</li>
<li><a class="active" href="Funda-probab.html"><span class="header-section-number">12</span> Probabilidad</a></li>
<li><a class="" href="Fundainfer.html"><span class="header-section-number">13</span> Inferencia estadística</a></li>
<li><a class="" href="muestreo.html"><span class="header-section-number">14</span> Muestreo y remuestreo</a></li>
<li class="book-part">Modelización estadística</li>
<li><a class="" href="cap-lm.html"><span class="header-section-number">15</span> Modelización lineal</a></li>
<li><a class="" href="cap-glm.html"><span class="header-section-number">16</span> Modelos lineales generalizados</a></li>
<li><a class="" href="cap-gam.html"><span class="header-section-number">17</span> Modelos aditivos generalizados</a></li>
<li><a class="" href="cap-mxm.html"><span class="header-section-number">18</span> Modelos mixtos</a></li>
<li><a class="" href="cap-sparse.html"><span class="header-section-number">19</span> Modelos sparse y métodos penalizados de regresión</a></li>
<li><a class="" href="cap-series-temp.html"><span class="header-section-number">20</span> Modelización de series temporales</a></li>
<li><a class="" href="cap-discriminante.html"><span class="header-section-number">21</span> Análisis discriminante</a></li>
<li><a class="" href="cap-conjunto.html"><span class="header-section-number">22</span> Análisis conjunto</a></li>
<li><a class="" href="tablas-contingencia.html"><span class="header-section-number">23</span> Análisis de tablas de contingencia</a></li>
<li class="book-part">Machine learning supervisado</li>
<li><a class="" href="cap-arboles.html"><span class="header-section-number">24</span> Árboles de clasificación y regresión</a></li>
<li><a class="" href="cap-svm.html"><span class="header-section-number">25</span> Máquinas de vector soporte</a></li>
<li><a class="" href="cap-knn.html"><span class="header-section-number">26</span> Clasificador k-vecinos más próximos</a></li>
<li><a class="" href="cap-naive-bayes.html"><span class="header-section-number">27</span> Naive Bayes</a></li>
<li><a class="" href="cap-bagg-rf.html"><span class="header-section-number">28</span> Métodos ensamblados: bagging y random forest</a></li>
<li><a class="" href="cap-boosting-xgboost.html"><span class="header-section-number">29</span> Boosting y el algoritmo XGBoost</a></li>
<li class="book-part">Machine learning no supervisado</li>
<li><a class="" href="jerarquico.html"><span class="header-section-number">30</span> Análisis cluster: clusterización jerárquica</a></li>
<li><a class="" href="no-jerarquico.html"><span class="header-section-number">31</span> Análisis cluster: clusterización no jerárquica</a></li>
<li><a class="" href="acp.html"><span class="header-section-number">32</span> Análisis de componentes principales</a></li>
<li><a class="" href="an%C3%A1lisis-factorial.html"><span class="header-section-number">33</span> Análisis factorial</a></li>
<li><a class="" href="escalamiento-multidimensional.html"><span class="header-section-number">34</span> Escalamiento multidimensional</a></li>
<li><a class="" href="correspondencias.html"><span class="header-section-number">35</span> Análisis de correspondencias</a></li>
<li class="book-part">Deep learning</li>
<li><a class="" href="capNN.html"><span class="header-section-number">36</span> Redes neuronales artificiales</a></li>
<li><a class="" href="cap-redes-convol.html"><span class="header-section-number">37</span> Redes neuronales convolucionales</a></li>
<li class="book-part">Ciencia de datos de texto y redes</li>
<li><a class="" href="mineria-textos.html"><span class="header-section-number">38</span> Minería de textos</a></li>
<li><a class="" href="grafos.html"><span class="header-section-number">39</span> Análisis de grafos y redes sociales</a></li>
<li class="book-part">Ciencia de datos espaciales</li>
<li><a class="" href="datos-espaciales.html"><span class="header-section-number">40</span> Trabajando con datos espaciales</a></li>
<li><a class="" href="geo.html"><span class="header-section-number">41</span> Geoestadística</a></li>
<li><a class="" href="cap-econom-esp.html"><span class="header-section-number">42</span> Modelos econométricos espaciales</a></li>
<li><a class="" href="cap-pp.html"><span class="header-section-number">43</span> Procesos de puntos</a></li>
<li class="book-part">Comunica y colabora</li>
<li><a class="" href="id_120007-informes.html"><span class="header-section-number">44</span> Informes reproducibles con R Markdown y Quarto</a></li>
<li><a class="" href="shiny.html"><span class="header-section-number">45</span> Creación de aplicaciones web interactivas con Shiny</a></li>
<li><a class="" href="github.html"><span class="header-section-number">46</span> Git y GitHub R</a></li>
<li><a class="" href="geoproces.html"><span class="header-section-number">47</span> Geoprocesamiento en nube</a></li>
<li class="book-part">Casos de estudio en ciencia de datos</li>
<li><a class="" href="cap-crimen.html"><span class="header-section-number">48</span> Análisis de una red criminal</a></li>
<li><a class="" href="cap-publicidad.html"><span class="header-section-number">49</span> Optimización de inversiones publicitarias</a></li>
<li><a class="" href="cap-twitter.html"><span class="header-section-number">50</span> ¿Cómo twitea Elon Musk?</a></li>
<li><a class="" href="cap-periodismo.html"><span class="header-section-number">51</span> Análisis electoral: de Rstudio a su periódico</a></li>
<li><a class="" href="paro-clm.html"><span class="header-section-number">52</span> Crisis: impacto en el paro de Castilla-La Mancha</a></li>
<li><a class="" href="cap-rfm.html"><span class="header-section-number">53</span> Segmentación de clientes en el comerico minorista</a></li>
<li><a class="" href="cap-medicina.html"><span class="header-section-number">54</span> Análisis de datos en medicina</a></li>
<li><a class="" href="cap-futbol.html"><span class="header-section-number">55</span> Messi y Ronaldo: dos ídolos desde la perspectiva de los datos</a></li>
<li><a class="" href="cambioclimatico.html"><span class="header-section-number">56</span> Un dato sobre el cambio climático</a></li>
<li><a class="" href="cap-ree.html"><span class="header-section-number">57</span> Predicción de consumo eléctrico con redes neuronales</a></li>
<li><a class="" href="cap-sist-exp.html"><span class="header-section-number">58</span> Implementación de un sistema experto en el ámbito pediátrico</a></li>
<li><a class="" href="nlp-textil.html"><span class="header-section-number">59</span> El procesamiento del lenguaje natural para tendencias de moda en textil</a></li>
<li><a class="" href="cap-fraude.html"><span class="header-section-number">60</span> Detección de fraude de tarjetas de crédito</a></li>
<li class="book-part">Appendix</li>
<li><a class="" href="info-session.html"><span class="header-section-number">A</span> Información de la sesión</a></li>
<li><a class="" href="referncias.html">Referncias</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="Funda-probab" class="section level1" number="12">
<h1>
<span class="header-section-number">Capítulo 12</span> Probabilidad<a class="anchor" aria-label="anchor" href="#Funda-probab"><i class="fas fa-link"></i></a>
</h1>
<p><em>Mª Leticia Meseguer Santamaría</em><span class="math inline">\(^{a}\)</span> y <em>Manuel Vargas Vargas</em><span class="math inline">\(^{a}\)</span></p>
<p><span class="math inline">\(^{a}\)</span> Universidad de Castilla-La Mancha</p>
<div id="introducción-a-la-probabilidad" class="section level2" number="12.1">
<h2>
<span class="header-section-number">12.1</span> Introducción a la probabilidad<a class="anchor" aria-label="anchor" href="#introducci%C3%B3n-a-la-probabilidad"><i class="fas fa-link"></i></a>
</h2>
<p>La incertidumbre es inevitable en muchos campos científicos, producto de la imposibilidad de predeterminar el resultado de un fenómeno repetido bajo idénticas condiciones, el desconocimiento de todas o algunas causas que pueden influir en él, o una información limitada sobre los condicionantes que rigen su comportamiento. De hecho, gran parte del avance científico consiste en reducir o controlar el nivel de incertidumbre, mejorando el proceso de obtención e interpretación de datos o estableciendo <strong>modelos</strong> que expliquen los resultados.</p>
<p>Producto de la <strong>incertidumbre</strong>, las decisiones que se toman (o la validez de los resultados que se obtienen) conllevan un <strong>riesgo</strong>, que puede concretarse en enunciados equivocados, modelos con escaso poder predictivo o decisiones con resultados no deseados. Sin embargo, no se prescinde de tomar decisiones en ambientes de incertidumbre, sino que se intenta evaluar y minimizar los riesgos asociados.</p>
<p>Así pues, resulta importante poder “<strong>medir</strong>” la incertidumbre, es decir, cuantificar su magnitud y establecer reglas de medida que permitan su tratamiento –la estimación de riesgo– y ayuden a la toma de decisiones. La <strong>teoría de la probabilidad</strong> se puede entender como un ente que proporciona reglas de comportamiento que ayudan a conseguir los objetivos anteriores, siendo el campo de aplicación tan amplio que puede cubrir cualquier rama de las ciencias sociales, técnicas y naturales.</p>
<p>El concepto de probabilidad apareció en la antiguedad, asociado a los juegos de azar, y se ha ido refinando y formalizando a lo largo de la historia. Sin embargo, la mayoría de las definiciones tradicionales presentan limitaciones que impiden su uso riguroso en cualquier situación. Aún así, siguen estando en el subconsciente colectivo, de forma que se entienden expresiones como “<em>es muy probable que llueva mañana</em>”, “<em>es improbable que me toque la lotería de Navidad</em>”, o “<em>es probable que se obtenga en breve una vacuna contra cierta enfermedad</em>”, cuando responden a conceptualizaciones diferentes y, en muchos casos, vagas e imprecisas.</p>
<p>Aunque sigue habiendo debates filosóficos y epistemológicos sobre el concepto de probabilidad (véase, por ejemplo, <span class="citation">Hajek and Hitchcock (<a href="referncias.html#ref-Hajek2016">2016</a>)</span>), su uso generalizado en muchos campos científicos está más relacionado con el desarrollo de su carácter de <strong>medida de la incertidumbre</strong> que con un tratamiento matemático que permite su aplicación práctica (véase, por ejemplo, <span class="citation">Ross (<a href="referncias.html#ref-Ross2012">2012</a>)</span>, <span class="citation">Morin (<a href="referncias.html#ref-Morin2016">2016</a>)</span> o <span class="citation">Balakrishnan, Koutras, and Politis (<a href="referncias.html#ref-Balakrishnanetal2019">2019</a>)</span>). Es este enfoque el que se desarrolla sucintamente en este capítulo.</p>
</div>
<div id="probabilidad-elementos-básicos-definición-y-teoremas" class="section level2" number="12.2">
<h2>
<span class="header-section-number">12.2</span> Probabilidad: elementos básicos, definición y teoremas<a class="anchor" aria-label="anchor" href="#probabilidad-elementos-b%C3%A1sicos-definici%C3%B3n-y-teoremas"><i class="fas fa-link"></i></a>
</h2>
<p>El desarrollo del concepto de probabilidad, entendido como medida de la incertidumbre sobre la ocurrencia de un evento, precisa de algunos requisitos previos que permitan una aplicación operativa.</p>
<p>En primer lugar, es necesario definir en qué situaciones se puede aplicar. Se entenderá por <strong>experimento</strong> cualquier acción u observación de la realidad que pueda repetirse varias veces en idénticas condiciones, dando lugar a resultados identificables y conocidos antes de ser realizado. Cuando, dadas las condiciones, se conoce qué resultado se producirá, se dice que el experimento es <strong>determinista</strong>; en caso contrario, si dadas las condiciones, no se puede saber cuál de los posibles resultados ocurrirá, el experimento se denomina <strong>aleatorio</strong> o <strong>estocástico</strong>. Así pues, sólo se puede hablar de <strong>probabilidad</strong> sobre <strong>experimentos aleatorios</strong>.</p>
<p>Ahora, dado un experimento aleatorio (<span class="math inline">\(E\)</span>) y el conjunto de posibles resultados, denominados genéricamente <strong>sucesos</strong> (<span class="math inline">\(\Omega\)</span>), se define <strong>probabilidad</strong> como una medida del grado de creencia en la ocurrencia de cada posible suceso, <span class="math inline">\(S \in \Omega\)</span>. Como se ve, la definición es muy amplia, por lo que precisa de algún requisito para evitar que una asignación concreta de grados de creencia produzca inconsistencias. Dicho requisito supone el cumplimiento de una estructura (matemática) concreta, que se adopta de forma axiomática. La más conocida, debida a Andrei Kolmogorov, se puede formalizar de la siguiente forma:</p>
<p><strong>Axiomática de Kolmogorov</strong>: se considera un experimento aleatorio <span class="math inline">\(E\)</span>, el conjunto de posibles sucesos <span class="math inline">\(\Omega\)</span>, y una función real <span class="math inline">\(P\)</span> que asigna a cada suceso un número real. Se dice que <span class="math inline">\(P\)</span> es una medida de probabilidad si cumple:</p>
<ul>
<li><ol style="list-style-type: decimal">
<li>
<span class="math inline">\(P(S)\geq 0 , \forall S \in \Omega\)</span>.</li>
</ol></li>
<li><ol start="2" style="list-style-type: decimal">
<li>
<span class="math inline">\(P(\Omega)=1\)</span>.</li>
</ol></li>
<li><ol start="3" style="list-style-type: decimal">
<li>Dada una sucesión numerable de sucesos <span class="math inline">\(\left\{ S_i \right\}\)</span> disjuntos dos a dos, es decir <span class="math inline">\(S_i \cap S_j = \emptyset\ \forall i,j\)</span> (donde <span class="math inline">\(\emptyset\)</span> es el suceso imposible), la probabilidad del suceso unión es la suma de sus probabilidades:
<span class="math inline">\(P \left( \underset {i}{\cup} S_i \right) = \underset{i}{\sum} P(S_i)\)</span>.</li>
</ol></li>
</ul>
<p>Así, una probabilidad es una medida que cumple esta axiomática, asignando a cada suceso un número real (entre 0 y 1) que expresa el grado de creencia en la ocurrencia de dicho suceso, entendiendo que 0 indica que se cree que no ocurre nunca y 1 que ocurre seguramente (véase, por ejemplo <span class="citation">Finetti (<a href="referncias.html#ref-deFinetti2017">2017</a>)</span> para su fundamentación).</p>
<p>Algunas consecuencias que se derivan de la axiomática de Kolmogorov de forma inmediata son:</p>
<ul>
<li><p><span class="math inline">\(P(\emptyset)=0\)</span>.</p></li>
<li><p>Denominando <span class="math inline">\(\bar S\)</span> al suceso complementario, <span class="math inline">\(P(\bar S)=1-P(S)\)</span>.</p></li>
<li><p>Dados dos sucesos cualesquiera, <span class="math inline">\(P(S_1 \cup S_2)=P(S_1)+P(S_2)-P(S_1 \cap S_2)\)</span>.</p></li>
</ul>
<p>Sin embargo, esta definición es formal, en el sentido de que indica qué requisitos debe cumplir para evitar inconsistencias, pero no determina qué valor concreto de probabilidad asignar a cada suceso. Históricamente, se han propuesto varias concepciones para resolver este problema:</p>
<ul>
<li><p><strong>Concepción clásica (o de Laplace)</strong>: dado un experimento aleatorio <span class="math inline">\(E\)</span> con <span class="math inline">\(n\)</span> posibles resultados elementales mutuamente excluyentes e igualmente verosímiles, la probabilidad de un suceso <span class="math inline">\(S_i\)</span> es:
<span class="math display">\[\begin{equation}
P(S_i)=\frac {\text{casos favorables a la ocurrencia de } S_i}{\text{casos posibles}}=\frac{n_i}{n}=f_i.
\end{equation}\]</span>
Por “<em>igualmente verosímiles</em>” se entiende que “no hay razón para afirmar que uno suceda más veces que otro”, conocido como “<em>principio de razón insuficiente</em>”. Es fácilmente comprobable que esta regla cumple la axiomática de Kolmogorov e interpreta la probabilidad como la “<em>frecuencia</em>” de ocurrencia de cada suceso. A pesar de sus limitaciones (utiliza la equiprobabilidad de los sucesos elementales para definir la probabilidade y asume un conjunto finito de ellos), su fácil comprensión y utilidad en casos sencillos hace que esta regla sea muy utilizada (e incluso confundida con una “definición” de probabilidad).</p></li>
<li><p><strong>Concepción frecuentista</strong>: se consideran <span class="math inline">\(n\)</span> repeticiones de un experimento aleatorio, manteniendo idénticas condiciones. Sea <span class="math inline">\(n_i\)</span> el número de veces que se presenta el suceso <span class="math inline">\(S_i\)</span>; entonces se le asigna la probabilidad:
<span class="math display">\[\begin{equation}
P(S_i)=\underset {n \to \infty}{lim} \frac {n_i}{n}.
\end{equation}\]</span>
Esta concepción extiende la versión clásica, identificando la probabilidad con la frecuencia relativa de cada suceso cuando el experimento se repite un gran número de veces.</p></li>
</ul>
<p>El siguiente paso es formalizar cómo influye la ocurrencia de un suceso sobre la probabilidad de que ocurran otros. Así, dado un suceso <span class="math inline">\(A\)</span> con <span class="math inline">\(P(A)&gt;0\)</span>, la probabilidad de que ocurra otro, <span class="math inline">\(B\)</span>, condicionado a que ha ocurrido <span class="math inline">\(A\)</span>, <span class="math inline">\(P(B/A)\)</span>, se calcula como:
<span class="math display" id="eq:probcondi">\[\begin{equation}
\tag{12.1}
P(B/A)= \frac {P(B \cap A)}{P(A)}.
\end{equation}\]</span>
es decir, la probabilidad de que ocurran simultáneamente ambos dividida entre <span class="math inline">\(P(A)\)</span> para que <span class="math inline">\(P(\Omega / A)=1\)</span>.</p>
<p>Esta nueva medida se denomina <strong>probabilidad condicionada</strong><a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Esta definición cumple la axiomática de Kolmogorov y es la forma de introducir “información” en la determinación de probabilidades. Su versión para distribuciones de probabilidad es muy utilizada en inferencia estadística.&lt;/p&gt;"><sup>92</sup></a> y permite obtener resultados fundamentales para el cálculo de probabilidades:</p>
<ul>
<li><p><strong>Independencia de sucesos</strong>: dos sucesos, A y B, se dicen independientes si <span class="math inline">\(P(A/B)=P(A) \Rightarrow P(A \cap B)=P(A)P(B)\)</span>.</p></li>
<li><p><strong>Teorema de la probabilidad total</strong>: dado un conjunto de sucesos <span class="math inline">\(\left \{ A_i \right\}\)</span> disjuntos y cuya unión es <span class="math inline">\(\Omega\)</span> (denominado <strong>partición</strong> de <span class="math inline">\(\Omega\)</span>), la probabilidad de cualquier suceso <span class="math inline">\(B\)</span> compatible con los <span class="math inline">\(A_i\)</span> es:
<span class="math display" id="eq:probtotal">\[\begin{equation}
P(B)= \underset {i}{\sum} P(B/A_i)P(A_i).
\tag{12.2}
\end{equation}\]</span>
Este teorema permite determinar la probabilidad de un suceso <span class="math inline">\(B\)</span>, que puede tener varias causas, o darse bajo diversas alternativas, <span class="math inline">\(A_i\)</span>, mediante la suma de las probabilidades de que aparezca <span class="math inline">\(B\)</span> condicionada a cada una de las causas ponderadas por la probabilidad de cada causa o alternativa.</p></li>
<li><p><strong>Teorema de Bayes</strong>: dada una partición de <span class="math inline">\(\Omega\)</span>, y un suceso <span class="math inline">\(B\)</span> con <span class="math inline">\(P(B)&gt;0\)</span>, la probabilidad de cada elemento de la partición condicionada a que ha ocurrido <span class="math inline">\(B\)</span> es:
<span class="math display" id="eq:bayes">\[\begin{equation}
\tag{12.3}
P(A_i/B)={P(A_i\cap B) \over P(B)} = {P(B/A_i)P(A_i) \over \underset {j}{\sum} P(B/A_j)P(A_j)}.
\end{equation}\]</span>
Este teorema, aplicación directa de la definición de probabilidad condicionada y del teorema de la probabilidad total, es un resultado tan importante que su uso ha dado nombre a una rama entera de la estadística, la conocida como <strong>estadística bayesiana</strong>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;&lt;span class="math inline"&gt;\(P(A_i)\)&lt;/span&gt; se denominan &lt;strong&gt;probabilidades a priori&lt;/strong&gt;, &lt;span class="math inline"&gt;\(P(B/A_i)\)&lt;/span&gt; &lt;strong&gt;verosimilitudes&lt;/strong&gt; y &lt;span class="math inline"&gt;\(P(A_i/B)\)&lt;/span&gt; &lt;strong&gt;probabilidades a posteriori&lt;/strong&gt;. El teorema establece cómo se modifican las probabilidades cuando se introduce información en forma de verosimilitudes, siendo muy utilizada su versión para distribuciones de probabilidad.&lt;/p&gt;'><sup>93</sup></a> También es utilizado en la moderna <strong>inteligencia artificial</strong>, en técnicas como Naive Bayes (véase Cap. <a href="cap-naive-bayes.html#cap-naive-bayes">27</a>)</p></li>
</ul>
</div>
<div id="variable-aleatoria-y-su-distribución-de-probabilidad" class="section level2" number="12.3">
<h2>
<span class="header-section-number">12.3</span> Variable aleatoria y su distribución de probabilidad<a class="anchor" aria-label="anchor" href="#variable-aleatoria-y-su-distribuci%C3%B3n-de-probabilidad"><i class="fas fa-link"></i></a>
</h2>
<p>Una limitación operativa de la probabilidad, tal como se ha utilizado hasta ahora, es que hace referencia a sucesos y operaciones entre conjuntos, lo que dificulta su tratamiento. Sin embargo, en muchos casos los sucesos están caracterizados por valores numéricos, por lo que podrían ser utilizados en sustitución de los primeros para facilitar los cálculos. A esta idea corresponde la noción de <strong>variable aleatoria</strong> (v.a.), que es una función que asigna un valor numérico a cada suceso de un experimento aleatorio. Para trabajar con probabilidades sobre números, a cada uno se le asigna la probabilidad de los sucesos que están caracterizados por dicho valor.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Matemáticamente, una variable aleatoria es una función &lt;span class="math inline"&gt;\(X: \Omega \longrightarrow \mathbb R\)&lt;/span&gt; que, para cada valor real, cumple &lt;span class="math inline"&gt;\(X^{-1}(x) \in \Omega\)&lt;/span&gt;, de forma que se pueda asignar &lt;span class="math inline"&gt;\(P(x)=P \left ( X^{-1}(x) \right )\)&lt;/span&gt;.&lt;/p&gt;'><sup>94</sup></a></p>
<p>Dada una v.a. <span class="math inline">\(X\)</span>, su <strong>función de distribución</strong> asigna a cada número real <span class="math inline">\(x\)</span> la probabilidad de que la variable tome un valor menor o igual que <span class="math inline">\(x\)</span>,</p>
<p><span class="math display" id="eq:funcdistrib">\[\begin{equation}
\tag{12.4}
F_X (x) = P(X \leq x).
\end{equation}\]</span></p>
<p>Una variable se dice <strong>discreta</strong> si sólo puede tomar un conjunto finito (o infinito numerable) de valores con probabilidad positiva. A ese conjunto de valores y sus probabilidades <span class="math inline">\(\left\{ x_i ; P(X=x_i) \right\}\)</span> se le denomina <strong>función de cuantía</strong>.</p>
<p>Una variable se denomina <strong>continua</strong>, si su función de distribución es continua y existe su primera derivada y es continua. Como consecuencia, la probabilidad en un valor concreto siempre será cero, <span class="math inline">\(P(X=x_i)=0\)</span>, por lo que sólo habrá probabilidades positivas sobre intervalos. Se denomina <strong>función de densidad</strong> a la derivada de la función de distribución
<span class="math inline">\(f(x)=F^{\prime}(x)=\frac{dF(x)}{dx}\)</span>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;La función de densidad es el equivalente continuo de la función de cuantía, indicando, de forma intuitiva, dónde se “concentra” la probabilidad de observar valores de &lt;span class="math inline"&gt;\(X\)&lt;/span&gt;. De hecho, no es raro que se utilice el término general de “densidad” independientemente del tipo de variable que sea.&lt;/p&gt;'><sup>95</sup></a></p>
<p>Dado que una v.a. <span class="math inline">\(X\)</span> está caracterizada por su distribución de probabilidad (a través de la función de distribución o de la de cuantía-densidad), se han desarrollado <strong>modelos de distribución de probabilidad</strong> que permiten modelizar el comportamiento aleatorio de las v.a. y calcular probabilidades de forma sencilla.</p>
</div>
<div id="modelos-de-distribución-de-probabilidad" class="section level2" number="12.4">
<h2>
<span class="header-section-number">12.4</span> Modelos de distribución de probabilidad<a class="anchor" aria-label="anchor" href="#modelos-de-distribuci%C3%B3n-de-probabilidad"><i class="fas fa-link"></i></a>
</h2>
<p>En esta sección se presentan los modelos más utilizados en la práctica, distinguiendo entre modelos discretos y continuos, según la naturaleza de la v.a. Para una visión completa, se puede consultar, por ejemplo, <span class="citation">Johnson, Kemp, and Kotz (<a href="referncias.html#ref-JohnsonKempKotz2008">2008</a>)</span>.</p>
<div id="modelos-discretos" class="section level3" number="12.4.1">
<h3>
<span class="header-section-number">12.4.1</span> Modelos discretos<a class="anchor" aria-label="anchor" href="#modelos-discretos"><i class="fas fa-link"></i></a>
</h3>
<p>Los modelos de distribución discretos más populares son el binomial, el binomial negativo y el de Poisson. Los dos primeros se asientan sobre el <strong>fenómeno de Bernoulli</strong> con independencia, que, de manera general, consiste en un experimento dicotómico (o que puede considerarse dicotómico), es decir, que se consideran sólo dos posibles resultados (uno identificado con el <strong>éxito</strong> del experimento, cuya probabildad se denota por <span class="math inline">\(p\)</span>, y el otro con el <strong>fracaso</strong>, con probabilidad <span class="math inline">\(q=(1-p)\)</span>) tal que los resultados producidos por el experimento son independientes de los precedentes.</p>
<ul>
<li><strong>Distribución Binomial B(<span class="math inline">\(n\)</span>,<span class="math inline">\(p\)</span>)</strong></li>
</ul>
<p>La distribución binomial <span class="math inline">\((n,p)\)</span> es una distribución de probabilidad discreta que asigna probabilidades al número de éxitos en una secuencia de <em>n</em> experimentos independientes de Bernoulli con una probabilidad fija de éxito <span class="math inline">\(p\)</span>. Puede tomar los valores <span class="math inline">\(x=0,1,...,n\)</span> y su función de cuantía es:
<span class="math display">\[\begin{equation}
P(X=x)=\binom{n}{x}p^xq^{n-x} \equiv \frac {n!}{x!(n-x)!} p^xq^{n-x}.
\end{equation}\]</span>
Su esperanza, valor esperado o media es <span class="math inline">\(E(X)=\mu=np\)</span>, y su varianza <span class="math inline">\(Var(X)=\sigma^2=npq\)</span>.</p>
<p>La representación gráfica de las funciones de cuantía y distribución se muestra en la Fig. <a href="Funda-probab.html#fig:150014binomd">12.1</a></p>
<div class="sourceCode" id="cb155"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">x</span><span class="op">&lt;-</span><span class="fl">0</span><span class="op">:</span><span class="fl">10</span></span>
<span><span class="va">dens</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">0</span><span class="op">:</span><span class="fl">10</span>, size<span class="op">=</span><span class="fl">10</span>, prob<span class="op">=</span><span class="fl">0.5</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">x</span>, y<span class="op">=</span><span class="va">dens</span>, type<span class="op">=</span><span class="st">"h"</span>, xlab<span class="op">=</span><span class="st">"x"</span>,ylab<span class="op">=</span><span class="st">"P(x)"</span>,main<span class="op">=</span><span class="st">"Función de cuantía"</span>, col<span class="op">=</span><span class="st">"red"</span>, lwd<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">x</span>, <span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">pbinom</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">10</span>,<span class="fl">0.5</span><span class="op">)</span>,ylab<span class="op">=</span><span class="st">"F(x)"</span>,xlab<span class="op">=</span><span class="st">"x"</span>,type<span class="op">=</span><span class="st">"s"</span>,main<span class="op">=</span><span class="st">"Función de distribución"</span>,lwd<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:150014binomd"></span>
<img src="img/150014img01.png" alt="Función de cuantía y de distribución para una variable B(10,0.5)" width="60%"><p class="caption">
Figura 12.1: Función de cuantía y de distribución para una variable B(10,0.5)
</p>
</div>
<p>En el <strong>caso particular</strong> de que <em>n</em>=1, B(1,<em>p</em>), se denomina <strong>distribución Bernoulli, B(<em>p</em>)</strong>.</p>
<ul>
<li><strong>Distribución Binomial negativa o de Pascal BN(<span class="math inline">\(r\)</span>,<span class="math inline">\(p\)</span>)</strong></li>
</ul>
<p>La distribución binomial negativa surge en el contexto de una serie de experimentos de Bernoulli independientes, con probabilidad constante de éxito <span class="math inline">\(p\)</span>, donde la v.a. <span class="math inline">\(X\)</span> denota el número de experimentos fracasados (<span class="math inline">\(x\)</span>) hasta que se produce un número determinado de éxitos (<span class="math inline">\(r\)</span>). Puede tomar los valores <span class="math inline">\(x=0,1,...\)</span> y su función de cuantía es:
<span class="math display">\[\begin{equation}
P(X=x)=\binom{x+r-1}{x}q^xp^r \equiv \frac {(x+r-1)!}{(r-1)!x!}q^xp^r,
\end{equation}\]</span>
con media <span class="math inline">\(E(X)=r\frac{q}{p}\)</span> y varianza <span class="math inline">\(Var(X)=r\frac{q}{p^2}\)</span>.</p>
<p>La representación gráfica de las funciones de cuantía y distribución se muestra en la Fig. <a href="Funda-probab.html#fig:150014nbin">12.2</a></p>
<div class="sourceCode" id="cb156"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">x</span><span class="op">&lt;-</span><span class="fl">0</span><span class="op">:</span><span class="fl">20</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">x</span>,<span class="fu"><a href="https://rdrr.io/r/stats/NegBinomial.html">dnbinom</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">3</span>,<span class="fl">0.35</span><span class="op">)</span>,type<span class="op">=</span><span class="st">"h"</span>,ylab<span class="op">=</span><span class="st">"P(x)"</span>,xlab<span class="op">=</span><span class="st">"x"</span>,main<span class="op">=</span><span class="st">"Función de cuantía"</span>, col<span class="op">=</span><span class="st">"pink"</span>, lwd<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">x</span>, <span class="fu"><a href="https://rdrr.io/r/stats/NegBinomial.html">pnbinom</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">3</span>,<span class="fl">0.35</span><span class="op">)</span>,ylab<span class="op">=</span><span class="st">"F(x)"</span>,xlab<span class="op">=</span><span class="st">"x"</span>,type<span class="op">=</span><span class="st">"s"</span>,main<span class="op">=</span><span class="st">"Función de distribución"</span>,lwd<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:150014nbin"></span>
<img src="img/150014img02.png" alt="Función de cuantía y de distribución para una variable BN(3,0.35)" width="60%"><p class="caption">
Figura 12.2: Función de cuantía y de distribución para una variable BN(3,0.35)
</p>
</div>
<p>En el <strong>caso particular</strong> de que <span class="math inline">\(r=1\)</span>, BN(1,<span class="math inline">\(p\)</span>), se denomina <strong>distribución geométrica G(<span class="math inline">\(p\)</span>)</strong>.</p>
<ul>
<li><strong>Distribución de Poisson P(<span class="math inline">\(\lambda)\)</span></strong></li>
</ul>
<p>Se denominan <strong>fenómenos de Poisson</strong> a aquéllos en los que la ocurrencia de un suceso se encuentra distribuida a lo largo de un tiempo (o espacio) dado, cumpliendo que el proceso es estable, con una media de ocurrencias <span class="math inline">\(\lambda\)</span> por unidad de tiempo, ocurrencias que se presentan de forma aleatoria e independiente. La variable que mide el número <span class="math inline">\(x\)</span> de ocurrencias puede tomar los valores <span class="math inline">\(x=0,1,2,...\)</span> y se dice que sigue una distribución de Poisson, con función de cuantía:
<span class="math display">\[\begin{equation}
P(X=x)=\frac{e^\lambda\lambda^x}{x!}.
\end{equation}\]</span>
Su media es <span class="math inline">\(E(X)=\lambda\)</span> y su varianza <span class="math inline">\(Var(X)=\lambda\)</span>.</p>
<p>La representación gráfica de las funciones de cuantía y distribución se muestra en la Fig. <a href="Funda-probab.html#fig:150014poisson">12.3</a></p>
<div class="sourceCode" id="cb157"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">x</span><span class="op">&lt;-</span><span class="fl">0</span><span class="op">:</span><span class="fl">10</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">x</span>,<span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html">dpois</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">3</span><span class="op">)</span>,type<span class="op">=</span><span class="st">"h"</span>,ylab<span class="op">=</span><span class="st">"P(x)"</span>,xlab<span class="op">=</span><span class="st">"x"</span>,main<span class="op">=</span><span class="st">"Función de cuantía"</span>, col<span class="op">=</span><span class="st">"darkred"</span>,lwd<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">x</span>, <span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html">ppois</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">3</span><span class="op">)</span>,ylab<span class="op">=</span><span class="st">"F(x)"</span>,xlab<span class="op">=</span><span class="st">"x"</span>,type<span class="op">=</span><span class="st">"s"</span>,main<span class="op">=</span><span class="st">"Función de distribución"</span>,lwd<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:150014poisson"></span>
<img src="img/150014img03.png" alt="Función de cuantía y de distribución para una variable P(2.5)" width="60%"><p class="caption">
Figura 12.3: Función de cuantía y de distribución para una variable P(2.5)
</p>
</div>
</div>
<div id="modelos-continuos" class="section level3" number="12.4.2">
<h3>
<span class="header-section-number">12.4.2</span> Modelos continuos<a class="anchor" aria-label="anchor" href="#modelos-continuos"><i class="fas fa-link"></i></a>
</h3>
<p>Los modelos de distribución para variables continuas más habituales son el Normal, el Gamma, el Chi-cuadrado, el <span class="math inline">\(t\)</span>-student y el <span class="math inline">\(F\)</span>-Snedecor.</p>
<ul>
<li><strong>Distribución Normal N<span class="math inline">\((\mu , \sigma)\)</span></strong></li>
</ul>
<p>La distribución Normal, de Gauss o gaussiana, tiene una gran importancia debido a que un gran número de fenómenos aleatorios se pueden modelizar a partir de ella (véase la Sec. <a href="Funda-probab.html#tcl">12.5</a> sobre el teorema central del límite). Además, es la distribución que se toma como supuesto y en la que se basan muchas de las técnicas estadísticas que se ven en este libro.</p>
<p>Una v.a. se dice que sigue una distribución normal de parámetros <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\sigma\)</span> si puede tomar cualquier valor real y su función de densidad es de la forma:</p>
<p><span class="math display">\[\begin{equation}
f(x)=\frac{1}{\sigma\sqrt{2\pi}}e^{-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2}.
\end{equation}\]</span>
Su media es <span class="math inline">\(E[X]=\mu\)</span> y su varianza, <span class="math inline">\(Var(X)=\sigma^2\)</span>. Por ello, se suele decir que la normal está caracterizada por su media y su desviación típica.</p>
<p>La gráfica de la función de densidad tiene forma de campana (conocida como <strong>campana de Gauss</strong>) y es simétrica respecto de la media, con mayor probabilidad en las colas conforme aumenta la desviación típica, como muestra la Fig. <a href="Funda-probab.html#fig:150014norm">12.4</a>.</p>
<div class="sourceCode" id="cb158"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">x</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">5</span>, <span class="fl">5</span>, <span class="fl">0.01</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">x</span>,<span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span>, ylab<span class="op">=</span><span class="st">"P(x)"</span>, xlab<span class="op">=</span><span class="st">"x"</span>, main<span class="op">=</span><span class="st">"Función de densidad"</span>,type<span class="op">=</span><span class="st">"l"</span>,col<span class="op">=</span><span class="st">"blue"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/curve.html">curve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">0</span>,<span class="fl">1.5</span><span class="op">)</span>, ylab<span class="op">=</span><span class="st">"P(x)"</span>, add<span class="op">=</span><span class="cn">TRUE</span>,type<span class="op">=</span><span class="st">"l"</span>,col<span class="op">=</span><span class="st">"red"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/curve.html">curve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">0</span>,<span class="fl">2</span><span class="op">)</span>, ylab<span class="op">=</span><span class="st">"P(x)"</span>, add<span class="op">=</span><span class="cn">TRUE</span> ,type<span class="op">=</span><span class="st">"l"</span>,col<span class="op">=</span><span class="st">"darkgreen"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">x</span>, <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">0</span>,<span class="fl">1</span><span class="op">)</span>,ylab<span class="op">=</span><span class="st">"F(x)"</span>,xlab<span class="op">=</span><span class="st">"x"</span>,type<span class="op">=</span><span class="st">"s"</span>,main<span class="op">=</span><span class="st">"Función de distribución"</span>,col<span class="op">=</span><span class="st">"blue"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/curve.html">curve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">0</span>,<span class="fl">1.5</span><span class="op">)</span>, ylab<span class="op">=</span><span class="st">"P(x)"</span>, add<span class="op">=</span><span class="cn">TRUE</span> ,type<span class="op">=</span><span class="st">"l"</span>,col<span class="op">=</span><span class="st">"red"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/curve.html">curve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">0</span>,<span class="fl">2</span><span class="op">)</span>, ylab<span class="op">=</span><span class="st">"P(x)"</span>, add<span class="op">=</span><span class="cn">TRUE</span> ,type<span class="op">=</span><span class="st">"l"</span>,col<span class="op">=</span><span class="st">"darkgreen"</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:150014norm"></span>
<img src="img/150014img04.png" alt="Función de densidad y de distribución de variables Normales, con media 0 y desviación típica 1 (azul), 1.5 (rojo), y 2 (verde)" width="60%"><p class="caption">
Figura 12.4: Función de densidad y de distribución de variables Normales, con media 0 y desviación típica 1 (azul), 1.5 (rojo), y 2 (verde)
</p>
</div>
<p>Una característica importante de la distribución normal es que verifica la
<strong>propiedad aditiva o reproductiva</strong>, es decir, que las combinaciones lineales de distribuciones normales independientes siguen siendo distribuciones normales. Si se consideran <span class="math inline">\(n\)</span> variables aleatorias independientes con distribuciones <span class="math inline">\(N(\mu_i,\sigma_i)\)</span>, cualquier combinación lineal cumple:
<span class="math display">\[\begin{equation}
\beta_0+\beta_1X_1+...+\beta_nX_n=\beta_0 + \sum_{i=1}^{n}\beta_iX_i \sim N \left( \beta_0+\sum_{i=1}^{n}\beta_i\mu_i, \sqrt{\sum_{i=1}^{n}\beta_i^2\sigma_i^2} \right).
\end{equation}\]</span></p>
<p>En particular, si <span class="math inline">\(X\sim N(\mu,\sigma)\)</span>, la variable <span class="math inline">\(Z=\frac{X-\mu}{\sigma} \sim N(0,1)\)</span>, y se conoce como <strong>normal estándar</strong> o <strong>normal tipificada</strong>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;También es posible interpretar que toda distribución normal es una transformada de la distribución &lt;span class="math inline"&gt;\(Z\)&lt;/span&gt;, ya que &lt;span class="math inline"&gt;\(X=\mu+\sigma Z\)&lt;/span&gt;.&lt;/p&gt;'><sup>96</sup></a></p>
<ul>
<li><strong>Distribución Gamma <span class="math inline">\(\Gamma ( \alpha, \beta )\)</span></strong></li>
</ul>
<p>La <strong>distribución Gamma</strong> es útil en el contexto de los fenómenos de Poisson o cuando se trata de asignar probabilidades al tiempo de espera (o la vida útil) hasta que ocurre un número determinado de sucesos (<span class="math inline">\(\alpha\)</span>), suponiendo que <span class="math inline">\(\beta\)</span> es el tiempo medio entre ocurrencias de un suceso.</p>
<p>Esta distribución toma valores positivos y su función de densidad viene dada por la expresión:
<span class="math display">\[\begin{equation}
f(x) = \frac {1}{\beta^\alpha \Gamma (\alpha)}x^{\alpha-1}e^{-x/\beta},
\end{equation}\]</span>
donde <span class="math inline">\(\Gamma( \alpha)= \int_0^\infty x^{\alpha-1}e^{-x}dx=(\alpha -1)!\)</span> si <span class="math inline">\(\alpha\)</span> es un número natural.</p>
<p>Su media es <span class="math inline">\(E(X)=\alpha\beta\)</span> y su varianza, <span class="math inline">\(Var(X)=\alpha\beta^2\)</span>. El parámetro <span class="math inline">\(\alpha\)</span> es conocido como <strong>parámetro de forma</strong>; si <span class="math inline">\(\alpha\leq1\)</span>, la función de densidad tiene forma de “L”; si <span class="math inline">\(\alpha&gt;1\)</span>, la distribución es campaniforme, con asimetría positiva, y conforme va aumentando, el centro de la distribución se desplaza hacia la derecha. <strong><span class="math inline">\(\beta\)</span></strong> se conoce como <strong>parámetro de escala</strong> y determina el alcance de la asimetría positiva. La Fig. <a href="Funda-probab.html#fig:150014gamma">12.5</a> muestra la representación gráfica de las funciones de densidad y distribución para varias combinaciones de valores de los parámetros (<span class="math inline">\(\beta=2\)</span>; <span class="math inline">\(\alpha=1\)</span> (azul), <span class="math inline">\(\alpha=2\)</span> (morado), <span class="math inline">\(\alpha=5\)</span> (rojo) y <span class="math inline">\(\alpha=10\)</span> (verde)).</p>
<div class="sourceCode" id="cb159"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">x</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span>, <span class="fl">0.01</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">x</span>, <span class="fu"><a href="https://rdrr.io/r/stats/GammaDist.html">dgamma</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">2</span>,<span class="fl">2</span><span class="op">)</span>,type<span class="op">=</span><span class="st">"l"</span>, ylab<span class="op">=</span><span class="st">"f(x)"</span>,main<span class="op">=</span><span class="st">"Función de densidad"</span>,col<span class="op">=</span><span class="st">"purple"</span>,lwd<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/curve.html">curve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/GammaDist.html">dgamma</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">5</span>,<span class="fl">2</span><span class="op">)</span>,type<span class="op">=</span><span class="st">"l"</span>, add<span class="op">=</span><span class="cn">TRUE</span>,col<span class="op">=</span><span class="st">"red"</span>,lwd<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/curve.html">curve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/GammaDist.html">dgamma</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">10</span>,<span class="fl">2</span><span class="op">)</span>,type<span class="op">=</span><span class="st">"l"</span>, add<span class="op">=</span><span class="cn">TRUE</span>,col<span class="op">=</span><span class="st">"green"</span>,lwd<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/curve.html">curve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/GammaDist.html">dgamma</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span>,type<span class="op">=</span><span class="st">"l"</span>, add<span class="op">=</span><span class="cn">TRUE</span>,col<span class="op">=</span><span class="st">"blue"</span>,lwd<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">x</span>, <span class="fu"><a href="https://rdrr.io/r/stats/GammaDist.html">pgamma</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">2</span>,<span class="fl">2</span><span class="op">)</span>,type<span class="op">=</span><span class="st">"l"</span>, ylab<span class="op">=</span><span class="st">"f(x)"</span>,main<span class="op">=</span><span class="st">"Función de distribución"</span>,col<span class="op">=</span><span class="st">"purple"</span>,lwd<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/curve.html">curve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/GammaDist.html">pgamma</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">5</span>,<span class="fl">2</span><span class="op">)</span>,type<span class="op">=</span><span class="st">"l"</span>, add<span class="op">=</span><span class="cn">TRUE</span>,col<span class="op">=</span><span class="st">"red"</span>,lwd<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/curve.html">curve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/GammaDist.html">pgamma</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">10</span>,<span class="fl">2</span><span class="op">)</span>,type<span class="op">=</span><span class="st">"l"</span>, add<span class="op">=</span><span class="cn">TRUE</span>,col<span class="op">=</span><span class="st">"green"</span>,lwd<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/curve.html">curve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/GammaDist.html">pgamma</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span>,type<span class="op">=</span><span class="st">"l"</span>, add<span class="op">=</span><span class="cn">TRUE</span>,col<span class="op">=</span><span class="st">"blue"</span>,lwd<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:150014gamma"></span>
<img src="img/150014img05.png" alt="Función de densidad y de distribución de variables Gamma" width="60%"><p class="caption">
Figura 12.5: Función de densidad y de distribución de variables Gamma
</p>
</div>
<p>El <strong>caso particular</strong> de que <span class="math inline">\(\alpha=1\)</span> se denomina <strong>distribución exponencial</strong> de parámetro <span class="math inline">\(\beta\)</span>.</p>
<ul>
<li><strong>Distribución <span class="math inline">\(\chi_n ^2\)</span> de Pearson</strong></li>
</ul>
<p>Sean <span class="math inline">\(X_1, X_2, ....,X_n\)</span> v.a. independientes, todas distribuidas según una <span class="math inline">\(N(0,1)\)</span>. La suma de sus cuadrados sigue una distribución <span class="math inline">\(\Gamma (\frac {n}{2} , 2 )\)</span>, que se denomina <strong>distribución Chi-cuadrado</strong>:<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Como se verá en la Sec. &lt;a href="Fundainfer.html#pobnormales"&gt;13.6&lt;/a&gt;, esta distribución aparece en el muestreo de poblaciones normales, en concreto al trabajar con varianzas, y también resulta fundamental en el Cap. &lt;a href="tablas-contingencia.html#tablas-contingencia"&gt;23&lt;/a&gt;. Además de otras aplicaciones, estos dos casos justifican su interés.&lt;/p&gt;'><sup>97</sup></a>
<span class="math display">\[\begin{equation}
\sum_{i=1}^n X_i^2 \sim \chi^2_n \equiv \Gamma (\frac {n}{2} , 2 ).
\end{equation}\]</span></p>
<p>Al parámetro <span class="math inline">\(n\)</span> se le llama <strong>grados de libertad</strong>. Su media es <span class="math inline">\(E(X)=n\)</span> y su varianza es <span class="math inline">\(Var(X)=2n\)</span> y la forma funcional de su densidad y distribución son casos particulares de la Gamma. De hecho, la Fig. <a href="Funda-probab.html#fig:150014gamma">12.5</a> corresponde a distribuciones <span class="math inline">\(\chi^2_n\)</span> con <span class="math inline">\(n=2,4,10, \text{y } 20\)</span>.</p>
<ul>
<li><strong>Distribución <span class="math inline">\(t-Student\)</span></strong></li>
</ul>
<p>La distribución <span class="math inline">\(t-Student\)</span> surge, entre otros contextos, en el muestreo de poblaciones normales (véase el Sec. <a href="Fundainfer.html#pobnormales">13.6</a>), asociada al uso de medias. Se dice que una v.a. <span class="math inline">\(X\)</span> sigue una distribución <span class="math inline">\(t-student\)</span> con <span class="math inline">\(n\)</span> <strong>grados de libertad</strong> si es el cociente entre una distribución normal estándar y la raiz de una <span class="math inline">\(\chi^2_n\)</span> dividida entre sus grados de libertad, ambas independientes: <span class="math inline">\(X \sim \frac{N(0,1)}{\sqrt{\chi^2_n /n}}\)</span>.</p>
<p>Su función de densidad viene dada por:
<span class="math display">\[\begin{equation}
f(x)=\frac{\Gamma((n+1)/2)}{\sqrt{n\pi}\Gamma(n/2)}(1+x^2/n)^{-(n+1)/2},
\end{equation}\]</span>
con media <span class="math inline">\(E(X)=0\)</span> y varianza <span class="math inline">\(Var(X)=\frac{n}{n-2}\)</span>, siendo <span class="math inline">\(n&gt;2\)</span>. Su densidad tiene forma acampanada, simétrica respecto a cero y parecida a la de la Normal, pero con mayor probabilidad en las colas. En la Fig. <a href="Funda-probab.html#fig:150014student">12.6</a> se muestran las funciones de densidad y distribución para tres <span class="math inline">\(t-Student\)</span>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Para valores de &lt;span class="math inline"&gt;\(n\)&lt;/span&gt; mayores que 30, la distribución &lt;span class="math inline"&gt;\(t-Student\)&lt;/span&gt; y la &lt;span class="math inline"&gt;\(N(0,1)\)&lt;/span&gt; prácticamente coinciden.&lt;/p&gt;'><sup>98</sup></a></p>
<div class="sourceCode" id="cb160"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">x</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="op">-</span><span class="fl">3</span>, <span class="fl">3</span>, <span class="fl">0.01</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">x</span>, <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">dt</a></span><span class="op">(</span><span class="va">x</span>,df<span class="op">=</span><span class="fl">100</span><span class="op">)</span>,type<span class="op">=</span><span class="st">"l"</span>, ylab<span class="op">=</span><span class="st">"f(x)"</span>,main<span class="op">=</span><span class="st">"Función de densidad"</span>,col<span class="op">=</span><span class="st">"blue"</span>,lwd<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/curve.html">curve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">dt</a></span><span class="op">(</span><span class="va">x</span>,df<span class="op">=</span><span class="fl">10</span><span class="op">)</span>,type<span class="op">=</span><span class="st">"l"</span>, add<span class="op">=</span><span class="cn">TRUE</span>,col<span class="op">=</span><span class="st">"red"</span>,lwd<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/curve.html">curve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">dt</a></span><span class="op">(</span><span class="va">x</span>,df<span class="op">=</span><span class="fl">3</span><span class="op">)</span>,type<span class="op">=</span><span class="st">"l"</span>, add<span class="op">=</span><span class="cn">TRUE</span>,col<span class="op">=</span><span class="st">"darkgreen"</span>,lwd<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">x</span>, <span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">pt</a></span><span class="op">(</span><span class="va">x</span>,df<span class="op">=</span><span class="fl">100</span><span class="op">)</span>,type<span class="op">=</span><span class="st">"l"</span>, ylab<span class="op">=</span><span class="st">"f(x)"</span>,main<span class="op">=</span><span class="st">"Función de distribución"</span>,col<span class="op">=</span><span class="st">"blue"</span>,lwd<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/curve.html">curve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">pt</a></span><span class="op">(</span><span class="va">x</span>,df<span class="op">=</span><span class="fl">10</span><span class="op">)</span>,type<span class="op">=</span><span class="st">"l"</span>, add<span class="op">=</span><span class="cn">TRUE</span>,col<span class="op">=</span><span class="st">"red"</span>,lwd<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/curve.html">curve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/TDist.html">pt</a></span><span class="op">(</span><span class="va">x</span>,df<span class="op">=</span><span class="fl">3</span><span class="op">)</span>,type<span class="op">=</span><span class="st">"l"</span>, add<span class="op">=</span><span class="cn">TRUE</span>,col<span class="op">=</span><span class="st">"darkgreen"</span>,lwd<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:150014student"></span>
<img src="img/150014img06.png" alt="Función de densidad y de distribución de variables t-Student, con 3 (verde), 10 (rojo) y 100 (azul) grados de libertad" width="60%"><p class="caption">
Figura 12.6: Función de densidad y de distribución de variables t-Student, con 3 (verde), 10 (rojo) y 100 (azul) grados de libertad
</p>
</div>
<ul>
<li><strong>Distribución <span class="math inline">\(F\)</span> de Snedecor</strong></li>
</ul>
<p>Este modelo también está asociado al muestreo sobre poblaciones normales, en este caso, a la comparación de varianzas. Se define una distribución <span class="math inline">\(F\)</span> de Snedecor con <span class="math inline">\(n\)</span> y <span class="math inline">\(m\)</span> grados de libertad como el cociente de dos distribuciones <span class="math inline">\(\chi^2\)</span> independientes divididas entre sus grados de libertad, <span class="math inline">\(F_{n,m} = \frac {\chi^2_{n}/n}{\chi^2_{m}/m}\)</span>.</p>
<p>La función de densidad <span class="math inline">\(F_{n,m}\)</span> viene dada por:
<span class="math display">\[\begin{equation}
f(x)=\frac{\Gamma(\frac{n+m}{2})}{\Gamma(\frac{n}{2})\Gamma(\frac{m}{2})}\left(\frac{n}{m}\right)^{\frac{n}{2}}\frac{x^{\frac{n-2}{2}}}{(1+\frac{nx}{m})^{\frac{n+m}{2}}}
\end{equation}\]</span>
con media <span class="math inline">\(E(X)=\frac{m}{m-2}\)</span>, siendo <span class="math inline">\(m\)</span>&gt;2 y varianza <span class="math inline">\(Var(X)=\frac{2m^2(n+m-2)}{n(m-2)^2(m-4)}\)</span>, cuando <span class="math inline">\(m\)</span>&gt;4.</p>
<p>La gráfica de la función de densidad es parecida a la de la <span class="math inline">\(\chi_n^2\)</span>. Así, sólo está definida para el semieje positivo y su apariencia variará según los grados de libertad. La Fig. <a href="Funda-probab.html#fig:150014FSnedecor">12.7</a> muestra las funciones de densidad y distribución para varias distribuciones F-Snedecor.</p>
<div class="sourceCode" id="cb161"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>,<span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="va">x</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">4</span>, <span class="fl">0.01</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">x</span>, <span class="fu"><a href="https://rdrr.io/r/stats/Fdist.html">df</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">5</span>,<span class="fl">10</span><span class="op">)</span>,type<span class="op">=</span><span class="st">"l"</span>, ylab<span class="op">=</span><span class="st">"f(x)"</span>,main<span class="op">=</span><span class="st">"Función de densidad"</span>,col<span class="op">=</span><span class="st">"blue"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/curve.html">curve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Fdist.html">df</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">10</span>,<span class="fl">5</span><span class="op">)</span>,type<span class="op">=</span><span class="st">"l"</span>, add<span class="op">=</span><span class="cn">TRUE</span>,col<span class="op">=</span><span class="st">"red"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/curve.html">curve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Fdist.html">df</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">5</span>,<span class="fl">5</span><span class="op">)</span>,type<span class="op">=</span><span class="st">"l"</span>, add<span class="op">=</span><span class="cn">TRUE</span>,col<span class="op">=</span><span class="st">"darkgreen"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">x</span>, <span class="fu"><a href="https://rdrr.io/r/stats/Fdist.html">pf</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">5</span>,<span class="fl">10</span><span class="op">)</span>,type<span class="op">=</span><span class="st">"l"</span>, ylab<span class="op">=</span><span class="st">"f(x)"</span>,main<span class="op">=</span><span class="st">"Función de distribución"</span>,col<span class="op">=</span><span class="st">"blue"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/curve.html">curve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Fdist.html">pf</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">10</span>,<span class="fl">5</span><span class="op">)</span>,type<span class="op">=</span><span class="st">"l"</span>, add<span class="op">=</span><span class="cn">TRUE</span>,col<span class="op">=</span><span class="st">"red"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/curve.html">curve</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Fdist.html">pf</a></span><span class="op">(</span><span class="va">x</span>,<span class="fl">5</span>,<span class="fl">5</span><span class="op">)</span>,type<span class="op">=</span><span class="st">"l"</span>, add<span class="op">=</span><span class="cn">TRUE</span>,col<span class="op">=</span><span class="st">"darkgreen"</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:150014FSnedecor"></span>
<img src="img/150014img07.png" alt="Función de densidad y de distribución de variables F-Snedecor, en azul con (5,10) grados de libertad, en rojo con (10,5) y en verde con (5,5)" width="60%"><p class="caption">
Figura 12.7: Función de densidad y de distribución de variables F-Snedecor, en azul con (5,10) grados de libertad, en rojo con (10,5) y en verde con (5,5)
</p>
</div>
</div>
</div>
<div id="tcl" class="section level2" number="12.5">
<h2>
<span class="header-section-number">12.5</span> Teorema central del límite<a class="anchor" aria-label="anchor" href="#tcl"><i class="fas fa-link"></i></a>
</h2>
<p>A veces es difícil encontrar la distribución muestral de algunos estadísticos o estimadores, o, incluso, es imposible determinar la distribución de la variable de interés; entonces es útil aplicar algunos teoremas de convergencia, en especial el <strong>Teorema Central del Límite (TCL)</strong>.</p>
<p>El TCL permite, bajo ciertas condiciones, usar la distribución normal para aproximar otras distribuciones o para modelizar el comportamiento de variables de las que se desconozca su distribución.</p>
<p><strong>Teorema central del límite</strong>: si <span class="math inline">\(X_1,..., X_n\)</span> son v.a. independientes e idénticamente distribuidas (iid) con media <span class="math inline">\(\mu\)</span> y desviación típica <span class="math inline">\(\sigma\)</span>, entonces <span class="math inline">\(\sum_{i=1}^n X_i\)</span> tiene asintóticamente una distribución normal de media <span class="math inline">\(n\mu\)</span> y desviación típica <span class="math inline">\(\sqrt{n}\sigma\)</span>,
<span class="math display">\[\begin{equation}
  \frac{\sum_{i=1}^n X_i-n\mu}{\sqrt{n}\sigma} \underset {n\rightarrow \infty}\longrightarrow N(0,1).
\end{equation}\]</span>
El TCL indica que la distribución de la suma de <span class="math inline">\(n\)</span> variables aleatorias independientes tiende a una distribución normal, cuando <span class="math inline">\(n\)</span> es muy grande. Es decir, aunque cada uno de los efectos sea raro o difícil de estudiar, si lo que se quiere estudiar es la suma de los mismos, se sabe que, bajo ciertas condiciones y siempre que sean independientes, ésta se comportará como una distribución normal. Así se explica el hecho constatado de que muchas distribuciones de variables observadas en la naturaleza o en experimentos físicos sean aproximadamente normales; por ejemplo, las medidas del cuerpo humano, altura, peso, longitud de los dedos, etc.</p>
</div>
<div id="distprobR" class="section level2" number="12.6">
<h2>
<span class="header-section-number">12.6</span> Distribuciones de probabilidad en <strong>R</strong><a class="anchor" aria-label="anchor" href="#distprobR"><i class="fas fa-link"></i></a>
</h2>
<p>En <strong>R</strong> están implementadas las distribuciones de probabilidad más importantes, de tal forma que, en el paquete <code>Rlab</code>, se aplica a cada nombre del modelo un determinado prefijo para calcular una función específica: <em>d</em> para la función de cuantía o densidad, <em>p</em> para la función de distribución, <em>q</em> para los cuantiles (o percentiles) y <em>r</em> para generar muestras pseudo-aleatorias.</p>
<p>En la Tabla <a href="Funda-probab.html#tab:distribuciones">12.1</a> se exponen los modelos de distribución vistos, indicando el tipo, con su notación y la función utilizada en <strong>R</strong> para su cálculo:</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:distribuciones">Tabla 12.1: </span> Funciones de distribución en <strong>R</strong>
</caption>
<thead><tr class="header">
<th align="center">Distribución</th>
<th align="center">Tipo de modelo</th>
<th align="center">Notación</th>
<th align="center">Función en <strong>R</strong>
</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="center">Binomial</td>
<td align="center">discreto</td>
<td align="center">B(n,p)</td>
<td align="center"><code>binom</code></td>
</tr>
<tr class="even">
<td align="center">Binomial negativa</td>
<td align="center">discreto</td>
<td align="center">BN(r;p)</td>
<td align="center"><code>nbinom</code></td>
</tr>
<tr class="odd">
<td align="center">Geométrica</td>
<td align="center">discreto</td>
<td align="center">G(p)</td>
<td align="center"><code>geom</code></td>
</tr>
<tr class="even">
<td align="center">Poisson</td>
<td align="center">discreto</td>
<td align="center">P(<span class="math inline">\(\lambda\)</span>)</td>
<td align="center"><code>pois</code></td>
</tr>
<tr class="odd">
<td align="center">Normal</td>
<td align="center">continuo</td>
<td align="center"><span class="math inline">\(N(\mu,\sigma)\)</span></td>
<td align="center"><code>norm</code></td>
</tr>
<tr class="even">
<td align="center">Gamma</td>
<td align="center">continuo</td>
<td align="center"><span class="math inline">\(\Gamma(\alpha,\beta)\)</span></td>
<td align="center"><code>gamma</code></td>
</tr>
<tr class="odd">
<td align="center">Exponencial</td>
<td align="center">continuo</td>
<td align="center"><span class="math inline">\(Exp (\beta)\)</span></td>
<td align="center"><code>exp</code></td>
</tr>
<tr class="even">
<td align="center">Chi-cuadrado</td>
<td align="center">continuo</td>
<td align="center"><span class="math inline">\(\chi^2_n\)</span></td>
<td align="center"><code>chisq</code></td>
</tr>
<tr class="odd">
<td align="center">t-student</td>
<td align="center">continuo</td>
<td align="center"><span class="math inline">\(t_n\)</span></td>
<td align="center"><code>t</code></td>
</tr>
<tr class="even">
<td align="center">F-Snedecor</td>
<td align="center">continuo</td>
<td align="center"><span class="math inline">\(F_{n,m}\)</span></td>
<td align="center"><code>f</code></td>
</tr>
</tbody>
</table></div>
<p>A continuación se realizan dos ejemplos con <strong>R</strong>, uno para modelos discretos y otro para la normal. La adaptación a cualquier otro modelo de probabilidad consiste, básicamente, en sustituir las funciones de <strong>R</strong>.</p>
<div id="ejemplo-de-distribuciones-discretas-con-r" class="section level3" number="12.6.1">
<h3>
<span class="header-section-number">12.6.1</span> <strong>Ejemplo de distribuciones discretas con R</strong><a class="anchor" aria-label="anchor" href="#ejemplo-de-distribuciones-discretas-con-r"><i class="fas fa-link"></i></a>
</h3>
<p>Sea un algoritmo de identificación que trata un número muy elevado de imágenes, teniendo acreditada una tasa de error del 20% en caso de personas y del 5% para el resto de imágenes. Supóngase que las imágenes de personas son el 25% del total de imágenes.</p>
<ol style="list-style-type: lower-alpha">
<li>Si se analizan 10 imágenes de personas, calcúlese la probabilidad de que identifique correctamente siete.</li>
</ol>
<p>Denominando <span class="math inline">\(X\)</span> al número de imágenes de personas correctamente clasificadas, se tiene que <span class="math inline">\(X \sim B(10,0.8)\)</span>. Se pide <span class="math inline">\(P(X=7)\)</span>:</p>
<div class="sourceCode" id="cb162"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">7</span>,size<span class="op">=</span><span class="fl">10</span>,prob<span class="op">=</span><span class="fl">0.8</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.2013266</span></span></code></pre></div>
<ol start="2" style="list-style-type: lower-alpha">
<li>Para el resto de imágenes, calcúlese la probabilidad de que identifique correctamente como mucho 50 hasta que se produzca el segundo error.</li>
</ol>
<p>Denominando <span class="math inline">\(Y\)</span> al número de imágenes correctamente identificadas hasta el segundo error, se tiene que <span class="math inline">\(Y \sim BN(2,0.05)\)</span>. Se pide <span class="math inline">\(P(Y \leq 50)\)</span>:</p>
<div class="sourceCode" id="cb163"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/NegBinomial.html">pnbinom</a></span><span class="op">(</span><span class="fl">50</span>,size<span class="op">=</span><span class="fl">2</span>,prob<span class="op">=</span><span class="fl">0.05</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.7405031</span></span></code></pre></div>
<ol start="3" style="list-style-type: lower-alpha">
<li>Históricamente, el número medio diario de imágenes incorrectamente clasificadas es de 7. Calcular la probabilidad de que un día seleccionado al azar clasifique incorrectamente entre 6 y 9 imágenes.</li>
</ol>
<p>Denominando <span class="math inline">\(T\)</span> al número de imágenes incorrectamente identificadas en un día, se tiene que <span class="math inline">\(T \sim P(\lambda = 7)\)</span>. Se pide <span class="math inline">\(P(6 \leq T \leq 9) = P(T \leq 9) - P(T \leq 5)\)</span>:</p>
<div class="sourceCode" id="cb164"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html">ppois</a></span><span class="op">(</span><span class="fl">9</span>,<span class="fl">7</span>,lower.tail <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span> <span class="op">-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Poisson.html">ppois</a></span><span class="op">(</span><span class="fl">5</span>,<span class="fl">7</span>,lower.tail <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.5297877</span></span></code></pre></div>
<ol start="4" style="list-style-type: lower-alpha">
<li>Calcúlese la probabilidad de que en un lote de 20 imágenes del mismo tipo todas sean correctamente clasificadas.</li>
</ol>
<p>Como no se especifica el tipo de imágenes, hay que calcular dicha probabilidad condicionada a cada grupo y utilizar el teorema de la probabilidad total: <span class="math inline">\(P(acierto)=P(acierto/personas)*P(personas)+P(acierto/otras)*P(otras)\)</span>.</p>
<div class="sourceCode" id="cb165"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">acierto_personas</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">20</span>,<span class="fl">0.2</span><span class="op">)</span></span>
<span><span class="va">acierto_otras</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/Binomial.html">dbinom</a></span><span class="op">(</span><span class="fl">0</span>,<span class="fl">20</span>,<span class="fl">0.05</span><span class="op">)</span></span>
<span><span class="va">acierto_total</span><span class="op">&lt;-</span><span class="va">acierto_personas</span><span class="op">*</span><span class="fl">0.25</span><span class="op">+</span><span class="va">acierto_otras</span><span class="op">*</span><span class="fl">0.75</span></span>
<span><span class="va">acierto_total</span></span>
<span><span class="co">#&gt; [1] 0.2717467</span></span></code></pre></div>
<ol start="5" style="list-style-type: lower-alpha">
<li>Si se han clasificado correctamente las 20 imágenes del lote, calcúlese la probabilidad de que correspondan a imágenes de personas.</li>
</ol>
<p>En este caso hay que utilizar el teorema de Bayes: <span class="math inline">\(P(personas/acierto)= \frac {P(acierto/personas)*P(personas)}{P(acierto)}\)</span>.</p>
<div class="sourceCode" id="cb166"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">acierto_personas</span><span class="op">*</span><span class="fl">0.25</span><span class="op">/</span><span class="va">acierto_total</span></span>
<span><span class="co">#&gt; [1] 0.01060658</span></span></code></pre></div>
</div>
<div id="ejemplo-de-una-distribución-normal-con-r" class="section level3" number="12.6.2">
<h3>
<span class="header-section-number">12.6.2</span> <strong>Ejemplo de una distribución normal con R</strong><a class="anchor" aria-label="anchor" href="#ejemplo-de-una-distribuci%C3%B3n-normal-con-r"><i class="fas fa-link"></i></a>
</h3>
<p>Las calificaciones (de 0 a 10) en un curso de estadística siguen una de distribución normal N(6, 1.25), <span class="math inline">\(X \sim N(6, 1.25)\)</span>. Calcúlese:</p>
<ol style="list-style-type: lower-alpha">
<li>La probabilidad de que una persona obtenga una calificación inferior a 4.</li>
</ol>
<div class="sourceCode" id="cb167"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span><span class="fl">4</span>,mean<span class="op">=</span><span class="fl">6</span>,sd<span class="op">=</span><span class="fl">1.25</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.05479929</span></span></code></pre></div>
<ol start="2" style="list-style-type: lower-alpha">
<li>El número esperado de personas que obtendrán sobresaliente (9 o más) en un grupo de 60 personas.</li>
</ol>
<div class="sourceCode" id="cb168"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">p</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span><span class="fl">9</span>,<span class="fl">6</span>,<span class="fl">1.25</span>,lower.tail<span class="op">=</span><span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="va">p</span></span>
<span><span class="co">#&gt; [1] 0.008197536</span></span>
<span><span class="co"># En un grupo de 60 personas, redondeando a un número entero</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Round.html">round</a></span><span class="op">(</span><span class="fl">60</span><span class="op">*</span><span class="va">p</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0</span></span></code></pre></div>
<ol start="3" style="list-style-type: lower-alpha">
<li>la nota mínima para estar en el 30% de personas con mejores calificaciones.</li>
</ol>
<div class="sourceCode" id="cb169"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">qnorm</a></span><span class="op">(</span><span class="fl">0.7</span>,<span class="fl">6</span>,<span class="fl">1.25</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 6.655501</span></span></code></pre></div>
<ol start="4" style="list-style-type: lower-alpha">
<li>En un curso de informática las calificaciones siguen una de distribución normal <span class="math inline">\(N(5, 1.75)\)</span>, independientes de las de estadística. Calcular la probabilidad de que una persona matriculada en ambos cursos saque mayor calificación en estadística.</li>
</ol>
<p>Llamando <span class="math inline">\(X=C_e-C_i\)</span> a la diferencia entre las calificaciones en estadística (<span class="math inline">\(C_e\)</span>) y en informatica (<span class="math inline">\(C_i\)</span>), ambas normales e independientes, la distribución de <span class="math inline">\(X\)</span> será <span class="math inline">\(X \sim N \left ( 6-5, \sqrt{1.25^2+1.75^2} \right )\)</span>. Se pide <span class="math inline">\(P(X&gt;0)\)</span>, que se representa en la Fig. <a href="Funda-probab.html#fig:150014graf">12.8</a>.</p>
<div class="sourceCode" id="cb170"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">pnorm</a></span><span class="op">(</span><span class="fl">0</span>,mean<span class="op">=</span><span class="fl">1</span>,sd<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fl">1.25</span><span class="op">^</span><span class="fl">2</span><span class="op">+</span><span class="fl">1.75</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span>,lower.tail <span class="op">=</span> <span class="cn">FALSE</span><span class="op">)</span></span>
<span><span class="co">#&gt; [1] 0.6790309</span></span></code></pre></div>
<div class="sourceCode" id="cb171"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="va">media</span><span class="op">&lt;-</span><span class="fl">1</span></span>
<span><span class="va">desv</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fl">1.25</span><span class="op">^</span><span class="fl">2</span><span class="op">+</span><span class="fl">1.75</span><span class="op">^</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="va">area_n</span><span class="op">&lt;-</span><span class="kw">function</span> <span class="op">(</span><span class="va">media</span>, <span class="va">desv</span> ,<span class="va">lb</span> , <span class="va">ub</span>,<span class="va">...</span><span class="op">)</span></span>
<span><span class="op">{</span></span>
<span>  <span class="va">x</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="va">media</span><span class="op">-</span><span class="fl">4</span><span class="op">*</span><span class="va">desv</span>, <span class="va">media</span><span class="op">+</span><span class="fl">4</span><span class="op">*</span><span class="va">desv</span>, <span class="fl">0.05</span><span class="op">)</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/missing.html">missing</a></span><span class="op">(</span><span class="va">lb</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span><span class="va">lb</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">min</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">}</span></span>
<span>  <span class="kw">if</span> <span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/missing.html">missing</a></span><span class="op">(</span><span class="va">ub</span><span class="op">)</span><span class="op">)</span> <span class="op">{</span><span class="va">ub</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/Extremes.html">max</a></span><span class="op">(</span><span class="va">x</span><span class="op">)</span><span class="op">}</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">x</span>,<span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">media</span>, <span class="va">desv</span><span class="op">)</span>, ylab<span class="op">=</span><span class="st">"P(x)"</span>, xlab<span class="op">=</span><span class="st">"x"</span>, main<span class="op">=</span><span class="st">"Probabilidad "</span>,type<span class="op">=</span><span class="st">"l"</span>, lty<span class="op">=</span><span class="fl">1</span>, lwd<span class="op">=</span><span class="fl">2</span><span class="op">)</span></span>
<span><span class="co"># Nueva rejilla de valores para x2, para el área.</span></span>
<span>  <span class="va">x2</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/base/seq.html">seq</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">10</span>, <span class="fl">0.05</span><span class="op">)</span></span>
<span>  <span class="va">y</span><span class="op">&lt;-</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">dnorm</a></span><span class="op">(</span><span class="va">x2</span>, <span class="va">media</span>, <span class="va">desv</span><span class="op">)</span></span>
<span>  <span class="fu"><a href="https://rdrr.io/r/graphics/polygon.html">polygon</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">x2</span>, <span class="fl">10</span><span class="op">)</span>, <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="va">y</span>, <span class="fl">0</span><span class="op">)</span>,col<span class="op">=</span><span class="st">"lightblue"</span><span class="op">)</span></span>
<span><span class="op">}</span></span>
<span><span class="fu">area_n</span><span class="op">(</span><span class="va">media</span>,<span class="va">desv</span>, <span class="fl">0</span>, <span class="fl">10</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:150014graf"></span>
<img src="img/150014img08.png" alt="P(X&gt;0) representada como el área bajo la función de densidad de X" width="60%"><p class="caption">
Figura 12.8: P(X&gt;0) representada como el área bajo la función de densidad de X
</p>
</div>
</div>
<div id="resumen-11" class="section level3 unnumbered infobox_resume">
<h3>Resumen<a class="anchor" aria-label="anchor" href="#resumen-11"><i class="fas fa-link"></i></a>
</h3>
<p>La teoría de la probabilidad proporciona reglas de comportamiento que permiten la ordenación y toma de decisiones en situaciones donde prevalecen condiciones de incertidumbre.</p>
<p>Los modelos de distribución de probabilidad más usuales en la práctica son, para variables discretas, el binomial, el binomial negativo y el Poisson (junto a sus casos particulares). Para el caso de variables continuas, los modelos más frecuentes son el normal, el gamma, el t-Student, el Chi-cuadrado y el F-Snedecor (así como sus casos particulares). Estos modelos facilitan el cálculo de probabilidades en, prácticamente, cualquier proyecto de las ciencias sociales, técnicas y naturales.</p>
</div>

</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="id_120006-aed.html"><span class="header-section-number">11</span> Análisis exploratorio de datos</a></div>
<div class="next"><a href="Fundainfer.html"><span class="header-section-number">13</span> Inferencia estadística</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="Índice capítulo"><h2>Índice capítulo</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#Funda-probab"><span class="header-section-number">12</span> Probabilidad</a></li>
<li><a class="nav-link" href="#introducci%C3%B3n-a-la-probabilidad"><span class="header-section-number">12.1</span> Introducción a la probabilidad</a></li>
<li><a class="nav-link" href="#probabilidad-elementos-b%C3%A1sicos-definici%C3%B3n-y-teoremas"><span class="header-section-number">12.2</span> Probabilidad: elementos básicos, definición y teoremas</a></li>
<li><a class="nav-link" href="#variable-aleatoria-y-su-distribuci%C3%B3n-de-probabilidad"><span class="header-section-number">12.3</span> Variable aleatoria y su distribución de probabilidad</a></li>
<li>
<a class="nav-link" href="#modelos-de-distribuci%C3%B3n-de-probabilidad"><span class="header-section-number">12.4</span> Modelos de distribución de probabilidad</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#modelos-discretos"><span class="header-section-number">12.4.1</span> Modelos discretos</a></li>
<li><a class="nav-link" href="#modelos-continuos"><span class="header-section-number">12.4.2</span> Modelos continuos</a></li>
</ul>
</li>
<li><a class="nav-link" href="#tcl"><span class="header-section-number">12.5</span> Teorema central del límite</a></li>
<li>
<a class="nav-link" href="#distprobR"><span class="header-section-number">12.6</span> Distribuciones de probabilidad en R</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#ejemplo-de-distribuciones-discretas-con-r"><span class="header-section-number">12.6.1</span> Ejemplo de distribuciones discretas con R</a></li>
<li><a class="nav-link" href="#ejemplo-de-una-distribuci%C3%B3n-normal-con-r"><span class="header-section-number">12.6.2</span> Ejemplo de una distribución normal con R</a></li>
<li><a class="nav-link" href="#resumen-11">Resumen</a></li>
</ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Fundamentos de ciencia de datos con R</strong>" coordinado por <a href="https://blog.uclm.es/gemafaviles/" class="text-light">Gema Fernández-Avilés y José-María Montero</a>. Generado por última vez el día 2023-06-16.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>Este libro ha sido generado con el paquete de R <a class="text-light" href="https://bookdown.org">bookdown</a>.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
