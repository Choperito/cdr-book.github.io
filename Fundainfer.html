<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Capítulo 13 Inferencia estadística | Fundamentos de ciencia de datos con R</title>
<meta name="author" content="Gema Fernández-Avilés y José-María Montero">
<meta name="description" content="Mª Leticia Meseguer Santamaría\(^{a}\) y Manuel Vargas Vargas\(^{a}\) \(^{a}\) Universidad de Castilla-La Mancha  13.1 Introducción Cuando se estudian fenómenos mediante variables aleatorias, el...">
<meta name="generator" content="bookdown 0.34 with bs4_book()">
<meta property="og:title" content="Capítulo 13 Inferencia estadística | Fundamentos de ciencia de datos con R">
<meta property="og:type" content="book">
<meta property="og:image" content="/img/cover.png">
<meta property="og:description" content="Mª Leticia Meseguer Santamaría\(^{a}\) y Manuel Vargas Vargas\(^{a}\) \(^{a}\) Universidad de Castilla-La Mancha  13.1 Introducción Cuando se estudian fenómenos mediante variables aleatorias, el...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Capítulo 13 Inferencia estadística | Fundamentos de ciencia de datos con R">
<meta name="twitter:description" content="Mª Leticia Meseguer Santamaría\(^{a}\) y Manuel Vargas Vargas\(^{a}\) \(^{a}\) Universidad de Castilla-La Mancha  13.1 Introducción Cuando se estudian fenómenos mediante variables aleatorias, el...">
<meta name="twitter:image" content="/img/cover.png">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.2/transition.js"></script><script src="libs/bs3compat-0.4.2/tabs.js"></script><script src="libs/bs3compat-0.4.2/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><link href="libs/tabwid-1.1.3/tabwid.css" rel="stylesheet">
<script src="libs/tabwid-1.1.3/tabwid.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><link rel="stylesheet" href="bs4_style.css">
<link rel="stylesheet" href="bs4_book.css">
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Fundamentos de ciencia de datos con R</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Buscar" aria-label="Buscar">
</form>

      <nav aria-label="Contenido"><h2>Contenido</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Prefacio</a></li>
<li class="book-part">Ciencia, datos, software… y científicos</li>
<li><a class="" href="ciencia-datos.html"><span class="header-section-number">1</span> ¿Es la ciencia de datos una ciencia?</a></li>
<li><a class="" href="metodologia.html"><span class="header-section-number">2</span> Metodología en ciencia de datos</a></li>
<li><a class="" href="ch-110003.html"><span class="header-section-number">3</span> R para ciencia de datos</a></li>
<li><a class="" href="cap-etica.html"><span class="header-section-number">4</span> Ética en la ciencia de datos</a></li>
<li class="book-part">Bienvenidos a la jungla de datos</li>
<li><a class="" href="datos-sql.html"><span class="header-section-number">5</span> Gestión de bases de datos relacionales</a></li>
<li><a class="" href="cap-nosql.html"><span class="header-section-number">6</span> Gestión de bases de datos NoSQL</a></li>
<li><a class="" href="DGDQM.html"><span class="header-section-number">7</span> Gobierno, gestión y calidad del dato</a></li>
<li><a class="" href="id_130009.html"><span class="header-section-number">8</span> Integración y limpieza de datos</a></li>
<li><a class="" href="chap-feature.html"><span class="header-section-number">9</span> Selección y transformación de variables</a></li>
<li><a class="" href="chap-herramientas.html"><span class="header-section-number">10</span> Herramientas para el análisis en ciencia de datos</a></li>
<li><a class="" href="id_120006-aed.html"><span class="header-section-number">11</span> Análisis exploratorio de datos</a></li>
<li class="book-part">Fundamentos de estadística</li>
<li><a class="" href="Funda-probab.html"><span class="header-section-number">12</span> Probabilidad</a></li>
<li><a class="active" href="Fundainfer.html"><span class="header-section-number">13</span> Inferencia estadística</a></li>
<li><a class="" href="muestreo.html"><span class="header-section-number">14</span> Muestreo y remuestreo</a></li>
<li class="book-part">Modelización estadística</li>
<li><a class="" href="cap-lm.html"><span class="header-section-number">15</span> Modelización lineal</a></li>
<li><a class="" href="cap-glm.html"><span class="header-section-number">16</span> Modelos lineales generalizados</a></li>
<li><a class="" href="cap-gam.html"><span class="header-section-number">17</span> Modelos aditivos generalizados</a></li>
<li><a class="" href="cap-mxm.html"><span class="header-section-number">18</span> Modelos mixtos</a></li>
<li><a class="" href="cap-sparse.html"><span class="header-section-number">19</span> Modelos sparse y métodos penalizados de regresión</a></li>
<li><a class="" href="cap-series-temp.html"><span class="header-section-number">20</span> Modelización de series temporales</a></li>
<li><a class="" href="cap-discriminante.html"><span class="header-section-number">21</span> Análisis discriminante</a></li>
<li><a class="" href="cap-conjunto.html"><span class="header-section-number">22</span> Análisis conjunto</a></li>
<li><a class="" href="tablas-contingencia.html"><span class="header-section-number">23</span> Análisis de tablas de contingencia</a></li>
<li class="book-part">Machine learning supervisado</li>
<li><a class="" href="cap-arboles.html"><span class="header-section-number">24</span> Árboles de clasificación y regresión</a></li>
<li><a class="" href="cap-svm.html"><span class="header-section-number">25</span> Máquinas de vector soporte</a></li>
<li><a class="" href="cap-knn.html"><span class="header-section-number">26</span> Clasificador k-vecinos más próximos</a></li>
<li><a class="" href="cap-naive-bayes.html"><span class="header-section-number">27</span> Naive Bayes</a></li>
<li><a class="" href="cap-bagg-rf.html"><span class="header-section-number">28</span> Métodos ensamblados: bagging y random forest</a></li>
<li><a class="" href="cap-boosting-xgboost.html"><span class="header-section-number">29</span> Boosting y el algoritmo XGBoost</a></li>
<li class="book-part">Machine learning no supervisado</li>
<li><a class="" href="jerarquico.html"><span class="header-section-number">30</span> Análisis cluster: clusterización jerárquica</a></li>
<li><a class="" href="no-jerarquico.html"><span class="header-section-number">31</span> Análisis cluster: clusterización no jerárquica</a></li>
<li><a class="" href="acp.html"><span class="header-section-number">32</span> Análisis de componentes principales</a></li>
<li><a class="" href="an%C3%A1lisis-factorial.html"><span class="header-section-number">33</span> Análisis factorial</a></li>
<li><a class="" href="escalamiento-multidimensional.html"><span class="header-section-number">34</span> Escalamiento multidimensional</a></li>
<li><a class="" href="correspondencias.html"><span class="header-section-number">35</span> Análisis de correspondencias</a></li>
<li class="book-part">Deep learning</li>
<li><a class="" href="capNN.html"><span class="header-section-number">36</span> Redes neuronales artificiales</a></li>
<li><a class="" href="cap-redes-convol.html"><span class="header-section-number">37</span> Redes neuronales convolucionales</a></li>
<li class="book-part">Ciencia de datos de texto y redes</li>
<li><a class="" href="mineria-textos.html"><span class="header-section-number">38</span> Minería de textos</a></li>
<li><a class="" href="grafos.html"><span class="header-section-number">39</span> Análisis de grafos y redes sociales</a></li>
<li class="book-part">Ciencia de datos espaciales</li>
<li><a class="" href="datos-espaciales.html"><span class="header-section-number">40</span> Trabajando con datos espaciales</a></li>
<li><a class="" href="geo.html"><span class="header-section-number">41</span> Geoestadística</a></li>
<li><a class="" href="cap-econom-esp.html"><span class="header-section-number">42</span> Modelos econométricos espaciales</a></li>
<li><a class="" href="cap-pp.html"><span class="header-section-number">43</span> Procesos de puntos</a></li>
<li class="book-part">Comunica y colabora</li>
<li><a class="" href="id_120007-informes.html"><span class="header-section-number">44</span> Informes reproducibles con R Markdown y Quarto</a></li>
<li><a class="" href="shiny.html"><span class="header-section-number">45</span> Creación de aplicaciones web interactivas con Shiny</a></li>
<li><a class="" href="github.html"><span class="header-section-number">46</span> Git y GitHub R</a></li>
<li><a class="" href="geoproces.html"><span class="header-section-number">47</span> Geoprocesamiento en nube</a></li>
<li class="book-part">Casos de estudio en ciencia de datos</li>
<li><a class="" href="cap-crimen.html"><span class="header-section-number">48</span> Análisis de una red criminal</a></li>
<li><a class="" href="cap-publicidad.html"><span class="header-section-number">49</span> Optimización de inversiones publicitarias</a></li>
<li><a class="" href="cap-twitter.html"><span class="header-section-number">50</span> ¿Cómo twitea Elon Musk?</a></li>
<li><a class="" href="cap-periodismo.html"><span class="header-section-number">51</span> Análisis electoral: de Rstudio a su periódico</a></li>
<li><a class="" href="paro-clm.html"><span class="header-section-number">52</span> Crisis: impacto en el paro de Castilla-La Mancha</a></li>
<li><a class="" href="cap-rfm.html"><span class="header-section-number">53</span> Segmentación de clientes en el comerico minorista</a></li>
<li><a class="" href="cap-medicina.html"><span class="header-section-number">54</span> Análisis de datos en medicina</a></li>
<li><a class="" href="cap-futbol.html"><span class="header-section-number">55</span> Messi y Ronaldo: dos ídolos desde la perspectiva de los datos</a></li>
<li><a class="" href="cambioclimatico.html"><span class="header-section-number">56</span> Un dato sobre el cambio climático</a></li>
<li><a class="" href="cap-ree.html"><span class="header-section-number">57</span> Predicción de consumo eléctrico con redes neuronales</a></li>
<li><a class="" href="cap-sist-exp.html"><span class="header-section-number">58</span> Implementación de un sistema experto en el ámbito pediátrico</a></li>
<li><a class="" href="nlp-textil.html"><span class="header-section-number">59</span> El procesamiento del lenguaje natural para tendencias de moda en textil</a></li>
<li><a class="" href="cap-fraude.html"><span class="header-section-number">60</span> Detección de fraude de tarjetas de crédito</a></li>
<li class="book-part">Appendix</li>
<li><a class="" href="info-session.html"><span class="header-section-number">A</span> Información de la sesión</a></li>
<li><a class="" href="referncias.html">Referncias</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="Fundainfer" class="section level1" number="13">
<h1>
<span class="header-section-number">Capítulo 13</span> Inferencia estadística<a class="anchor" aria-label="anchor" href="#Fundainfer"><i class="fas fa-link"></i></a>
</h1>
<p><em>Mª Leticia Meseguer Santamaría</em><span class="math inline">\(^{a}\)</span> y <em>Manuel Vargas Vargas</em><span class="math inline">\(^{a}\)</span></p>
<p><span class="math inline">\(^{a}\)</span> Universidad de Castilla-La Mancha</p>
<div id="introinfer" class="section level2" number="13.1">
<h2>
<span class="header-section-number">13.1</span> Introducción<a class="anchor" aria-label="anchor" href="#introinfer"><i class="fas fa-link"></i></a>
</h2>
<p>Cuando se estudian fenómenos mediante variables aleatorias, el objetivo estadístico básico es determinar cuáles son las distribuciones probabilísticas que rigen dichas variables o algunas características determinadas por ellas. Es este comportamiento aleatorio el que permite hacer predicciones con unos márgenes de error conocidos, analizar y cuantificar la relación entre variables, evaluar si hipótesis o modelos teóricos son congruentes con los datos disponibles, etc. Así, en la práctica, cuando se estudia una variable <span class="math inline">\(X\)</span>, lo habitual es que se desconozca su distribución probabilística, <span class="math inline">\(F(x)\)</span>, pero que se disponga de un conjunto de realizaciones <span class="math inline">\((x_1,...,x_n)\)</span>, también llamado muestra, valores concretos de dicha variable a partir de los cuales “aproximar” la distribución desconocida.</p>
<p>La inferencia estadística proporciona las herramientas y técnicas que permiten, a partir de la información muestral, extrapolar resultados a la distribución poblacional con márgenes de error conocidos. Un primer objetivo (más detallado en el Cap. <a href="muestreo.html#muestreo">14</a>) es analizar qué condiciones debe cumplir la muestra para que su información sea válida y extrapolable a toda la población (es la conocida como <strong>teoría de muestreo</strong>). Un segundo objetivo es establecer los mecanismos que permitan dicha extrapolación manteniendo controlados los errores de muestreo.</p>
<p>Es habitual que se conozca (o se asuma) que la distribución poblacional <span class="math inline">\(F(x)\)</span> pertenezca a alguna familia paramétrica, es decir, que se asuma su forma funcional pero que dependa de algunos parámetros (lo más frecuente es que se asuma la normalidad, pero podría ser cualquiera de los modelos paramétricos existentes). Se habla entonces de <strong>inferencia paramétrica</strong>, ya que se usa la información muestral para determinar los “mejores” valores (bajo algún criterio) de los parámetros que rigen la distribución poblacional, existiendo tres planteamientos básicos: estimación puntual (Sec. <a href="Fundainfer.html#estimpuntual">13.3</a>), por intervalo (Sec. <a href="Fundainfer.html#estimintervalos">13.4</a>) y contraste de hipótesis (Sec. <a href="Fundainfer.html#contrhip">13.5</a>).
</p>
<p>También hay situaciones en las que la forma funcional de la distribución poblacional es desconocida, o se duda de que la familia paramétrica considerada sea adecuada. En estos casos, bajo el nombre genérico de <strong>inferencia no paramétrica</strong>, se plantean contrastes que buscan determinar cuándo es posible asumir un modelo concreto de distribución, entre los que destacan, por su frecuente uso, los contrastes de normalidad (Sec. <a href="Fundainfer.html#contrnormalidad">13.8</a>). Otra alternativa que permite aproximar características poblacionales sin asumir ninguna distribución poblacional concreta es el <strong>remuestreo</strong>, fundamentalmente el denominado “<em>bootstrap</em>” (se aborda en el Cap. <a href="muestreo.html#muestreo">14</a>).</p>
</div>
<div id="mas" class="section level2" number="13.2">
<h2>
<span class="header-section-number">13.2</span> Muestreo aleatorio simple<a class="anchor" aria-label="anchor" href="#mas"><i class="fas fa-link"></i></a>
</h2>
<p>Al estudiar una variable poblacional, <span class="math inline">\(X\)</span>, de la que se desconoce su distribución, llamada <strong>distribución poblacional, <span class="math inline">\(F(x)\)</span></strong>, se utiliza la información suministrada por una <strong>muestra</strong> obtenida por algún método de muestreo probabilístico que garantice que sea representativa de la variable poblacional.</p>
<p>En la mayoría de los casos y técnicas estadísticas se asume que la muestra está obtenida mediante el método básico de muestreo, conocido como <strong>muestreo aleatorio simple</strong>, consistente en seleccionar totalmente al azar y con reemplazo a los individuos de la muestra, por lo que todos tienen la misma probabilidad de formar parte de ella. De esta forma, dada una distribución poblacional <span class="math inline">\(F(x)\)</span>, una muestra aleatoria simple (m.a.s.) es una realización de un conjunto de <span class="math inline">\(n\)</span> variables aleatorias independientes e idénticamente distribuidas <span class="math inline">\(X=(X_1,...,X_n)\)</span>, denominadas <strong>variables muestrales</strong> y cuya <strong>distribución conjunta</strong> es de la forma:</p>
<p><span class="math display" id="eq:distrconjunta">\[\begin{equation}
F(X_1,...,X_n)=F_{X_1}(x_1)...F_{X_n}(x_n)=F(x_1)...F(x_n).
\tag{13.1}
\end{equation}\]</span></p>
<p>Una herramienta básica para la inferencia es la <strong>distribución empírica de la muestra</strong>, definida como:</p>
<p><span class="math display" id="eq:distrempirica">\[\begin{equation}
\tag{13.2}
\hat{\mathbb{F}}_n (x)= {1 \over n} \sum_{i=1}^n \mathbb{I}_{(-\infty ,x]}(X_i),
\end{equation}\]</span></p>
<p>donde <span class="math inline">\(\mathbb{I}_{(-\infty ,x]}(X_i)\)</span> es una función indicadora que toma el valor 1 si <span class="math inline">\(X_1 \leq x\)</span> y 0 en caso contrario.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Es decir, la distribución empírica de la muestra indica, para cada valor &lt;em&gt;x&lt;/em&gt;, la proporción de elementos de la muestra que toman un valor menor o igual que él.&lt;/p&gt;"><sup>99</sup></a></p>
<p>La gran ventaja del muestreo aleatorio simple consiste en que, dada una m.a.s. <span class="math inline">\((X_1,..., X_n)\)</span>:</p>
<p><span class="math display" id="eq:glivenko">\[\begin{equation}
\tag{13.3}
\underset {n \rightarrow \infty}{lim} \ E \left [ {\left ( \hat{\mathbb{F}}_n (x)- F(x) \right )^2} \right ] = 0,
\end{equation}\]</span></p>
<p>expresión conocida como <em>teorema de Glivenko-Cantelli</em>. Este resultado es fundamental en inferencia, pues garantiza que el muestreo aleatorio simple produce muestras representativas de la población, ya que, a medida que aumenta el tamaño muestral, la distribución empírica de la muestra se aproxima cada vez más a la distribución poblacional (véase Fig. <a href="Fundainfer.html#fig:150015distrempir">13.1</a>).<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Un tema que se abordará en el Cap. &lt;a href="muestreo.html#muestreo"&gt;14&lt;/a&gt; es la determinación del tamaño muestral necesario para que la aproximación tenga un error menor que uno prefijado.&lt;/p&gt;'><sup>100</sup></a> Así, cualquier característica (media, varianza…) de una distribución poblacional puede ser aproximada por su equivalente en la distribución empírica.</p>
<div class="sourceCode" id="cb172"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">3</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">196</span><span class="op">)</span></span>
<span><span class="va">x1</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">20</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/ecdf.html">plot.ecdf</a></span><span class="op">(</span><span class="va">x1</span>, main <span class="op">=</span> <span class="st">"n=20"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/curve.html">curve</a></span><span class="op">(</span><span class="va">pnorm</span>, add <span class="op">=</span> <span class="cn">TRUE</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span>
<span><span class="va">x2</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">50</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/ecdf.html">plot.ecdf</a></span><span class="op">(</span><span class="va">x2</span>, main <span class="op">=</span> <span class="st">"n=50"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/curve.html">curve</a></span><span class="op">(</span><span class="va">pnorm</span>, add <span class="op">=</span> <span class="cn">TRUE</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span>
<span><span class="va">x3</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/stats/Normal.html">rnorm</a></span><span class="op">(</span><span class="fl">200</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/ecdf.html">plot.ecdf</a></span><span class="op">(</span><span class="va">x3</span>, main <span class="op">=</span> <span class="st">"n=200"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/graphics/curve.html">curve</a></span><span class="op">(</span><span class="va">pnorm</span>, add <span class="op">=</span> <span class="cn">TRUE</span>, col <span class="op">=</span> <span class="st">"red"</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:150015distrempir"></span>
<img src="img/150015img01.png" alt="Distribución empírica para muestras de diferente tamaño de una distribución Normal" width="60%"><p class="caption">
Figura 13.1: Distribución empírica para muestras de diferente tamaño de una distribución Normal
</p>
</div>
<p>Es muy frecuente que, a efectos de inferencia, no se estudie el comportamiento aleatorio de toda la muestra (su distribución conjunta) sino que interese el comportamiento de una función de la muestra que no dependa de ningún valor desconocido, <span class="math inline">\(T(X)=T(X_1,...,X_n)\)</span>, llamada genéricamente <strong>estadístico muestral</strong>; dicho comportamiento vendrá determinado por la <strong>distribución en el muestreo</strong> del estadístico <span class="math inline">\(T(X)\)</span>. El hecho de utilizar una m.a.s. permite establecer resultados de interés sobre los estadísticos o, en algunos casos, incluso obtener la distribución en el muestreo exacta de los estadísticos más usuales (Sec. <a href="Fundainfer.html#pobnormales">13.6</a>).</p>
<p>Así, dadas una variable poblacional <span class="math inline">\(X\)</span> con varianza finita y una m.a.s., se define la <strong>media muestral</strong> (aleatoria) como:</p>
<p><span class="math display" id="eq:mediamuestral">\[\begin{equation}
\tag{13.4}
\bar X = \frac {X_1, + ... + X_n}{n}.
\end{equation}\]</span></p>
<p>El hecho de utilizar una m.a.s. garantiza que:</p>
<p><span class="math display">\[\begin{equation}
E[\bar X] = E[X] \ \text{;} \ Var(\bar X)=\frac{Var(X)}{n}.
\end{equation}\]</span></p>
<p>Este resultado es muy útil, ya que indica que la variabilidad de la media muestral es más pequeña que la variabilidad de la variable poblacional, siendo inversamente proporcional al tamaño muestral.</p>
<p>Otro estadístico muy utilizado es la <strong>varianza muestral</strong>,<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;que, como estadístico, también es aleatoria&lt;/p&gt;"><sup>101</sup></a> que se define como:</p>
<p><span class="math display" id="eq:varmuestral">\[\begin{equation}
\tag{13.5}
S^2 = {\sum_{i=1}^n \left ( X_i - \bar X \right ) ^2 \over n}.
\end{equation}\]</span></p>
<p>En este caso, su esperanza es:</p>
<p><span class="math display">\[\begin{equation}
E[S^2] = \frac {n-1}{n} Var[X],
\end{equation}\]</span></p>
<p>que no coincide con la varianza poblacional. Para evitar este hecho, se define la <strong>cuasivarianza muestral</strong> (aleatoria):</p>
<p><span class="math display" id="eq:cuasivarmuestral">\[\begin{equation}
\tag{13.6}
S_c^2 = {\sum_{i=1}^n \left ( X_i - \bar X \right ) ^2 \over {n-1}},
\end{equation}\]</span></p>
<p>estadístico para el que sí se cumple que <span class="math inline">\(E[S_c ^2] = Var[X]\)</span>, ya que existe una relación de proporcionalidad entre ambos estadísticos <span class="math inline">\(nS^2 = (n-1)S_c ^2\)</span>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;Muchos textos, sobre todo anglosajones, no hacen esta distinción, sino que denominan directamente &lt;em&gt;“varianza muestral”&lt;/em&gt; a la cuasivarianza. En &lt;strong&gt;R&lt;/strong&gt;, por ejemplo, las funciones &lt;code&gt;var()&lt;/code&gt; o &lt;code&gt;sd()&lt;/code&gt; proporcionan la cuasivarianza y cuasidesviación típica muestrales respectivamente, matiz que hay que tener siempre presente.&lt;/p&gt;"><sup>102</sup></a></p>
</div>
<div id="estimpuntual" class="section level2" number="13.3">
<h2>
<span class="header-section-number">13.3</span> Estimación puntual<a class="anchor" aria-label="anchor" href="#estimpuntual"><i class="fas fa-link"></i></a>
</h2>
<p>Sea una población caracterizada por una distribución poblacional, <span class="math inline">\(F (x,\theta)\)</span>, de una familia paramétrica de la que se desconoce el valor del parámetro <span class="math inline">\(\theta \in \Theta\)</span>, donde <span class="math inline">\(\Theta\)</span> es el espacio paramétrico (conjunto de posibles valores de <span class="math inline">\(\theta\)</span>). Dada una m.a.s. <span class="math inline">\(X=(X_1,...,X_n)\)</span>, se considera como <em>estimador</em> de <span class="math inline">\(\theta\)</span> a un estadístico muestral cuyo resultado sea un posible valor del parámetro:</p>
<p><span class="math display" id="eq:estimador">\[\begin{equation}
\tag{13.7}
\hat{\theta}=T(X)=T(X_1,...,X_n) \in \Theta.
\end{equation}\]</span></p>
<p>La siguiente expresión corresponde al <strong>error cuadrático medio</strong> de un estimador:</p>
<p><span class="math display" id="eq:ecm">\[\begin{equation}
\tag{13.8}
ECM_\theta (\hat{\theta})=E_\theta \left[ { \left ( \hat{\theta}-\theta \right ) ^2 } \right],
\end{equation}\]</span></p>
<p>que proporciona un valor medio del error que se comete al “aproximar” el verdadero valor <span class="math inline">\(\theta\)</span> por el resultado del estimador <span class="math inline">\(\hat{\theta}\)</span>.
Así, el criterio de <em>“mínimos cuadrados”</em> propone utilizar el estimador que minimiza el error cuadrático medio:</p>
<p><span class="math display">\[\begin{equation}
\hat{\theta}_{MC}= \underset {\hat{\theta}} {min} E_\theta \left[ {\left ( \hat{\theta}-\theta \right )^2} \right].
\end{equation}\]</span></p>
<p>Desarrollando la expresión del ECM (<span class="math inline">\(\ref{eq:ecm}\)</span>), éste se puede re-expresar como</p>
<p><span class="math display">\[\begin{equation}
ECM_\theta (\hat{\theta})=Var_\theta (\hat{\theta}) + \left ( E_{\theta}(\hat{\theta}) - \theta \right ) ^2  = Var_\theta (\hat{\theta}) + b_\theta ^2 (\hat{\theta}),
\end{equation}\]</span></p>
<p>donde <span class="math inline">\(b_\theta(\hat{\theta}) =\left ( E_{\theta}(\hat{\theta}) - \theta \right )\)</span> se conoce como <strong>sesgo</strong> del estimador (<em>bias</em>, en inglés). Así, el ECM de un estimador depende de su varianza y de su sesgo al cuadrado.</p>
<p>Por tanto, la determinación del <em>“mejor”</em> estimador, bajo el criterio de mínimos cuadrados, se puede llevar a cabo en dos pasos:</p>
<ul>
<li><p>Seleccionar estimadores “insesgados”, es decir, de sesgo cero, o sea, <span class="math inline">\(E(\hat{\theta})=\theta\)</span> (el valor medio del estimador coincide con el parámetro).</p></li>
<li><p>De entre los estimadores inesgados, seleccionar el de varianza mínima, <span class="math inline">\(Var(\hat{\theta}_{MC})= \underset {\hat{\theta}} {min} Var(\hat{\theta})\)</span>.</p></li>
</ul>
<p>Queda fuera del objetivo de este capítulo plantear la obtención del estimador de mínimos cuadrados para cualquier distribución poblacional y parámetros, que el lector interesado puede encontrar en cualquier texto teórico de inferencia estadística (<span class="citation">Casella and Berger (<a href="referncias.html#ref-CasellaBerger2007" role="doc-biblioref">2007</a>)</span>, <span class="citation">Blais (<a href="referncias.html#ref-Blais2020" role="doc-biblioref">2020</a>)</span>, <span class="citation">Almudevar (<a href="referncias.html#ref-Almudevar2021" role="doc-biblioref">2021</a>)</span>).</p>
<p>Otro planteamiento para encontrar estimadores puntuales se basa en la función de densidad conjunta de la muestra, que depende de ésta y del parámetro que caracteriza a la distribución poblacional:</p>
<p><span class="math display" id="eq:verosimilitud">\[\begin{equation}
\tag{13.9}
f(x_1,...,x_n;\theta)=f(x_1;\theta)...f(x_n;\theta)=L(\theta;x_1,...,x_n).
\end{equation}\]</span></p>
<p>Considerando el parámetro como fijo, la función se interpreta como la densidad de probablilidad de la muestra. Sin embargo, si se considera que la muestra está dada, entonces se puede interpretar como una función del parámetro que mide la <strong>verosimilitud</strong> (<em>likelihood</em>, en inglés) de cada valor del parámetro en función de la muestra obtenida. Así, el criterio para determinar el <em>“mejor”</em> estimador puede ser seleccionar aquél que maximiza la función de verosimilitud; se obtiene entonces el conocido como <strong>estimador máximo verosímil</strong> :</p>
<p><span class="math display">\[\begin{equation}
\hat{\theta}_{MV}= \underset {\theta} {max} L(\theta;x_1,...,x_n).
\end{equation}\]</span></p>
<p>Para el cálculo del estimador máximo verosímil no se suele utilizar la función de verosimilitud, sino su logaritmo (que alcanza los máximos y mínimos en los mismos puntos), derivando respecto al parámetro e igualando a cero (ecuación de verosimilitud).</p>
<p>Este método suele proporcionar estimadores con buenas propiedades estadísticas y, en muchos casos, suele conducir al mismo resultado que el método de mínimos cuadrados.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content="&lt;p&gt;En las distribuciones usuales es así, salvo que el estimador de máxima verosimilitud sea sesgado, como es el caso de estimar la varianza en una distibución normal.&lt;/p&gt;"><sup>103</sup></a> En las distribuciones usuales, es relativamente sencillo obtener la ecuación de verosimilitud y resolverla, por lo que se dispone de estimadores máximo verosímiles conocidos. En modelos más elaborados, la resolución de la ecuación de verosimilitud se puede complicar, hasta el extremo de que haya que recurrir a métodos numéricos de aproximación.</p>
<p>Una alternativa computacionalmente más sencilla es la basada en el conocido como <strong>método de los momentos</strong>. El planteamiento básico es expresar el parámetro en función de los momentos poblacionales (esperanza, varianza, etc.) y utilizar como estimador la misma función pero de los momentos muestrales (media muestral, varianza muestral, etc.). En las distribuciones más usuales, los parámetros suelen ser momentos poblacionales o tranformadas simples de éstos, por lo que el método de los momentos es muy sencillo. Como contrapartida, es más difícil evaluar las propiedades estadísticas de estos estimadores, salvo que coincidan con los de mínimos cuadrados o de máxima verosimilitud.</p>
<p>En <strong>R</strong>, el paquete <code>fdistrplus</code> dispone de la función <code><a href="https://rdrr.io/pkg/fitdistrplus/man/fitdist.html">fitdist()</a></code>, que permite la obtención de los estimadores para las distribuciones usuales por diversos métodos, incluidos el de máxima verosimilitud (<code>mle</code>) y el de los momentos (<code>mme</code>).</p>
</div>
<div id="estimintervalos" class="section level2" number="13.4">
<h2>
<span class="header-section-number">13.4</span> Estimación por intervalos<a class="anchor" aria-label="anchor" href="#estimintervalos"><i class="fas fa-link"></i></a>
</h2>
<p>Dado que todo estimador es una variable aleatoria, su valor concreto, la <em>“estimación”</em> del parámetro <span class="math inline">\(\hat\theta\)</span>, depende de la muestra. Esta variación muestral ocasiona incertidumbre sobre la estimación. Una forma de incluir esta variabilidad en la estimación puede consistir en sustituir la estimación puntual por un intervalo de valores en el que se tenga un cierto nivel de confianza de que contenga al verdadero valor del parámetro.</p>
<p>El método más extendido para obtener <strong>intervalos de confianza</strong> consiste en utilizar un estimador puntual y su distribución en el muestreo para construir un intervalo que contenga, con cierta probabilidad <span class="math inline">\((1-\alpha)\)</span>, el verdadero valor <span class="math inline">\(\theta\)</span>:</p>
<p><span class="math display" id="eq:interconfianza">\[\begin{equation}
\tag{13.10}
IC_{(1-\alpha)}=[LIC , LSC] \ \text{tal que} \ P \left ( LIC \leq \theta \leq LSC  \right ) = (1-\alpha),
\end{equation}\]</span></p>
<p>donde los límites inferior (LIC) y superior (LSC) de confianza, denominados <strong>valores críticos</strong>, dependen de la desviación típica del estimador y de constantes asociadas a su distribución y al nivel de confianza <span class="math inline">\((1-\alpha)\)</span>. En esta ecuación, tanto el LIC como el LSC son variables aleatorias; cuando se utilizan los datos de una muestra, se convierten en valores reales, por lo que no se puede hablar de <em>“probabilidad de que el parámetro esté dentro del intervalo”</em>, sino que se habla de <em>“confianza en que el intervalo contenga el valor del parámetro”</em>.</p>
<p>En <strong>R</strong>, el paquete <code>Rlab</code> permite obtener los valores críticos de las distribuciones usuales a través de los cuantiles, anteponiendo <em>q</em> al nombre de la distribución (véase la Tabla <a href="Funda-probab.html#tab:distribuciones">12.1</a> “Funciones de distribución en <strong>R</strong>”); por ejemplo, usando las funciones <code><a href="https://rdrr.io/r/stats/Binomial.html">qbinom()</a></code>, <code><a href="https://rdrr.io/r/stats/Normal.html">qnorm()</a></code>, <code><a href="https://rdrr.io/r/stats/TDist.html">qt()</a></code>, <code><a href="https://rdrr.io/r/stats/Fdist.html">qf()</a></code>, etc.. Igualmente, el paquete <code>DescTools</code> dispone de funciones para calcular intervalos de confianza en poblaciones normales para la media (<code><a href="https://andrisignorell.github.io/DescTools/reference/MeanCI.html">MeanCI()</a></code>), la diferencia de medias (<code><a href="https://andrisignorell.github.io/DescTools/reference/MeanDiffCI.html">MeanDiffCI()</a></code>), la mediana (<code><a href="https://andrisignorell.github.io/DescTools/reference/MedianCI.html">MedianCI()</a></code>), cualquier cuantil (<code><a href="https://andrisignorell.github.io/DescTools/reference/QuantileCI.html">QuantileCI()</a></code>) o la varianza (<code><a href="https://andrisignorell.github.io/DescTools/reference/VarCI.html">VarCI()</a></code>). Por último, en el caso de no conocer la distribución en el muestreo del estimador, se puede recurrir al remuestreo por <em>bootstrap</em>, que se detallará en el Cap. <a href="muestreo.html#muestreo">14</a>, indicando el método <code>boot</code> en las funciones anteriores.</p>
</div>
<div id="contrhip" class="section level2" number="13.5">
<h2>
<span class="header-section-number">13.5</span> Contrastes de hipótesis<a class="anchor" aria-label="anchor" href="#contrhip"><i class="fas fa-link"></i></a>
</h2>
<p>Hay situaciones donde no interesa tanto estimar el valor de un parámetro sino decidir si la información muestral es congruente con algún valor concreto del parámetro. En estos casos, se puede establecer como <strong>hipótesis</strong> que el parámetro toma un valor concreto y <em>contrastar</em> si es verosímil haber obtenido el resultado muestral dado. Este planteamiento se conoce como <strong>contrastes de significación</strong>.</p>
<p>Así, se establece una hipótesis, históricamente conocida como <strong>hipótesis nula</strong>, que determina un valor del parámetro:</p>
<p><span class="math display">\[\begin{equation}
H_0 \equiv \theta = \theta_0.
\end{equation}\]</span></p>
<p>Suponiendo cierta la hipótesis nula, la distribución muestral del estimador permite obtener la probabilidad de observar un valor del estimador más <em>“distante”</em> del valor del parámetro fijado en la hipótesis nula que el obtenido en la muestra, probabilidad conocida como <strong>p-valor</strong>: si es muy pequeño, es muy poco probable que se observe el valor obtenido en la muestra cuando la hipótesis es cierta, por lo que la evidencia empírica no es congruente con ella; si no es pequeño, dicho valor es probable que se observe (bajo la hipótesis nula), por lo que no habría evidencia empírica <em>“en contra”</em> de ella.</p>
<p>Se habla de <strong>p-valor bilateral</strong> o “a dos colas” cuando la distancia se considera tanto por la derecha como por la izquierda de la distribución del estimador bajo la hipótesis nula. En caso de que se considere sólo por la izquierda o por la derecha, se habla de <strong>p-valor unilateral</strong> (a la izquierda o a la derecha, respectivamente) o “a una cola”. La comparación (distancia) entre el valor del parámetro establecido en la hipótesis nula y el del estimador de dicho parámetro puede llevarse a cabo por diferencia (tal es el caso del contraste de medias) o por cociente (caso de los contrastes de varianzas).</p>
<p>Habitualmente, se considera que un p-valor por debajo de 0.05 ya indica que la evidencia empírica no permite asumir como cierta la hipótesis nula, expresándose como que el valor del parámetro es <em>“significativamente distinto (menor o mayor)”</em> que <span class="math inline">\(\theta_0\)</span>. También es posible interpretar el p-valor como <em>“la probabilidad máxima de cometer el error de rechazar la hipótesis nula cuando es cierta”</em>, abreviado como <em>“tamaño del error si se rechaza la hipótesis nula”</em>.</p>
<p>Estos contrastes de significación, originalmente desarrollados por Ronald Fisher, fueron incluidos en un esquema de toma de decisiones por Jerzy Neyman y Egon Pearson, planteando que, de no ser cierta la hipótesis nula, se debe plantear una hipótesis alternativa <span class="math inline">\(H_1\)</span>. La decisión de qué hipótesis resulta más congruente con los datos se basa en la comparación por cociente de las verosimilitudes de la muestra bajo cada una de ellas, decidiendo el rechazo de la hipótesis nula a favor de la alternativa cuando dicho cociente es, en probabilidad, inferior a un valor prefijado, <span class="math inline">\(\alpha\)</span>, conocido como <strong>nivel de significación</strong>. Dependiendo de la estructura de las hipótesis (simples, si sólo determinan un valor del parámetro, o compuestas, si determinan más de uno; a su vez, unilaterales si los valores son todos menores, o mayores, que uno dado, o bilaterales en caso contrario) la regla de decisión del contrate resulta más o menos compleja de obtener.</p>
<p>Cuando se adopta el planteamiento decisional de Neyman-Pearson, el nivel de significación permite evaluar la probabilidad de rechazar la hipótesis nula cuando es cierta (conocida también como <strong>probabilidad de error de tipo I</strong>, <span class="math inline">\(\alpha\)</span>), pero también la probabilidad de aceptar como cierta <span class="math inline">\(H_0\)</span> cuando es más correcta <span class="math inline">\(H_1\)</span> (denominada <strong>probabilidad de error de tipo II</strong>, <span class="math inline">\(\beta\)</span>) o, equivalentemente, su complementario: la probabilidad de rechazar <span class="math inline">\(H_0\)</span> cuando <span class="math inline">\(H_1\)</span> es más correcta, probabilidad conocida como <strong>potencia del contraste</strong>, <span class="math inline">\((1-\beta)\)</span>. Si la hipótesis alternativa es simple, es posible evaluar la potencia, por lo que se tiene una medida probabilística de la magnitud de ambos errores (de tipo I y de tipo II), lop cual permite una valoración completa del resultado de la regla de decisión (contraste de hipótesis). Sin embargo, si la hipótesis <span class="math inline">\(H_1\)</span> es compuesta, la magnitud de la potencia es una función evaluada en el rango de valores que establezca dicha hipótesis. En este caso, se dispone de una medida probabilística del error de tipo I pero no del error de tipo II, puesto que depende de valores concretos del parámetro que no son especificados en la hipótesis alternativa, <span class="math inline">\(H_1\)</span>.</p>
<p>Computacionalmente, dada la información muestral, es más fácil calcular el p-valor que plantear el esquema de decisión de Neyman-Pearson, por lo que es la estrategia utilizada en la práctica.</p>
<p>Dado el carácter breve e introductorio de este capítulo, no se profundizará más en este esquema de decisión, que puede consultarse, por ejemplo, en <span class="citation">Casella and Berger (<a href="referncias.html#ref-CasellaBerger2007" role="doc-biblioref">2007</a>)</span>, <span class="citation">Blais (<a href="referncias.html#ref-Blais2020" role="doc-biblioref">2020</a>)</span> o <span class="citation">Almudevar (<a href="referncias.html#ref-Almudevar2021" role="doc-biblioref">2021</a>)</span>, entre otros muchos.</p>
</div>
<div id="pobnormales" class="section level2" number="13.6">
<h2>
<span class="header-section-number">13.6</span> Inferencia estadística paramétrica sobre poblaciones normales<a class="anchor" aria-label="anchor" href="#pobnormales"><i class="fas fa-link"></i></a>
</h2>
<p>Como consecuencia del teorema central del límite (Sec. <a href="Funda-probab.html#tcl">12.5</a>), el supuesto de que la distribución poblacional es una normal es el caso más habitual en la práctica, siendo requisito básico en muchísimas técnicas estadísticas. En este caso, las distribuciones muestrales de los estimadores de los parámetros poblacionales, tanto de la media <span class="math inline">\(\mu\)</span> como de la varianza <span class="math inline">\(\sigma^2\)</span>, son conocidas, lo que facilita la construcción de intervalos de confianza y contrastes de hipótesis.</p>
<p>Así, dada una distribución poblacional normal y una m.a.s. de tamaño <span class="math inline">\(n\)</span>,</p>
<ul>
<li>Para estimar la varianza poblacional, <span class="math inline">\(\sigma ^2\)</span>, el estimador máximo verosímil es la varianza muestral <a href="Fundainfer.html#eq:varmuestral">(13.5)</a>, que es sesgado. El estimador insesgado es la cuasivarianza muestral <a href="Fundainfer.html#eq:cuasivarmuestral">(13.6)</a>. Sus distribuciones en el muestreo, en el caso habitual de que la media poblacional sea desconocida, son:</li>
</ul>
<p><span class="math display">\[\begin{equation}
{n S^2 \over \sigma^2} = {(n-1) S_c^2 \over \sigma^2} \sim \chi^2_{n-1}.
\end{equation}\]</span></p>
<p>Así, el intervalo de confianza a nivel <span class="math inline">\((1-\alpha)\)</span> es:</p>
<p><span class="math display">\[\begin{equation}
IC_{(1-\alpha)} =\left [ {n s^2 \over {\chi^2_{n-1,\alpha /2}}} , {n s^2 \over {\chi^2_{n-1, 1-\alpha /2}}}  \right ],
\end{equation}\]</span></p>
<p>o, equivalentemente, usando la proporcionalidad entre varianza y cuasivarianza muestrales:</p>
<p><span class="math display">\[\begin{equation}
IC_{(1-\alpha)} = \left [ {(n-1) s_c^2 \over {\chi^2_{n-1,\alpha /2}}} , {(n-1) s_c^2 \over {\chi^2_{n-1, 1-\alpha /2}}}  \right ],
\end{equation}\]</span></p>
<p>donde <span class="math inline">\(\chi ^2 _{n-1,\alpha / 2}\)</span> representa el cuantil en la distribución.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Nótese que en los IC se utilizan los valores observados del estimador, &lt;span class="math inline"&gt;\(s^2\)&lt;/span&gt; o &lt;span class="math inline"&gt;\(S_c^2\)&lt;/span&gt;, según se haya utilizado como estimador la varianza o la cuasi-varianza. Lo mismo ocurre en los demás intervalos&lt;/p&gt;'><sup>104</sup></a></p>
<p>Para el contraste de <span class="math inline">\(H_0 \equiv \sigma^2 = \sigma_0^2\)</span>, la “distancia” es <span class="math inline">\({n s^2 \over \sigma^2_0} = {(n-1) s_c^2 \over \sigma_0^2}\)</span>, lo que permite calcular los p-valores mediante una distribución <span class="math inline">\(\chi^2_{n-1}\)</span>.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Nótese que la “distancia” no involucra sólo al valor observado del estimador y el valor del parámetro bajo la hipótesis nula, sino también una constante (en este caso &lt;span class="math inline"&gt;\(n\)&lt;/span&gt; o &lt;span class="math inline"&gt;\(n-1\)&lt;/span&gt;). Ello se hace porque así el valor de esta “distancia” puede compararse directamente con el facilitado por las tablas de la distribución probabilística correspondiente (en este caso una Chi-cuadrado).&lt;/p&gt;'><sup>105</sup></a></p>
<p>Para el caso de querer estimar la desviación típica, basta con calcular la raiz cuadrada del estimador de la varianza, o si se busca un intervalo de confianza, la raíz de los extremos del intervalo para la varianza. Los contrastes de hipótesis son equivalentes, ya que <span class="math inline">\(\sigma^2=\sigma_0^2 \equiv \sigma = \sigma_0\)</span>.</p>
<ul>
<li>Para estimar el parámetro <span class="math inline">\(\mu\)</span> se utiliza el estimador media muestral <span class="math inline">\(\hat{\mu} = \bar X\)</span>, en el que coinciden los métodos de mínimos cuadrados, de máxima verosimilitud y de los momentos, siendo insesgado y de varianza mínima.</li>
</ul>
<p>Si la varianza poblacional es conocida, la distribución en el muestreo de la media muestral es:</p>
<p><span class="math display">\[\begin{equation}
\bar X \sim N \left ( \mu , {\sigma \over {\sqrt{n}}} \right ) \equiv {\bar X - \mu \over {\sigma / \sqrt n}} \sim N(0,1).
\end{equation}\]</span></p>
<p>El intervalo de confianza a nivel <span class="math inline">\((1-\alpha)\)</span> es:</p>
<p><span class="math display">\[\begin{equation}
IC_{(1-\alpha)} =\left [ \bar x - z_{\alpha / 2} {\sigma \over \sqrt n} , \bar x + z_{\alpha / 2} {\sigma \over \sqrt n}  \right ],
\end{equation}\]</span></p>
<p>donde <span class="math inline">\(z_{\alpha/2}\)</span> representa el cuantil en una distribución normal estándar.</p>
<p>Para el contraste de <span class="math inline">\(H_0 \equiv \mu = \mu_0\)</span>, la “distancia” es <span class="math inline">\(\bar X - \mu_0 \over \sigma / \sqrt n\)</span>, lo que permite calcular los p-valores, directamente, mediante una distribución <span class="math inline">\(N(0,1)\)</span>.</p>
<p>Si la varianza poblacional es desconocida, se sustituye por su estimación, por lo que la distribución en el muestreo de la media muestral es:</p>
<p><span class="math display">\[\begin{equation}
{\bar X - \mu \over {S / \sqrt {n-1}}} \equiv {\bar X - \mu \over {S_c / \sqrt n}} \sim t_{n-1}.
\end{equation}\]</span></p>
<p>El intervalo de confianza a nivel <span class="math inline">\((1-\alpha)\)</span> es:</p>
<p><span class="math display">\[\begin{equation}
IC_{(1-\alpha)} =\left [ \bar x - t_{n-1,\alpha / 2} {s \over \sqrt {n-1}} , \bar c + t_{n-1, \alpha / 2} {s \over \sqrt {n-1}}  \right ],
\end{equation}\]</span></p>
<p>o, equivalentemente:</p>
<p><span class="math display">\[\begin{equation}
IC_{(1-\alpha)} = \left [ \bar x - t_{n-1,\alpha / 2} {s_c \over \sqrt n} , \bar x + t_{n-1, \alpha / 2} {s_c \over \sqrt n}  \right ],
\end{equation}\]</span></p>
<p>donde <span class="math inline">\(t_{n-1,\alpha/2}\)</span> representa el cuantil de la distribución <em>t-Student</em>.</p>
<p>Para el contraste de <span class="math inline">\(H_0 \equiv \mu = \mu_0\)</span>, la “distancia” es <span class="math inline">\({\bar X - \mu_0 \over S / \sqrt {n-1}} = {\bar X - \mu_0 \over S_c / \sqrt n}\)</span>, lo que permite calcular los p-valores mediante una distribución <span class="math inline">\(t_{n-1}\)</span>.</p>
<p>A continuación, el interés se centra en la comparación de dos poblaciones normales independientes, X e Y, a partir de muestras <span class="math inline">\((X_1,...,X_n)\)</span> y <span class="math inline">\((Y_1,...,Y_m)\)</span>:</p>
<ul>
<li>Para la comparación de las varianzas poblacionales (una es mayor que la otra, o al revés; y que se lleva a cabo mediante el cociente de las correspondientes varianzas o cuasivarianzas muestrales), se tiene que:</li>
</ul>
<p><span class="math display">\[\begin{equation}
{{{m S_Y^2} \over {(m-1)\sigma_Y^2}} \over {{n S_X^2} \over {(n-1)\sigma_X^2}}} \equiv {S_{cY}^2 / \sigma_Y^2 \over S_{cX} ^2 / \sigma_X^2} \sim F_{m-1,n-1},
\end{equation}\]</span></p>
<p>lo cual permite calcular intervalos de confianza de forma idéntica a la expuesta a los casos anteriores pero con la distribución <span class="math inline">\(F\)</span>. Un caso muy frecuente es querer contrastar si ambas varianzas poblacionales son iguales (el cociente entre ellas es la unidad).</p>
<ul>
<li>Para la comparación de las medias poblacionales (que se lleva a cabo mediante la diferencia de las correspondientes medias muestrales), el caso más común es asumir que las varianzas (aunque desconocidas) son iguales, por lo que el estimador es:</li>
</ul>
<p><span class="math display">\[\begin{equation}
{(\bar X - \bar Y)-(\mu_X - \mu_Y) \over \sqrt{{nS_X^2+mS_Y^2} \over n+m-2} \sqrt{{1\over n} + {1 \over m}}} \sim t_{n+m-2},
\end{equation}\]</span></p>
<p>si se utiliza la varianza muestral como estimador de su homónima poblacional, o:</p>
<p><span class="math display">\[\begin{equation}
{(\bar X - \bar Y)-(\mu_X - \mu_Y) \over \sqrt{{(n-1)S_{cX}^2+(m-1)S_{cY}^2} \over n+m-2} \sqrt{{1\over n} + {1 \over m}}} \sim t_{n+m-2},
\end{equation}\]</span></p>
<p>si se utiliza la cuasivarianza muestral.</p>
<p>Al utilizarse distribuciones t-Student, los intervalos de confianza y contrastes de hipótesis son similares a los del caso de una única población con las correcciones pertinentes.</p>
</div>
<div id="ejemplopobnorm" class="section level2" number="13.7">
<h2>
<span class="header-section-number">13.7</span> Inferencia sobre poblaciones normales con <strong>R</strong><a class="anchor" aria-label="anchor" href="#ejemplopobnorm"><i class="fas fa-link"></i></a>
</h2>
<p>Los datos sobre calidad del aire en la ciudad de Nueva York (<code>airquality</code>) incluyen la variable <code>Wind</code>, que recoge, en mph, la velocidad del viento entre el día 1 de mayo y el 30 de septiembre DE 1973. Los datos de dicha variable se dividen en dos variables <span class="math inline">\(X=\text{Velocidad del viento hasta el 15 de julio}\)</span> e <span class="math inline">\(Y=\text{Velocidad del viento desde el 16 de julio}\)</span>. Asumiendo que las distribuciones poblacionales son normales, se propone:</p>
<ol style="list-style-type: lower-alpha">
<li>Obtener una estimación de la velocidad media y de la desviación típica de ambas variables, usando el método de máxima verosimilitud.</li>
</ol>
<div class="sourceCode" id="cb173"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="https://www.r-project.org">'Rlab'</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="https://lbbe.univ-lyon1.fr/fr/fitdistrplus">'fitdistrplus'</a></span><span class="op">)</span></span>
<span><span class="va">x</span> <span class="op">&lt;-</span> <span class="va">airquality</span><span class="op">$</span><span class="va">Wind</span><span class="op">[</span><span class="fl">1</span><span class="op">:</span><span class="fl">76</span><span class="op">]</span></span>
<span><span class="va">y</span> <span class="op">&lt;-</span> <span class="va">airquality</span><span class="op">$</span><span class="va">Wind</span><span class="op">[</span><span class="fl">77</span><span class="op">:</span><span class="fl">153</span><span class="op">]</span> <span class="co"># Se particiona la muestra en los dos períodos</span></span>
<span><span class="va">mle_x</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/fitdistrplus/man/fitdist.html">fitdist</a></span><span class="op">(</span><span class="va">x</span>, distr <span class="op">=</span> <span class="st">"norm"</span>, method <span class="op">=</span> <span class="st">"mle"</span><span class="op">)</span></span>
<span><span class="va">mle_y</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/fitdistrplus/man/fitdist.html">fitdist</a></span><span class="op">(</span><span class="va">y</span>, distr <span class="op">=</span> <span class="st">"norm"</span>, method <span class="op">=</span> <span class="st">"mle"</span><span class="op">)</span></span>
<span><span class="va">mle_x</span></span>
<span><span class="co">#&gt; Fitting of the distribution ' norm ' by maximum likelihood </span></span>
<span><span class="co">#&gt; Parameters:</span></span>
<span><span class="co">#&gt;       estimate Std. Error</span></span>
<span><span class="co">#&gt; mean 10.640789  0.4274723</span></span>
<span><span class="co">#&gt; sd    3.726618  0.3022685</span></span>
<span><span class="va">mle_y</span></span>
<span><span class="co">#&gt; Fitting of the distribution ' norm ' by maximum likelihood </span></span>
<span><span class="co">#&gt; Parameters:</span></span>
<span><span class="co">#&gt;      estimate Std. Error</span></span>
<span><span class="co">#&gt; mean 9.283117  0.3581657</span></span>
<span><span class="co">#&gt; sd   3.142891  0.2532613</span></span></code></pre></div>
<p>El resultado muestra las estimaciones de la media y la desviación típica de la velocidad del viento ( junto al “<em>error estandar</em>” o desviación típica de los estimadores respectivos) para las dos variables anteriormente creadas.</p>
<p>La orden <code>plot(mle_x)</code> permite visualizar la congruencia entre la muestra y la distribución probabilística basada en las estimaciones realizadas; por ejemplo, optando por el primer período, se obtiene la Fig.<a href="Fundainfer.html#fig:150015mle">13.2</a>, que representa el histograma de los valores muestrales junto a la distribución teórica construida con las estimaciones.</p>
<div class="sourceCode" id="cb174"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html">plot</a></span><span class="op">(</span><span class="va">mle_x</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:150015mle"></span>
<img src="img/150015img02.png" alt="Resultados gráficos de la estimación por máxima verosimilitud" width="60%"><p class="caption">
Figura 13.2: Resultados gráficos de la estimación por máxima verosimilitud
</p>
</div>
<ol start="2" style="list-style-type: lower-alpha">
<li>Construir un intervalo de confianza para la velocidad media del viento hasta el 15 de julio, con un nivel de confianza del 95%.</li>
</ol>
<div class="sourceCode" id="cb175"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="https://andrisignorell.github.io/DescTools/">'DescTools'</a></span><span class="op">)</span></span>
<span><span class="fu"><a href="https://andrisignorell.github.io/DescTools/reference/MeanCI.html">MeanCI</a></span><span class="op">(</span><span class="va">x</span>, conf.level <span class="op">=</span> <span class="fl">0.95</span><span class="op">)</span></span>
<span><span class="co">#&gt;      mean    lwr.ci    upr.ci </span></span>
<span><span class="co">#&gt; 10.640789  9.783563 11.498016</span></span></code></pre></div>
<ol start="3" style="list-style-type: lower-alpha">
<li>Calcular un intervalo de confianza para la desviación típica de la velocidad del viento desde el 16 de julio, con un nivel de confianza del 90%.</li>
</ol>
<div class="sourceCode" id="cb176"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/base/MathFun.html">sqrt</a></span><span class="op">(</span><span class="fu"><a href="https://andrisignorell.github.io/DescTools/reference/VarCI.html">VarCI</a></span><span class="op">(</span><span class="va">y</span>, conf.level <span class="op">=</span> <span class="fl">0.9</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co">#&gt;      var   lwr.ci   upr.ci </span></span>
<span><span class="co">#&gt; 3.163501 2.795147 3.655468</span></span></code></pre></div>
<ol start="4" style="list-style-type: lower-alpha">
<li>¿Se puede considerar que las varianzas poblacionales en ambos períodos son iguales, con un nivel de significación del 1%?</li>
</ol>
<div class="sourceCode" id="cb177"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/var.test.html">var.test</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, conf.level <span class="op">=</span> <span class="fl">0.99</span>, alternative <span class="op">=</span> <span class="st">"two.sided"</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  F test to compare two variances</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  x and y</span></span>
<span><span class="co">#&gt; F = 1.4062, num df = 75, denom df = 76, p-value = 0.1406</span></span>
<span><span class="co">#&gt; alternative hypothesis: true ratio of variances is not equal to 1</span></span>
<span><span class="co">#&gt; 99 percent confidence interval:</span></span>
<span><span class="co">#&gt;  0.7727136 2.5616496</span></span>
<span><span class="co">#&gt; sample estimates:</span></span>
<span><span class="co">#&gt; ratio of variances </span></span>
<span><span class="co">#&gt;           1.406197</span></span></code></pre></div>
<p>El estadístico <em>F-Snedecor</em> de contraste arroja un valor de 1.4062, con un p-valor de 0.1406. Como este p-valor no es pequeño (es superior al nivel de significación prefijado), no hay suficiente evidencia empírica como para rechazar la hipótesis nula de igualdad de varianzas.</p>
<ol start="5" style="list-style-type: lower-alpha">
<li>Teniendo en cuenta los resultados del apartado anterior, ¿se puede afirmar que la velocidad media del viento en el primer período es mayor que la del segundo, con un nivel de significación del 1%?</li>
</ol>
<div class="sourceCode" id="cb178"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/t.test.html">t.test</a></span><span class="op">(</span><span class="va">x</span>, <span class="va">y</span>, conf.level <span class="op">=</span> <span class="fl">0.99</span>, alternative <span class="op">=</span> <span class="st">"greater"</span>, var.equal <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Two Sample t-test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  x and y</span></span>
<span><span class="co">#&gt; t = 2.4212, df = 151, p-value = 0.008328</span></span>
<span><span class="co">#&gt; alternative hypothesis: true difference in means is greater than 0</span></span>
<span><span class="co">#&gt; 99 percent confidence interval:</span></span>
<span><span class="co">#&gt;  0.03918338        Inf</span></span>
<span><span class="co">#&gt; sample estimates:</span></span>
<span><span class="co">#&gt; mean of x mean of y </span></span>
<span><span class="co">#&gt; 10.640789  9.283117</span></span></code></pre></div>
<p>Un p-valor tan bajo (0.008, inferior al nivel de significación prefijado) indica que existe suficiente evidencia empírica como para rechazar la hipótesis nula de igualdad de medias; en otros términos, la evidencia empírica no es suficiente para rechazar, con un nivel de confianza del 99%, que la velocidad media del viento en el primer período es superior a la del segundo.</p>
</div>
<div id="contrnormalidad" class="section level2" number="13.8">
<h2>
<span class="header-section-number">13.8</span> Inferencia estadística no paramétrica: contrastes de normalidad<a class="anchor" aria-label="anchor" href="#contrnormalidad"><i class="fas fa-link"></i></a>
</h2>
<p>Hasta ahora, se ha supuesto que la distribución muestral del estimador era “funcionalmente” conocida, aunque dependiente de un parámetro (o varios). Sin embargo, hay situaciones donde no se conoce cómo se distribuyen los datos, debiendo decidir qué distribución los ha generado. Es lo que se conoce como <strong>inferencia estadística no paramétrica</strong>. En este capítulo no se aborda un planteamiento sistemático de esta rama, sino que se presenta la situación más habitual en la práctica, que es decidir si se puede mantener que una muestra proviene de una distribución normal, supuesto básico en muchas técnicas estadísticas.</p>
<p>Posiblemente el test más potente para contrastar la normalidad sea la prueba de Shapiro-Wilks, que asume como hipótesis nula que los datos están generados por una distribución normal. Un rechazo de esta hipótesis (p-valor muy bajo) debería hacer reflexionar sobre la adecuación de muchas técnicas y la interpretación de los resultados. En <strong>R</strong>, la función <code><a href="https://rdrr.io/r/stats/shapiro.test.html">shapiro.test()</a></code> proporciona dicho contraste de normalidad.</p>
<p>Una alternativa es el uso del test de Kolmogorov-Smirnov, diseñado para comparar las distribuciones de dos muestras, fijando que una de ellas sea la distribución normal (este test puede ser igualmente utilizado para cualquier otra distribución usual). La función <code><a href="https://rdrr.io/r/stats/ks.test.html">ks.test()</a></code> permite en <strong>R</strong> obtener los resultados de este contraste.</p>
<p>Para ilustrar el uso del test de Shapiro-Wilk en <strong>R</strong> se recurre de nuevo a los datos sobre calidad del aire en la ciudad de Nueva York del ejemplo anterior (Sec. <a href="Fundainfer.html#ejemplopobnorm">13.7</a>) y se contrasta si se puede asumir que las variables <code>Temp</code> y <code>Wind</code> están generadas por distribuciones normales:</p>
<div class="sourceCode" id="cb179"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/stats/shapiro.test.html">shapiro.test</a></span><span class="op">(</span><span class="va">airquality</span><span class="op">$</span><span class="va">Temp</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Shapiro-Wilk normality test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  airquality$Temp</span></span>
<span><span class="co">#&gt; W = 0.97617, p-value = 0.009319</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/shapiro.test.html">shapiro.test</a></span><span class="op">(</span><span class="va">airquality</span><span class="op">$</span><span class="va">Wind</span><span class="op">)</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt;  Shapiro-Wilk normality test</span></span>
<span><span class="co">#&gt; </span></span>
<span><span class="co">#&gt; data:  airquality$Wind</span></span>
<span><span class="co">#&gt; W = 0.98575, p-value = 0.1178</span></span></code></pre></div>
<p>Para la variable <code>Temp</code> el p-valor (0,0093) es muy bajo en comparación con los niveles de significación habituales (0,01, 0,05), por lo que hay suficiente evidencia empírica como para rechazar que dicha variable tenga una distribución normal. Por el contrario, en el caso de la variable <code>Wind</code>, el p-valor (0.1178) no es pequeño, por lo que no hay suficiente evidencia como para rechazar que esté generada por una distribución normal. La Fig. <a href="Fundainfer.html#fig:150015qqplots">13.3</a> muestra la comparación entre los cuantiles empíricos de ambas variables y los teóricos de una distribución normal.</p>
<div class="sourceCode" id="cb180"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://rdrr.io/r/graphics/par.html">par</a></span><span class="op">(</span>mfrow <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span>, <span class="fl">2</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/qqnorm.html">qqnorm</a></span><span class="op">(</span><span class="va">airquality</span><span class="op">$</span><span class="va">Temp</span>, main <span class="op">=</span> <span class="st">"Normal Q-Q Plot for Temp"</span><span class="op">)</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/stats/qqnorm.html">qqnorm</a></span><span class="op">(</span><span class="va">airquality</span><span class="op">$</span><span class="va">Wind</span>, main <span class="op">=</span> <span class="st">"Normal Q-Q Plot for Wind"</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:150015qqplots"></span>
<img src="img/150015img03.png" alt="Q-Q Plots normales para las variables Temp (izq) y Wind (der)" width="60%"><p class="caption">
Figura 13.3: Q-Q Plots normales para las variables Temp (izq) y Wind (der)
</p>
</div>
<div id="resumen-12" class="section level3 unnumbered infobox_resume">
<h3>Resumen<a class="anchor" aria-label="anchor" href="#resumen-12"><i class="fas fa-link"></i></a>
</h3>
<p>La inferencia estadística permite estimar la distribución poblacional de una variable a partir de la información suministrada por una muestra. Se abordan los métodos de estimación puntual de los principales parámetros poblacionales y la construcción de intervalos de confianza para ellos, así se implementan y resuelven una serie de contrastes de significación sobre diversas hipótesis.</p>
<p>Para el caso de poblaciones normales, se desarrollan las expresiones operativas de los métodos anteriores. Igualmente, en el ámbito de la inferencia no paramétrica, se presenta un contraste de normalidad que permite decidir cuándo el supuesto de normalidad es adecuado o no.</p>
</div>

</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="Funda-probab.html"><span class="header-section-number">12</span> Probabilidad</a></div>
<div class="next"><a href="muestreo.html"><span class="header-section-number">14</span> Muestreo y remuestreo</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="Índice capítulo"><h2>Índice capítulo</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#Fundainfer"><span class="header-section-number">13</span> Inferencia estadística</a></li>
<li><a class="nav-link" href="#introinfer"><span class="header-section-number">13.1</span> Introducción</a></li>
<li><a class="nav-link" href="#mas"><span class="header-section-number">13.2</span> Muestreo aleatorio simple</a></li>
<li><a class="nav-link" href="#estimpuntual"><span class="header-section-number">13.3</span> Estimación puntual</a></li>
<li><a class="nav-link" href="#estimintervalos"><span class="header-section-number">13.4</span> Estimación por intervalos</a></li>
<li><a class="nav-link" href="#contrhip"><span class="header-section-number">13.5</span> Contrastes de hipótesis</a></li>
<li><a class="nav-link" href="#pobnormales"><span class="header-section-number">13.6</span> Inferencia estadística paramétrica sobre poblaciones normales</a></li>
<li><a class="nav-link" href="#ejemplopobnorm"><span class="header-section-number">13.7</span> Inferencia sobre poblaciones normales con R</a></li>
<li>
<a class="nav-link" href="#contrnormalidad"><span class="header-section-number">13.8</span> Inferencia estadística no paramétrica: contrastes de normalidad</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#resumen-12">Resumen</a></li></ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Fundamentos de ciencia de datos con R</strong>" coordinado por <a href="https://blog.uclm.es/gemafaviles/" class="text-light">Gema Fernández-Avilés y José-María Montero</a>. Generado por última vez el día 2023-06-16.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>Este libro ha sido generado con el paquete de R <a class="text-light" href="https://bookdown.org">bookdown</a>.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
