<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Capítulo 27 Naive Bayes | Fundamentos de ciencia de datos con R</title>
<meta name="author" content="Gema Fernández-Avilés y José-María Montero">
<meta name="description" content="Ramón A. Carrasco\(^{a}\) e Itzcóatl Bueno\(^{b,a}\) \(^{a}\)Universidad Complutense de Madrid \(^{b}\)Instituto Nacional de Estadística  27.1 Introducción Naive Bayes es un algoritmo de...">
<meta name="generator" content="bookdown 0.28 with bs4_book()">
<meta property="og:title" content="Capítulo 27 Naive Bayes | Fundamentos de ciencia de datos con R">
<meta property="og:type" content="book">
<meta property="og:image" content="/img/cover.png">
<meta property="og:description" content="Ramón A. Carrasco\(^{a}\) e Itzcóatl Bueno\(^{b,a}\) \(^{a}\)Universidad Complutense de Madrid \(^{b}\)Instituto Nacional de Estadística  27.1 Introducción Naive Bayes es un algoritmo de...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Capítulo 27 Naive Bayes | Fundamentos de ciencia de datos con R">
<meta name="twitter:description" content="Ramón A. Carrasco\(^{a}\) e Itzcóatl Bueno\(^{b,a}\) \(^{a}\)Universidad Complutense de Madrid \(^{b}\)Instituto Nacional de Estadística  27.1 Introducción Naive Bayes es un algoritmo de...">
<meta name="twitter:image" content="/img/cover.png">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.2/transition.js"></script><script src="libs/bs3compat-0.4.2/tabs.js"></script><script src="libs/bs3compat-0.4.2/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><link href="libs/tabwid-1.1.0/tabwid.css" rel="stylesheet">
<link href="libs/tabwid-1.1.0/scrool.css" rel="stylesheet">
<script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><link rel="stylesheet" href="bs4_style.css">
<link rel="stylesheet" href="bs4_book.css">
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Fundamentos de ciencia de datos con R</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Buscar" aria-label="Buscar">
</form>

      <nav aria-label="Contenido"><h2>Contenido</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Prefacio</a></li>
<li class="book-part">Ciencia, datos, software… y científicos</li>
<li><a class="" href="ciencia-datos.html"><span class="header-section-number">1</span> ¿Es la ciencia de datos una ciencia?</a></li>
<li><a class="" href="metodologia.html"><span class="header-section-number">2</span> Metodología en ciencia de datos</a></li>
<li><a class="" href="ch-110003.html"><span class="header-section-number">3</span> R para ciencia de datos</a></li>
<li><a class="" href="cap-etica.html"><span class="header-section-number">4</span> Ética en la ciencia de datos</a></li>
<li class="book-part">Bienvenidos a la jungla de datos</li>
<li><a class="" href="datos-sql.html"><span class="header-section-number">5</span> Gestión de bases de datos relacionales</a></li>
<li><a class="" href="cap-nosql.html"><span class="header-section-number">6</span> Gestión de bases de datos NoSQL</a></li>
<li><a class="" href="DGDQM.html"><span class="header-section-number">7</span> Gobierno, gestión y calidad del dato</a></li>
<li><a class="" href="id_130009.html"><span class="header-section-number">8</span> Integración y limpieza de datos</a></li>
<li><a class="" href="chap-feature.html"><span class="header-section-number">9</span> Selección y transformación de variables</a></li>
<li><a class="" href="chap-herramientas.html"><span class="header-section-number">10</span> Herramientas para el análisis en ciencia de datos</a></li>
<li><a class="" href="id_120006-aed.html"><span class="header-section-number">11</span> Análisis exploratorio de datos</a></li>
<li class="book-part">Fundamentos de estadística</li>
<li><a class="" href="Funda-probab.html"><span class="header-section-number">12</span> Probabilidad</a></li>
<li><a class="" href="Fundainfer.html"><span class="header-section-number">13</span> Inferencia estadística</a></li>
<li><a class="" href="muestreo.html"><span class="header-section-number">14</span> Muestreo y remuestreo</a></li>
<li class="book-part">Modelización estadística</li>
<li><a class="" href="cap-lm.html"><span class="header-section-number">15</span> Modelización lineal</a></li>
<li><a class="" href="cap-glm.html"><span class="header-section-number">16</span> Modelos lineales generalizados</a></li>
<li><a class="" href="cap-gam.html"><span class="header-section-number">17</span> Modelos aditivos generalizados</a></li>
<li><a class="" href="cap-mxm.html"><span class="header-section-number">18</span> Modelos mixtos</a></li>
<li><a class="" href="cap-sparse.html"><span class="header-section-number">19</span> Modelos sparse y métodos penalizados de regresión</a></li>
<li><a class="" href="cap-series-temp.html"><span class="header-section-number">20</span> Modelización de series temporales</a></li>
<li><a class="" href="cap-discriminante.html"><span class="header-section-number">21</span> Análisis discriminante</a></li>
<li><a class="" href="cap-conjunto.html"><span class="header-section-number">22</span> Análisis conjunto</a></li>
<li><a class="" href="tablas-contingencia.html"><span class="header-section-number">23</span> Análisis de tablas de contingencia</a></li>
<li class="book-part">Machine learning supervisado</li>
<li><a class="" href="cap-arboles.html"><span class="header-section-number">24</span> Árboles de clasificación y regresión</a></li>
<li><a class="" href="cap-svm.html"><span class="header-section-number">25</span> Máquinas de vector soporte</a></li>
<li><a class="" href="cap-knn.html"><span class="header-section-number">26</span> Clasificador k-vecinos más próximos</a></li>
<li><a class="active" href="cap-naive-bayes.html"><span class="header-section-number">27</span> Naive Bayes</a></li>
<li><a class="" href="cap-bagg-rf.html"><span class="header-section-number">28</span> Métodos ensamblados: bagging y random forest</a></li>
<li><a class="" href="cap-boosting-xgboost.html"><span class="header-section-number">29</span> Boosting y el algoritmo XGBoost</a></li>
<li class="book-part">Machine learning no supervisado</li>
<li><a class="" href="jerarquico.html"><span class="header-section-number">30</span> Análisis cluster: clusterización jerárquica</a></li>
<li><a class="" href="no-jerarquico.html"><span class="header-section-number">31</span> Análisis cluster: clusterización no jerárquica</a></li>
<li><a class="" href="acp.html"><span class="header-section-number">32</span> Análisis de componentes principales</a></li>
<li><a class="" href="an%C3%A1lisis-factorial.html"><span class="header-section-number">33</span> Análisis factorial</a></li>
<li><a class="" href="escalamiento-multidimensional.html"><span class="header-section-number">34</span> Escalamiento multidimensional</a></li>
<li><a class="" href="correspondencias.html"><span class="header-section-number">35</span> Análisis de correspondencias</a></li>
<li class="book-part">Deep learning</li>
<li><a class="" href="capNN.html"><span class="header-section-number">36</span> Redes neuronales artificiales</a></li>
<li><a class="" href="cap-redes-convol.html"><span class="header-section-number">37</span> Redes neuronales convolucionales</a></li>
<li class="book-part">Ciencia de datos de texto y redes</li>
<li><a class="" href="mineria-textos.html"><span class="header-section-number">38</span> Minería de textos</a></li>
<li><a class="" href="grafos.html"><span class="header-section-number">39</span> Análisis de grafos y redes sociales</a></li>
<li class="book-part">Ciencia de datos espaciales</li>
<li><a class="" href="datos-espaciales.html"><span class="header-section-number">40</span> Trabajando con datos espaciales</a></li>
<li><a class="" href="geo.html"><span class="header-section-number">41</span> Geoestadística</a></li>
<li><a class="" href="cap-econom-esp.html"><span class="header-section-number">42</span> Modelos econométricos espaciales</a></li>
<li><a class="" href="cap-pp.html"><span class="header-section-number">43</span> Procesos de puntos</a></li>
<li class="book-part">Comunica y colabora</li>
<li><a class="" href="id_120007-informes.html"><span class="header-section-number">44</span> Informes reproducibles con R Markdown y Quarto</a></li>
<li><a class="" href="shiny.html"><span class="header-section-number">45</span> Creación de aplicaciones web interactivas con Shiny</a></li>
<li><a class="" href="github.html"><span class="header-section-number">46</span> Git y GitHub R</a></li>
<li><a class="" href="geoproces.html"><span class="header-section-number">47</span> Geoprocesamiento en nube</a></li>
<li class="book-part">Casos de estudio en ciencia de datos</li>
<li><a class="" href="cap-crimen.html"><span class="header-section-number">48</span> Análisis de una red criminal</a></li>
<li><a class="" href="cap-publicidad.html"><span class="header-section-number">49</span> Optimización de inversiones publicitarias</a></li>
<li><a class="" href="cap-twitter.html"><span class="header-section-number">50</span> ¿Cómo twitea Elon Musk?</a></li>
<li><a class="" href="cap-periodismo.html"><span class="header-section-number">51</span> Análisis electoral: de Rstudio a su periódico</a></li>
<li><a class="" href="paro-clm.html"><span class="header-section-number">52</span> Crisis: impacto en el paro de Castilla-La Mancha</a></li>
<li><a class="" href="cap-rfm.html"><span class="header-section-number">53</span> Segmentación de clientes en el comerico minorista</a></li>
<li><a class="" href="cap-medicina.html"><span class="header-section-number">54</span> Análisis de datos en medicina</a></li>
<li><a class="" href="cap-futbol.html"><span class="header-section-number">55</span> Messi y Ronaldo: dos ídolos desde la perspectiva de los datos</a></li>
<li><a class="" href="cambioclimatico.html"><span class="header-section-number">56</span> Un dato sobre el cambio climático</a></li>
<li><a class="" href="cap-ree.html"><span class="header-section-number">57</span> Predicción de consumo eléctrico con redes neuronales</a></li>
<li><a class="" href="cap-sist-exp.html"><span class="header-section-number">58</span> Implementación de un sistema experto en el ámbito pediátrico</a></li>
<li><a class="" href="nlp-textil.html"><span class="header-section-number">59</span> El procesamiento del lenguaje natural para tendencias de moda en textil</a></li>
<li><a class="" href="cap-fraude.html"><span class="header-section-number">60</span> Detección de fraude de tarjetas de crédito</a></li>
<li class="book-part">Appendix</li>
<li><a class="" href="info-session.html"><span class="header-section-number">A</span> Información de la sesión</a></li>
<li><a class="" href="referncias.html">Referncias</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="cap-naive-bayes" class="section level1" number="27">
<h1>
<span class="header-section-number">Capítulo 27</span> Naive Bayes<a class="anchor" aria-label="anchor" href="#cap-naive-bayes"><i class="fas fa-link"></i></a>
</h1>
<p><em>Ramón A. Carrasco</em><span class="math inline">\(^{a}\)</span> e <em>Itzcóatl Bueno</em><span class="math inline">\(^{b,a}\)</span></p>
<p><span class="math inline">\(^{a}\)</span>Universidad Complutense de Madrid
<span class="math inline">\(^{b}\)</span>Instituto Nacional de Estadística</p>
<div id="nb-intro" class="section level2" number="27.1">
<h2>
<span class="header-section-number">27.1</span> Introducción<a class="anchor" aria-label="anchor" href="#nb-intro"><i class="fas fa-link"></i></a>
</h2>
<p><em>Naive Bayes</em> es un algoritmo de aprendizaje supervisado que se utiliza principalmente para la clasificación. Como otros algoritmos de aprendizaje supervisado, este algoritmo se entrena con variables de entrada y la categoría asociada a cada observación y que el modelo debe predecir. Sin embargo, se denomina <em>‘naive’</em> dado que asume que las variables de entrada que se incluyen en el modelo son independientes entre sí. Por lo tanto, si se cambia una de las variables de entrada, las demás no se verán afectadas.</p>
<p>Aunque el algoritmo <em>Naive Bayes</em> es sencillo, destaca por su facilidad de implementación y su potencia predictiva. Su ventaja principal es que utiliza un enfoque probabilístico, lo que implica que todos los cálculos se realizan en tiempo real y, por tanto, los resultados se obtienen inmediatamente, como se detalla más adelante. Además, cuando el conjunto de datos tiene un gran número de observaciones, el algoritmo <em>Naive Bayes</em> es ventajoso respecto a algoritmos como la SVM (Cap. <a href="cap-svm.html#cap-svm">25</a>) o el Random Forest (Cap. <a href="cap-bagg-rf.html#cap-bagg-rf">28</a>) debido a su mejor tiempo de computación.</p>
<p>Al utilizar un enfoque probabilístico, el algoritmo <em>Naive Bayes</em> está construido sobre conceptos de probabilidad, presentados en el Cap. <a href="Funda-probab.html#Funda-probab">12</a>, y en especial, este algoritmo hace uso del <strong>Teorema de Bayes</strong>. A continuación se repasan los conceptos fundamentales en los que está basado el algoritmo.</p>
</div>
<div id="teorema-de-bayes" class="section level2" number="27.2">
<h2>
<span class="header-section-number">27.2</span> Teorema de Bayes<a class="anchor" aria-label="anchor" href="#teorema-de-bayes"><i class="fas fa-link"></i></a>
</h2>
<p>Sean dos eventos A y B definidos en un espacio muestral, se puede definir la probabilidad condicional de que ocurra el evento A dado que previamente se haya observado B como:</p>
<p><span class="math display">\[\begin{equation}
P(A|B) = \frac{P(A\cap B)}{P(B)}
\end{equation}\]</span></p>
<p>Siempre que <span class="math inline">\(P(B) \neq 0\)</span> y donde <span class="math inline">\(P(A\cap B)\)</span> es la probabilidad de que ocurran ambos eventos a la vez. Los eventos son intercambiables de tal forma que <span class="math inline">\(P(A\cap B) = P(B|A)P(A)\)</span> y si se reemplaza en la primera ecuación tenemos:</p>
<p><span class="math display">\[\begin{equation}
P(A|B) = \frac{P(B|A)\cdot P(A)}{P(B)}
\end{equation}\]</span></p>
<p>Esta fórmula es la definición del teorema de Bayes. El algoritmo de clasificación <em>Naive Bayes</em> (NB) está basado en este teorema. Para ampliar los conceptos estadísticos aquí presentados pueden consultarse en más detalle en el Cap. <a href="Funda-probab.html#Funda-probab">12</a>.</p>
</div>
<div id="el-algoritmo-naive-bayes" class="section level2" number="27.3">
<h2>
<span class="header-section-number">27.3</span> El algoritmo <em>naive</em> Bayes<a class="anchor" aria-label="anchor" href="#el-algoritmo-naive-bayes"><i class="fas fa-link"></i></a>
</h2>
<p>Si se adapta el teorema de Bayes a un problema de clasificación, se tendría:</p>
<p><span class="math display">\[\begin{equation}
P(C=c|\ell)=\frac{P(\ell|C=c)\cdot P(C=c)}{P(\ell)}
\end{equation}\]</span></p>
<p>En este caso, <span class="math inline">\(P(C=c|\ell)\)</span> representa el objetivo de estimación en un problema de clasificación, es decir, la probabilidad de que un individuo pertenezca a la clase <span class="math inline">\(c\)</span> después de haber observado la evidencia <span class="math inline">\(\ell\)</span> (incluida en las variables del modelo). Esta es la denominada <strong>probabilidad a posteriori</strong>. El resto de elementos de la fórmula, se definen como:</p>
<ul>
<li><p><span class="math inline">\(P(C=c)\)</span> es la <strong>probabilidad a priori</strong> de pertenecer a la clase <span class="math inline">\(c\)</span>, es decir, la probabilidad que un individuo tiene de ser asignado a esa clase sin observar sus características previamente.</p></li>
<li><p><span class="math inline">\(P(\ell|C=c)\)</span> es la verosimilitud de observar una instancia particular de las variables incluidas en el modelo cuando el individuo pertenece a la clase <span class="math inline">\(c\)</span>.</p></li>
<li><p><span class="math inline">\(P(\ell)\)</span> es la verosimilitud de observar una instancia particular de las variables incluidas en el modelo, independientemente de a qué clase pertenezca el individuo.</p></li>
</ul>
<p>Sin embargo, una gran dificultad para aplicar esta ecuación es la necesidad de conocer que <span class="math inline">\(P(\ell|c)\)</span> es igual a <span class="math inline">\(P(\ell_1\cap\ell_2\cap\dots\cap\ell_\kappa|c)\)</span>. La existencia de un ejemplo concreto en el conjunto de datos de entrenamiento que coincida a la perfección con <span class="math inline">\(\ell\)</span> es complicado, y en el caso de existir, no se tendrían suficientes ejemplos para poder estimar una probabilidad de forma fiable. La forma de solucionar este problema es incluir una suposición de independencia particularmente fuerte, que como ya se mencionó en la Sec. <a href="cap-naive-bayes.html#nb-intro">27.1</a>, es lo que aporta la denominación de <em>‘naive’</em> al algoritmo.</p>
<p>La <em>independencia condicional</em> implica que conocer un evento no aporta información sobre otro evento. Esto es equivalente a:</p>
<p><span class="math display">\[\begin{equation}
P(AB|C) = P(A|C)\cdot P(B|C)
\end{equation}\]</span></p>
<p>De este modo, el problema de clasificación en el que era difícil estimar <span class="math inline">\(P(\ell_1\cap\ell_2\cap\dots\cap\ell_\kappa|c)\)</span>, ahora se tendría:</p>
<p><span class="math display">\[\begin{equation}
P(\ell|c)=P(\ell_1|c)\cdot P(\ell_2|c)\cdots P(\ell_\kappa|c)
\end{equation}\]</span></p>
<p>Y cada uno de los elementos <span class="math inline">\(P(\ell_i|c)\)</span> puede obtenerse directamente de los datos. Combinando este resultado con la regla de Bayes aplicada a un problema de decisión, se obtiene la ecuación dada por el algoritmo <em>Naive Bayes</em>:</p>
<p><span class="math display">\[\begin{equation}
P(c|\ell)=P(\ell_1|c)\cdot P(\ell_2|c)\cdots P(\ell_\kappa|c)P(c)
\end{equation}\]</span></p>
<p>El algoritmo <em>Naive Bayes</em> clasifica una nueva observación estimando la probabilidad de que pertenezca a cada clase y asignándole a aquella que tenga la mayor probabilidad.</p>
<p>En definitiva, el clasificador <em>Naive Bayes</em> es muy eficiente en términos de espacio de almacenamiento necesario, así como tiempos de procesamiento. Además, a pesar de ser muy simple, tiene en cuenta las características observadas. Otra de las ventajas de este clasificador es que es un modelo de aprendizaje incremental. Esto quiere decir que es una técnica de inducción que se actualiza con cada nueva observación de entrenamiento, es decir, no es necesario volver a procesar todo el conjunto de entrenamiento cuando se dispone de nuevas observaciones.</p>
<p>El ejemplo presentado en el Cap. <a href="cap-arboles.html#cap-arboles">24</a> en el que se buscaba predecir si se podría jugar o no al tenis bajo unas condiciones meteorológicas determinadas, puede desarrollarse utilizando el modelo <em>Naive Bayes</em>. En este caso, el procedimiento puede resumirse en tres pasos:</p>
<ul>
<li>Resumir los datos en una tabla de frecuencias.</li>
<li>Generar una tabla de verosimilitud obteniendo las probabilidades de las variables.</li>
<li>Aplicar el teorema de Bayes para calcular la probabilidad a posteriori.</li>
</ul>
<p>De este modo, las 15 observaciones registradas con el tipo de día (soleado, nublado, lluvioso) y si ese día se jugó, deben resumirse en una tabla de frecuencias como la Tabla <a href="cap-naive-bayes.html#tab:tenis-freq">27.1</a>. En este primer paso no se tiene en cuenta la información sobre humedad o viento.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:tenis-freq">Tabla 27.1: </span> Tabla de frecuencias - Tipo de día vs Jugar partido</caption>
<thead><tr class="header">
<th></th>
<th align="center">SI</th>
<th align="center">NO</th>
<th align="center">Total</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Soleado</td>
<td align="center">2</td>
<td align="center">4</td>
<td align="center">6</td>
</tr>
<tr class="even">
<td>Nublado</td>
<td align="center">4</td>
<td align="center">0</td>
<td align="center">4</td>
</tr>
<tr class="odd">
<td>Lluvia</td>
<td align="center">4</td>
<td align="center">1</td>
<td align="center">5</td>
</tr>
<tr class="even">
<td>Total</td>
<td align="center">10</td>
<td align="center">5</td>
<td align="center">15</td>
</tr>
</tbody>
</table></div>
<p>En un segundo paso, se obtienen las probabilidades de cada categoría a partir de la Tabla <a href="cap-naive-bayes.html#tab:tenis-freq">27.1</a> resultando en la Tabla <a href="cap-naive-bayes.html#tab:tenis-likelihood">27.2</a>.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:tenis-likelihood">Tabla 27.2: </span> Tabla de verosimilitud - Tipo de día vs Jugar partido</caption>
<colgroup>
<col width="21%">
<col width="5%">
<col width="7%">
<col width="64%">
</colgroup>
<thead><tr class="header">
<th></th>
<th align="center">SI</th>
<th align="center">NO</th>
<th align="center"><span class="math inline">\(P(\textrm{Tipo de día}_i)\)</span></th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Soleado</td>
<td align="center">2</td>
<td align="center">4</td>
<td align="center"><span class="math inline">\(\frac{6}{15} = 0,40\)</span></td>
</tr>
<tr class="even">
<td>Nublado</td>
<td align="center">4</td>
<td align="center">0</td>
<td align="center"><span class="math inline">\(\frac{4}{15} = 0,27\)</span></td>
</tr>
<tr class="odd">
<td>Lluvia</td>
<td align="center">4</td>
<td align="center">1</td>
<td align="center"><span class="math inline">\(\frac{5}{15} = 0,33\)</span></td>
</tr>
<tr class="even">
<td>P(Jugar)</td>
<td align="center"><span class="math inline">\(\frac{10}{15} = 0,67\)</span></td>
<td align="center"><span class="math inline">\(\frac{5}{15} = 0,33\)</span></td>
<td align="center"></td>
</tr>
</tbody>
</table></div>
<p>A partir de la Tabla <a href="cap-naive-bayes.html#tab:tenis-likelihood">27.2</a> se obtiene la probabilidad de cada tipo de día dado que con esa climatología se jugó o no, es decir, <span class="math inline">\(P(\textrm{Tipo de día}|Jugar)\)</span>. Obteniendo las probabilidades mostradas en la Tabla <a href="cap-naive-bayes.html#tab:probs-tipodia">27.3</a></p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:probs-tipodia">Tabla 27.3: </span> Probabilidad de Tipo de día sabiendo si se jugó el partido</caption>
<thead><tr class="header">
<th align="center"></th>
<th align="center">c = SI</th>
<th align="center">c = NO</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="center">P(Soleado | C=c)</td>
<td align="center"><span class="math inline">\(\frac{2}{15}\)</span></td>
<td align="center"><span class="math inline">\(\frac{4}{15}\)</span></td>
</tr>
<tr class="even">
<td align="center">P(Nublado | C=c)</td>
<td align="center"><span class="math inline">\(\frac{4}{15}\)</span></td>
<td align="center"><span class="math inline">\(\frac{0}{15}\)</span></td>
</tr>
<tr class="odd">
<td align="center">P(Lluvia | C=c)</td>
<td align="center"><span class="math inline">\(\frac{4}{15}\)</span></td>
<td align="center"><span class="math inline">\(\frac{1}{15}\)</span></td>
</tr>
</tbody>
</table></div>
<p>Este proceso se repite de forma independiente para las variables <em>viento</em> y <em>humedad</em> obteniendo la Tabla <a href="cap-naive-bayes.html#tab:probs-viento">27.4</a> y la Tabla <a href="cap-naive-bayes.html#tab:probs-humedad">27.5</a> respectivamente.</p>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:probs-viento">Tabla 27.4: </span> Probabilidad fuerza del Viento sabiendo si se jugó el partido</caption>
<thead><tr class="header">
<th align="center"></th>
<th align="center">c = SI</th>
<th align="center">c = NO</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="center">P(Débil | C=c)</td>
<td align="center"><span class="math inline">\(\frac{6}{15}\)</span></td>
<td align="center"><span class="math inline">\(\frac{2}{15}\)</span></td>
</tr>
<tr class="even">
<td align="center">P(Fuerte | C=c)</td>
<td align="center"><span class="math inline">\(\frac{4}{15}\)</span></td>
<td align="center"><span class="math inline">\(\frac{3}{15}\)</span></td>
</tr>
</tbody>
</table></div>
<div class="inline-table"><table class="table table-sm">
<caption>
<span id="tab:probs-humedad">Tabla 27.5: </span> Probabilidad nivel de Humedad sabiendo si se jugó el partido</caption>
<thead><tr class="header">
<th align="center"></th>
<th align="center">c = SI</th>
<th align="center">c = NO</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="center">P(Débil | C=c)</td>
<td align="center"><span class="math inline">\(\frac{6}{15}\)</span></td>
<td align="center"><span class="math inline">\(\frac{1}{15}\)</span></td>
</tr>
<tr class="even">
<td align="center">P(Fuerte | C=c)</td>
<td align="center"><span class="math inline">\(\frac{4}{15}\)</span></td>
<td align="center"><span class="math inline">\(\frac{4}{15}\)</span></td>
</tr>
</tbody>
</table></div>
<p>Finalmente, aplicando el teorema de Bayes se podría predecir si se juega o no el partido ante la previsión de un nuevo día. Por ejemplo, ¿cuál es la probabilidad de no jugar al tenis si el día se espera soleado, con fuertes rachas de viento y escasa humedad? Esto es, <span class="math inline">\(\ell\)</span>=[Soleado, Fuerte, Débil] y, de acuerdo al teorema de Bayes, esta pregunta se respondería a través de:</p>
<p><span class="math display">\[\begin{equation*}
P(c|\ell) = \frac{P(\ell|c)\cdot P(c)}{P(\ell)}
\end{equation*}\]</span></p>
<p>A partir de las probabilidades previamente obtenidas y de la asunción de independencia entre las variables, se puede calcular la probabilidad de jugar como:</p>
<p><span class="math display">\[\begin{equation}
P(Si|\ell) = P(Soleado|Si)\cdot P(Fuerte|Si) \cdot P (Débil|Si) \cdot P(Si) = \frac{2}{15}\frac{4}{15}\frac{2}{15}\frac{10}{15} = 0,0032
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
P(No|\ell) = P(Soleado|No)\cdot P(Fuerte|No) \cdot P (Débil|No) \cdot P(No) = \frac{4}{15}\frac{3}{15}\frac{1}{15}\frac{5}{15} = 0,0012
\end{equation}\]</span></p>
<p>La probabilidad de jugar es superior a la probabilidad de no jugar y, por tanto, dado un día con esas condiciones climáticas se clasificará como un día en el que se puede jugar.</p>
</div>
<div id="procedimiento-con-r-la-función-naive_bayes" class="section level2" number="27.4">
<h2>
<span class="header-section-number">27.4</span> Procedimiento con <strong>R</strong>: la función <code>naive_bayes()</code><a class="anchor" aria-label="anchor" href="#procedimiento-con-r-la-funci%C3%B3n-naive_bayes"><i class="fas fa-link"></i></a>
</h2>
<p>En el paquete <code>naivebayes</code> de R se encuentra la función <code><a href="https://majkamichal.github.io/naivebayes//reference/naive_bayes.html">naive_bayes()</a></code> que se utiliza para entrenar un modelo <em>Naive Bayes</em>:</p>
<div class="sourceCode" id="cb376"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">naive_bayes</span><span class="op">(</span><span class="va">formula</span>, <span class="va">data</span>, prior <span class="op">=</span> <span class="va">...</span>, <span class="va">...</span><span class="op">)</span></span></code></pre></div>
<ul>
<li>
<code>formula</code>: refleja la relación lineal entre la variable dependiente y los predictores <span class="math inline">\(Y \sim X_1 + ... + X_p\)</span>.</li>
<li>
<code>data</code>: conjunto de datos con el que se entrena el modelo.</li>
<li>
<code>prior</code>: vector con las probabilidades a priori de las clases.</li>
</ul>
</div>
<div id="clasificación-de-clientes-utilizando-el-modelo-naive-bayes" class="section level2" number="27.5">
<h2>
<span class="header-section-number">27.5</span> Clasificación de clientes utilizando el modelo <em>Naive Bayes</em><a class="anchor" aria-label="anchor" href="#clasificaci%C3%B3n-de-clientes-utilizando-el-modelo-naive-bayes"><i class="fas fa-link"></i></a>
</h2>
<p>Como en los capítulos precedentes, en este ejemplo se pretende entrenar un modelo <em>Naive Bayes</em> utilizando el conjunto de datos de compras realizadas por clientes incluido en el paquete <code>CDR</code>. Este conjunto de datos cuenta con unas variables predictoras que indican qué productos han comprado los clientes, el importe que han gastado y otras características como su edad y su nivel educativo. Se utiliza el conjunto de datos sin transformar (<code>dp_entr</code>), es decir, en su escala original y con las variables categóricas sin codificar. La variable objetivo indica si un cliente comprará o no el nuevo producto (<em>tensiómetro digital</em>).</p>
<div class="sourceCode" id="cb377"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="https://github.com/topepo/caret/">"caret"</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="https://github.com/majkamichal/naivebayes">"naivebayes"</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="http://had.co.nz/reshape">"reshape"</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st"><a href="https://ggplot2.tidyverse.org">"ggplot2"</a></span><span class="op">)</span></span>
<span><span class="kw"><a href="https://rdrr.io/r/base/library.html">library</a></span><span class="op">(</span><span class="st">"CDR"</span><span class="op">)</span></span>
<span></span>
<span><span class="fu"><a href="https://rdrr.io/r/utils/data.html">data</a></span><span class="op">(</span><span class="st">"dp_entr"</span><span class="op">)</span></span></code></pre></div>
<div class="sourceCode" id="cb378"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># se fija la semilla aleatoria</span></span>
<span><span class="fu"><a href="https://rdrr.io/r/base/Random.html">set.seed</a></span><span class="op">(</span><span class="fl">101</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># se entrena el modelo</span></span>
<span><span class="va">model</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/pkg/caret/man/train.html">train</a></span><span class="op">(</span><span class="va">CLS_PRO_pro13</span> <span class="op">~</span> <span class="va">.</span>,</span>
<span>            data<span class="op">=</span><span class="va">dp_entr</span>,</span>
<span>            method<span class="op">=</span><span class="st">"nb"</span>, </span>
<span>            metric<span class="op">=</span><span class="st">"Accuracy"</span>,</span>
<span>            trControl<span class="op">=</span><span class="fu"><a href="https://rdrr.io/pkg/caret/man/trainControl.html">trainControl</a></span><span class="op">(</span>classProbs <span class="op">=</span> <span class="cn">TRUE</span>,</span>
<span>                                   method <span class="op">=</span> <span class="st">"cv"</span>,</span>
<span>                                   number <span class="op">=</span> <span class="fl">10</span><span class="op">)</span><span class="op">)</span></span>
<span><span class="co"># se muestra la salida del modelo</span></span>
<span><span class="va">model</span></span></code></pre></div>
<div class="sourceCode" id="cb379"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb379-1"><a href="cap-naive-bayes.html#cb379-1" tabindex="-1"></a>Naive Bayes </span>
<span id="cb379-2"><a href="cap-naive-bayes.html#cb379-2" tabindex="-1"></a></span>
<span id="cb379-3"><a href="cap-naive-bayes.html#cb379-3" tabindex="-1"></a><span class="dv">558</span> samples</span>
<span id="cb379-4"><a href="cap-naive-bayes.html#cb379-4" tabindex="-1"></a> <span class="dv">17</span> predictor</span>
<span id="cb379-5"><a href="cap-naive-bayes.html#cb379-5" tabindex="-1"></a>  <span class="dv">2</span> classes<span class="sc">:</span> <span class="st">'S'</span>, <span class="st">'N'</span> </span>
<span id="cb379-6"><a href="cap-naive-bayes.html#cb379-6" tabindex="-1"></a></span>
<span id="cb379-7"><a href="cap-naive-bayes.html#cb379-7" tabindex="-1"></a>No pre<span class="sc">-</span>processing</span>
<span id="cb379-8"><a href="cap-naive-bayes.html#cb379-8" tabindex="-1"></a>Resampling<span class="sc">:</span> Cross<span class="sc">-</span><span class="fu">Validated</span> (<span class="dv">10</span> fold) </span>
<span id="cb379-9"><a href="cap-naive-bayes.html#cb379-9" tabindex="-1"></a>Summary of sample sizes<span class="sc">:</span> <span class="dv">502</span>, <span class="dv">502</span>, <span class="dv">502</span>, <span class="dv">503</span>, <span class="dv">503</span>, <span class="dv">502</span>, ... </span>
<span id="cb379-10"><a href="cap-naive-bayes.html#cb379-10" tabindex="-1"></a>Resampling results across tuning parameters<span class="sc">:</span></span>
<span id="cb379-11"><a href="cap-naive-bayes.html#cb379-11" tabindex="-1"></a></span>
<span id="cb379-12"><a href="cap-naive-bayes.html#cb379-12" tabindex="-1"></a>  usekernel  Accuracy   Kappa    </span>
<span id="cb379-13"><a href="cap-naive-bayes.html#cb379-13" tabindex="-1"></a>  <span class="cn">FALSE</span>      <span class="fl">0.8512662</span>  <span class="fl">0.7026716</span></span>
<span id="cb379-14"><a href="cap-naive-bayes.html#cb379-14" tabindex="-1"></a>   <span class="cn">TRUE</span>      <span class="fl">0.8512338</span>  <span class="fl">0.7025165</span></span>
<span id="cb379-15"><a href="cap-naive-bayes.html#cb379-15" tabindex="-1"></a></span>
<span id="cb379-16"><a href="cap-naive-bayes.html#cb379-16" tabindex="-1"></a>Tuning parameter <span class="st">'fL'</span> was held constant at a value of <span class="dv">0</span></span>
<span id="cb379-17"><a href="cap-naive-bayes.html#cb379-17" tabindex="-1"></a>Tuning parameter</span>
<span id="cb379-18"><a href="cap-naive-bayes.html#cb379-18" tabindex="-1"></a> <span class="st">'adjust'</span> was held constant at a value of <span class="dv">1</span></span>
<span id="cb379-19"><a href="cap-naive-bayes.html#cb379-19" tabindex="-1"></a>Accuracy was used to select the optimal model using the largest value.</span>
<span id="cb379-20"><a href="cap-naive-bayes.html#cb379-20" tabindex="-1"></a>The final values used <span class="cf">for</span> the model were fL <span class="ot">=</span> <span class="dv">0</span>, usekernel <span class="ot">=</span> <span class="cn">FALSE</span> and adjust <span class="ot">=</span> <span class="fl">1.</span></span></code></pre></div>
<p>Los resultados del proceso de entrenamiento muestran que, en este caso, es indiferente indicar el argumento <code>usekernel</code> como FALSE o TRUE, los resultados de precisión son equivalentes. El resumen del modelo muestra que la precisión media obtenida durante la validación cruzada alcanza el 85,1%, lo cual indica que el modelo ajusta bastante bien la intención de compra de nuevos clientes.</p>
<div class="sourceCode" id="cb380"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb380-1"><a href="cap-naive-bayes.html#cb380-1" tabindex="-1"></a><span class="fu">confusionMatrix</span>(model)</span>
<span id="cb380-2"><a href="cap-naive-bayes.html#cb380-2" tabindex="-1"></a>Cross<span class="sc">-</span><span class="fu">Validated</span> (<span class="dv">10</span> fold) Confusion Matrix </span>
<span id="cb380-3"><a href="cap-naive-bayes.html#cb380-3" tabindex="-1"></a></span>
<span id="cb380-4"><a href="cap-naive-bayes.html#cb380-4" tabindex="-1"></a>(entries are percentual average cell counts across resamples)</span>
<span id="cb380-5"><a href="cap-naive-bayes.html#cb380-5" tabindex="-1"></a> </span>
<span id="cb380-6"><a href="cap-naive-bayes.html#cb380-6" tabindex="-1"></a>          Reference</span>
<span id="cb380-7"><a href="cap-naive-bayes.html#cb380-7" tabindex="-1"></a>Prediction    S    N</span>
<span id="cb380-8"><a href="cap-naive-bayes.html#cb380-8" tabindex="-1"></a>         S <span class="fl">41.8</span>  <span class="fl">6.6</span></span>
<span id="cb380-9"><a href="cap-naive-bayes.html#cb380-9" tabindex="-1"></a>         N  <span class="fl">8.2</span> <span class="fl">43.4</span></span>
<span id="cb380-10"><a href="cap-naive-bayes.html#cb380-10" tabindex="-1"></a>                            </span>
<span id="cb380-11"><a href="cap-naive-bayes.html#cb380-11" tabindex="-1"></a> <span class="fu">Accuracy</span> (average) <span class="sc">:</span> <span class="fl">0.8513</span></span></code></pre></div>
<p>En la matriz de confusión del modelo se observa para cada celda el promedio porcentual entre remuestreos. Así, se observa que en media el modelo predice mejor cuando un cliente no va a comprar el nuevo producto que cuando sí lo hace, aunque no con mucha diferencia (menos de un 2%). En ambos casos, las clasificaciones erróneas no suponen ni el 10%.</p>
<div class="sourceCode" id="cb381"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/reshape/man/melt-24.html">melt</a></span><span class="op">(</span><span class="va">model</span><span class="op">$</span><span class="va">resample</span><span class="op">[</span>,<span class="op">-</span><span class="fl">4</span><span class="op">]</span><span class="op">)</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">variable</span>, y <span class="op">=</span> <span class="va">value</span>, fill<span class="op">=</span><span class="va">variable</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_boxplot.html">geom_boxplot</a></span><span class="op">(</span>show.legend<span class="op">=</span><span class="cn">FALSE</span><span class="op">)</span> <span class="op">+</span> </span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span><span class="op">(</span><span class="cn">NULL</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span><span class="op">(</span><span class="cn">NULL</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:NBRESULTS"></span>
<img src="img/nb_boxplot.png" alt="Resultados del modelo Naive Bayes obtenidos durante el proceso de validación cruzada." width="60%"><p class="caption">
Figura 27.1: Resultados del modelo Naive Bayes obtenidos durante el proceso de validación cruzada.
</p>
</div>
<p>Se puede observar como la precisión oscila entre el 75% y el 95%, aunque en uno de los resultados se obtuvo un 96% de precisión, el cual se marca como un resultado atípico.</p>
<div id="resumen-24" class="section level3 unnumbered infobox_resume">
<h3>Resumen<a class="anchor" aria-label="anchor" href="#resumen-24"><i class="fas fa-link"></i></a>
</h3>
<p>En este capítulo se introduce al lector en el algoritmo de <em>Naive Bayes</em>, en concreto:</p>
<ul>
<li>Se presentan los fundamentos del algoritmo bayesiano, particularmente el Teorema de Bayes.</li>
<li>Se explica el funcionamiento del algoritmo <em>Naive Bayes</em> y su relación con dicho Teorema de Bayes.</li>
<li>Se demuestra su aplicabilidad a un caso real de clasificación a través de <code>R</code>.</li>
</ul>
</div>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="cap-knn.html"><span class="header-section-number">26</span> Clasificador k-vecinos más próximos</a></div>
<div class="next"><a href="cap-bagg-rf.html"><span class="header-section-number">28</span> Métodos ensamblados: bagging y random forest</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="Índice capítulo"><h2>Índice capítulo</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#cap-naive-bayes"><span class="header-section-number">27</span> Naive Bayes</a></li>
<li><a class="nav-link" href="#nb-intro"><span class="header-section-number">27.1</span> Introducción</a></li>
<li><a class="nav-link" href="#teorema-de-bayes"><span class="header-section-number">27.2</span> Teorema de Bayes</a></li>
<li><a class="nav-link" href="#el-algoritmo-naive-bayes"><span class="header-section-number">27.3</span> El algoritmo naive Bayes</a></li>
<li><a class="nav-link" href="#procedimiento-con-r-la-funci%C3%B3n-naive_bayes"><span class="header-section-number">27.4</span> Procedimiento con R: la función naive_bayes()</a></li>
<li>
<a class="nav-link" href="#clasificaci%C3%B3n-de-clientes-utilizando-el-modelo-naive-bayes"><span class="header-section-number">27.5</span> Clasificación de clientes utilizando el modelo Naive Bayes</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#resumen-24">Resumen</a></li></ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Fundamentos de ciencia de datos con R</strong>" coordinado por <a href="https://blog.uclm.es/gemafaviles/" class="text-light">Gema Fernández-Avilés y José-María Montero</a>. Generado por última vez el día 2023-06-16.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>Este libro ha sido generado con el paquete de R <a class="text-light" href="https://bookdown.org">bookdown</a>.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
