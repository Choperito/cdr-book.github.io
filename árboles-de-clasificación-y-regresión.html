<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 25 Árboles de clasificación y regresión  | Fundamentos de ciencia de datos con R</title>
  <meta name="description" content="Falta hacer" />
  <meta name="generator" content="bookdown 0.28 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 25 Árboles de clasificación y regresión  | Fundamentos de ciencia de datos con R" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Falta hacer" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 25 Árboles de clasificación y regresión  | Fundamentos de ciencia de datos con R" />
  
  <meta name="twitter:description" content="Falta hacer" />
  

<meta name="author" content="Gema Fernández-Avilés y José-María Montero" />


<meta name="date" content="2022-12-01" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="análisis-discriminante.html"/>
<link rel="next" href="máquinas-de-vector-soporte.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-33KQ1S5ZCJ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-33KQ1S5ZCJ');
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"> Ciencia de datos con <strong>R</strong></a></li>

<li class="divider"></li>
<li class="part"><span><b>I Fundamentos y ‘tool-kit’ de la ciencia de datos</b></span></li>
<li class="chapter" data-level="1" data-path="ciencia-datos.html"><a href="ciencia-datos.html"><i class="fa fa-check"></i><b>1</b> ¿Es la Ciencia de datos una Ciencia?</a>
<ul>
<li class="chapter" data-level="1.1" data-path="ciencia-datos.html"><a href="ciencia-datos.html#ciencia"><i class="fa fa-check"></i><b>1.1</b> ¿Qué se entiende por Ciencia?</a></li>
<li class="chapter" data-level="1.2" data-path="ciencia-datos.html"><a href="ciencia-datos.html#qué-es-la-ciencia-de-datos"><i class="fa fa-check"></i><b>1.2</b> ¿Qué es la Ciencia de Datos?</a></li>
<li class="chapter" data-level="1.3" data-path="ciencia-datos.html"><a href="ciencia-datos.html#lo-científico-de-la-ciencia-de-datos"><i class="fa fa-check"></i><b>1.3</b> Lo científico de la Ciencia de datos</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="metodología.html"><a href="metodología.html"><i class="fa fa-check"></i><b>2</b> Metodología para la Ciencia de datos</a>
<ul>
<li class="chapter" data-level="2.1" data-path="metodología.html"><a href="metodología.html#preliminares"><i class="fa fa-check"></i><b>2.1</b> Preliminares</a></li>
<li class="chapter" data-level="2.2" data-path="metodología.html"><a href="metodología.html#principales-metodologías-en-ciencia-de-datos"><i class="fa fa-check"></i><b>2.2</b> Principales metodologías en Ciencia de datos</a></li>
<li class="chapter" data-level="2.3" data-path="metodología.html"><a href="metodología.html#met-crisp-dm"><i class="fa fa-check"></i><b>2.3</b> CRISP-DM para Ciencia de datos</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ch-110003.html"><a href="ch-110003.html"><i class="fa fa-check"></i><b>3</b> R para ciencia de datos</a>
<ul>
<li class="chapter" data-level="3.1" data-path="ch-110003.html"><a href="ch-110003.html#introducción"><i class="fa fa-check"></i><b>3.1</b> Introducción</a></li>
<li class="chapter" data-level="3.2" data-path="ch-110003.html"><a href="ch-110003.html#id_110003-bases"><i class="fa fa-check"></i><b>3.2</b> La sesión de R</a></li>
<li class="chapter" data-level="3.3" data-path="ch-110003.html"><a href="ch-110003.html#instalación-de-r"><i class="fa fa-check"></i><b>3.3</b> Instalación de R</a></li>
<li class="chapter" data-level="3.4" data-path="ch-110003.html"><a href="ch-110003.html#id_110003-proyectos"><i class="fa fa-check"></i><b>3.4</b> Trabajar con proyectos de RStudio</a></li>
<li class="chapter" data-level="3.5" data-path="ch-110003.html"><a href="ch-110003.html#manipulación-de-datos-con-r"><i class="fa fa-check"></i><b>3.5</b> Manipulación de datos con R</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="ch-110003.html"><a href="ch-110003.html#id_110003-estructuras"><i class="fa fa-check"></i><b>3.5.1</b> Estructuras y tipos de datos</a></li>
<li class="chapter" data-level="3.5.2" data-path="ch-110003.html"><a href="ch-110003.html#id_110003-importacion"><i class="fa fa-check"></i><b>3.5.2</b> Importación de datos</a></li>
<li class="chapter" data-level="3.5.3" data-path="ch-110003.html"><a href="ch-110003.html#exportación-y-archivos-de-datos-de-r"><i class="fa fa-check"></i><b>3.5.3</b> Exportación y archivos de datos de R</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="ch-110003.html"><a href="ch-110003.html#id_110003-tidyverse"><i class="fa fa-check"></i><b>3.6</b> Organización de datos con el <em>tidyverse</em></a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="ch-110003.html"><a href="ch-110003.html#el-tidyverse-y-su-flujo-de-trabajo"><i class="fa fa-check"></i><b>3.6.1</b> El <em>tidyverse</em> y su flujo de trabajo</a></li>
<li class="chapter" data-level="3.6.2" data-path="ch-110003.html"><a href="ch-110003.html#transformación-de-datos-con-dplyr"><i class="fa fa-check"></i><b>3.6.2</b> Transformación de datos con <code>dplyr</code></a></li>
<li class="chapter" data-level="3.6.3" data-path="ch-110003.html"><a href="ch-110003.html#combinación-de-datos"><i class="fa fa-check"></i><b>3.6.3</b> Combinación de datos</a></li>
<li class="chapter" data-level="3.6.4" data-path="ch-110003.html"><a href="ch-110003.html#reorganización-de-datos"><i class="fa fa-check"></i><b>3.6.4</b> Reorganización de datos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html"><a href="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html"><i class="fa fa-check"></i><b>4</b> Gestión y operación de datos con bases de datos relacionales</a>
<ul>
<li class="chapter" data-level="4.1" data-path="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html"><a href="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html#introducción-1"><i class="fa fa-check"></i><b>4.1</b> Introducción</a></li>
<li class="chapter" data-level="4.2" data-path="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html"><a href="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html#concepto-de-base-de-datos"><i class="fa fa-check"></i><b>4.2</b> Concepto de Base de datos</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html"><a href="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html#gestión-de-los-datos-en-una-base-o-repositorio-de-datos"><i class="fa fa-check"></i><b>4.2.1</b> Gestión de los datos en una base o repositorio de datos</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html"><a href="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html#el-lenguaje-estructurado-de-consulta-sql"><i class="fa fa-check"></i><b>4.3</b> El Lenguaje Estructurado de Consulta (SQL)</a>
<ul>
<li class="chapter" data-level="4.3.1" data-path="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html"><a href="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html#sql-como-lenguaje-de-definición-de-datos-ldd"><i class="fa fa-check"></i><b>4.3.1</b> SQL como Lenguaje de Definición de Datos (LDD)</a></li>
<li class="chapter" data-level="4.3.2" data-path="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html"><a href="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html#sql-como-lenguaje-de-manipulación-de-datos-lmd"><i class="fa fa-check"></i><b>4.3.2</b> SQL como Lenguaje de Manipulación de Datos (LMD)</a></li>
<li class="chapter" data-level="4.3.3" data-path="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html"><a href="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html#sql-como-lenguaje-de-administración-de-datos-lad"><i class="fa fa-check"></i><b>4.3.3</b> SQL como Lenguaje de Administración de Datos (LAD)</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html"><a href="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html#usando-bases-de-datos-desde-r"><i class="fa fa-check"></i><b>4.4</b> Usando bases de datos desde R</a>
<ul>
<li class="chapter" data-level="4.4.1" data-path="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html"><a href="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html#conexión-a-una-base-de-datos"><i class="fa fa-check"></i><b>4.4.1</b> Conexión a una base de datos</a></li>
<li class="chapter" data-level="4.4.2" data-path="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html"><a href="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html#operaciones-de-lectura-selección-read-de-datos"><i class="fa fa-check"></i><b>4.4.2</b> Operaciones de lectura / selección (<em>read</em>) de datos</a></li>
<li class="chapter" data-level="4.4.3" data-path="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html"><a href="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html#operaciones-de-inserción-create-y-actualización-update-de-datos"><i class="fa fa-check"></i><b>4.4.3</b> Operaciones de inserción (<em>create</em>) y actualización (<em>update</em>) de datos</a></li>
<li class="chapter" data-level="4.4.4" data-path="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html"><a href="gestión-y-operación-de-datos-con-bases-de-datos-relacionales.html#operaciones-de-borrado-de-datos-delete"><i class="fa fa-check"></i><b>4.4.4</b> Operaciones de Borrado de datos (<em>delete</em>)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="datos-no-sql.html"><a href="datos-no-sql.html"><i class="fa fa-check"></i><b>5</b> Gestión y operación de datos masivos (BigData) con bases de datos NoSQL</a>
<ul>
<li class="chapter" data-level="5.1" data-path="datos-no-sql.html"><a href="datos-no-sql.html#introducción-al-big-data"><i class="fa fa-check"></i><b>5.1</b> Introducción al Big Data</a></li>
<li class="chapter" data-level="5.2" data-path="datos-no-sql.html"><a href="datos-no-sql.html#VsBigData"><i class="fa fa-check"></i><b>5.2</b> Las V’s del Big Data</a></li>
<li class="chapter" data-level="5.3" data-path="datos-no-sql.html"><a href="datos-no-sql.html#fuentes-de-datos-en-entornos-big-data"><i class="fa fa-check"></i><b>5.3</b> Fuentes de Datos en entornos Big Data</a></li>
<li class="chapter" data-level="5.4" data-path="datos-no-sql.html"><a href="datos-no-sql.html#bases-de-datos-relacionales-vs.-nosql"><i class="fa fa-check"></i><b>5.4</b> Bases de datos Relacionales vs. NoSQL</a></li>
<li class="chapter" data-level="5.5" data-path="datos-no-sql.html"><a href="datos-no-sql.html#bases-de-datos-nosql"><i class="fa fa-check"></i><b>5.5</b> Bases de datos NoSQL</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="datos-no-sql.html"><a href="datos-no-sql.html#definición-de-bases-de-datos-nosql"><i class="fa fa-check"></i><b>5.5.1</b> Definición de bases de datos NoSQL</a></li>
<li class="chapter" data-level="5.5.2" data-path="datos-no-sql.html"><a href="datos-no-sql.html#necesidades-no-cubiertas-por-las-bases-de-datos-relacionales"><i class="fa fa-check"></i><b>5.5.2</b> Necesidades no cubiertas por las bases de datos relacionales</a></li>
<li class="chapter" data-level="5.5.3" data-path="datos-no-sql.html"><a href="datos-no-sql.html#tipos-de-almacenamiento-en-bases-de-datos-nosql"><i class="fa fa-check"></i><b>5.5.3</b> Tipos de almacenamiento en bases de datos NoSQL</a></li>
<li class="chapter" data-level="5.5.4" data-path="datos-no-sql.html"><a href="datos-no-sql.html#limitaciones-de-las-bases-de-datos-nosql"><i class="fa fa-check"></i><b>5.5.4</b> Limitaciones de las bases de datos NoSQL</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="datos-no-sql.html"><a href="datos-no-sql.html#ejemplo-de-integración-de-una-base-de-datos-nosql-y-análisis-de-datos-en-r"><i class="fa fa-check"></i><b>5.6</b> Ejemplo de integración de una base de datos NoSQL y análisis de datos en R</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="datos-no-sql.html"><a href="datos-no-sql.html#introMongo"><i class="fa fa-check"></i><b>5.6.1</b> Introducción a MongoDB</a></li>
<li class="chapter" data-level="5.6.2" data-path="datos-no-sql.html"><a href="datos-no-sql.html#paquetesCaso"><i class="fa fa-check"></i><b>5.6.2</b> Plataforma tecnológica para el caso práctico</a></li>
<li class="chapter" data-level="5.6.3" data-path="datos-no-sql.html"><a href="datos-no-sql.html#conexionMongo"><i class="fa fa-check"></i><b>5.6.3</b> Conexión y acceso a MongoDB desde R</a></li>
<li class="chapter" data-level="5.6.4" data-path="datos-no-sql.html"><a href="datos-no-sql.html#consultaViajes"><i class="fa fa-check"></i><b>5.6.4</b> Obtención de datos en R desde MongoDB</a></li>
<li class="chapter" data-level="5.6.5" data-path="datos-no-sql.html"><a href="datos-no-sql.html#analisisViajes"><i class="fa fa-check"></i><b>5.6.5</b> Analizando datos de MongoDB en R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="id_120007-informes.html"><a href="id_120007-informes.html"><i class="fa fa-check"></i><b>6</b> Informes reproducibles con R-markdown -&gt; Quarto</a>
<ul>
<li class="chapter" data-level="6.1" data-path="id_120007-informes.html"><a href="id_120007-informes.html#introducción-2"><i class="fa fa-check"></i><b>6.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="id_120007-informes.html"><a href="id_120007-informes.html#por-qué-informes-reproducibles"><i class="fa fa-check"></i><b>6.1.1</b> ¿Por qué informes reproducibles?</a></li>
<li class="chapter" data-level="6.1.2" data-path="id_120007-informes.html"><a href="id_120007-informes.html#markdown-r-markdown-y-rstudio"><i class="fa fa-check"></i><b>6.1.2</b> Markdown, R Markdown y RStudio</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="id_120007-informes.html"><a href="id_120007-informes.html#documentos-r-markdown"><i class="fa fa-check"></i><b>6.2</b> Documentos R Markdown</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="id_120007-informes.html"><a href="id_120007-informes.html#encabezado-yaml-y-configuración"><i class="fa fa-check"></i><b>6.2.1</b> Encabezado YAML y configuración</a></li>
<li class="chapter" data-level="6.2.2" data-path="id_120007-informes.html"><a href="id_120007-informes.html#formateado-de-texto"><i class="fa fa-check"></i><b>6.2.2</b> Formateado de texto</a></li>
<li class="chapter" data-level="6.2.3" data-path="id_120007-informes.html"><a href="id_120007-informes.html#inclusión-de-código"><i class="fa fa-check"></i><b>6.2.3</b> Inclusión de código</a></li>
<li class="chapter" data-level="6.2.4" data-path="id_120007-informes.html"><a href="id_120007-informes.html#opciones-de-los-bloques-de-código-chunks"><i class="fa fa-check"></i><b>6.2.4</b> Opciones de los bloques de código (<em>chunks</em>)</a></li>
<li class="chapter" data-level="6.2.5" data-path="id_120007-informes.html"><a href="id_120007-informes.html#editor-visual"><i class="fa fa-check"></i><b>6.2.5</b> Editor visual</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="id_120007-informes.html"><a href="id_120007-informes.html#otros-formatos"><i class="fa fa-check"></i><b>6.3</b> Otros formatos</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="github.html"><a href="github.html"><i class="fa fa-check"></i><b>7</b> Git y GitHub en R</a>
<ul>
<li class="chapter" data-level="7.1" data-path="github.html"><a href="github.html#qué-es-git"><i class="fa fa-check"></i><b>7.1</b> ¿Qué es Git?</a></li>
<li class="chapter" data-level="7.2" data-path="github.html"><a href="github.html#qué-es-github"><i class="fa fa-check"></i><b>7.2</b> ¿Qué es GitHub?</a></li>
<li class="chapter" data-level="7.3" data-path="github.html"><a href="github.html#por-qué-usar-git-y-github"><i class="fa fa-check"></i><b>7.3</b> ¿Por qué usar Git y GitHub?</a></li>
<li class="chapter" data-level="7.4" data-path="github.html"><a href="github.html#configuración"><i class="fa fa-check"></i><b>7.4</b> Configuración</a></li>
<li class="chapter" data-level="7.5" data-path="github.html"><a href="github.html#configurar-git"><i class="fa fa-check"></i><b>7.5</b> Configurar git</a></li>
<li class="chapter" data-level="7.6" data-path="github.html"><a href="github.html#workflow"><i class="fa fa-check"></i><b>7.6</b> Workflow</a></li>
</ul></li>
<li class="part"><span><b>II Manipulación de datos con R. Técnicas y herramientas</b></span></li>
<li class="chapter" data-level="8" data-path="id_120006-aed.html"><a href="id_120006-aed.html"><i class="fa fa-check"></i><b>8</b> Análisis exploratorio de datos</a>
<ul>
<li class="chapter" data-level="8.1" data-path="id_120006-aed.html"><a href="id_120006-aed.html#introducción-3"><i class="fa fa-check"></i><b>8.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="8.1.1" data-path="id_120006-aed.html"><a href="id_120006-aed.html#el-cuarterto-de-anscombe"><i class="fa fa-check"></i><b>8.1.1</b> El cuarterto de Anscombe</a></li>
<li class="chapter" data-level="8.1.2" data-path="id_120006-aed.html"><a href="id_120006-aed.html#conceptos-generales"><i class="fa fa-check"></i><b>8.1.2</b> Conceptos generales</a></li>
<li class="chapter" data-level="8.1.3" data-path="id_120006-aed.html"><a href="id_120006-aed.html#componentes-de-un-gráfico-y-su-representación-en-r"><i class="fa fa-check"></i><b>8.1.3</b> Componentes de un gráfico y su representación en R</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="id_120006-aed.html"><a href="id_120006-aed.html#id_120006-aeduni"><i class="fa fa-check"></i><b>8.2</b> Análisis exploratorio de una característica</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="id_120006-aed.html"><a href="id_120006-aed.html#variables-cualitativas"><i class="fa fa-check"></i><b>8.2.1</b> Variables cualitativas</a></li>
<li class="chapter" data-level="8.2.2" data-path="id_120006-aed.html"><a href="id_120006-aed.html#variables-cuantitativas"><i class="fa fa-check"></i><b>8.2.2</b> Variables cuantitativas</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="id_120006-aed.html"><a href="id_120006-aed.html#id_120006-aedmulti"><i class="fa fa-check"></i><b>8.3</b> Análisis exploratorio de varias características</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="id_120006-aed.html"><a href="id_120006-aed.html#variables-cualitativas-1"><i class="fa fa-check"></i><b>8.3.1</b> Variables cualitativas</a></li>
<li class="chapter" data-level="8.3.2" data-path="id_120006-aed.html"><a href="id_120006-aed.html#variables-cuantitativas-1"><i class="fa fa-check"></i><b>8.3.2</b> Variables cuantitativas</a></li>
<li class="chapter" data-level="8.3.3" data-path="id_120006-aed.html"><a href="id_120006-aed.html#variables-cualitativas-y-cuantitativas"><i class="fa fa-check"></i><b>8.3.3</b> Variables cualitativas y cuantitativas</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Preparación de datos: evaluación de la calidad de los datos. Integración, limpieza y transformación</b></span></li>
<li class="chapter" data-level="9" data-path="DGDQM.html"><a href="DGDQM.html"><i class="fa fa-check"></i><b>9</b> Gobierno y gestión de calidad de Datos</a>
<ul>
<li class="chapter" data-level="9.1" data-path="DGDQM.html"><a href="DGDQM.html#introducción-4"><i class="fa fa-check"></i><b>9.1</b> Introducción</a></li>
<li class="chapter" data-level="9.2" data-path="DGDQM.html"><a href="DGDQM.html#concepto-de-gobierno-de-datos"><i class="fa fa-check"></i><b>9.2</b> Concepto de Gobierno de datos</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="DGDQM.html"><a href="DGDQM.html#beneficiosDG"><i class="fa fa-check"></i><b>9.2.1</b> Beneficios del Gobierno de Datos</a></li>
<li class="chapter" data-level="9.2.2" data-path="DGDQM.html"><a href="DGDQM.html#artefactosDG"><i class="fa fa-check"></i><b>9.2.2</b> Artefactos de un sistema de Gobierno de Datos</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="DGDQM.html"><a href="DGDQM.html#marcos-y-metodologías-existentes-de-gobierno-de-datos"><i class="fa fa-check"></i><b>9.3</b> Marcos y metodologías existentes de Gobierno de Datos</a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="DGDQM.html"><a href="DGDQM.html#modelo-alarcos-de-mejora-de-datos-mamd"><i class="fa fa-check"></i><b>9.3.1</b> Modelo Alarcos de Mejora de Datos (MAMD)</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="DGDQM.html"><a href="DGDQM.html#gestión-de-calidad-de-datos"><i class="fa fa-check"></i><b>9.4</b> Gestión de calidad de datos</a>
<ul>
<li class="chapter" data-level="9.4.1" data-path="DGDQM.html"><a href="DGDQM.html#medición-de-calidad-de-datos-vs-perfilado-de-datos"><i class="fa fa-check"></i><b>9.4.1</b> Medición de calidad de datos vs perfilado de datos</a></li>
<li class="chapter" data-level="9.4.2" data-path="DGDQM.html"><a href="DGDQM.html#mejora-de-datos"><i class="fa fa-check"></i><b>9.4.2</b> Mejora de datos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="id_130009.html"><a href="id_130009.html"><i class="fa fa-check"></i><b>10</b> Integración y limpieza de datos</a>
<ul>
<li class="chapter" data-level="10.1" data-path="id_130009.html"><a href="id_130009.html#introducción-5"><i class="fa fa-check"></i><b>10.1</b> Introducción</a></li>
<li class="chapter" data-level="10.2" data-path="id_130009.html"><a href="id_130009.html#problemas-de-calidad-de-datos"><i class="fa fa-check"></i><b>10.2</b> Problemas de calidad de datos</a></li>
<li class="chapter" data-level="10.3" data-path="id_130009.html"><a href="id_130009.html#niveles-inadecuados-de-completitud-valores-missing"><i class="fa fa-check"></i><b>10.3</b> Niveles inadecuados de completitud: Valores <em>missing</em></a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="id_130009.html"><a href="id_130009.html#visualización"><i class="fa fa-check"></i><b>10.3.1</b> Visualización</a></li>
<li class="chapter" data-level="10.3.2" data-path="id_130009.html"><a href="id_130009.html#imputacion"><i class="fa fa-check"></i><b>10.3.2</b> Técnicas de Imputación</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="id_130009.html"><a href="id_130009.html#mejorando-la-exactitud-y-la-precisión-eliminación-del-ruido-estadístico"><i class="fa fa-check"></i><b>10.4</b> Mejorando la exactitud y la precisión: eliminación del ruido estadístico</a></li>
<li class="chapter" data-level="10.5" data-path="id_130009.html"><a href="id_130009.html#integración-de-datos"><i class="fa fa-check"></i><b>10.5</b> Integración de datos</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="id_130010.html"><a href="id_130010.html"><i class="fa fa-check"></i><b>11</b> Feature Selection and Engineering</a>
<ul>
<li class="chapter" data-level="11.1" data-path="id_130010.html"><a href="id_130010.html#introducción-6"><i class="fa fa-check"></i><b>11.1</b> Introducción</a></li>
<li class="chapter" data-level="11.2" data-path="id_130010.html"><a href="id_130010.html#feature-selection-selección-de-variables"><i class="fa fa-check"></i><b>11.2</b> <em>Feature Selection</em> (Selección de variables)</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="id_130010.html"><a href="id_130010.html#métodos-de-selección-tipo-filtro"><i class="fa fa-check"></i><b>11.2.1</b> Métodos de selección tipo Filtro</a></li>
<li class="chapter" data-level="11.2.2" data-path="id_130010.html"><a href="id_130010.html#métodos-de-selección-de-variables-tipo-wrapper"><i class="fa fa-check"></i><b>11.2.2</b> Métodos de selección de variables tipo <em>wrapper</em></a></li>
<li class="chapter" data-level="11.2.3" data-path="id_130010.html"><a href="id_130010.html#métodos-de-selección-tipo-embedded"><i class="fa fa-check"></i><b>11.2.3</b> Métodos de selección tipo Embedded</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="id_130010.html"><a href="id_130010.html#transformaciones-de-escala-y-de-la-distribución-de-la-variable-objetivo"><i class="fa fa-check"></i><b>11.3</b> Transformaciones de escala y de la distribución de la variable objetivo</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="id_130010.html"><a href="id_130010.html#id_31"><i class="fa fa-check"></i><b>11.3.1</b> Transformaciones de la variable objetivo</a></li>
<li class="chapter" data-level="11.3.2" data-path="id_130010.html"><a href="id_130010.html#escalado-de-datos"><i class="fa fa-check"></i><b>11.3.2</b> Escalado de datos</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="id_130010.html"><a href="id_130010.html#feature-engineering"><i class="fa fa-check"></i><b>11.4</b> <em>Feature engineering</em></a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="id_130010.html"><a href="id_130010.html#binning"><i class="fa fa-check"></i><b>11.4.1</b> <em>Binning</em></a></li>
<li class="chapter" data-level="11.4.2" data-path="id_130010.html"><a href="id_130010.html#codificación"><i class="fa fa-check"></i><b>11.4.2</b> Codificación</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="id_130010.html"><a href="id_130010.html#reducción-de-dimensionalidad"><i class="fa fa-check"></i><b>11.5</b> Reducción de dimensionalidad</a></li>
<li class="chapter" data-level="11.6" data-path="id_130010.html"><a href="id_130010.html#otras-transformaciones"><i class="fa fa-check"></i><b>11.6</b> Otras transformaciones</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="id_130010.html"><a href="id_130010.html#particionado-de-datos"><i class="fa fa-check"></i><b>11.6.1</b> Particionado de datos</a></li>
<li class="chapter" data-level="11.6.2" data-path="id_130010.html"><a href="id_130010.html#técnicas-para-manejar-datos-no-balanceados"><i class="fa fa-check"></i><b>11.6.2</b> Técnicas para manejar datos no balanceados</a></li>
<li class="chapter" data-level="11.6.3" data-path="id_130010.html"><a href="id_130010.html#métodos-de-remuestreo"><i class="fa fa-check"></i><b>11.6.3</b> Métodos de remuestreo</a></li>
<li class="chapter" data-level="11.6.4" data-path="id_130010.html"><a href="id_130010.html#ajuste-de-hiperparámetros"><i class="fa fa-check"></i><b>11.6.4</b> Ajuste de hiperparámetros</a></li>
<li class="chapter" data-level="11.6.5" data-path="id_130010.html"><a href="id_130010.html#evaluación-de-modelos"><i class="fa fa-check"></i><b>11.6.5</b> Evaluación de modelos</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>IV Técnicas de modelización estadísticas avanzadas</b></span></li>
<li class="chapter" data-level="12" data-path="Funda-probab.html"><a href="Funda-probab.html"><i class="fa fa-check"></i><b>12</b> Fundamentos de probabilidad</a>
<ul>
<li class="chapter" data-level="12.1" data-path="Funda-probab.html"><a href="Funda-probab.html#introducción-a-la-probabilidad"><i class="fa fa-check"></i><b>12.1</b> Introducción a la probabilidad</a></li>
<li class="chapter" data-level="12.2" data-path="Funda-probab.html"><a href="Funda-probab.html#probabilidad-elementos-básicos-definición-y-teoremas"><i class="fa fa-check"></i><b>12.2</b> Probabilidad: elementos básicos, definición y teoremas</a></li>
<li class="chapter" data-level="12.3" data-path="Funda-probab.html"><a href="Funda-probab.html#variable-aleatoria-y-su-distribución-tipos-de-variables-aleatorias"><i class="fa fa-check"></i><b>12.3</b> Variable aleatoria y su distribución: tipos de variables aleatorias</a></li>
<li class="chapter" data-level="12.4" data-path="Funda-probab.html"><a href="Funda-probab.html#modelos-de-distribución-de-probabilidad"><i class="fa fa-check"></i><b>12.4</b> Modelos de distribución de probabilidad</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="Funda-probab.html"><a href="Funda-probab.html#modelos-discretos"><i class="fa fa-check"></i><b>12.4.1</b> Modelos discretos</a></li>
<li class="chapter" data-level="12.4.2" data-path="Funda-probab.html"><a href="Funda-probab.html#modelos-continuos"><i class="fa fa-check"></i><b>12.4.2</b> Modelos continuos</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="Funda-probab.html"><a href="Funda-probab.html#tcl"><i class="fa fa-check"></i><b>12.5</b> Teorema central del límite (TCL)</a></li>
<li class="chapter" data-level="12.6" data-path="Funda-probab.html"><a href="Funda-probab.html#ejemplo-de-distribuciones-usando-r"><i class="fa fa-check"></i><b>12.6</b> Ejemplo de distribuciones usando <strong>R</strong></a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="Fundainfer.html"><a href="Fundainfer.html"><i class="fa fa-check"></i><b>13</b> Fundamentos de Inferencia Estadística</a>
<ul>
<li class="chapter" data-level="13.1" data-path="Fundainfer.html"><a href="Fundainfer.html#introinfer"><i class="fa fa-check"></i><b>13.1</b> Introducción a la Inferencia Estadística</a></li>
<li class="chapter" data-level="13.2" data-path="Fundainfer.html"><a href="Fundainfer.html#mas"><i class="fa fa-check"></i><b>13.2</b> Muestreo aleatorio simple</a></li>
<li class="chapter" data-level="13.3" data-path="Fundainfer.html"><a href="Fundainfer.html#estimpuntual"><i class="fa fa-check"></i><b>13.3</b> Estimación puntual</a></li>
<li class="chapter" data-level="13.4" data-path="Fundainfer.html"><a href="Fundainfer.html#estimintervalos"><i class="fa fa-check"></i><b>13.4</b> Estimación por intervalos</a></li>
<li class="chapter" data-level="13.5" data-path="Fundainfer.html"><a href="Fundainfer.html#contrhip"><i class="fa fa-check"></i><b>13.5</b> Contrastes de hipótesis</a></li>
<li class="chapter" data-level="13.6" data-path="Fundainfer.html"><a href="Fundainfer.html#pobnormales"><i class="fa fa-check"></i><b>13.6</b> Inferencia estadística paramétrica sobre poblaciones normales</a></li>
<li class="chapter" data-level="13.7" data-path="Fundainfer.html"><a href="Fundainfer.html#ejemplopobnorm"><i class="fa fa-check"></i><b>13.7</b> Inferencia sobre poblaciones normales con <strong>R</strong></a></li>
<li class="chapter" data-level="13.8" data-path="Fundainfer.html"><a href="Fundainfer.html#contrnormalidad"><i class="fa fa-check"></i><b>13.8</b> Inferencia estadística no paramétrica: contrastes de normalidad</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="muestreo.html"><a href="muestreo.html"><i class="fa fa-check"></i><b>14</b> Métodos de muestreo y remuestreo</a>
<ul>
<li class="chapter" data-level="14.1" data-path="muestreo.html"><a href="muestreo.html#introducción-al-muestreo"><i class="fa fa-check"></i><b>14.1</b> Introducción al muestreo</a></li>
<li class="chapter" data-level="14.2" data-path="muestreo.html"><a href="muestreo.html#muestreo-aleatorio-simple-1"><i class="fa fa-check"></i><b>14.2</b> Muestreo aleatorio simple</a></li>
<li class="chapter" data-level="14.3" data-path="muestreo.html"><a href="muestreo.html#muestestra"><i class="fa fa-check"></i><b>14.3</b> Muestreo estratificado</a></li>
<li class="chapter" data-level="14.4" data-path="muestreo.html"><a href="muestreo.html#otros-tipos-de-muestreo-probabilístico"><i class="fa fa-check"></i><b>14.4</b> Otros tipos de muestreo probabilístico</a></li>
<li class="chapter" data-level="14.5" data-path="muestreo.html"><a href="muestreo.html#técnicas-de-remuestreo-bootstrap."><i class="fa fa-check"></i><b>14.5</b> Técnicas de remuestreo: Bootstrap.</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="modelización-lineal.html"><a href="modelización-lineal.html"><i class="fa fa-check"></i><b>15</b> Modelización lineal</a>
<ul>
<li class="chapter" data-level="15.1" data-path="modelización-lineal.html"><a href="modelización-lineal.html#modelización"><i class="fa fa-check"></i><b>15.1</b> Modelización</a></li>
<li class="chapter" data-level="15.2" data-path="modelización-lineal.html"><a href="modelización-lineal.html#procedimiento-de-modelización"><i class="fa fa-check"></i><b>15.2</b> Procedimiento de modelización</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="modelización-lineal.html"><a href="modelización-lineal.html#Bondad"><i class="fa fa-check"></i><b>15.2.1</b> Estimación del modelo</a></li>
<li class="chapter" data-level="15.2.2" data-path="modelización-lineal.html"><a href="modelización-lineal.html#validación-del-modelo"><i class="fa fa-check"></i><b>15.2.2</b> Validación del modelo</a></li>
<li class="chapter" data-level="15.2.3" data-path="modelización-lineal.html"><a href="modelización-lineal.html#interpretación-de-los-coeficientes"><i class="fa fa-check"></i><b>15.2.3</b> Interpretación de los coeficientes</a></li>
<li class="chapter" data-level="15.2.4" data-path="modelización-lineal.html"><a href="modelización-lineal.html#predicción"><i class="fa fa-check"></i><b>15.2.4</b> Predicción</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="modelización-lineal.html"><a href="modelización-lineal.html#procedimiento-con-r-la-función-lm"><i class="fa fa-check"></i><b>15.3</b> Procedimiento con R: la función <code>lm</code></a></li>
<li class="chapter" data-level="15.4" data-path="modelización-lineal.html"><a href="modelización-lineal.html#Casos"><i class="fa fa-check"></i><b>15.4</b> Casos prácticos</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="modelización-lineal.html"><a href="modelización-lineal.html#estimación-de-los-coeficientes"><i class="fa fa-check"></i><b>15.4.1</b> Estimación de los coeficientes</a></li>
<li class="chapter" data-level="15.4.2" data-path="modelización-lineal.html"><a href="modelización-lineal.html#validación"><i class="fa fa-check"></i><b>15.4.2</b> Validación</a></li>
<li class="chapter" data-level="15.4.3" data-path="modelización-lineal.html"><a href="modelización-lineal.html#interpretación-de-los-coeficientes-1"><i class="fa fa-check"></i><b>15.4.3</b> Interpretación de los coeficientes</a></li>
<li class="chapter" data-level="15.4.4" data-path="modelización-lineal.html"><a href="modelización-lineal.html#predicción-1"><i class="fa fa-check"></i><b>15.4.4</b> Predicción</a></li>
<li class="chapter" data-level="15.4.5" data-path="modelización-lineal.html"><a href="modelización-lineal.html#nuevo-ajuste-con-logozone"><i class="fa fa-check"></i><b>15.4.5</b> Nuevo ajuste con <code>log(Ozone)</code></a></li>
<li class="chapter" data-level="15.4.6" data-path="modelización-lineal.html"><a href="modelización-lineal.html#coeficientes-de-variables-categóricas"><i class="fa fa-check"></i><b>15.4.6</b> Coeficientes de variables categóricas</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="modelización-lineal.html"><a href="modelización-lineal.html#comentarios-finales"><i class="fa fa-check"></i><b>15.5</b> Comentarios finales</a>
<ul>
<li class="chapter" data-level="" data-path="modelización-lineal.html"><a href="modelización-lineal.html#resumen"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html"><i class="fa fa-check"></i><b>16</b> Modelos lineales generalizados</a>
<ul>
<li class="chapter" data-level="16.1" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#motivación"><i class="fa fa-check"></i><b>16.1</b> Motivación</a></li>
<li class="chapter" data-level="16.2" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#modelo-y-sus-componentes"><i class="fa fa-check"></i><b>16.2</b> Modelo y sus componentes</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#función-enlace"><i class="fa fa-check"></i><b>16.2.1</b> Función enlace </a></li>
<li class="chapter" data-level="16.2.2" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#glms-en-r"><i class="fa fa-check"></i><b>16.2.2</b> GLMs en <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#regresión-logística"><i class="fa fa-check"></i><b>16.3</b> Regresión logística</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#procedimiento-de-ajuste"><i class="fa fa-check"></i><b>16.3.1</b> Procedimiento de ajuste</a></li>
<li class="chapter" data-level="16.3.2" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#adecuación-del-modelo"><i class="fa fa-check"></i><b>16.3.2</b> Adecuación del modelo</a></li>
<li class="chapter" data-level="16.3.3" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#SECCinterp"><i class="fa fa-check"></i><b>16.3.3</b> Interpretación de resultados</a></li>
<li class="chapter" data-level="16.3.4" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#predicción.-curva-roc-y-auc"><i class="fa fa-check"></i><b>16.3.4</b> Predicción. Curva ROC y AUC</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#regresión-de-poisson"><i class="fa fa-check"></i><b>16.4</b> Regresión de Poisson</a></li>
<li class="chapter" data-level="16.5" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#casos-prácticos"><i class="fa fa-check"></i><b>16.5</b> Casos prácticos</a>
<ul>
<li class="chapter" data-level="16.5.1" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#ejemplos-de-regresión-logística"><i class="fa fa-check"></i><b>16.5.1</b> Ejemplos de regresión logística</a></li>
<li class="chapter" data-level="16.5.2" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#ejemplo-de-regresión-de-poisson"><i class="fa fa-check"></i><b>16.5.2</b> Ejemplo de regresión de Poisson</a></li>
<li class="chapter" data-level="" data-path="modelos-lineales-generalizados.html"><a href="modelos-lineales-generalizados.html#resumen-1"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html"><i class="fa fa-check"></i><b>17</b> Modelos aditivos generalizados</a>
<ul>
<li class="chapter" data-level="17.1" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#introducción-7"><i class="fa fa-check"></i><b>17.1</b> Introducción</a></li>
<li class="chapter" data-level="17.2" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#splines-con-penalizaciones"><i class="fa fa-check"></i><b>17.2</b> Splines con penalizaciones</a></li>
<li class="chapter" data-level="17.3" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#aspectos-metodológicos"><i class="fa fa-check"></i><b>17.3</b> Aspectos metodológicos</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#estimación-de-los-paraámetros-del-modelo"><i class="fa fa-check"></i><b>17.3.1</b> Estimación de los paraámetros del modelo</a></li>
<li class="chapter" data-level="17.3.2" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#inferencia-sobre-las-funciones-suaves"><i class="fa fa-check"></i><b>17.3.2</b> Inferencia sobre las funciones suaves</a></li>
<li class="chapter" data-level="17.3.3" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#suavizado-mutidimensional-y-para-datos-no-gaussianos"><i class="fa fa-check"></i><b>17.3.3</b> Suavizado mutidimensional y para datos no Gaussianos</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#la-función-gam-del-paquete-mgcv"><i class="fa fa-check"></i><b>17.4</b> La función <code>gam</code> del paquete <code>mgcv</code></a></li>
<li class="chapter" data-level="17.5" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#casos-prácticos-1"><i class="fa fa-check"></i><b>17.5</b> Casos prácticos</a>
<ul>
<li class="chapter" data-level="17.5.1" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#modelo-unidimensional-con-fossil"><i class="fa fa-check"></i><b>17.5.1</b> Modelo unidimensional con <code>fossil</code></a></li>
<li class="chapter" data-level="17.5.2" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#modelo-aditivo-con-airquality"><i class="fa fa-check"></i><b>17.5.2</b> Modelo aditivo con <code>airquality</code></a></li>
<li class="chapter" data-level="17.5.3" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#modelo-semiparamétrico-con-onions"><i class="fa fa-check"></i><b>17.5.3</b> Modelo semiparamétrico con <code>onions</code></a></li>
<li class="chapter" data-level="17.5.4" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#modelo-aditivo-generalizado-y-multidimensional-con-smacker"><i class="fa fa-check"></i><b>17.5.4</b> Modelo aditivo generalizado y multidimensional, con <code>smacker</code></a></li>
<li class="chapter" data-level="" data-path="modelos-aditivos-generalizados.html"><a href="modelos-aditivos-generalizados.html#resumen-2"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="modelos-mixtos.html"><a href="modelos-mixtos.html"><i class="fa fa-check"></i><b>18</b> Modelos mixtos</a>
<ul>
<li class="chapter" data-level="18.1" data-path="modelos-mixtos.html"><a href="modelos-mixtos.html#conceptos-básicos"><i class="fa fa-check"></i><b>18.1</b> Conceptos básicos</a>
<ul>
<li class="chapter" data-level="18.1.1" data-path="modelos-mixtos.html"><a href="modelos-mixtos.html#tipo-y-estructura-de-los-datos"><i class="fa fa-check"></i><b>18.1.1</b> Tipo y estructura de los datos</a></li>
<li class="chapter" data-level="18.1.2" data-path="modelos-mixtos.html"><a href="modelos-mixtos.html#efectos-fijos-o-aleatorios"><i class="fa fa-check"></i><b>18.1.2</b> ¿Efectos fijos o aleatorios?</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="modelos-mixtos.html"><a href="modelos-mixtos.html#formulación-del-modelo-con-efectos-aleatorios-o-modelos-mixtos"><i class="fa fa-check"></i><b>18.2</b> Formulación del modelo con efectos aleatorios o modelos mixtos</a>
<ul>
<li class="chapter" data-level="18.2.1" data-path="modelos-mixtos.html"><a href="modelos-mixtos.html#formulación-general"><i class="fa fa-check"></i><b>18.2.1</b> Formulación general</a></li>
<li class="chapter" data-level="18.2.2" data-path="modelos-mixtos.html"><a href="modelos-mixtos.html#inferencia-y-selección-del-modelo"><i class="fa fa-check"></i><b>18.2.2</b> Inferencia y selección del modelo</a></li>
<li class="chapter" data-level="18.2.3" data-path="modelos-mixtos.html"><a href="modelos-mixtos.html#diagnosis-del-modelo"><i class="fa fa-check"></i><b>18.2.3</b> Diagnosis del modelo</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="modelos-mixtos.html"><a href="modelos-mixtos.html#funciones-de-r-para-ajustar-modelos-mixtos"><i class="fa fa-check"></i><b>18.3</b> Funciones de <code>R</code> para ajustar modelos mixtos</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="modelos-mixtos.html"><a href="modelos-mixtos.html#la-función-lmer"><i class="fa fa-check"></i><b>18.3.1</b> La función <code>lmer()</code></a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="modelos-mixtos.html"><a href="modelos-mixtos.html#caso-práctico"><i class="fa fa-check"></i><b>18.4</b> Caso práctico</a>
<ul>
<li class="chapter" data-level="18.4.1" data-path="modelos-mixtos.html"><a href="modelos-mixtos.html#modelo-con-ordenada-en-el-origen-aleatoria"><i class="fa fa-check"></i><b>18.4.1</b> Modelo con ordenada en el origen aleatoria</a></li>
<li class="chapter" data-level="18.4.2" data-path="modelos-mixtos.html"><a href="modelos-mixtos.html#modelo-con-pendiente-aleatoria"><i class="fa fa-check"></i><b>18.4.2</b> Modelo con pendiente aleatoria</a></li>
<li class="chapter" data-level="18.4.3" data-path="modelos-mixtos.html"><a href="modelos-mixtos.html#cómo-construir-el-modelo-en-la-práctica"><i class="fa fa-check"></i><b>18.4.3</b> ¿Cómo construir el modelo en la práctica?</a></li>
<li class="chapter" data-level="" data-path="modelos-mixtos.html"><a href="modelos-mixtos.html#resumen-3"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="modelos-sparse-y-métodos-penalizados-de-regresión.html"><a href="modelos-sparse-y-métodos-penalizados-de-regresión.html"><i class="fa fa-check"></i><b>19</b> Modelos sparse y métodos penalizados de regresión</a>
<ul>
<li class="chapter" data-level="19.1" data-path="modelos-sparse-y-métodos-penalizados-de-regresión.html"><a href="modelos-sparse-y-métodos-penalizados-de-regresión.html#introducción-8"><i class="fa fa-check"></i><b>19.1</b> Introducción</a></li>
<li class="chapter" data-level="19.2" data-path="modelos-sparse-y-métodos-penalizados-de-regresión.html"><a href="modelos-sparse-y-métodos-penalizados-de-regresión.html#selección-del-mejor-subconjunto"><i class="fa fa-check"></i><b>19.2</b> Selección del mejor subconjunto</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="modelos-sparse-y-métodos-penalizados-de-regresión.html"><a href="modelos-sparse-y-métodos-penalizados-de-regresión.html#ejemplo-sueldo-de-jugadores-de-béisbol"><i class="fa fa-check"></i><b>19.2.1</b> Ejemplo: Sueldo de jugadores de béisbol</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="modelos-sparse-y-métodos-penalizados-de-regresión.html"><a href="modelos-sparse-y-métodos-penalizados-de-regresión.html#selección-stepwise"><i class="fa fa-check"></i><b>19.3</b> Selección <em>Stepwise</em></a>
<ul>
<li class="chapter" data-level="19.3.1" data-path="modelos-sparse-y-métodos-penalizados-de-regresión.html"><a href="modelos-sparse-y-métodos-penalizados-de-regresión.html#forward-stepwise"><i class="fa fa-check"></i><b>19.3.1</b> Forward stepwise</a></li>
<li class="chapter" data-level="19.3.2" data-path="modelos-sparse-y-métodos-penalizados-de-regresión.html"><a href="modelos-sparse-y-métodos-penalizados-de-regresión.html#backward-stepwise"><i class="fa fa-check"></i><b>19.3.2</b> Backward stepwise</a></li>
<li class="chapter" data-level="19.3.3" data-path="modelos-sparse-y-métodos-penalizados-de-regresión.html"><a href="modelos-sparse-y-métodos-penalizados-de-regresión.html#ejemplo-sueldo-de-jugadores-de-béisbol-1"><i class="fa fa-check"></i><b>19.3.3</b> Ejemplo: Sueldo de jugadores de béisbol</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="modelos-sparse-y-métodos-penalizados-de-regresión.html"><a href="modelos-sparse-y-métodos-penalizados-de-regresión.html#métodos-shrinkage"><i class="fa fa-check"></i><b>19.4</b> Métodos Shrinkage</a>
<ul>
<li class="chapter" data-level="19.4.1" data-path="modelos-sparse-y-métodos-penalizados-de-regresión.html"><a href="modelos-sparse-y-métodos-penalizados-de-regresión.html#regresión-ridge"><i class="fa fa-check"></i><b>19.4.1</b> Regresión ridge</a></li>
<li class="chapter" data-level="19.4.2" data-path="modelos-sparse-y-métodos-penalizados-de-regresión.html"><a href="modelos-sparse-y-métodos-penalizados-de-regresión.html#selección-del-parámetro-de-tuneado"><i class="fa fa-check"></i><b>19.4.2</b> Selección del parámetro de tuneado</a></li>
<li class="chapter" data-level="19.4.3" data-path="modelos-sparse-y-métodos-penalizados-de-regresión.html"><a href="modelos-sparse-y-métodos-penalizados-de-regresión.html#regresión-lasso"><i class="fa fa-check"></i><b>19.4.3</b> Regresión Lasso</a></li>
<li class="chapter" data-level="19.4.4" data-path="modelos-sparse-y-métodos-penalizados-de-regresión.html"><a href="modelos-sparse-y-métodos-penalizados-de-regresión.html#elastic-net"><i class="fa fa-check"></i><b>19.4.4</b> Elastic net </a></li>
<li class="chapter" data-level="" data-path="modelos-sparse-y-métodos-penalizados-de-regresión.html"><a href="modelos-sparse-y-métodos-penalizados-de-regresión.html#resumen-4"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="20" data-path="modelización-de-series-temporales.html"><a href="modelización-de-series-temporales.html"><i class="fa fa-check"></i><b>20</b> Modelización de series temporales</a>
<ul>
<li class="chapter" data-level="20.1" data-path="modelización-de-series-temporales.html"><a href="modelización-de-series-temporales.html#conceptos-básicos-1"><i class="fa fa-check"></i><b>20.1</b> Conceptos básicos</a></li>
<li class="chapter" data-level="20.2" data-path="modelización-de-series-temporales.html"><a href="modelización-de-series-temporales.html#modelos-arima"><i class="fa fa-check"></i><b>20.2</b> Modelos ARIMA</a></li>
<li class="chapter" data-level="20.3" data-path="modelización-de-series-temporales.html"><a href="modelización-de-series-temporales.html#análisis-de-series-temporales-con-r"><i class="fa fa-check"></i><b>20.3</b> Análisis de series temporales con R</a>
<ul>
<li class="chapter" data-level="20.3.1" data-path="modelización-de-series-temporales.html"><a href="modelización-de-series-temporales.html#identificación-o-especificación-del-modelo"><i class="fa fa-check"></i><b>20.3.1</b> Identificación o especificación del modelo</a></li>
<li class="chapter" data-level="20.3.2" data-path="modelización-de-series-temporales.html"><a href="modelización-de-series-temporales.html#estimación-del-modelo"><i class="fa fa-check"></i><b>20.3.2</b> Estimación del modelo</a></li>
<li class="chapter" data-level="20.3.3" data-path="modelización-de-series-temporales.html"><a href="modelización-de-series-temporales.html#diagnosis-validación-y-contrastación"><i class="fa fa-check"></i><b>20.3.3</b> Diagnosis, validación y contrastación</a></li>
<li class="chapter" data-level="20.3.4" data-path="modelización-de-series-temporales.html"><a href="modelización-de-series-temporales.html#predicción-2"><i class="fa fa-check"></i><b>20.3.4</b> Predicción</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliografía.html"><a href="bibliografía.html"><i class="fa fa-check"></i>Bibliografía</a></li>
<li class="chapter" data-level="21" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html"><i class="fa fa-check"></i><b>21</b> Análisis de tablas de contingencia</a>
<ul>
<li class="chapter" data-level="21.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#introducción-9"><i class="fa fa-check"></i><b>21.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="21.1.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#motiv"><i class="fa fa-check"></i><b>21.1.1</b> Motivación</a></li>
<li class="chapter" data-level="21.1.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#notac"><i class="fa fa-check"></i><b>21.1.2</b> Notación</a></li>
<li class="chapter" data-level="21.1.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#diseños-experimentales-o-procedimientos-de-muestreo-que-dan-lugar-a-una-tabla-de-contingencia"><i class="fa fa-check"></i><b>21.1.3</b> Diseños experimentales o procedimientos de muestreo que dan lugar a una tabla de contingencia</a></li>
</ul></li>
<li class="chapter" data-level="21.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contraste-de-independencia-en-tablas-2times-2"><i class="fa fa-check"></i><b>21.2</b> Contraste de independencia en tablas <span class="math inline">\((2\times 2)\)</span></a>
<ul>
<li class="chapter" data-level="21.2.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#introducción-10"><i class="fa fa-check"></i><b>21.2.1</b> Introducción</a></li>
<li class="chapter" data-level="21.2.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#plantgen"><i class="fa fa-check"></i><b>21.2.2</b> Planteamiento general del contraste exacto de independencia</a></li>
<li class="chapter" data-level="21.2.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#algoritmo"><i class="fa fa-check"></i><b>21.2.3</b> Algoritmo para la realización del contraste exacto de independencia</a></li>
<li class="chapter" data-level="21.2.4" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contraste-de-independencia-diseño-tipo-1"><i class="fa fa-check"></i><b>21.2.4</b> Contraste de independencia: Diseño Tipo 1</a></li>
<li class="chapter" data-level="21.2.5" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#dise"><i class="fa fa-check"></i><b>21.2.5</b> Contraste de independencia: Diseños Tipo 2 y Tipo 3</a></li>
</ul></li>
<li class="chapter" data-level="21.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contraste-de-independencia-en-tablas-rtimes-c"><i class="fa fa-check"></i><b>21.3</b> Contraste de independencia en tablas <span class="math inline">\(R\times C\)</span></a>
<ul>
<li class="chapter" data-level="21.3.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#IntroRxC"><i class="fa fa-check"></i><b>21.3.1</b> Introducción</a></li>
<li class="chapter" data-level="21.3.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contaprox"><i class="fa fa-check"></i><b>21.3.2</b> Contrastes aproximados</a></li>
<li class="chapter" data-level="21.3.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contraste-aproximado-con-corrección-de-continuidad-1"><i class="fa fa-check"></i><b>21.3.3</b> Contraste aproximado con corrección de continuidad</a></li>
</ul></li>
<li class="chapter" data-level="21.4" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#medidas"><i class="fa fa-check"></i><b>21.4</b> Medidas de asociación en tablas <span class="math inline">\(2\times 2\)</span></a>
<ul>
<li class="chapter" data-level="21.4.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#introducción-11"><i class="fa fa-check"></i><b>21.4.1</b> Introducción</a></li>
<li class="chapter" data-level="21.4.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#la-hatq-de-yule"><i class="fa fa-check"></i><b>21.4.2</b> La <span class="math inline">\(\hat{Q}\)</span> de Yule</a></li>
<li class="chapter" data-level="21.4.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#otras-medidas-de-asociación-para-tablas-2times-2"><i class="fa fa-check"></i><b>21.4.3</b> Otras medidas de asociación para tablas <span class="math inline">\(2\times 2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="21.5" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#medidas-de-asociación-en-tablas-rtimes-c"><i class="fa fa-check"></i><b>21.5</b> Medidas de asociación en tablas <span class="math inline">\(R\times C\)</span></a>
<ul>
<li class="chapter" data-level="21.5.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#introducción-12"><i class="fa fa-check"></i><b>21.5.1</b> Introducción</a></li>
<li class="chapter" data-level="21.5.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#medidas-derivadas-del-estadístico-chi-cuadrado"><i class="fa fa-check"></i><b>21.5.2</b> Medidas derivadas del estadístico Chi-cuadrado</a></li>
<li class="chapter" data-level="21.5.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#medidas-basadas-en-la-reducción-proporcional-del-error-lambda-de-goodman-y-kruskal"><i class="fa fa-check"></i><b>21.5.3</b> Medidas basadas en la reducción proporcional del error: <span class="math inline">\(\lambda\)</span> de Goodman y Kruskal</a></li>
<li class="chapter" data-level="21.5.4" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#determinación-de-las-fuentes-de-asociación"><i class="fa fa-check"></i><b>21.5.4</b> Determinación de las fuentes de asociación</a></li>
</ul></li>
<li class="chapter" data-level="21.6" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contrastes-de-independencia-en-tablas-multidimensionales"><i class="fa fa-check"></i><b>21.6</b> Contrastes de independencia en tablas multidimensionales</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="correspondencias.html"><a href="correspondencias.html"><i class="fa fa-check"></i><b>22</b> Análisis de correspondencias</a>
<ul>
<li class="chapter" data-level="22.1" data-path="correspondencias.html"><a href="correspondencias.html#introducción-13"><i class="fa fa-check"></i><b>22.1</b> Introducción</a></li>
<li class="chapter" data-level="22.2" data-path="correspondencias.html"><a href="correspondencias.html#metodología-del-análisis-de-correspondencias"><i class="fa fa-check"></i><b>22.2</b> Metodología del análisis de correspondencias</a>
<ul>
<li class="chapter" data-level="22.2.1" data-path="correspondencias.html"><a href="correspondencias.html#proyecciones-fila-columna-y-simétrica"><i class="fa fa-check"></i><b>22.2.1</b> Proyecciones fila, columna y simétrica</a></li>
</ul></li>
<li class="chapter" data-level="22.3" data-path="correspondencias.html"><a href="correspondencias.html#ejemplos-de-análisis-de-correspondencias-con-r"><i class="fa fa-check"></i><b>22.3</b> Ejemplos de análisis de correspondencias con <strong>R</strong></a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="análisis-conjunto.html"><a href="análisis-conjunto.html"><i class="fa fa-check"></i><b>23</b> Análisis conjunto</a>
<ul>
<li class="chapter" data-level="23.1" data-path="análisis-conjunto.html"><a href="análisis-conjunto.html#introducción-conceptos-clave-y-tipos-de-análisis"><i class="fa fa-check"></i><b>23.1</b> Introducción, conceptos clave y tipos de análisis</a></li>
<li class="chapter" data-level="23.2" data-path="análisis-conjunto.html"><a href="análisis-conjunto.html#aplicación-del-análisis-conjunto-etapas"><i class="fa fa-check"></i><b>23.2</b> Aplicación del Análisis Conjunto (etapas):</a></li>
<li class="chapter" data-level="23.3" data-path="análisis-conjunto.html"><a href="análisis-conjunto.html#ejemplo-utilizando-r"><i class="fa fa-check"></i><b>23.3</b> Ejemplo utilizando R:</a></li>
</ul></li>
<li class="chapter" data-level="24" data-path="análisis-discriminante.html"><a href="análisis-discriminante.html"><i class="fa fa-check"></i><b>24</b> Análisis discriminante</a>
<ul>
<li class="chapter" data-level="24.1" data-path="análisis-discriminante.html"><a href="análisis-discriminante.html#introducción-14"><i class="fa fa-check"></i><b>24.1</b> Introducción</a></li>
<li class="chapter" data-level="24.2" data-path="análisis-discriminante.html"><a href="análisis-discriminante.html#tipos-de-análisis-discriminantes"><i class="fa fa-check"></i><b>24.2</b> Tipos de análisis discriminantes:</a></li>
<li class="chapter" data-level="24.3" data-path="análisis-discriminante.html"><a href="análisis-discriminante.html#ejemplos"><i class="fa fa-check"></i><b>24.3</b> Ejemplos:</a></li>
</ul></li>
<li class="chapter" data-level="25" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html"><i class="fa fa-check"></i><b>25</b> Árboles de clasificación y regresión </a>
<ul>
<li class="chapter" data-level="25.1" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#introducción-15"><i class="fa fa-check"></i><b>25.1</b> Introducción </a></li>
<li class="chapter" data-level="25.2" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#aprendizaje-con-árboles-de-decisión"><i class="fa fa-check"></i><b>25.2</b> Aprendizaje con árboles de decisión</a></li>
<li class="chapter" data-level="25.3" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#cómo-se-va-dividiendo-el-árbol"><i class="fa fa-check"></i><b>25.3</b> ¿Cómo se va dividiendo el árbol? </a>
<ul>
<li class="chapter" data-level="25.3.1" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#impureza-de-gini"><i class="fa fa-check"></i><b>25.3.1</b> Impureza de Gini</a></li>
<li class="chapter" data-level="25.3.2" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#entropía"><i class="fa fa-check"></i><b>25.3.2</b> Entropía </a></li>
<li class="chapter" data-level="25.3.3" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#ganancia-de-información"><i class="fa fa-check"></i><b>25.3.3</b> Ganancia de información</a></li>
<li class="chapter" data-level="25.3.4" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#suma-residual-de-cuadrados-mínima"><i class="fa fa-check"></i><b>25.3.4</b> Suma residual de cuadrados mínima</a></li>
</ul></li>
<li class="chapter" data-level="25.4" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#sobreajuste"><i class="fa fa-check"></i><b>25.4</b> Sobreajuste </a></li>
<li class="chapter" data-level="25.5" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#cuánto-debe-crecer-un-árbol"><i class="fa fa-check"></i><b>25.5</b> ¿Cuánto debe crecer un árbol? </a>
<ul>
<li class="chapter" data-level="25.5.1" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#la-parada-temprana"><i class="fa fa-check"></i><b>25.5.1</b> La parada temprana </a></li>
<li class="chapter" data-level="25.5.2" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#la-poda"><i class="fa fa-check"></i><b>25.5.2</b> La poda </a></li>
</ul></li>
<li class="chapter" data-level="25.6" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#el-algoritmo-id3-para-la-construcción-de-un-árbol-de-decisión"><i class="fa fa-check"></i><b>25.6</b> El algoritmo ID3 para la construcción de un árbol de decisión</a></li>
<li class="chapter" data-level="25.7" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#procedimiento-con-r-la-funcion-rpart"><i class="fa fa-check"></i><b>25.7</b> Procedimiento con R: la funcion <code>rpart</code></a></li>
<li class="chapter" data-level="25.8" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#aplicaciones-de-los-árboles-de-decisión"><i class="fa fa-check"></i><b>25.8</b> Aplicaciones de los árboles de decisión</a>
<ul>
<li class="chapter" data-level="25.8.1" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#el-caso-de-negocio"><i class="fa fa-check"></i><b>25.8.1</b> El caso de negocio</a></li>
<li class="chapter" data-level="25.8.2" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#árbol-de-clasificación-para-determinar-la-intención-de-compra"><i class="fa fa-check"></i><b>25.8.2</b> Árbol de clasificación para determinar la intención de compra</a></li>
<li class="chapter" data-level="25.8.3" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#árbol-de-regresión-para-estimar-el-número-de-días-hospitalizado"><i class="fa fa-check"></i><b>25.8.3</b> Árbol de regresión para estimar el número de días hospitalizado</a></li>
<li class="chapter" data-level="" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#resumen-5"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="26" data-path="máquinas-de-vector-soporte.html"><a href="máquinas-de-vector-soporte.html"><i class="fa fa-check"></i><b>26</b> Máquinas de Vector Soporte</a>
<ul>
<li class="chapter" data-level="26.1" data-path="máquinas-de-vector-soporte.html"><a href="máquinas-de-vector-soporte.html#introducción-16"><i class="fa fa-check"></i><b>26.1</b> Introducción</a></li>
<li class="chapter" data-level="26.2" data-path="máquinas-de-vector-soporte.html"><a href="máquinas-de-vector-soporte.html#algoritmo-svm-para-clasificación-binaria"><i class="fa fa-check"></i><b>26.2</b> Algoritmo SVM para clasificación binaria</a></li>
<li class="chapter" data-level="26.3" data-path="máquinas-de-vector-soporte.html"><a href="máquinas-de-vector-soporte.html#y-si-tengo-más-de-dos-clases"><i class="fa fa-check"></i><b>26.3</b> ¿Y si tengo más de dos clases?</a></li>
<li class="chapter" data-level="26.4" data-path="máquinas-de-vector-soporte.html"><a href="máquinas-de-vector-soporte.html#truco-del-kernel-tratando-con-la-no-linearidad"><i class="fa fa-check"></i><b>26.4</b> Truco del Kernel: Tratando con la no linearidad</a>
<ul>
<li class="chapter" data-level="26.4.1" data-path="máquinas-de-vector-soporte.html"><a href="máquinas-de-vector-soporte.html#algunos-kernels-populares"><i class="fa fa-check"></i><b>26.4.1</b> Algunos kernels populares</a></li>
</ul></li>
<li class="chapter" data-level="26.5" data-path="máquinas-de-vector-soporte.html"><a href="máquinas-de-vector-soporte.html#procedimiento-con-r-la-funcion-svm"><i class="fa fa-check"></i><b>26.5</b> Procedimiento con R: la funcion <code>svm</code></a></li>
<li class="chapter" data-level="26.6" data-path="máquinas-de-vector-soporte.html"><a href="máquinas-de-vector-soporte.html#aplicación-de-un-modelo-svm-radial-con-ajuste-automático-en-r"><i class="fa fa-check"></i><b>26.6</b> Aplicación de un modelo SVM Radial con ajuste automático en R</a>
<ul>
<li class="chapter" data-level="26.6.1" data-path="máquinas-de-vector-soporte.html"><a href="máquinas-de-vector-soporte.html#importancia-de-las-variables"><i class="fa fa-check"></i><b>26.6.1</b> Importancia de las variables</a></li>
<li class="chapter" data-level="" data-path="máquinas-de-vector-soporte.html"><a href="máquinas-de-vector-soporte.html#resumen-6"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="27" data-path="clasificador-k-vecinos-más-próximos.html"><a href="clasificador-k-vecinos-más-próximos.html"><i class="fa fa-check"></i><b>27</b> Clasificador k-vecinos más próximos</a>
<ul>
<li class="chapter" data-level="27.1" data-path="clasificador-k-vecinos-más-próximos.html"><a href="clasificador-k-vecinos-más-próximos.html#introducción-17"><i class="fa fa-check"></i><b>27.1</b> Introducción</a></li>
<li class="chapter" data-level="27.2" data-path="clasificador-k-vecinos-más-próximos.html"><a href="clasificador-k-vecinos-más-próximos.html#decisiones-a-tener-en-cuenta"><i class="fa fa-check"></i><b>27.2</b> Decisiones a tener en cuenta</a>
<ul>
<li class="chapter" data-level="27.2.1" data-path="clasificador-k-vecinos-más-próximos.html"><a href="clasificador-k-vecinos-más-próximos.html#función-de-distancia-a-utilizar"><i class="fa fa-check"></i><b>27.2.1</b> Función de distancia a utilizar</a></li>
<li class="chapter" data-level="27.2.2" data-path="clasificador-k-vecinos-más-próximos.html"><a href="clasificador-k-vecinos-más-próximos.html#número-de-vecinos-k-seleccionados"><i class="fa fa-check"></i><b>27.2.2</b> Número de vecinos (k) seleccionados</a></li>
</ul></li>
<li class="chapter" data-level="27.3" data-path="clasificador-k-vecinos-más-próximos.html"><a href="clasificador-k-vecinos-más-próximos.html#procedimiento-con-r-la-funcion-knn"><i class="fa fa-check"></i><b>27.3</b> Procedimiento con R: la funcion knn</a></li>
<li class="chapter" data-level="27.4" data-path="clasificador-k-vecinos-más-próximos.html"><a href="clasificador-k-vecinos-más-próximos.html#aplicación-del-modelo-knn-en-r"><i class="fa fa-check"></i><b>27.4</b> Aplicación del modelo KNN en R</a>
<ul>
<li class="chapter" data-level="" data-path="clasificador-k-vecinos-más-próximos.html"><a href="clasificador-k-vecinos-más-próximos.html#resumen-7"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="28" data-path="naive-bayes.html"><a href="naive-bayes.html"><i class="fa fa-check"></i><b>28</b> Naive Bayes</a>
<ul>
<li class="chapter" data-level="28.1" data-path="naive-bayes.html"><a href="naive-bayes.html#introducción-18"><i class="fa fa-check"></i><b>28.1</b> Introducción</a></li>
<li class="chapter" data-level="28.2" data-path="naive-bayes.html"><a href="naive-bayes.html#teorema-de-bayes"><i class="fa fa-check"></i><b>28.2</b> Teorema de Bayes</a></li>
<li class="chapter" data-level="28.3" data-path="naive-bayes.html"><a href="naive-bayes.html#el-algoritmo-naive-bayes"><i class="fa fa-check"></i><b>28.3</b> El algoritmo Naive Bayes</a></li>
<li class="chapter" data-level="28.4" data-path="naive-bayes.html"><a href="naive-bayes.html#procedimiento-con-r-la-funcion-naive_bayes"><i class="fa fa-check"></i><b>28.4</b> Procedimiento con R: la funcion <code>naive_bayes</code></a></li>
<li class="chapter" data-level="28.5" data-path="naive-bayes.html"><a href="naive-bayes.html#aplicación-del-modelo-naive-bayes"><i class="fa fa-check"></i><b>28.5</b> Aplicación del modelo Naive Bayes</a>
<ul>
<li class="chapter" data-level="" data-path="naive-bayes.html"><a href="naive-bayes.html#resumen-8"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="29" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html"><i class="fa fa-check"></i><b>29</b> Bagging. Random Forest </a>
<ul>
<li class="chapter" data-level="29.1" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#introducción-metodos-de-ensamble"><i class="fa fa-check"></i><b>29.1</b> Introducción: Metodos de Ensamble</a></li>
<li class="chapter" data-level="29.2" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#bagging"><i class="fa fa-check"></i><b>29.2</b> Bagging</a></li>
<li class="chapter" data-level="29.3" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#procedimiento-con-r-la-función-bagging"><i class="fa fa-check"></i><b>29.3</b> Procedimiento con R: la función <code>bagging</code> </a></li>
<li class="chapter" data-level="29.4" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#implementando-bagging-en-r"><i class="fa fa-check"></i><b>29.4</b> Implementando bagging en R</a>
<ul>
<li class="chapter" data-level="29.4.1" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#interpretación-de-variables-en-el-bagging"><i class="fa fa-check"></i><b>29.4.1</b> Interpretación de variables en el bagging</a></li>
</ul></li>
<li class="chapter" data-level="29.5" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#random-forest"><i class="fa fa-check"></i><b>29.5</b> Random Forest</a>
<ul>
<li class="chapter" data-level="29.5.1" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#número-de-árboles-k"><i class="fa fa-check"></i><b>29.5.1</b> Número de árboles (<span class="math inline">\(K\)</span>)</a></li>
<li class="chapter" data-level="29.5.2" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#número-de-variables-a-considerar-mtry"><i class="fa fa-check"></i><b>29.5.2</b> Número de variables a considerar (<span class="math inline">\(mtry\)</span>)</a></li>
<li class="chapter" data-level="29.5.3" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#complejidad-de-los-árboles"><i class="fa fa-check"></i><b>29.5.3</b> Complejidad de los árboles</a></li>
<li class="chapter" data-level="29.5.4" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#esquema-de-muestreo"><i class="fa fa-check"></i><b>29.5.4</b> Esquema de muestreo</a></li>
<li class="chapter" data-level="29.5.5" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#regla-de-división"><i class="fa fa-check"></i><b>29.5.5</b> Regla de división</a></li>
</ul></li>
<li class="chapter" data-level="29.6" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#procedimiento-con-r-la-función-randomforest"><i class="fa fa-check"></i><b>29.6</b> Procedimiento con R: la función <code>randomForest</code></a></li>
<li class="chapter" data-level="29.7" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#aplicación-del-modelo-random-forest-en-r"><i class="fa fa-check"></i><b>29.7</b> Aplicación del modelo Random Forest en R</a>
<ul>
<li class="chapter" data-level="29.7.1" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#aplicación-del-random-forest"><i class="fa fa-check"></i><b>29.7.1</b> Aplicación del Random Forest</a></li>
<li class="chapter" data-level="" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#resumen-9"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="30" data-path="boosting.-xgboost..html"><a href="boosting.-xgboost..html"><i class="fa fa-check"></i><b>30</b> Boosting. XGBoost.</a>
<ul>
<li class="chapter" data-level="30.1" data-path="boosting.-xgboost..html"><a href="boosting.-xgboost..html#introducción.-boosting."><i class="fa fa-check"></i><b>30.1</b> Introducción. Boosting.</a></li>
<li class="chapter" data-level="30.2" data-path="boosting.-xgboost..html"><a href="boosting.-xgboost..html#gradient-boosting"><i class="fa fa-check"></i><b>30.2</b> Gradient Boosting</a>
<ul>
<li class="chapter" data-level="30.2.1" data-path="boosting.-xgboost..html"><a href="boosting.-xgboost..html#hiperparámetros-del-modelo-gradient-boosting"><i class="fa fa-check"></i><b>30.2.1</b> Hiperparámetros del modelo gradient boosting</a></li>
<li class="chapter" data-level="30.2.2" data-path="boosting.-xgboost..html"><a href="boosting.-xgboost..html#estrategia-de-ajuste-de-hiperparametros"><i class="fa fa-check"></i><b>30.2.2</b> Estrategia de ajuste de hiperparametros</a></li>
</ul></li>
<li class="chapter" data-level="30.3" data-path="boosting.-xgboost..html"><a href="boosting.-xgboost..html#procedimiento-con-r-la-funcion-gbm"><i class="fa fa-check"></i><b>30.3</b> Procedimiento con R: la funcion <code>gbm</code></a></li>
<li class="chapter" data-level="30.4" data-path="boosting.-xgboost..html"><a href="boosting.-xgboost..html#aplicación-del-modelo-gbm-en-r"><i class="fa fa-check"></i><b>30.4</b> Aplicación del modelo GBM en R</a>
<ul>
<li class="chapter" data-level="30.4.1" data-path="boosting.-xgboost..html"><a href="boosting.-xgboost..html#gbm-con-ajuste-automático"><i class="fa fa-check"></i><b>30.4.1</b> GBM con ajuste automático</a></li>
</ul></li>
<li class="chapter" data-level="30.5" data-path="boosting.-xgboost..html"><a href="boosting.-xgboost..html#extreme-gradient-boosting-xgb"><i class="fa fa-check"></i><b>30.5</b> eXtreme Gradient Boosting (XGB)</a>
<ul>
<li class="chapter" data-level="30.5.1" data-path="boosting.-xgboost..html"><a href="boosting.-xgboost..html#hiperparametros-del-modelo-xgboost"><i class="fa fa-check"></i><b>30.5.1</b> Hiperparametros del modelo XGBoost</a></li>
</ul></li>
<li class="chapter" data-level="30.6" data-path="boosting.-xgboost..html"><a href="boosting.-xgboost..html#procedimiento-con-r-la-funcion-xgboost"><i class="fa fa-check"></i><b>30.6</b> Procedimiento con R: la funcion <code>xgboost</code></a></li>
<li class="chapter" data-level="30.7" data-path="boosting.-xgboost..html"><a href="boosting.-xgboost..html#aplicación-del-módelo-xgboost-en-r"><i class="fa fa-check"></i><b>30.7</b> Aplicación del módelo XGBoost en R</a>
<ul>
<li class="chapter" data-level="30.7.1" data-path="boosting.-xgboost..html"><a href="boosting.-xgboost..html#xgboost-y-ajuste-automático"><i class="fa fa-check"></i><b>30.7.1</b> XGBoost y ajuste automático</a></li>
<li class="chapter" data-level="" data-path="boosting.-xgboost..html"><a href="boosting.-xgboost..html#resumen-10"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://blog.uclm.es/tp-mbsba/"> Ciencia de datos con R </a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Fundamentos de ciencia de datos con R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="árboles-de-clasificación-y-regresión" class="section level1 hasAnchor" number="25">
<h1><span class="header-section-number">Capítulo 25</span> Árboles de clasificación y regresión <a href="árboles-de-clasificación-y-regresión.html#árboles-de-clasificación-y-regresión" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><em>Ramón A. Carrasco e Itzcóatl Bueno<a href="#fn68" class="footnote-ref" id="fnref68"><sup>68</sup></a></em></p>
<p></p>
<div id="introducción-15" class="section level2 hasAnchor" number="25.1">
<h2><span class="header-section-number">25.1</span> Introducción <a href="árboles-de-clasificación-y-regresión.html#introducción-15" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Los árboles de decisión, donde decisión es el término genérico para clasificación y regresión, son modelos que se utilizan principalmente para la resolución de problemas de clasficación, aunque también son aplicables a la predicción de valores numéricos, esto es, como modelos de regresión. De ahi, que sean conocidos como árboles de clasificación y regresión (CART). Los árboles de decisión predicen categorías y variables cuantitativas utilizando variables de entrada númericas y categóricas. Algunos ejemplos de arboles de decisión para clasificación y regresión son: </p>
<ul>
<li><strong>Clasificación</strong>: Tomar la decisión de que empleados promocionar en base a sus méritos, capacidades, edad, etc. O por ejemplo, organizar un partido de ténis en base a la climatología prevista. Este ejemplo se muestra gráficamente en la figura <a href="árboles-de-clasificación-y-regresión.html#fig:dectree-plot">25.1</a>. En este ejemplo, en base a los registros climatológicos de los partidos que ya se hayan jugado el algoritmo podrá tomar decisiones. Así, si un nuevo día se quiere jugar al tenis se deberán aportar los datos de previsión, fuerza del viento y fuerza de la humedad. En caso de ser un día nublado, el algoritmo nos sugerirá que juguemos. En caso de ser soleado, comprobará el nivel de humedad y en caso de ser debíl recomendará que se juegue el partido. Lo mismo pasará si la previsión es de lluvia pero comprobando la fuerza del viento.</li>
</ul>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:dectree-plot"></span>
<img src="img/dectree_example.jpg" alt="Ejemplo de árbol de decisión." width="60%" />
<p class="caption">
Figura 25.1: Ejemplo de árbol de decisión.
</p>
</div>
<ul>
<li><strong>Regresión</strong>: Siguiendo con el ejemplo del partido de tenis, también se puede aplicar un arbol de decisión para determinar cuantas horas jugar de acuerdo a la climatología. En este ejemplo, en la figura <a href="árboles-de-clasificación-y-regresión.html#fig:dectree-plot">25.1</a> se sustituirían la predicción dicotómica SI/NO por un valor númerico. Por ejemplo, el algoritmo puede sugerir jugar 5 horas al tenis si el día esta soleado pero tiene una humedad débil, y 3.5 horas si está soleado pero la humedad es fuerte. También puede decidir que si la previsión es nublada se jueguen 4 horas.O en caso de lluvia podría decidir que el partido con viento fuerte no dure más de 0.75 horas y en caso de viento débil poder jugar 1.15 horas.</li>
</ul>
<p>
CART es un término genérico para describir algoritmos de árbol y también un nombre específico para el algoritmo original de para construir árboles de clasificación y regresión. Sin embargo, existen Sin embargo, existen otros como el ID3, que se presenta en secciones posteriores, o el C4.5, que esta basado en ID3. En la tabla <span class="math inline">\(\ref{comparativa-treealg}\)</span> se muestra una pequeña comparativa de estos tres algoritmos:</p>
<table>
<caption>Características de los principales algoritmos de árboles de decisión.</caption>
<colgroup>
<col width="21%" />
<col width="18%" />
<col width="29%" />
<col width="29%" />
</colgroup>
<thead>
<tr class="header">
<th align="right">Algoritmo</th>
<th align="left">Criterio de división</th>
<th>Tipo de variables</th>
<th align="center">Estrategia de poda</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">ID3</td>
<td align="left">Ganancia de información</td>
<td>Solo categóricas</td>
<td align="center">No poda</td>
</tr>
<tr class="even">
<td align="right">CART</td>
<td align="left">Indice de Gini</td>
<td>Categóricas y numéricas</td>
<td align="center">Poda basada en el coste de complejidad</td>
</tr>
<tr class="odd">
<td align="right">C4.5</td>
<td align="left">Ratio de ganancia</td>
<td>Categóricas y numéricas</td>
<td align="center">Poda basada en el error</td>
</tr>
</tbody>
</table>
<p>En resumen, los arboles de decisión tienen multiples ventajas. Entre las que destacan:</p>
<p>Sin embargo, el algoritmo tambien tiene ciertas desventajas:</p>
</div>
<div id="aprendizaje-con-árboles-de-decisión" class="section level2 hasAnchor" number="25.2">
<h2><span class="header-section-number">25.2</span> Aprendizaje con árboles de decisión<a href="árboles-de-clasificación-y-regresión.html#aprendizaje-con-árboles-de-decisión" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>
Formalmente, un árbol de decisión es un gráfico acíclico que se inicia en un <strong>nodo raiz</strong>, el cual se divide en <strong>ramas</strong>, también conocidas como <strong>aristas</strong>. Después, estas ramas se unen a las <strong>hojas</strong>, también denominadas <strong>nodos</strong>, las cuales determinan <strong>puntos de decisión</strong>. En el ejemplo de la figura <a href="árboles-de-clasificación-y-regresión.html#fig:dectree-plot">25.1</a> el nodo raiz es la caja <em>Previsión</em>. Las ramas o aristas, son los tres posibles valores que puede tomar la previsión: <em>Soleado</em>, <em>Nublado</em> o <em>Lluvia</em>. Cada una de estas ramas conecta con una nueva hoja o nodo, a <em>Humedad</em> o <em>Viento</em> en los casos de soleado o lluvia. Sin embargo, en ese ejemplo, el <em>Nublado</em> representa un nodo terminal, puesto que llegado a ese punto la salida que proporcionaría el árbol es <em>“No jugar al tenis”</em>. Este proceso se repite utilizando el conjunto de datos disponible en cada hoja. Así, se genera una clasificación final cuando una hoja ya no produce ramas nuevas, y es lo que se conoce como un nodo terminal. El objetivo al construir un árbol, es mantenerlo lo más pequeño posible. Esto se consigue eligiendo una variable que divida de forma óptima los datos en conjuntos homogeneos, de tal forma que se prediga mejor la clase objetivo.</p>
</div>
<div id="cómo-se-va-dividiendo-el-árbol" class="section level2 hasAnchor" number="25.3">
<h2><span class="header-section-number">25.3</span> ¿Cómo se va dividiendo el árbol? <a href="árboles-de-clasificación-y-regresión.html#cómo-se-va-dividiendo-el-árbol" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Como ya se ha mencionado, un árbol de decisión se va diviendo en dos nuevas ramas de forma recursiva, es decir, cada división esta condicionada a las anteriores. El objetivo en cada hoja es encontrar la variable más adecuada para dividir los datos de ese nodo en dos nuevas hojas de tal forma que el error global entre la clase observada y la predicha por el arbol se minimice. En problemas de regresión, la función a minimizar es la suma residual de cuadrados (SSR, por las siglas en inglés de: <em>sum of squares due to regression</em>) total. Para problemas de clasificación, la partición generalmente se realiza para maximizar la reducción en la entropía.</p>
<p>El algoritmo CART utiliza la impureza de Gini para generar las particiones, mientras que los algoritmo ID3 y C4.5 utilizan la entropía o la ganancia de información, la cual esta relacionada con la entropía. Y como ya se ha mencionado, en regresión la función a minimizar es la suma residual de cuadrados.</p>
<div id="impureza-de-gini" class="section level3 hasAnchor" number="25.3.1">
<h3><span class="header-section-number">25.3.1</span> Impureza de Gini<a href="árboles-de-clasificación-y-regresión.html#impureza-de-gini" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La Impureza de Gini, utilizada por el algoritmo CART, es una medida de la frecuencia con la que una observación elegida aleatoriamente de los datos se asignaría a la clase erronea si se etiquetase al azar de acuerdo con la distribución de las clases en el conjunto de datos. Entonces, sea <span class="math inline">\(X\)</span> un conjunto de datos con <span class="math inline">\(\kappa\)</span> clases, y sea <span class="math inline">\(p_i\)</span> la probabilidad de que una observación pertenezca a la clase <span class="math inline">\(i\)</span>, la Impureza de Gini para <span class="math inline">\(X\)</span> se puede definir como:</p>
<p><span class="math display">\[\begin{equation}
Gini(X) = 1 - \sum^{\kappa}_{i=1}{p^{2}_{i}}
\end{equation}\]</span></p>
<p>En el ejemplo de la figura <a href="árboles-de-clasificación-y-regresión.html#fig:dectree-plot">25.1</a> podría pasar que sucediese la siguiente situación:</p>
<table>
<caption>Ejemplo impureza de Gini</caption>
<thead>
<tr class="header">
<th></th>
<th align="center"><span class="math inline">\(p_{SÍ}\)</span></th>
<th align="center"><span class="math inline">\(p_{NO}\)</span></th>
<th align="center">Impureza de Gini</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Soleado</td>
<td align="center">0,75</td>
<td align="center">0,25</td>
<td align="center">0,3750</td>
</tr>
<tr class="even">
<td>Nublado</td>
<td align="center">1,00</td>
<td align="center">0,00</td>
<td align="center">0,0000</td>
</tr>
<tr class="odd">
<td>Lluvia</td>
<td align="center">0,50</td>
<td align="center">0,50</td>
<td align="center">0,5000</td>
</tr>
</tbody>
</table>
<p>Se puede ver que la impureza es mayor en el nodo en el que la distribución de las observaciones es uniforme entre clases, mientras que el menor valor se obtiene en el nodo en el que todas las observaciones pertenecen a una clase. Se selecciona un atributo con la menor impureza de Gini para dividir el nodo. Si un conjunto de datos <span class="math inline">\(X\)</span> se divide en un atributo <span class="math inline">\(\varphi\)</span> en dos subconjuntos <span class="math inline">\(X_1\)</span> y <span class="math inline">\(X_2\)</span> con tamaños <span class="math inline">\(n_1\)</span> y <span class="math inline">\(n_2\)</span>, respectivamente, la impureza de Gini se puede definir como:</p>
<p><span class="math display">\[\begin{equation}
Gini_{\varphi}(X) = \frac{n_1}{n}{Gini(X_{1})} + \frac{n_2}{n}{Gini(X_{2})}
\end{equation}\]</span></p>
<p>Al entrenar un árbol de decisión, se elige para dividir el nodo la variable que proporciona el menor <span class="math inline">\(Gini_{\varphi}(X)\)</span>. Para conocer la ganancia de información para una variable, las impurezas ponderadas de las ramas se restan de la impureza original. La ganancia de Gini se calcula tal que:</p>
<p><span class="math display">\[\begin{equation}
\Delta Gini(\varphi) =  Gini(X) - Gini_{\varphi}(X)
\end{equation}\]</span></p>
<p>Siguiendo el ejemplo del árbol de decisión para saber si se puede jugar al tenis o no se tendría que obtener la impureza de gini para el nodo <em>niebla</em> o el nodo <em>viento</em>. En caso, de que para el nodo <em>niebla</em> se tuviese <span class="math inline">\(P(SÍ)=0,75\)</span> y <span class="math inline">\(P(NO) = 0,25\)</span>, siendo su impureza igual a 0,375; y para el nodo <em>viento</em> <span class="math inline">\(P(SÍ)= 0.9\)</span> y <span class="math inline">\(P(NO)=0,1\)</span> teniendo un valor de 0,18 para su impureza de Gini. Entonces, la ganancia de Gini para cada nodo será:</p>
<p>Y por tanto, el árbol tomaría como nodo a dividir el que indica que decisión tomar en caso de que la humedad sea débil o fuerte.</p>
</div>
<div id="entropía" class="section level3 hasAnchor" number="25.3.2">
<h3><span class="header-section-number">25.3.2</span> Entropía <a href="árboles-de-clasificación-y-regresión.html#entropía" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La entropia es un concepto matemático que explica la varianza en los datos entre diferentes clases. Busca que los datos sean más homogeneos en cada capa respecto de la anterior partición. A partir de la ecuación <span class="math inline">\(\ref{eq:entropy}\)</span> se calcula, expresada en bits entre 0 y 1, la entropía para cada división de variable potencial:</p>
<p><span class="math display">\[\begin{equation}\label{eq:entropy}
E = -p_1\log_2 (p_1) - p_2\log_2 (p_2)
\end{equation}\]</span></p>
<p>donde <span class="math inline">\(p_1\)</span> y <span class="math inline">\(p_2\)</span> representan la probabilidad de pertenecer a cada una de las clases en ese nodo. En teoría de la información, la base logarítmica varía dependiendo de la aplicación y con ella varía la unidad de medida. En el caso de la entropía, se utiliza el logaritmo base 2 que da la unidad de bits o shannons. En cambio, el logaritmo neperiano (con base <span class="math inline">\(e\)</span>) medirá en unidades naturales, y el logaritmo en base 10 utiliza como unidades los dits, bans o hartleys.</p>
</div>
<div id="ganancia-de-información" class="section level3 hasAnchor" number="25.3.3">
<h3><span class="header-section-number">25.3.3</span> Ganancia de información<a href="árboles-de-clasificación-y-regresión.html#ganancia-de-información" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Se puede definir la ganancia de información como cuanta información proporciona una variable sobre una clase. Obtener esta información ayuda a ordenar los atributos en los nodos del árbol de decisión. La ganancia de información se obtiene tal que:</p>
<p><span class="math display">\[\begin{equation}
IG = E_{\varkappa} - E_{\varkappa + 1}
\end{equation}\]</span></p>
<p>donde <span class="math inline">\(E_\varkappa\)</span> representa la entropía en el nodo padre, mientras que <span class="math inline">\(E_{\varkappa+1}\)</span> es la entropia en el nodo que resulta de dividir el nodo padre. Cuanto más entropía se elimine, mayor será la ganancia de información, y por tanto, cuanto mayor sea la ganancia de información, mejor será la división.</p>
</div>
<div id="suma-residual-de-cuadrados-mínima" class="section level3 hasAnchor" number="25.3.4">
<h3><span class="header-section-number">25.3.4</span> Suma residual de cuadrados mínima<a href="árboles-de-clasificación-y-regresión.html#suma-residual-de-cuadrados-mínima" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En el caso de un problema de regresión, el árbol elige la variable con la que seguir diviendo nodos aquella que reduce la suma de residuos al cuadrado. Esto es, que al dividir los datos utilizando la variable <em>X</em> en dos regiones <span class="math inline">\(R_1\)</span> y <span class="math inline">\(R_2\)</span> el error global entre la variable respuesta observada <em>Y</em> y el valor constante predicho por el árbol <span class="math inline">\(\kappa_i\)</span> se minimice. Entonces, la función a minimizar es:</p>
<p><span class="math display">\[\begin{equation}
SSR = \sum_{i\in R_1}{(y_i-\kappa_1)^2} + \sum_{i\in R_2}{(y_i-\kappa_2)^2}
\end{equation}\]</span></p>
</div>
</div>
<div id="sobreajuste" class="section level2 hasAnchor" number="25.4">
<h2><span class="header-section-number">25.4</span> Sobreajuste <a href="árboles-de-clasificación-y-regresión.html#sobreajuste" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Ya se ha comentado en la sección <span class="math inline">\(\ref{intro_dectree}\)</span> que una de las principales desventajas de los árboles de decisión es su propensión a sobreajustar el modelo al conjunto de datos de entrenamiento, y por tanto, hay que prestar especial atención a la complejidad del modelo. Basandose en los datos de entrenamiento, un arbol de decisión puede extraer los patrones presentes en éste y ser muy preciso en el ajuste de estos datos. Sin embargo, puede ocurrir que el árbol resultante no sea capaz de clasificar correctamente ni el conjunto de validación ni nuevas observaciones. Esto puede darse porque haya patrones no observados en los datos de entrenamiento que el modelo no es capaz de detectar o porque la división de los datos entre entrenamiento y validación no se realizo correctamente y no era representativa del conjunto completo. La forma de evitar el sobreajuste es controlar el crecimiento del árbol para evitar que se vuelva muy complejo.</p>
</div>
<div id="cuánto-debe-crecer-un-árbol" class="section level2 hasAnchor" number="25.5">
<h2><span class="header-section-number">25.5</span> ¿Cuánto debe crecer un árbol? <a href="árboles-de-clasificación-y-regresión.html#cuánto-debe-crecer-un-árbol" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Una vez se determina la variable optima para realizar la división de los datos, se generan dos nuevas hojas y como se ha mencionado el proceso se repite recursivamente. Entonces, ¿cuándo se detiene? se debe determinar un criterio de parada adecuado. Por ejemplo, se puede determinar una profundidad máxima de árbol para que no se vuelva excesivamente complejo. Sin embargo, esto genera una nueva pregunta ¿qué profundidad máxima determinar? Si el árbol tiene mucha profundidad se hará muy complejo y sobreajustará los datos de entrenamiento resultando en un ajuste deficiente a nuevas observaciones.</p>
<p>En consecuencia, se debe llegar a un equilibrio entre la profundidad y complejidad del árbol para optimizar la predicción de futuras observaciones. Este equilibrio se puede lograr siguiendo alguno de los siguientes enfoques: la parada temprana o la poda.</p>
<div id="la-parada-temprana" class="section level3 hasAnchor" number="25.5.1">
<h3><span class="header-section-number">25.5.1</span> La parada temprana <a href="árboles-de-clasificación-y-regresión.html#la-parada-temprana" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La parada temprana restringe el crecimiento del árbol de forma explicita. Existen distintas maneras de establecer esta restricción al árbol, pero dos de las técnicas más populares son las de restringir la profundidad a un cierto nivel o la de establecer un número mínimo de observaciones permitidas en un nodo terminal. En el primer caso, el árbol deja de dividirse al llegar a cierta profundidad. Así, cuanto menos profundo sea el árbol, menos variación habrá en las predicciones que proporcione. Sin embargo, existe el riesgo de introducir mucho sesgo al modelo al no ser capaz de captar interacciones y patrones complejos en los datos. El segundo enfoque lo que provoca es que no se dividan nodos intermedios con pocas observaciones. En el un extremo, si se permite que un nodo terminal solo contuviese una observación esta actuaría como predicción. De este modo, los resultados no serían generalizables y tendrían mucha variabilidad. En el otro extremo, si se exigen un gran número de observaciones en el nodo terminal se reduce el número de divisiones y en consecuencia se reduce la varianza.</p>
</div>
<div id="la-poda" class="section level3 hasAnchor" number="25.5.2">
<h3><span class="header-section-number">25.5.2</span> La poda <a href="árboles-de-clasificación-y-regresión.html#la-poda" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El otro enfoque es el de la poda. Éste consiste en dejar crecer un árbol muy profundo y complejo y despues podarlo para encontrar un sub-árbol óptimo. El sub-árbol optimo se encuentra utilizando un parametro de complejidad del coste <span class="math inline">\((\zeta)\)</span> que penaliza la función objetivo de la partición por el número de nodos terminales del árbol <span class="math inline">\((\tau)\)</span> tal que:</p>
<p><span class="math display">\[\begin{equation}
\min\{SSR + \zeta |\tau |\}
\end{equation}\]</span></p>
<p>Para un valor dado de <span class="math inline">\(\zeta\)</span> se encuentra el árbol podado más pequeño que tenga el error penalizado más bajo. Las penalizaciones más bajas tienden a producir modelos más complejos, y en consecuencia árboles más grandes. Por otro lado, las mayores penalizaciones dan como resultado árboles pequeños. En conclusión, a medida que un árbol crece, el SSR debe tener una reducción mayor que la penalización por la complejidad en los costes.</p>
</div>
</div>
<div id="el-algoritmo-id3-para-la-construcción-de-un-árbol-de-decisión" class="section level2 hasAnchor" number="25.6">
<h2><span class="header-section-number">25.6</span> El algoritmo ID3 para la construcción de un árbol de decisión<a href="árboles-de-clasificación-y-regresión.html#el-algoritmo-id3-para-la-construcción-de-un-árbol-de-decisión" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>
</p>
<p>Dado un conjunto de observaciones pertenecientes a dos clases {0,1}, se quiere construir un árbol de decisión que permita predecir a que clase pertenece una observación dado un vector de características. Existen múltiples formulaciones del algoritmo de árboles de decisión. En este libro se presenta el <em>ID3</em>. En este caso, el criterio de optimización es la verosimilitud logarítmica media:</p>
<p><span class="math display">\[\begin{equation}
\frac{1}{N}\sum_{i=1}^{N} y_{i}\ln f_{ID3}(x_i) + (1-y_{i})\ln(1-f_{ID3}(x_i))
\end{equation}\]</span></p>
<p>donde <span class="math inline">\(f_{ID3}\)</span> es un árbol de decisión. El algoritmo ID3 obtiene la solución óptima construyendo un modelo no parametrico <span class="math inline">\(f_{ID3}(x)=P(y=1|x)\)</span>. El funcionamiento del algorítmo () es el siguiente.</p>
<p>Sea <span class="math inline">\(\mathbb{S}\)</span> el conjunto de observaciones etiquetadas. En el nodo raiz del árbol se incluyen todas las observaciones <span class="math inline">\(\mathbb{S}=\{(x_i,y_i)\}^{N}_{i=1}\)</span>, empezando así con un modelo constante:</p>
<p><span class="math display">\[\begin{equation}
f^{\mathbb{S}}_{ID3} = \frac{1}{|\mathbb{S}|}\sum_{(x,y)\in\mathbb{S}}y.
\end{equation}\]</span></p>
<p>Este modelo produce la misma predicción independientemente de los valores de entrada. Teniendo en cuenta las variables <span class="math inline">\(j=1,\dots,p\)</span> y los todos los umbrales <span class="math inline">\(t\)</span> se divide el conjunto <span class="math inline">\(\mathbb{S}\)</span> en dos subconjuntos <span class="math inline">\(\mathbb{S}\_ = \{(x,y)|(x,y)\in\mathbb{S},x^{(j)}&lt;t\}\)</span> y <span class="math inline">\(\mathbb{S}_{+} = \{(x,y)|(x,y)\in\mathbb{S},x^{(j)}\geq t\}\)</span>. Estos nuevos conjuntos llevan al árbol a producir hojas nuevas, por lo que se evalua que pareja <span class="math inline">\((j,t)\)</span> es la mejor utilizando la ya mencionada entropía. Este proceso continua recursivamente hasta llegar a los nodos terminales.</p>
</div>
<div id="procedimiento-con-r-la-funcion-rpart" class="section level2 hasAnchor" number="25.7">
<h2><span class="header-section-number">25.7</span> Procedimiento con R: la funcion <code>rpart</code><a href="árboles-de-clasificación-y-regresión.html#procedimiento-con-r-la-funcion-rpart" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En el paquete <code>rpart</code> de <strong>R</strong> se encuentra la función <code>rpart</code> que se utiliza para entrenar un arbol de decisión:</p>
<div class="sourceCode" id="cb311"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb311-1"><a href="árboles-de-clasificación-y-regresión.html#cb311-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">rpart</span>(formula, data, ...)</span></code></pre></div>
</div>
<div id="aplicaciones-de-los-árboles-de-decisión" class="section level2 hasAnchor" number="25.8">
<h2><span class="header-section-number">25.8</span> Aplicaciones de los árboles de decisión<a href="árboles-de-clasificación-y-regresión.html#aplicaciones-de-los-árboles-de-decisión" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En esta sección se incluyen ejemplos de distintos modelos de arboles de decisión que se pueden obtener con <strong>R</strong>. Usando los datos <code>dp_entr</code> incluidos en el paquete <code>CDR</code> consistentes en la información de compras de distintos productos por parte de los clientes, se pretende predecir si estos compraran o no un nuevo producto (tensiómetro digital) no incluido en el modelo. A continuación se expone el caso a resolver en este y en futuros capítulos.</p>
<div id="el-caso-de-negocio" class="section level3 hasAnchor" number="25.8.1">
<h3><span class="header-section-number">25.8.1</span> El caso de negocio<a href="árboles-de-clasificación-y-regresión.html#el-caso-de-negocio" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A continuación se describe el caso que se va a resolver mediante modelos de clasificación tanto en este como en los siguientes capítulos. Existen diversas aserciones para definir Comercio Electrónico (CE).
Entre ellas, la Organización para la Cooperación y el Desarrollo Económico lo define como el proceso de compra, venta o intercambio de bienes, servicios e información a través de redes de comunicación, comunmente Internet.
La clasificación más básica del CE se hace en base al tipo de entes que se relacionan: empresas (businesses, B), consumidores (consummers, C) y entes públicos (governments, G).
De esta forma, una empresa de CE convencional suele ser B2B si vende a otras empresas, B2G si su relación comercial es con administraciones o B2C si vende consumidores finales.</p>
<p>En nuestro caso, la empresa “Beauty eSheep” se puede considerar un CE de tipo B2C.
Su producto estrella es una crema hidratante unisex, denominada internamente como “Crema Luxury”, con mucho éxito entre su clientela.
A partir de este producto inicial, la empresa ha ido ofreciendo un catálogo de productos tanto de tanto de belleza como de bienestar y salud.</p>
<p>Hace tiempo la empresa instauró una estrategia relacional, centrada en el cliente, de tal manera que ha ido recabando diversos datos sobre los mismos incluidas las distintas compras que han realizado.</p>
<p>Basándose en los datos recopilados para cada cliente, la empresa quiere realizar una campaña para impulsar la venta de tensiómetros digitales.
La empresa tiene acceso a un stock muy flexible en fechas de envío de estos productos y a muy buen precio, por lo que se espera una buena rentabilidad en su venta.</p>
<p>Por tanto, en este proyecto hay que identificar el público objetivo susceptible de comprar dicho producto para ofrecerselo a través de la plataforma de CE de la compañía, SMS y/o webmail durante el periodo que dura la campaña.</p>
<p>La tabla con los datos integrados a nivel de cliente, incluyendo el consumo de los distintos productos de la empresa, es la siguiente:</p>
<ul>
<li><strong>dp_ENTR</strong>: incluida en el paquete <code>CDR</code></li>
</ul>
<p>A continuación se describe los campos de dicha tabla:</p>
<table>
<caption>Descripción de las variables del conjunto de datos utilizado en los ejemplos.</caption>
<colgroup>
<col width="25%" />
<col width="25%" />
<col width="49%" />
</colgroup>
<thead>
<tr class="header">
<th><em>COLUMNA</em></th>
<th><em>TIPO</em></th>
<th><em>DESCRIPCIÓN</em></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>ind_pro11</td>
<td>Factor</td>
<td>Indicador si el cliente es consumidor del producto “Fragancia Luxury” (‘S’) o no (‘N’)</td>
</tr>
<tr class="even">
<td>ind_pro12</td>
<td>Factor</td>
<td>Indicador si el cliente es consumidor del producto “Depiladora Eléctrica” (‘S’) o no (‘N’)</td>
</tr>
<tr class="odd">
<td>ind_pro14</td>
<td>Factor</td>
<td>Indicador si el cliente es consumidor del producto “Crema Luxury” (‘S’) o no (‘N’)</td>
</tr>
<tr class="even">
<td>ind_pro15</td>
<td>Factor</td>
<td>Indicador si el cliente es consumidor del producto “Smartwatch Fitness” (‘S’) o no (‘N’)</td>
</tr>
<tr class="odd">
<td>ind_pro16</td>
<td>Factor</td>
<td>Indicador si el cliente es consumidor del producto “Kit Pesas Inteligentes” (‘S’) o no (‘N’)</td>
</tr>
<tr class="even">
<td>ind_pro17</td>
<td>Factor</td>
<td>Indicador si el cliente es consumidor del producto “Estimulador Muscular” (‘S’) o no (‘N’)</td>
</tr>
<tr class="odd">
<td>importe_pro11</td>
<td>Doble</td>
<td>Importe neto global consumido por el cliente en ese producto en euros</td>
</tr>
<tr class="even">
<td>importe_pro12</td>
<td>Doble</td>
<td>Importe neto global consumido por el cliente en ese producto en euros</td>
</tr>
<tr class="odd">
<td>importe_pro14</td>
<td>Doble</td>
<td>Importe neto global consumido por el cliente en ese producto en euros</td>
</tr>
<tr class="even">
<td>importe_pro15</td>
<td>Doble</td>
<td>Importe neto global consumido por el cliente en ese producto en euros</td>
</tr>
<tr class="odd">
<td>importe_pro16</td>
<td>Doble</td>
<td>Importe neto global consumido por el cliente en ese producto en euros</td>
</tr>
<tr class="even">
<td>importe_pro17</td>
<td>Doble</td>
<td>Importe neto global consumido por el cliente en ese producto en euros</td>
</tr>
<tr class="odd">
<td>edad</td>
<td>Entero</td>
<td>Edad del cliente</td>
</tr>
<tr class="even">
<td>tamano_fam</td>
<td>Entero</td>
<td>Número de miembros de la unidad familiar a la que pertenece el cliente incluyéndolo a él mismo</td>
</tr>
<tr class="odd">
<td>anos_exp</td>
<td>Entero</td>
<td>Años de trabajo del cliente</td>
</tr>
<tr class="even">
<td>ingresos_ano</td>
<td>Doble</td>
<td>Ingresos anuales del cliente en euros</td>
</tr>
<tr class="odd">
<td>des_nivel_edu</td>
<td>Factor</td>
<td>Descripción del nivel de educación del cliente</td>
</tr>
<tr class="even">
<td>CLS_PRO_pro13</td>
<td>Factor</td>
<td>Clase objetivo, es un indicador si el cliente es consumidor de ese producto “Tensiómetro Digital” (‘S’) o no (‘N’)</td>
</tr>
</tbody>
</table>
</div>
<div id="árbol-de-clasificación-para-determinar-la-intención-de-compra" class="section level3 hasAnchor" number="25.8.2">
<h3><span class="header-section-number">25.8.2</span> Árbol de clasificación para determinar la intención de compra<a href="árboles-de-clasificación-y-regresión.html#árbol-de-clasificación-para-determinar-la-intención-de-compra" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Se contruye un árbol de clasificación usando todo el conjunto de entrenamiento completo sin transformar (en su escala orginal) mediante el algoritmo de Partición Recursiva y Àrboles de Regresión (Recursive Partitioning and Regression Trees, RPART) que se puede usar tanto para regresión como para clasificación.</p>
<div class="sourceCode" id="cb312"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb312-1"><a href="árboles-de-clasificación-y-regresión.html#cb312-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">library</span>(CDR)</span>
<span id="cb312-2"><a href="árboles-de-clasificación-y-regresión.html#cb312-2" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> </span>
<span id="cb312-3"><a href="árboles-de-clasificación-y-regresión.html#cb312-3" aria-hidden="true" tabindex="-1"></a><span class="er">&gt;</span> <span class="fu">data</span>(dp_entr)</span>
<span id="cb312-4"><a href="árboles-de-clasificación-y-regresión.html#cb312-4" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> </span>
<span id="cb312-5"><a href="árboles-de-clasificación-y-regresión.html#cb312-5" aria-hidden="true" tabindex="-1"></a><span class="er">&gt;</span> trControl <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(</span>
<span id="cb312-6"><a href="árboles-de-clasificación-y-regresión.html#cb312-6" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   <span class="at">method =</span> <span class="st">&quot;cv&quot;</span>,</span>
<span id="cb312-7"><a href="árboles-de-clasificación-y-regresión.html#cb312-7" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   <span class="at">number =</span> <span class="dv">10</span>,</span>
<span id="cb312-8"><a href="árboles-de-clasificación-y-regresión.html#cb312-8" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   <span class="at">classProbs =</span> <span class="cn">TRUE</span>,</span>
<span id="cb312-9"><a href="árboles-de-clasificación-y-regresión.html#cb312-9" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   <span class="at">summaryFunction =</span> twoClassSummary</span>
<span id="cb312-10"><a href="árboles-de-clasificación-y-regresión.html#cb312-10" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span> )</span></code></pre></div>
<p>En primer lugar, se ha cargado la librería necesaria para entrenar el modelo y los datos de compras de los clientes para predecir si compraran o no el nuevo producto. Además, se define el método de remuestreo para el entrenamiento del modelo. El método definido es validación cruzada con 10 folds, visto en el capítulo <span class="math inline">\(\ref{#featureengineering}\)</span>. A continuación, se determina la semilla aleatoria para hacer los resultados comparables y a su vez se entrena el modelo.</p>
<div class="sourceCode" id="cb313"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb313-1"><a href="árboles-de-clasificación-y-regresión.html#cb313-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> </span>
<span id="cb313-2"><a href="árboles-de-clasificación-y-regresión.html#cb313-2" aria-hidden="true" tabindex="-1"></a><span class="er">&gt;</span> <span class="co"># se fija una semilla común a todos los modelos</span></span>
<span id="cb313-3"><a href="árboles-de-clasificación-y-regresión.html#cb313-3" aria-hidden="true" tabindex="-1"></a><span class="er">&gt;</span> <span class="fu">set.seed</span>(<span class="dv">101</span>)</span>
<span id="cb313-4"><a href="árboles-de-clasificación-y-regresión.html#cb313-4" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> </span>
<span id="cb313-5"><a href="árboles-de-clasificación-y-regresión.html#cb313-5" aria-hidden="true" tabindex="-1"></a><span class="er">&gt;</span> <span class="co"># se entrena el modelo</span></span>
<span id="cb313-6"><a href="árboles-de-clasificación-y-regresión.html#cb313-6" aria-hidden="true" tabindex="-1"></a><span class="er">&gt;</span> model <span class="ot">&lt;-</span> <span class="fu">train</span>(CLS_PRO_pro13 <span class="sc">~</span> .,</span>
<span id="cb313-7"><a href="árboles-de-clasificación-y-regresión.html#cb313-7" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   <span class="at">data =</span> dp_entr,</span>
<span id="cb313-8"><a href="árboles-de-clasificación-y-regresión.html#cb313-8" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   <span class="at">method =</span> <span class="st">&quot;rpart&quot;</span>,</span>
<span id="cb313-9"><a href="árboles-de-clasificación-y-regresión.html#cb313-9" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   <span class="at">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb313-10"><a href="árboles-de-clasificación-y-regresión.html#cb313-10" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   <span class="at">trControl =</span> trControl</span>
<span id="cb313-11"><a href="árboles-de-clasificación-y-regresión.html#cb313-11" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> )</span></code></pre></div>
<div class="sourceCode" id="cb314"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb314-1"><a href="árboles-de-clasificación-y-regresión.html#cb314-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">ggplot</span>(<span class="fu">melt</span>(model<span class="sc">$</span>resample[, <span class="sc">-</span><span class="dv">4</span>]), <span class="fu">aes</span>(<span class="at">x =</span> variable, <span class="at">y =</span> value, <span class="at">fill =</span> variable)) <span class="sc">+</span></span>
<span id="cb314-2"><a href="árboles-de-clasificación-y-regresión.html#cb314-2" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   <span class="fu">geom_boxplot</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:006-002-001RPARTRESULTS"></span>
<img src="Ciencia_de_datos_con_r_files/figure-html/006-002-001RPARTRESULTS-1.svg" alt="Resultados del modelo durante la validación cruzada." width="60%" />
<p class="caption">
Figura 25.2: Resultados del modelo durante la validación cruzada.
</p>
</div>
<p>Los resultados de validación cruzada quedan recogidos en los boxplot, por lo que podemos ver en que rangos oscilan las principales medidas, definidas <span class="math inline">\(\ref{#featureengineering}\)</span>, de precisión del modelo (ROC, sensibilidad y especificidad). A continuación se muestra el árbol generado. Se puede observar que este árbol es muy sencillo, y por tanto es facil seguir su interpretación. En primer lugar, decide que si un cliente compra el <em>smartchwatch fitness</em> comprará el nuevo producto. En caso de no comprar el <em>smartchwatch fitness</em>, pero si comprar la <em>depiladora eléctrica</em> si comprará el <em>tensiómetro digital</em>. Mientras que si no compra ninguno de esos dos productos no comprará el nuevo producto.</p>
<div class="sourceCode" id="cb315"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb315-1"><a href="árboles-de-clasificación-y-regresión.html#cb315-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="co"># se pinta el árbol obtenido</span></span>
<span id="cb315-2"><a href="árboles-de-clasificación-y-regresión.html#cb315-2" aria-hidden="true" tabindex="-1"></a><span class="er">&gt;</span> <span class="fu">rpart.plot</span>(model<span class="sc">$</span>finalModel)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:006-002-001RPARTRESULTS2"></span>
<img src="Ciencia_de_datos_con_r_files/figure-html/006-002-001RPARTRESULTS2-1.svg" alt="Árbol de clasificación sin ajuste automático." width="60%" />
<p class="caption">
Figura 25.3: Árbol de clasificación sin ajuste automático.
</p>
</div>
<p>Este modelo se puede mejorar ajustando automaticamente los hiperparametros correspondientes a un modelo de árboles de decisión. De tal manera, primero es necesario saber los hiperparámetros a optimizar en el algoritmo implementado <strong>R</strong>.</p>
<div class="sourceCode" id="cb316"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb316-1"><a href="árboles-de-clasificación-y-regresión.html#cb316-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">modelLookup</span>(<span class="st">&quot;rpart&quot;</span>)</span>
<span id="cb316-2"><a href="árboles-de-clasificación-y-regresión.html#cb316-2" aria-hidden="true" tabindex="-1"></a>  model parameter                label forReg forClass probModel</span>
<span id="cb316-3"><a href="árboles-de-clasificación-y-regresión.html#cb316-3" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> rpart        cp Complexity Parameter   <span class="cn">TRUE</span>     <span class="cn">TRUE</span>      <span class="cn">TRUE</span></span></code></pre></div>
<p>El hiperparámetro a optimizar es la complejidad del árbol. El valor de <code>cp</code> es un parámetro de parada. Ayuda a acelerar la búsqueda de divisiones porque puede identificar las divisiones que no cumplen con este criterio y podarlas antes de ir avanzar por ella. También se puede entender <code>cp</code> como la mejora mínima necesaria en cada nodo del modelo. En busca del mejor valor de <code>cp</code> se define una red de posibles valores con los que evaluar el modelo.</p>
<div class="sourceCode" id="cb317"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb317-1"><a href="árboles-de-clasificación-y-regresión.html#cb317-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="co"># Se especifica un rango de valores típicos para los hiperparámetros</span></span>
<span id="cb317-2"><a href="árboles-de-clasificación-y-regresión.html#cb317-2" aria-hidden="true" tabindex="-1"></a><span class="er">&gt;</span> tuneGrid <span class="ot">&lt;-</span> <span class="fu">expand.grid</span>(<span class="at">cp =</span> <span class="fu">seq</span>(<span class="dv">0</span>, <span class="fl">0.1</span>, <span class="fl">0.01</span>))</span></code></pre></div>
<div class="sourceCode" id="cb318"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb318-1"><a href="árboles-de-clasificación-y-regresión.html#cb318-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="co"># se entrena el modelo</span></span>
<span id="cb318-2"><a href="árboles-de-clasificación-y-regresión.html#cb318-2" aria-hidden="true" tabindex="-1"></a><span class="er">&gt;</span> <span class="fu">set.seed</span>(<span class="dv">101</span>)</span>
<span id="cb318-3"><a href="árboles-de-clasificación-y-regresión.html#cb318-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> </span>
<span id="cb318-4"><a href="árboles-de-clasificación-y-regresión.html#cb318-4" aria-hidden="true" tabindex="-1"></a><span class="er">&gt;</span> model <span class="ot">&lt;-</span> <span class="fu">train</span>(CLS_PRO_pro13 <span class="sc">~</span> .,</span>
<span id="cb318-5"><a href="árboles-de-clasificación-y-regresión.html#cb318-5" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   <span class="at">data =</span> dp_entr,</span>
<span id="cb318-6"><a href="árboles-de-clasificación-y-regresión.html#cb318-6" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   <span class="at">method =</span> <span class="st">&quot;rpart&quot;</span>,</span>
<span id="cb318-7"><a href="árboles-de-clasificación-y-regresión.html#cb318-7" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   <span class="at">metric =</span> <span class="st">&quot;ROC&quot;</span>,</span>
<span id="cb318-8"><a href="árboles-de-clasificación-y-regresión.html#cb318-8" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   <span class="at">trControl =</span> trControl,</span>
<span id="cb318-9"><a href="árboles-de-clasificación-y-regresión.html#cb318-9" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   <span class="at">tuneGrid =</span> tuneGrid</span>
<span id="cb318-10"><a href="árboles-de-clasificación-y-regresión.html#cb318-10" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> )</span></code></pre></div>
<div class="sourceCode" id="cb319"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb319-1"><a href="árboles-de-clasificación-y-regresión.html#cb319-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> model</span>
<span id="cb319-2"><a href="árboles-de-clasificación-y-regresión.html#cb319-2" aria-hidden="true" tabindex="-1"></a>CART </span>
<span id="cb319-3"><a href="árboles-de-clasificación-y-regresión.html#cb319-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb319-4"><a href="árboles-de-clasificación-y-regresión.html#cb319-4" aria-hidden="true" tabindex="-1"></a><span class="dv">558</span> samples</span>
<span id="cb319-5"><a href="árboles-de-clasificación-y-regresión.html#cb319-5" aria-hidden="true" tabindex="-1"></a> <span class="dv">17</span> predictor</span>
<span id="cb319-6"><a href="árboles-de-clasificación-y-regresión.html#cb319-6" aria-hidden="true" tabindex="-1"></a>  <span class="dv">2</span> classes<span class="sc">:</span> <span class="st">&#39;S&#39;</span>, <span class="st">&#39;N&#39;</span> </span>
<span id="cb319-7"><a href="árboles-de-clasificación-y-regresión.html#cb319-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb319-8"><a href="árboles-de-clasificación-y-regresión.html#cb319-8" aria-hidden="true" tabindex="-1"></a>No pre<span class="sc">-</span>processing</span>
<span id="cb319-9"><a href="árboles-de-clasificación-y-regresión.html#cb319-9" aria-hidden="true" tabindex="-1"></a>Resampling<span class="sc">:</span> Cross<span class="sc">-</span><span class="fu">Validated</span> (<span class="dv">10</span> fold) </span>
<span id="cb319-10"><a href="árboles-de-clasificación-y-regresión.html#cb319-10" aria-hidden="true" tabindex="-1"></a>Summary of sample sizes<span class="sc">:</span> <span class="dv">502</span>, <span class="dv">502</span>, <span class="dv">502</span>, <span class="dv">503</span>, <span class="dv">503</span>, <span class="dv">502</span>, ... </span>
<span id="cb319-11"><a href="árboles-de-clasificación-y-regresión.html#cb319-11" aria-hidden="true" tabindex="-1"></a>Resampling results across tuning parameters<span class="sc">:</span></span>
<span id="cb319-12"><a href="árboles-de-clasificación-y-regresión.html#cb319-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb319-13"><a href="árboles-de-clasificación-y-regresión.html#cb319-13" aria-hidden="true" tabindex="-1"></a>  cp    ROC        Sens       Spec     </span>
<span id="cb319-14"><a href="árboles-de-clasificación-y-regresión.html#cb319-14" aria-hidden="true" tabindex="-1"></a>  <span class="fl">0.00</span>  <span class="fl">0.9390141</span>  <span class="fl">0.8531746</span>  <span class="fl">0.8854497</span></span>
<span id="cb319-15"><a href="árboles-de-clasificación-y-regresión.html#cb319-15" aria-hidden="true" tabindex="-1"></a>  <span class="fl">0.01</span>  <span class="fl">0.8962254</span>  <span class="fl">0.8678571</span>  <span class="fl">0.8167989</span></span>
<span id="cb319-16"><a href="árboles-de-clasificación-y-regresión.html#cb319-16" aria-hidden="true" tabindex="-1"></a>  <span class="fl">0.02</span>  <span class="fl">0.8663454</span>  <span class="fl">0.9000000</span>  <span class="fl">0.7667989</span></span>
<span id="cb319-17"><a href="árboles-de-clasificación-y-regresión.html#cb319-17" aria-hidden="true" tabindex="-1"></a>  <span class="fl">0.03</span>  <span class="fl">0.8458097</span>  <span class="fl">0.9392857</span>  <span class="fl">0.7310847</span></span>
<span id="cb319-18"><a href="árboles-de-clasificación-y-regresión.html#cb319-18" aria-hidden="true" tabindex="-1"></a>  <span class="fl">0.04</span>  <span class="fl">0.8449381</span>  <span class="fl">0.9214286</span>  <span class="fl">0.7383598</span></span>
<span id="cb319-19"><a href="árboles-de-clasificación-y-regresión.html#cb319-19" aria-hidden="true" tabindex="-1"></a>  <span class="fl">0.05</span>  <span class="fl">0.8172123</span>  <span class="fl">0.9214286</span>  <span class="fl">0.7026455</span></span>
<span id="cb319-20"><a href="árboles-de-clasificación-y-regresión.html#cb319-20" aria-hidden="true" tabindex="-1"></a>  <span class="fl">0.06</span>  <span class="fl">0.7978269</span>  <span class="fl">0.9607143</span>  <span class="fl">0.6628307</span></span>
<span id="cb319-21"><a href="árboles-de-clasificación-y-regresión.html#cb319-21" aria-hidden="true" tabindex="-1"></a>  <span class="fl">0.07</span>  <span class="fl">0.7978269</span>  <span class="fl">0.9607143</span>  <span class="fl">0.6628307</span></span>
<span id="cb319-22"><a href="árboles-de-clasificación-y-regresión.html#cb319-22" aria-hidden="true" tabindex="-1"></a>  <span class="fl">0.08</span>  <span class="fl">0.7978269</span>  <span class="fl">0.9607143</span>  <span class="fl">0.6628307</span></span>
<span id="cb319-23"><a href="árboles-de-clasificación-y-regresión.html#cb319-23" aria-hidden="true" tabindex="-1"></a>  <span class="fl">0.09</span>  <span class="fl">0.7866662</span>  <span class="fl">0.9321429</span>  <span class="fl">0.6664021</span></span>
<span id="cb319-24"><a href="árboles-de-clasificación-y-regresión.html#cb319-24" aria-hidden="true" tabindex="-1"></a>  <span class="fl">0.10</span>  <span class="fl">0.7677249</span>  <span class="fl">0.8821429</span>  <span class="fl">0.6699735</span></span>
<span id="cb319-25"><a href="árboles-de-clasificación-y-regresión.html#cb319-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb319-26"><a href="árboles-de-clasificación-y-regresión.html#cb319-26" aria-hidden="true" tabindex="-1"></a>ROC was used to select the optimal model using the largest value.</span>
<span id="cb319-27"><a href="árboles-de-clasificación-y-regresión.html#cb319-27" aria-hidden="true" tabindex="-1"></a>The final value used <span class="cf">for</span> the model was cp <span class="ot">=</span> <span class="fl">0.</span></span></code></pre></div>
<div class="sourceCode" id="cb320"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb320-1"><a href="árboles-de-clasificación-y-regresión.html#cb320-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">ggplot</span>(<span class="fu">melt</span>(model<span class="sc">$</span>resample[, <span class="sc">-</span><span class="dv">4</span>]), <span class="fu">aes</span>(<span class="at">x =</span> variable, <span class="at">y =</span> value, <span class="at">fill =</span> variable)) <span class="sc">+</span></span>
<span id="cb320-2"><a href="árboles-de-clasificación-y-regresión.html#cb320-2" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   <span class="fu">geom_violin</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:006-002-003RPARTRESULTS1"></span>
<img src="Ciencia_de_datos_con_r_files/figure-html/006-002-003RPARTRESULTS1-1.svg" alt="Resultados modelo con ajuste automático durante la validación cruzada" width="60%" />
<p class="caption">
Figura 25.4: Resultados modelo con ajuste automático durante la validación cruzada
</p>
</div>
<p>De nuevo se puede ver el rendimiento de cada una de las métricas de los árboles entrenados utilizando validación cruzada. A continuación se muestra el árbol que genera este nuevo modelo.</p>
<div class="sourceCode" id="cb321"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb321-1"><a href="árboles-de-clasificación-y-regresión.html#cb321-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="co"># se pinta el árbol obtenido</span></span>
<span id="cb321-2"><a href="árboles-de-clasificación-y-regresión.html#cb321-2" aria-hidden="true" tabindex="-1"></a><span class="er">&gt;</span> <span class="fu">rpart.plot</span>(model<span class="sc">$</span>finalModel)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:006-002-003RPARTPLOT2"></span>
<img src="Ciencia_de_datos_con_r_files/figure-html/006-002-003RPARTPLOT2-1.svg" alt="Árbol de clasificación con ajuste automático" width="100%" />
<p class="caption">
Figura 25.5: Árbol de clasificación con ajuste automático
</p>
</div>
</div>
<div id="árbol-de-regresión-para-estimar-el-número-de-días-hospitalizado" class="section level3 hasAnchor" number="25.8.3">
<h3><span class="header-section-number">25.8.3</span> Árbol de regresión para estimar el número de días hospitalizado<a href="árboles-de-clasificación-y-regresión.html#árbol-de-regresión-para-estimar-el-número-de-días-hospitalizado" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En este ejemplo se utilizan los datos <code>cleveland</code>, los cuales estan contenidos en el paquete <code>CDR</code>, y que han sido utilizados en el capítulo <span class="math inline">\(\ref{###}\)</span> para estimar <strong></strong>. El conjunto de datos contiene información sobre pacientes que llegan a un hospital con dolor de pecho, de los que se han registrado distintas características. Se pretende predecir el número de días que un paciente necesitará de hospitalización en base al resto de caracteristicas observadas. Estas variables registran si el paciente esta diagnosticado de accidente coronario, su edad, su género, el tipo de dolor que padece y la depresión en el segmento ST inducida por ejercicio en relación al reposo.</p>
<div class="sourceCode" id="cb322"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb322-1"><a href="árboles-de-clasificación-y-regresión.html#cb322-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="co"># se cargan los datos</span></span>
<span id="cb322-2"><a href="árboles-de-clasificación-y-regresión.html#cb322-2" aria-hidden="true" tabindex="-1"></a><span class="er">&gt;</span> <span class="fu">data</span>(<span class="st">&quot;cleveland&quot;</span>)</span>
<span id="cb322-3"><a href="árboles-de-clasificación-y-regresión.html#cb322-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> </span>
<span id="cb322-4"><a href="árboles-de-clasificación-y-regresión.html#cb322-4" aria-hidden="true" tabindex="-1"></a><span class="er">&gt;</span> <span class="co"># se entrena el modelo</span></span>
<span id="cb322-5"><a href="árboles-de-clasificación-y-regresión.html#cb322-5" aria-hidden="true" tabindex="-1"></a><span class="er">&gt;</span> <span class="fu">set.seed</span>(<span class="dv">101</span>)</span>
<span id="cb322-6"><a href="árboles-de-clasificación-y-regresión.html#cb322-6" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> model <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb322-7"><a href="árboles-de-clasificación-y-regresión.html#cb322-7" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   dhosp <span class="sc">~</span> diag <span class="sc">+</span> edad <span class="sc">+</span> sexo <span class="sc">+</span></span>
<span id="cb322-8"><a href="árboles-de-clasificación-y-regresión.html#cb322-8" aria-hidden="true" tabindex="-1"></a><span class="er">&gt;</span>     tdolor <span class="sc">+</span> dep,</span>
<span id="cb322-9"><a href="árboles-de-clasificación-y-regresión.html#cb322-9" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   <span class="at">data =</span> cleveland,</span>
<span id="cb322-10"><a href="árboles-de-clasificación-y-regresión.html#cb322-10" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   <span class="at">method =</span> <span class="st">&quot;rpart&quot;</span>,</span>
<span id="cb322-11"><a href="árboles-de-clasificación-y-regresión.html#cb322-11" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   <span class="at">metric =</span> <span class="st">&quot;RMSE&quot;</span>,</span>
<span id="cb322-12"><a href="árboles-de-clasificación-y-regresión.html#cb322-12" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span>   <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">number =</span> <span class="dv">10</span>)</span>
<span id="cb322-13"><a href="árboles-de-clasificación-y-regresión.html#cb322-13" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> )</span></code></pre></div>
<div class="sourceCode" id="cb323"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb323-1"><a href="árboles-de-clasificación-y-regresión.html#cb323-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> model</span>
<span id="cb323-2"><a href="árboles-de-clasificación-y-regresión.html#cb323-2" aria-hidden="true" tabindex="-1"></a>CART </span>
<span id="cb323-3"><a href="árboles-de-clasificación-y-regresión.html#cb323-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb323-4"><a href="árboles-de-clasificación-y-regresión.html#cb323-4" aria-hidden="true" tabindex="-1"></a><span class="dv">303</span> samples</span>
<span id="cb323-5"><a href="árboles-de-clasificación-y-regresión.html#cb323-5" aria-hidden="true" tabindex="-1"></a>  <span class="dv">5</span> predictor</span>
<span id="cb323-6"><a href="árboles-de-clasificación-y-regresión.html#cb323-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb323-7"><a href="árboles-de-clasificación-y-regresión.html#cb323-7" aria-hidden="true" tabindex="-1"></a>No pre<span class="sc">-</span>processing</span>
<span id="cb323-8"><a href="árboles-de-clasificación-y-regresión.html#cb323-8" aria-hidden="true" tabindex="-1"></a>Resampling<span class="sc">:</span> Cross<span class="sc">-</span><span class="fu">Validated</span> (<span class="dv">10</span> fold) </span>
<span id="cb323-9"><a href="árboles-de-clasificación-y-regresión.html#cb323-9" aria-hidden="true" tabindex="-1"></a>Summary of sample sizes<span class="sc">:</span> <span class="dv">272</span>, <span class="dv">273</span>, <span class="dv">273</span>, <span class="dv">272</span>, <span class="dv">274</span>, <span class="dv">272</span>, ... </span>
<span id="cb323-10"><a href="árboles-de-clasificación-y-regresión.html#cb323-10" aria-hidden="true" tabindex="-1"></a>Resampling results across tuning parameters<span class="sc">:</span></span>
<span id="cb323-11"><a href="árboles-de-clasificación-y-regresión.html#cb323-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb323-12"><a href="árboles-de-clasificación-y-regresión.html#cb323-12" aria-hidden="true" tabindex="-1"></a>  cp          RMSE      Rsquared   MAE     </span>
<span id="cb323-13"><a href="árboles-de-clasificación-y-regresión.html#cb323-13" aria-hidden="true" tabindex="-1"></a>  <span class="fl">0.01132433</span>  <span class="fl">1.508393</span>  <span class="fl">0.3168135</span>  <span class="fl">1.135381</span></span>
<span id="cb323-14"><a href="árboles-de-clasificación-y-regresión.html#cb323-14" aria-hidden="true" tabindex="-1"></a>  <span class="fl">0.01674747</span>  <span class="fl">1.472518</span>  <span class="fl">0.3435459</span>  <span class="fl">1.103713</span></span>
<span id="cb323-15"><a href="árboles-de-clasificación-y-regresión.html#cb323-15" aria-hidden="true" tabindex="-1"></a>  <span class="fl">0.37275022</span>  <span class="fl">1.576962</span>  <span class="fl">0.3526015</span>  <span class="fl">1.210831</span></span>
<span id="cb323-16"><a href="árboles-de-clasificación-y-regresión.html#cb323-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb323-17"><a href="árboles-de-clasificación-y-regresión.html#cb323-17" aria-hidden="true" tabindex="-1"></a>RMSE was used to select the optimal model using the smallest value.</span>
<span id="cb323-18"><a href="árboles-de-clasificación-y-regresión.html#cb323-18" aria-hidden="true" tabindex="-1"></a>The final value used <span class="cf">for</span> the model was cp <span class="ot">=</span> <span class="dv">0</span>.<span class="fl">01674747.</span></span></code></pre></div>
<p>Los resultados durante la validación cruzada se observan en la figura <span class="math inline">\(\ref{006-002-003RPARTRESULTSREG}\)</span>. Se puede comprobar que los resultados son bastante pobres, obteniendo un valor de <span class="math inline">\(R^2\)</span> que oscila entre un 20% y un 55%. Estos valores bajos de <span class="math inline">\(R^2\)</span> se corresponden con los altos valores obtenidos en RMSE.</p>
<div class="sourceCode" id="cb324"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb324-1"><a href="árboles-de-clasificación-y-regresión.html#cb324-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="fu">ggplot</span>(<span class="fu">melt</span>(model<span class="sc">$</span>resample[, <span class="sc">-</span><span class="dv">4</span>]), <span class="fu">aes</span>(<span class="at">x =</span> variable, <span class="at">y =</span> value, <span class="at">fill =</span> variable)) <span class="sc">+</span></span>
<span id="cb324-2"><a href="árboles-de-clasificación-y-regresión.html#cb324-2" aria-hidden="true" tabindex="-1"></a><span class="sc">+</span>   <span class="fu">geom_boxplot</span>()</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:006-002-003RPARTRESULTSREG"></span>
<img src="Ciencia_de_datos_con_r_files/figure-html/006-002-003RPARTRESULTSREG-1.svg" alt="Resultados árbol de regresión durante la validación cruzada" width="60%" />
<p class="caption">
Figura 25.6: Resultados árbol de regresión durante la validación cruzada
</p>
</div>
<p>El resultado del modelo se muestra en el árbol de la figura <span class="math inline">\(\ref{RPARTREGPLOT}\)</span>. La interpretación de este árbol sería:</p>
<ol style="list-style-type: decimal">
<li><p>Si el paciente no tiene diagnóstico de accidente coronario, solo necesita un día de hospitalización.</p></li>
<li><p>En el caso de tener este diagnostico, y una depresión mayor igual a dos en el segmento ST inducida por ejercicio en relación al reposo, necesitará 1,9 días de hospitalización.</p></li>
<li><p>En un último ejemplo, si la depresión en el segmento ST inducida por ejercicio en relación al reposo es mayor a 0,35 y menor 2 entonces se distingue por genero para saber el número de días hospitalizados. En el caso de los hombres, permaneceran 3,2 días hospitalizados. Mientras que las mujeres solo 1,9 días.</p></li>
</ol>
<div class="sourceCode" id="cb325"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb325-1"><a href="árboles-de-clasificación-y-regresión.html#cb325-1" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="co"># Se entrena de nuevo para obtener un objeto rpart</span></span>
<span id="cb325-2"><a href="árboles-de-clasificación-y-regresión.html#cb325-2" aria-hidden="true" tabindex="-1"></a><span class="er">&gt;</span> <span class="fu">set.seed</span>(<span class="dv">101</span>)</span>
<span id="cb325-3"><a href="árboles-de-clasificación-y-regresión.html#cb325-3" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> model <span class="ot">&lt;-</span> <span class="fu">rpart</span>(dhosp <span class="sc">~</span> ., <span class="at">data =</span> cleveland, <span class="at">cp =</span> <span class="fu">unlist</span>(model<span class="sc">$</span>bestTune, <span class="at">use.names =</span> <span class="cn">FALSE</span>))</span>
<span id="cb325-4"><a href="árboles-de-clasificación-y-regresión.html#cb325-4" aria-hidden="true" tabindex="-1"></a><span class="sc">&gt;</span> <span class="co"># se pinta el árbol obtenido</span></span>
<span id="cb325-5"><a href="árboles-de-clasificación-y-regresión.html#cb325-5" aria-hidden="true" tabindex="-1"></a><span class="er">&gt;</span> <span class="fu">rpart.plot</span>(model)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:RPARTREGPLOT"></span>
<img src="Ciencia_de_datos_con_r_files/figure-html/RPARTREGPLOT-1.svg" alt="Árbol de regresión para predecir el número de días de hospitalización" width="60%" />
<p class="caption">
Figura 25.7: Árbol de regresión para predecir el número de días de hospitalización
</p>
</div>
</div>
<div id="resumen-5" class="section level3 unnumbered hasAnchor infobox_resume">
<h3>Resumen<a href="árboles-de-clasificación-y-regresión.html#resumen-5" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En este capítulo se ha introducido al lector en los árboles de decisión para clasificación y regresión, en particular:</p>
<ul>
<li>Se ha presentado la lógica para la construcción de árboles de decisión, ya sean de regresión o clasificación.</li>
<li>Se han contemplado diferentes medidas con las que el árbol decide avanzar hacia un nuevo punto de decisión.</li>
<li>Se presentan los conceptos de sobreajuste y complejidad del árbol, así como la forma de controlarlos.</li>
<li>Se ha mostrado el uso de <code>R</code> para la clasificación de clases binarias, y para la predicción de variables respuesta numéricas a través de casos aplicados.</li>
</ul>
</div>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="68">
<li id="fn68"><p>Universidad Complutense de Madrid<a href="árboles-de-clasificación-y-regresión.html#fnref68" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="análisis-discriminante.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="máquinas-de-vector-soporte.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Ciencia_de_datos_con_r.pdf", "Ciencia_de_datos_con_r.epub"],
"search": {
"engine": "lunr",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
