<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Capítulo 26 Clasificador k-vecinos más próximos | Fundamentos de ciencia de datos con R</title>
<meta name="author" content="Gema Fernández-Avilés y José-María Montero">
<meta name="description" content="Ramón A. Carrasco\(^{a}\) e Itzcóatl Bueno\(^{b,a}\) \(^{a}\)Universidad Complutense de Madrid \(^{b}\)Instituto Nacional de Estadística  26.1 Introducción El k-vecinos más próximos (KNN, por sus...">
<meta name="generator" content="bookdown 0.28 with bs4_book()">
<meta property="og:title" content="Capítulo 26 Clasificador k-vecinos más próximos | Fundamentos de ciencia de datos con R">
<meta property="og:type" content="book">
<meta property="og:image" content="/img/cover.png">
<meta property="og:description" content="Ramón A. Carrasco\(^{a}\) e Itzcóatl Bueno\(^{b,a}\) \(^{a}\)Universidad Complutense de Madrid \(^{b}\)Instituto Nacional de Estadística  26.1 Introducción El k-vecinos más próximos (KNN, por sus...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Capítulo 26 Clasificador k-vecinos más próximos | Fundamentos de ciencia de datos con R">
<meta name="twitter:description" content="Ramón A. Carrasco\(^{a}\) e Itzcóatl Bueno\(^{b,a}\) \(^{a}\)Universidad Complutense de Madrid \(^{b}\)Instituto Nacional de Estadística  26.1 Introducción El k-vecinos más próximos (KNN, por sus...">
<meta name="twitter:image" content="/img/cover.png">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.2/transition.js"></script><script src="libs/bs3compat-0.4.2/tabs.js"></script><script src="libs/bs3compat-0.4.2/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><link href="libs/tabwid-1.1.0/tabwid.css" rel="stylesheet">
<link href="libs/tabwid-1.1.0/scrool.css" rel="stylesheet">
<script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><link rel="stylesheet" href="bs4_style.css">
<link rel="stylesheet" href="bs4_book.css">
<link rel="stylesheet" href="style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Fundamentos de ciencia de datos con R</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Buscar" aria-label="Buscar">
</form>

      <nav aria-label="Contenido"><h2>Contenido</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Prefacio</a></li>
<li class="book-part">Ciencia, datos, software… y científicos</li>
<li><a class="" href="ciencia-datos.html"><span class="header-section-number">1</span> ¿Es la ciencia de datos una ciencia?</a></li>
<li><a class="" href="metodologia.html"><span class="header-section-number">2</span> Metodología en ciencia de datos</a></li>
<li><a class="" href="ch-110003.html"><span class="header-section-number">3</span> R para ciencia de datos</a></li>
<li><a class="" href="cap-etica.html"><span class="header-section-number">4</span> Ética en la ciencia de datos</a></li>
<li class="book-part">Bienvenidos a la jungla de datos</li>
<li><a class="" href="datos-sql.html"><span class="header-section-number">5</span> Gestión de bases de datos relacionales</a></li>
<li><a class="" href="cap-nosql.html"><span class="header-section-number">6</span> Gestión de bases de datos NoSQL</a></li>
<li><a class="" href="DGDQM.html"><span class="header-section-number">7</span> Gobierno, gestión y calidad del dato</a></li>
<li><a class="" href="id_130009.html"><span class="header-section-number">8</span> Integración y limpieza de datos</a></li>
<li><a class="" href="chap-feature.html"><span class="header-section-number">9</span> Selección y transformación de variables</a></li>
<li><a class="" href="chap-herramientas.html"><span class="header-section-number">10</span> Herramientas para el análisis en ciencia de datos</a></li>
<li><a class="" href="id_120006-aed.html"><span class="header-section-number">11</span> Análisis exploratorio de datos</a></li>
<li class="book-part">Fundamentos de estadística</li>
<li><a class="" href="Funda-probab.html"><span class="header-section-number">12</span> Probabilidad</a></li>
<li><a class="" href="Fundainfer.html"><span class="header-section-number">13</span> Inferencia estadística</a></li>
<li><a class="" href="muestreo.html"><span class="header-section-number">14</span> Muestreo y remuestreo</a></li>
<li class="book-part">Modelización estadística</li>
<li><a class="" href="cap-lm.html"><span class="header-section-number">15</span> Modelización lineal</a></li>
<li><a class="" href="cap-glm.html"><span class="header-section-number">16</span> Modelos lineales generalizados</a></li>
<li><a class="" href="cap-gam.html"><span class="header-section-number">17</span> Modelos aditivos generalizados</a></li>
<li><a class="" href="cap-mxm.html"><span class="header-section-number">18</span> Modelos mixtos</a></li>
<li><a class="" href="cap-sparse.html"><span class="header-section-number">19</span> Modelos sparse y métodos penalizados de regresión</a></li>
<li><a class="" href="cap-series-temp.html"><span class="header-section-number">20</span> Modelización de series temporales</a></li>
<li><a class="" href="cap-discriminante.html"><span class="header-section-number">21</span> Análisis discriminante</a></li>
<li><a class="" href="cap-conjunto.html"><span class="header-section-number">22</span> Análisis conjunto</a></li>
<li><a class="" href="tablas-contingencia.html"><span class="header-section-number">23</span> Análisis de tablas de contingencia</a></li>
<li class="book-part">Machine learning supervisado</li>
<li><a class="" href="cap-arboles.html"><span class="header-section-number">24</span> Árboles de clasificación y regresión</a></li>
<li><a class="" href="cap-svm.html"><span class="header-section-number">25</span> Máquinas de vector soporte</a></li>
<li><a class="active" href="cap-knn.html"><span class="header-section-number">26</span> Clasificador k-vecinos más próximos</a></li>
<li><a class="" href="cap-naive-bayes.html"><span class="header-section-number">27</span> Naive Bayes</a></li>
<li><a class="" href="cap-bagg-rf.html"><span class="header-section-number">28</span> Métodos ensamblados: bagging y random forest</a></li>
<li><a class="" href="cap-boosting-xgboost.html"><span class="header-section-number">29</span> Boosting y el algoritmo XGBoost</a></li>
<li class="book-part">Machine learning no supervisado</li>
<li><a class="" href="jerarquico.html"><span class="header-section-number">30</span> Análisis cluster: clusterización jerárquica</a></li>
<li><a class="" href="no-jerarquico.html"><span class="header-section-number">31</span> Análisis cluster: clusterización no jerárquica</a></li>
<li><a class="" href="acp.html"><span class="header-section-number">32</span> Análisis de componentes principales</a></li>
<li><a class="" href="an%C3%A1lisis-factorial.html"><span class="header-section-number">33</span> Análisis factorial</a></li>
<li><a class="" href="escalamiento-multidimensional.html"><span class="header-section-number">34</span> Escalamiento multidimensional</a></li>
<li><a class="" href="correspondencias.html"><span class="header-section-number">35</span> Análisis de correspondencias</a></li>
<li class="book-part">Deep learning</li>
<li><a class="" href="capNN.html"><span class="header-section-number">36</span> Redes neuronales artificiales</a></li>
<li><a class="" href="cap-redes-convol.html"><span class="header-section-number">37</span> Redes neuronales convolucionales</a></li>
<li class="book-part">Ciencia de datos de texto y redes</li>
<li><a class="" href="mineria-textos.html"><span class="header-section-number">38</span> Minería de textos</a></li>
<li><a class="" href="grafos.html"><span class="header-section-number">39</span> Análisis de grafos y redes sociales</a></li>
<li class="book-part">Ciencia de datos espaciales</li>
<li><a class="" href="datos-espaciales.html"><span class="header-section-number">40</span> Trabajando con datos espaciales</a></li>
<li><a class="" href="geo.html"><span class="header-section-number">41</span> Geoestadística</a></li>
<li><a class="" href="cap-econom-esp.html"><span class="header-section-number">42</span> Modelos econométricos espaciales</a></li>
<li><a class="" href="cap-pp.html"><span class="header-section-number">43</span> Procesos de puntos</a></li>
<li class="book-part">Comunica y colabora</li>
<li><a class="" href="id_120007-informes.html"><span class="header-section-number">44</span> Informes reproducibles con R Markdown y Quarto</a></li>
<li><a class="" href="shiny.html"><span class="header-section-number">45</span> Creación de aplicaciones web interactivas con Shiny</a></li>
<li><a class="" href="github.html"><span class="header-section-number">46</span> Git y GitHub R</a></li>
<li><a class="" href="geoproces.html"><span class="header-section-number">47</span> Geoprocesamiento en nube</a></li>
<li class="book-part">Casos de estudio en ciencia de datos</li>
<li><a class="" href="cap-crimen.html"><span class="header-section-number">48</span> Análisis de una red criminal</a></li>
<li><a class="" href="cap-publicidad.html"><span class="header-section-number">49</span> Optimización de inversiones publicitarias</a></li>
<li><a class="" href="cap-twitter.html"><span class="header-section-number">50</span> ¿Cómo twitea Elon Musk?</a></li>
<li><a class="" href="cap-periodismo.html"><span class="header-section-number">51</span> Análisis electoral: de Rstudio a su periódico</a></li>
<li><a class="" href="paro-clm.html"><span class="header-section-number">52</span> Crisis: impacto en el paro de Castilla-La Mancha</a></li>
<li><a class="" href="cap-rfm.html"><span class="header-section-number">53</span> Segmentación de clientes en el comerico minorista</a></li>
<li><a class="" href="cap-medicina.html"><span class="header-section-number">54</span> Análisis de datos en medicina</a></li>
<li><a class="" href="cap-futbol.html"><span class="header-section-number">55</span> Messi y Ronaldo: dos ídolos desde la perspectiva de los datos</a></li>
<li><a class="" href="cambioclimatico.html"><span class="header-section-number">56</span> Un dato sobre el cambio climático</a></li>
<li><a class="" href="cap-ree.html"><span class="header-section-number">57</span> Predicción de consumo eléctrico con redes neuronales</a></li>
<li><a class="" href="cap-sist-exp.html"><span class="header-section-number">58</span> Implementación de un sistema experto en el ámbito pediátrico</a></li>
<li><a class="" href="nlp-textil.html"><span class="header-section-number">59</span> El procesamiento del lenguaje natural para tendencias de moda en textil</a></li>
<li><a class="" href="cap-fraude.html"><span class="header-section-number">60</span> Detección de fraude de tarjetas de crédito</a></li>
<li class="book-part">Appendix</li>
<li><a class="" href="info-session.html"><span class="header-section-number">A</span> Información de la sesión</a></li>
<li><a class="" href="referncias.html">Referncias</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="cap-knn" class="section level1" number="26">
<h1>
<span class="header-section-number">Capítulo 26</span> Clasificador k-vecinos más próximos<a class="anchor" aria-label="anchor" href="#cap-knn"><i class="fas fa-link"></i></a>
</h1>
<p><em>Ramón A. Carrasco</em><span class="math inline">\(^{a}\)</span> e <em>Itzcóatl Bueno</em><span class="math inline">\(^{b,a}\)</span></p>
<p><span class="math inline">\(^{a}\)</span>Universidad Complutense de Madrid
<span class="math inline">\(^{b}\)</span>Instituto Nacional de Estadística</p>
<div id="introducción-12" class="section level2" number="26.1">
<h2>
<span class="header-section-number">26.1</span> Introducción<a class="anchor" aria-label="anchor" href="#introducci%C3%B3n-12"><i class="fas fa-link"></i></a>
</h2>
<p>El k-vecinos más próximos (KNN, por sus siglas en inglés <em>k-Nearest Neighbors</em>) es un algoritmo de aprendizaje no paramétrico. Un algoritmo no paramétrico no presupone la forma concreta del modelo a entrenar, siendo más flexible. Sin embargo, esto se consigue a costa de necesitar más datos de entrenamiento y siendo más lentos que los algoritmos paramétricos. Al contrario que otros algoritmos de aprendizaje que permiten deshacerse de los datos de entrenamiento una vez se entrena el modelo, el modelo KNN guarda las observaciones de entrenamiento en memoria. Esto es, al incorporar una nueva observación <em><span class="math inline">\(x\)</span></em>, el algoritmo KNN encuentra las <span class="math inline">\(k\)</span> observaciones del conjunto de datos de entrenamiento más similares a la nueva y proporciona la clase mayoritaria (en el caso de clasificación) o el valor medio (en el caso de regresión).</p>
<p>El número de casos (<span class="math inline">\(k\)</span>) a utilizar para clasificar las nuevas observaciones es un parámetro crucial para este algoritmo <span class="citation">(<a href="referncias.html#ref-james2013introduction">G. James et al. 2013</a>)</span>. Si, por ejemplo, <span class="math inline">\(k=3\)</span>, el modelo KNN utilizará las tres observaciones más similares (vecinos) al nuevo caso para clasificarlo. Es recomendable probar distintos valores de <span class="math inline">\(k\)</span> para conseguir el mejor ajuste del modelo, y por tanto, es conveniente evitar valores extremos de <span class="math inline">\(k\)</span>. Si se establece un valor muy bajo de <span class="math inline">\(k\)</span> aumentará el sesgo y llevará a clasificaciones erróneas. Mientras que valores muy elevados de <span class="math inline">\(k\)</span> harán que el algoritmo sea computacionalmente costoso y además tampoco será un buen clasificador. Además, también se recomienda establecer valores impares de <span class="math inline">\(k\)</span> para evitar puntos muertos estadísticos (empate entre categorías) y un resultado no válido.</p>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:knn-ejemplo"></span>
<img src="img/knn.png" alt="Ejemplo de k-vecinos más próximos." width="60%"><p class="caption">
Figura 26.1: Ejemplo de k-vecinos más próximos.
</p>
</div>
<p>La escala de las variables puede impactar en el resultado del modelo KNN. Por ello, el conjunto de datos debe escalarse para que aquellas variables con unidades de medida grandes no tengan más importancia en el cálculo que otras con magnitudes menores. Así se reduce la importancia de las variables debido a sus unidades de medida y se estandariza la varianza.</p>
<p>Pese a que el modelo KNN es fácil de entender y generalmente preciso, almacenar el conjunto de datos de entrenamiento, así como calcular la distancia entre cada nueva observación a clasificar y las observaciones del conjunto de datos, supone la necesidad de recursos computacionales altos. Esto implica que cuanto mayor es la cantidad de observaciones en el conjunto de datos, mayor es el tiempo para la ejecución de una sola predicción, y, por tanto, esto puede dar lugar a tiempos de procesamiento lentos. Por este motivo, no se recomienda el uso del algoritmo KNN cuando se dispone de conjuntos de datos muy grandes. Otra desventaja a tener en cuenta es la dificultad de aplicar KNN a conjuntos de datos con un gran número de variables, puesto que calcular las distancias entre observaciones con múltiples dimensiones también incrementará la necesidad de recursos computacionales y podría dificultar que se clasifique de forma precisa.</p>
</div>
<div id="decisiones-a-tener-en-cuenta" class="section level2" number="26.2">
<h2>
<span class="header-section-number">26.2</span> Decisiones a tener en cuenta<a class="anchor" aria-label="anchor" href="#decisiones-a-tener-en-cuenta"><i class="fas fa-link"></i></a>
</h2>
<p>La elección de la función de distancia, así como el número de vecinos <span class="math inline">\(k\)</span> son decisiones que debe tomar el investigador antes de ejecutar el algoritmo. Siendo este último el hiperparámetro del modelo que la función <code><a href="https://rdrr.io/pkg/caret/man/modelLookup.html">modelLookup()</a></code> de <code>caret</code> nos devuelve considerando que es primordial ajustarlo:</p>
<div class="sourceCode" id="cb369"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb369-1"><a href="cap-knn.html#cb369-1" tabindex="-1"></a><span class="fu">modelLookup</span>(<span class="st">"knn"</span>)</span>
<span id="cb369-2"><a href="cap-knn.html#cb369-2" tabindex="-1"></a>  model parameter      label forReg forClass probModel</span>
<span id="cb369-3"><a href="cap-knn.html#cb369-3" tabindex="-1"></a><span class="dv">1</span>   knn         k <span class="co">#Neighbors   TRUE     TRUE      TRUE</span></span></code></pre></div>
<div id="función-de-distancia-a-utilizar" class="section level3" number="26.2.1">
<h3>
<span class="header-section-number">26.2.1</span> Función de distancia a utilizar<a class="anchor" aria-label="anchor" href="#funci%C3%B3n-de-distancia-a-utilizar"><i class="fas fa-link"></i></a>
</h3>
<p>El modelo KNN determina la cercanía entre dos observaciones a través de una función de distancia. Generalmente, se utilizan la distancia euclídea, mostrada en la ecuación <a href="cap-knn.html#eq:dist-eu">(26.1)</a>, y la distancia de Manhattan, mostrada en la ecuación <a href="cap-knn.html#eq:dist-man">(26.2)</a>. Otras funciones de distancia, como las presentadas en el Cap. <a href="#cap-cluster"><strong>??</strong></a>, también pueden ser utilizadas para el entrenamiento de este algoritmo.</p>
<p><span class="math display" id="eq:dist-eu">\[\begin{equation}
d(x_i,x_k)=\sqrt{\sum_{j=1}^{p}{(x_i^{(j)}-x_k^{(j)})^2}}
\tag{26.1}
\end{equation}\]</span></p>
<p><span class="math display" id="eq:dist-man">\[\begin{equation}
d(x_i,x_k)=\sum_{j=1}^{p}{|x_i^{(j)}-x_k^{(j)}|}
\tag{26.2}
\end{equation}\]</span></p>
<p>En el caso de querer incluir tanto variables cuantitativas como variables cualitativas en el cálculo de la distancia, el coeficiente de disimilitud de Gower es la función de distancia más popular para esta situación. El coeficiente de disimilitud de Gower se define como:</p>
<p><span class="math display">\[\begin{equation}
d(i,j) = \frac{\sum^{p}_{k=1}{\omega_k \delta^{(k)}_{ij}d^(k)_{ij}}}{\omega_k \delta^{(k)}_{ij}}
\end{equation}\]</span></p>
<p>El coeficiente de Gower es una media ponderada de las distancias <span class="math inline">\(d^{(k)}_{ij}\)</span> con ponderaciones <span class="math inline">\(\omega_{k}\delta_{ij}^{(k)}\)</span>.</p>
</div>
<div id="número-de-vecinos-k-seleccionados" class="section level3" number="26.2.2">
<h3>
<span class="header-section-number">26.2.2</span> Número de vecinos (k) seleccionados<a class="anchor" aria-label="anchor" href="#n%C3%BAmero-de-vecinos-k-seleccionados"><i class="fas fa-link"></i></a>
</h3>
<p>Como se ha reiterado, la elección de cuántos vecinos (<span class="math inline">\(k\)</span>) intervienen en el ajuste del algoritmo es determinante para su rendimiento. Si se escogen demasiado pocos vecinos, se producirá sobreajuste en el modelo. En el extremo en el que sólo se utilizará un vecino (<span class="math inline">\(k=1\)</span>), la predicción se basará en la observación con la menor distancia al elemento a clasificar. Por otro lado, un número alto de vecinos (<span class="math inline">\(k\)</span>) hace que el modelo no ajuste bien al tener en cuenta un vecindario más grande. En este sentido, en el caso extremo de elegir todas las observaciones como vecinos más próximos (<span class="math inline">\(k=n\)</span>), se obtendrá el valor medio (en el caso de la regresión) o la clase mayoritaria (en el caso de la clasificación) como valor predicho para todas las observaciones del conjunto de entrenamiento.</p>
<p>No existe una regla general para la elección óptima de <span class="math inline">\(k\)</span>, puesto que en gran medida dependerá del conjunto de datos utilizado. Cuando el conjunto de datos tiene pocas variables que no aporten información, valores pequeños de <span class="math inline">\(k\)</span> tienden a funcionar mejor. Cuantas más variables sin importancia se incluyen en el conjunto de datos, mayor deberá ser el valor de <span class="math inline">\(k\)</span> para suavizar su efecto.</p>
</div>
</div>
<div id="procedimiento-con-r-la-función-knn" class="section level2" number="26.3">
<h2>
<span class="header-section-number">26.3</span> Procedimiento con <strong>R</strong>: la función <code>knn()</code><a class="anchor" aria-label="anchor" href="#procedimiento-con-r-la-funci%C3%B3n-knn"><i class="fas fa-link"></i></a>
</h2>
<p>En el paquete <code>class</code> de R se encuentra la función <code>knn()</code> que se utiliza para entrenar el modelo k-vecinos más próximos:</p>
<div class="sourceCode" id="cb370"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu">knn</span><span class="op">(</span><span class="va">train</span>, <span class="va">test</span>, <span class="va">cl</span>, k <span class="op">=</span> <span class="fl">1</span>, <span class="va">...</span><span class="op">)</span></span></code></pre></div>
<ul>
<li>
<code>train</code>: conjunto de datos con las observaciones de entrenamiento.</li>
<li>
<code>test</code>: conjunto de datos con las observaciones de validación. Un vector se interpreta como una única observación a validar.</li>
<li>
<code>cl</code>: clases de las observaciones de entrenamiento.</li>
<li>
<code>k</code>: número de vecinos a considerar</li>
</ul>
</div>
<div id="aplicación-del-modelo-knn-en-r" class="section level2" number="26.4">
<h2>
<span class="header-section-number">26.4</span> Aplicación del modelo KNN en R<a class="anchor" aria-label="anchor" href="#aplicaci%C3%B3n-del-modelo-knn-en-r"><i class="fas fa-link"></i></a>
</h2>
<p>En este ejemplo se entrena un modelo KNN para clasificar qué clientes comprarán el <em>tensiómetro digital</em> teniendo en cuenta sus características y el resto de sus compras. Este conjunto de datos está incluido en el paquete <code>CDR</code> con el nombre <code>dp_entr_NUM</code>. En este conjunto de datos todas las variables son cuantitativas (excepto la clase objetivo) pero dichas variables tienen distintas escalas de medida (euros, años, unidades, etc.) por lo que es necesario indicar en la función <code><a href="https://rdrr.io/pkg/caret/man/trainControl.html">trainControl()</a></code> que se haga un preprocesamiento para estandarizar las variables. Además, se define como método de remuestreo la validación cruzada, como la presentada en el Cap. <a href="chap-feature.html#chap-feature">9</a>, con 10 folds.</p>
<div class="sourceCode" id="cb371"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb371-1"><a href="cap-knn.html#cb371-1" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"CDR"</span>)</span>
<span id="cb371-2"><a href="cap-knn.html#cb371-2" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"class"</span>)</span>
<span id="cb371-3"><a href="cap-knn.html#cb371-3" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"caret"</span>)</span>
<span id="cb371-4"><a href="cap-knn.html#cb371-4" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"reshape"</span>)</span>
<span id="cb371-5"><a href="cap-knn.html#cb371-5" tabindex="-1"></a><span class="fu">library</span>(<span class="st">"ggplot2"</span>)</span>
<span id="cb371-6"><a href="cap-knn.html#cb371-6" tabindex="-1"></a></span>
<span id="cb371-7"><a href="cap-knn.html#cb371-7" tabindex="-1"></a><span class="fu">data</span>(dp_entr_NUM)</span>
<span id="cb371-8"><a href="cap-knn.html#cb371-8" tabindex="-1"></a></span>
<span id="cb371-9"><a href="cap-knn.html#cb371-9" tabindex="-1"></a><span class="fu">head</span>(dp_entr_NUM)</span>
<span id="cb371-10"><a href="cap-knn.html#cb371-10" tabindex="-1"></a></span>
<span id="cb371-11"><a href="cap-knn.html#cb371-11" tabindex="-1"></a>  ind_pro11 ind_pro12 ind_pro14 ind_pro15 ind_pro16 ind_pro17 des_nivel_edu.ALTO</span>
<span id="cb371-12"><a href="cap-knn.html#cb371-12" tabindex="-1"></a><span class="dv">1</span>         <span class="dv">1</span>         <span class="dv">0</span>         <span class="dv">1</span>         <span class="dv">1</span>         <span class="dv">1</span>         <span class="dv">0</span>                  <span class="dv">0</span></span>
<span id="cb371-13"><a href="cap-knn.html#cb371-13" tabindex="-1"></a><span class="dv">2</span>         <span class="dv">0</span>         <span class="dv">0</span>         <span class="dv">1</span>         <span class="dv">0</span>         <span class="dv">1</span>         <span class="dv">0</span>                  <span class="dv">0</span></span>
<span id="cb371-14"><a href="cap-knn.html#cb371-14" tabindex="-1"></a><span class="dv">3</span>         <span class="dv">0</span>         <span class="dv">0</span>         <span class="dv">1</span>         <span class="dv">1</span>         <span class="dv">1</span>         <span class="dv">1</span>                  <span class="dv">0</span></span>
<span id="cb371-15"><a href="cap-knn.html#cb371-15" tabindex="-1"></a><span class="dv">4</span>         <span class="dv">0</span>         <span class="dv">1</span>         <span class="dv">1</span>         <span class="dv">0</span>         <span class="dv">0</span>         <span class="dv">0</span>                  <span class="dv">0</span></span>
<span id="cb371-16"><a href="cap-knn.html#cb371-16" tabindex="-1"></a><span class="dv">5</span>         <span class="dv">0</span>         <span class="dv">1</span>         <span class="dv">1</span>         <span class="dv">0</span>         <span class="dv">1</span>         <span class="dv">0</span>                  <span class="dv">0</span></span>
<span id="cb371-17"><a href="cap-knn.html#cb371-17" tabindex="-1"></a><span class="dv">6</span>         <span class="dv">1</span>         <span class="dv">0</span>         <span class="dv">1</span>         <span class="dv">0</span>         <span class="dv">0</span>         <span class="dv">0</span>                  <span class="dv">1</span></span>
<span id="cb371-18"><a href="cap-knn.html#cb371-18" tabindex="-1"></a>  des_nivel_edu.BASICO des_nivel_edu.MEDIO importe_pro11 importe_pro12 importe_pro14</span>
<span id="cb371-19"><a href="cap-knn.html#cb371-19" tabindex="-1"></a><span class="dv">1</span>                    <span class="dv">0</span>                   <span class="dv">1</span>           <span class="dv">157</span>             <span class="dv">0</span>            <span class="dv">40</span></span>
<span id="cb371-20"><a href="cap-knn.html#cb371-20" tabindex="-1"></a><span class="dv">2</span>                    <span class="dv">0</span>                   <span class="dv">1</span>             <span class="dv">0</span>             <span class="dv">0</span>           <span class="dv">240</span></span>
<span id="cb371-21"><a href="cap-knn.html#cb371-21" tabindex="-1"></a><span class="dv">3</span>                    <span class="dv">1</span>                   <span class="dv">0</span>             <span class="dv">0</span>             <span class="dv">0</span>           <span class="dv">425</span></span>
<span id="cb371-22"><a href="cap-knn.html#cb371-22" tabindex="-1"></a><span class="dv">4</span>                    <span class="dv">0</span>                   <span class="dv">1</span>             <span class="dv">0</span>           <span class="dv">120</span>            <span class="dv">60</span></span>
<span id="cb371-23"><a href="cap-knn.html#cb371-23" tabindex="-1"></a><span class="dv">5</span>                    <span class="dv">1</span>                   <span class="dv">0</span>             <span class="dv">0</span>           <span class="dv">120</span>           <span class="dv">133</span></span>
<span id="cb371-24"><a href="cap-knn.html#cb371-24" tabindex="-1"></a><span class="dv">6</span>                    <span class="dv">0</span>                   <span class="dv">0</span>           <span class="dv">115</span>             <span class="dv">0</span>           <span class="dv">220</span></span>
<span id="cb371-25"><a href="cap-knn.html#cb371-25" tabindex="-1"></a>  importe_pro15 importe_pro16 importe_pro17 edad tamano_fam anos_exp ingresos_ano CLS_PRO_pro13</span>
<span id="cb371-26"><a href="cap-knn.html#cb371-26" tabindex="-1"></a><span class="dv">1</span>           <span class="dv">200</span>           <span class="dv">180</span>             <span class="dv">0</span>   <span class="dv">49</span>          <span class="dv">4</span>       <span class="dv">24</span>        <span class="dv">30000</span>             S</span>
<span id="cb371-27"><a href="cap-knn.html#cb371-27" tabindex="-1"></a><span class="dv">2</span>             <span class="dv">0</span>           <span class="dv">180</span>             <span class="dv">0</span>   <span class="dv">38</span>          <span class="dv">2</span>       <span class="dv">12</span>        <span class="dv">53000</span>             N</span>
<span id="cb371-28"><a href="cap-knn.html#cb371-28" tabindex="-1"></a><span class="dv">3</span>           <span class="dv">200</span>           <span class="dv">180</span>           <span class="dv">300</span>   <span class="dv">61</span>          <span class="dv">4</span>       <span class="dv">37</span>       <span class="dv">172000</span>             S</span>
<span id="cb371-29"><a href="cap-knn.html#cb371-29" tabindex="-1"></a><span class="dv">4</span>             <span class="dv">0</span>             <span class="dv">0</span>             <span class="dv">0</span>   <span class="dv">47</span>          <span class="dv">3</span>       <span class="dv">21</span>        <span class="dv">38000</span>             N</span>
<span id="cb371-30"><a href="cap-knn.html#cb371-30" tabindex="-1"></a><span class="dv">5</span>             <span class="dv">0</span>           <span class="dv">180</span>             <span class="dv">0</span>   <span class="dv">34</span>          <span class="dv">1</span>       <span class="dv">10</span>        <span class="dv">38000</span>             N</span>
<span id="cb371-31"><a href="cap-knn.html#cb371-31" tabindex="-1"></a><span class="dv">6</span>             <span class="dv">0</span>             <span class="dv">0</span>             <span class="dv">0</span>   <span class="dv">43</span>          <span class="dv">2</span>       <span class="dv">18</span>        <span class="dv">60000</span>             N</span>
<span id="cb371-32"><a href="cap-knn.html#cb371-32" tabindex="-1"></a></span>
<span id="cb371-33"><a href="cap-knn.html#cb371-33" tabindex="-1"></a></span>
<span id="cb371-34"><a href="cap-knn.html#cb371-34" tabindex="-1"></a><span class="co"># Definimos un método de remuestreo</span></span>
<span id="cb371-35"><a href="cap-knn.html#cb371-35" tabindex="-1"></a>cv <span class="ot">&lt;-</span> <span class="fu">trainControl</span>(</span>
<span id="cb371-36"><a href="cap-knn.html#cb371-36" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"repeatedcv"</span>,</span>
<span id="cb371-37"><a href="cap-knn.html#cb371-37" tabindex="-1"></a>  <span class="at">number =</span> <span class="dv">10</span>,</span>
<span id="cb371-38"><a href="cap-knn.html#cb371-38" tabindex="-1"></a>  <span class="at">repeats =</span> <span class="dv">5</span>,</span>
<span id="cb371-39"><a href="cap-knn.html#cb371-39" tabindex="-1"></a>  <span class="at">classProbs =</span> <span class="cn">TRUE</span>,</span>
<span id="cb371-40"><a href="cap-knn.html#cb371-40" tabindex="-1"></a>  <span class="at">preProcOptions =</span> <span class="fu">list</span>(<span class="st">"center"</span>),</span>
<span id="cb371-41"><a href="cap-knn.html#cb371-41" tabindex="-1"></a>  <span class="at">summaryFunction =</span> twoClassSummary</span>
<span id="cb371-42"><a href="cap-knn.html#cb371-42" tabindex="-1"></a>)</span></code></pre></div>
<p>Antes de obtener el modelo definitivo, es necesario la selección del número óptimo de vecinos <span class="math inline">\(k\)</span> entrenando distintos modelos variando dicho hiperparámetro. Para facilitar este trabajo arduo, en el paquete <code>caret</code> de <strong>R</strong> se puede definir una red de posibles valores sobre los que evaluar el modelo KNN y que de forma automática se determine el valor que mejor rendimiento proporcione. A continuación se definen los posibles valores de <span class="math inline">\(k\)</span> que se quieren evaluar.</p>
<div class="sourceCode" id="cb372"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="co"># Definimos la red de posibles valores del hiperparámetro</span></span>
<span><span class="va">hyper_grid</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/expand.grid.html">expand.grid</a></span><span class="op">(</span>k <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html">c</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">10</span>,<span class="fl">15</span>,<span class="fl">20</span>,<span class="fl">30</span>,<span class="fl">50</span>,<span class="fl">75</span>,<span class="fl">100</span><span class="op">)</span><span class="op">)</span></span></code></pre></div>
<p>Una vez se que se ha definido tanto el método de remuestreo como la red de posibles valores del hiperparámetro se puede entrenar el modelo:</p>
<div class="sourceCode" id="cb373"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb373-1"><a href="cap-knn.html#cb373-1" tabindex="-1"></a></span>
<span id="cb373-2"><a href="cap-knn.html#cb373-2" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">101</span>)</span>
<span id="cb373-3"><a href="cap-knn.html#cb373-3" tabindex="-1"></a><span class="co"># Se entrena el modelo ajustando el hiperparámetro óptimo</span></span>
<span id="cb373-4"><a href="cap-knn.html#cb373-4" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb373-5"><a href="cap-knn.html#cb373-5" tabindex="-1"></a>  CLS_PRO_pro13 <span class="sc">~</span> .,</span>
<span id="cb373-6"><a href="cap-knn.html#cb373-6" tabindex="-1"></a>  <span class="at">data =</span> dp_entr_NUM,</span>
<span id="cb373-7"><a href="cap-knn.html#cb373-7" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"knn"</span>,</span>
<span id="cb373-8"><a href="cap-knn.html#cb373-8" tabindex="-1"></a>  <span class="at">trControl =</span> cv,</span>
<span id="cb373-9"><a href="cap-knn.html#cb373-9" tabindex="-1"></a>  <span class="at">tuneGrid =</span> hyper_grid,</span>
<span id="cb373-10"><a href="cap-knn.html#cb373-10" tabindex="-1"></a>  <span class="at">metric =</span> <span class="st">"ROC"</span></span>
<span id="cb373-11"><a href="cap-knn.html#cb373-11" tabindex="-1"></a>)</span>
<span id="cb373-12"><a href="cap-knn.html#cb373-12" tabindex="-1"></a></span>
<span id="cb373-13"><a href="cap-knn.html#cb373-13" tabindex="-1"></a>model</span>
<span id="cb373-14"><a href="cap-knn.html#cb373-14" tabindex="-1"></a></span>
<span id="cb373-15"><a href="cap-knn.html#cb373-15" tabindex="-1"></a>k<span class="sc">-</span>Nearest Neighbors</span>
<span id="cb373-16"><a href="cap-knn.html#cb373-16" tabindex="-1"></a></span>
<span id="cb373-17"><a href="cap-knn.html#cb373-17" tabindex="-1"></a><span class="dv">558</span> samples</span>
<span id="cb373-18"><a href="cap-knn.html#cb373-18" tabindex="-1"></a> <span class="dv">17</span> predictor</span>
<span id="cb373-19"><a href="cap-knn.html#cb373-19" tabindex="-1"></a>  <span class="dv">2</span> classes<span class="sc">:</span> <span class="st">'S'</span>, <span class="st">'N'</span></span>
<span id="cb373-20"><a href="cap-knn.html#cb373-20" tabindex="-1"></a></span>
<span id="cb373-21"><a href="cap-knn.html#cb373-21" tabindex="-1"></a>No pre<span class="sc">-</span>processing</span>
<span id="cb373-22"><a href="cap-knn.html#cb373-22" tabindex="-1"></a>Resampling<span class="sc">:</span> Cross<span class="sc">-</span><span class="fu">Validated</span> (<span class="dv">10</span> fold, repeated <span class="dv">5</span> times)</span>
<span id="cb373-23"><a href="cap-knn.html#cb373-23" tabindex="-1"></a>Summary of sample sizes<span class="sc">:</span> <span class="dv">502</span>, <span class="dv">502</span>, <span class="dv">502</span>, <span class="dv">503</span>, <span class="dv">503</span>, <span class="dv">502</span>, ...</span>
<span id="cb373-24"><a href="cap-knn.html#cb373-24" tabindex="-1"></a>Resampling results across tuning parameters<span class="sc">:</span></span>
<span id="cb373-25"><a href="cap-knn.html#cb373-25" tabindex="-1"></a></span>
<span id="cb373-26"><a href="cap-knn.html#cb373-26" tabindex="-1"></a>  k    ROC        Sens       Spec</span>
<span id="cb373-27"><a href="cap-knn.html#cb373-27" tabindex="-1"></a>    <span class="dv">1</span>  <span class="fl">0.6584524</span>  <span class="fl">0.6466402</span>  <span class="fl">0.6702646</span></span>
<span id="cb373-28"><a href="cap-knn.html#cb373-28" tabindex="-1"></a>    <span class="dv">2</span>  <span class="fl">0.6769109</span>  <span class="fl">0.6179101</span>  <span class="fl">0.6131217</span></span>
<span id="cb373-29"><a href="cap-knn.html#cb373-29" tabindex="-1"></a>    <span class="dv">3</span>  <span class="fl">0.6828893</span>  <span class="fl">0.6216402</span>  <span class="fl">0.6496561</span></span>
<span id="cb373-30"><a href="cap-knn.html#cb373-30" tabindex="-1"></a>    <span class="dv">4</span>  <span class="fl">0.6851087</span>  <span class="fl">0.6404233</span>  <span class="fl">0.6394709</span></span>
<span id="cb373-31"><a href="cap-knn.html#cb373-31" tabindex="-1"></a>    <span class="dv">5</span>  <span class="fl">0.6951129</span>  <span class="fl">0.6540212</span>  <span class="fl">0.6666138</span></span>
<span id="cb373-32"><a href="cap-knn.html#cb373-32" tabindex="-1"></a>    <span class="dv">6</span>  <span class="fl">0.6914664</span>  <span class="fl">0.6216402</span>  <span class="fl">0.6543386</span></span>
<span id="cb373-33"><a href="cap-knn.html#cb373-33" tabindex="-1"></a>    <span class="dv">7</span>  <span class="fl">0.6982592</span>  <span class="fl">0.6252381</span>  <span class="fl">0.6953439</span></span>
<span id="cb373-34"><a href="cap-knn.html#cb373-34" tabindex="-1"></a>    <span class="dv">8</span>  <span class="fl">0.6974556</span>  <span class="fl">0.6281481</span>  <span class="fl">0.6960053</span></span>
<span id="cb373-35"><a href="cap-knn.html#cb373-35" tabindex="-1"></a>    <span class="dv">9</span>  <span class="fl">0.6992229</span>  <span class="fl">0.6159524</span>  <span class="fl">0.7117725</span></span>
<span id="cb373-36"><a href="cap-knn.html#cb373-36" tabindex="-1"></a>   <span class="dv">10</span>  <span class="fl">0.6994133</span>  <span class="fl">0.6037037</span>  <span class="fl">0.7052910</span></span>
<span id="cb373-37"><a href="cap-knn.html#cb373-37" tabindex="-1"></a>   <span class="dv">15</span>  <span class="fl">0.6875879</span>  <span class="fl">0.5749206</span>  <span class="fl">0.7232011</span></span>
<span id="cb373-38"><a href="cap-knn.html#cb373-38" tabindex="-1"></a>   <span class="dv">20</span>  <span class="fl">0.6731477</span>  <span class="fl">0.5722751</span>  <span class="fl">0.7010582</span></span>
<span id="cb373-39"><a href="cap-knn.html#cb373-39" tabindex="-1"></a>   <span class="dv">30</span>  <span class="fl">0.6752986</span>  <span class="fl">0.5529630</span>  <span class="fl">0.7024603</span></span>
<span id="cb373-40"><a href="cap-knn.html#cb373-40" tabindex="-1"></a>   <span class="dv">50</span>  <span class="fl">0.6890259</span>  <span class="fl">0.5163757</span>  <span class="fl">0.7605556</span></span>
<span id="cb373-41"><a href="cap-knn.html#cb373-41" tabindex="-1"></a>   <span class="dv">75</span>  <span class="fl">0.6852886</span>  <span class="fl">0.5092593</span>  <span class="fl">0.7670106</span></span>
<span id="cb373-42"><a href="cap-knn.html#cb373-42" tabindex="-1"></a>  <span class="dv">100</span>  <span class="fl">0.6719378</span>  <span class="fl">0.5049471</span>  <span class="fl">0.7820106</span></span>
<span id="cb373-43"><a href="cap-knn.html#cb373-43" tabindex="-1"></a></span>
<span id="cb373-44"><a href="cap-knn.html#cb373-44" tabindex="-1"></a>ROC was used to select the optimal model using the largest value.</span>
<span id="cb373-45"><a href="cap-knn.html#cb373-45" tabindex="-1"></a>The final value used <span class="cf">for</span> the model was k <span class="ot">=</span> <span class="fl">10.</span></span></code></pre></div>
<p>En la Fig. <a href="cap-knn.html#fig:006-002-102KNNKCHOOSING3">26.2</a> se observa que el número óptimo de vecinos es <span class="math inline">\(k=10\)</span>, donde se alcanza el rendimiento óptimo del modelo.</p>
<div class="sourceCode" id="cb374"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span></span>
<span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="va">model</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_abline.html">geom_vline</a></span><span class="op">(</span>xintercept <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/unlist.html">unlist</a></span><span class="op">(</span><span class="va">model</span><span class="op">$</span><span class="va">bestTune</span><span class="op">)</span>,col<span class="op">=</span><span class="st">"red"</span>,linetype<span class="op">=</span><span class="st">"dashed"</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggtheme.html">theme_light</a></span><span class="op">(</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:006-002-102KNNKCHOOSING3"></span>
<img src="img/knn-tune-k.png" alt="Número óptimo de vecinos (k)." width="60%"><p class="caption">
Figura 26.2: Número óptimo de vecinos (k).
</p>
</div>
<p>El boxplot de los resultados obtenidos durante el proceso de validación cruzada muestra que el AUC del modelo oscila entre un 60% y un 85% aproximadamente.</p>
<div class="sourceCode" id="cb375"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="fu"><a href="https://ggplot2.tidyverse.org/reference/ggplot.html">ggplot</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/pkg/reshape/man/melt-24.html">melt</a></span><span class="op">(</span><span class="va">model</span><span class="op">$</span><span class="va">resample</span><span class="op">[</span>,<span class="op">-</span><span class="fl">4</span><span class="op">]</span><span class="op">)</span>, <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/aes.html">aes</a></span><span class="op">(</span>x <span class="op">=</span> <span class="va">variable</span>, y <span class="op">=</span> <span class="va">value</span>, fill<span class="op">=</span><span class="va">variable</span><span class="op">)</span><span class="op">)</span> <span class="op">+</span></span>
<span>   <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/geom_boxplot.html">geom_boxplot</a></span><span class="op">(</span>show.legend<span class="op">=</span><span class="cn">FALSE</span><span class="op">)</span> <span class="op">+</span></span>
<span>  <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">xlab</a></span><span class="op">(</span><span class="cn">NULL</span><span class="op">)</span> <span class="op">+</span> <span class="fu"><a href="https://ggplot2.tidyverse.org/reference/labs.html">ylab</a></span><span class="op">(</span><span class="cn">NULL</span><span class="op">)</span></span></code></pre></div>
<div class="figure" style="text-align: center">
<span style="display:block;" id="fig:006-002-102KNNRESULTS3"></span>
<img src="img/knn-boxplot.png" alt="Resultados obtenidos durante el proceso de validación cruzada." width="60%"><p class="caption">
Figura 26.3: Resultados obtenidos durante el proceso de validación cruzada.
</p>
</div>
<p>El modelo se resiente en su rendimiento al tener dificultades en predecir correctamente la clase positiva, más concretamente se puede observar en la Fig. <a href="cap-knn.html#fig:006-002-102KNNRESULTS3">26.3</a> que la sensibilidad oscila entre el 40% y el 75%; resultados ligeramente peores que los que obtiene al predecir observaciones de la clase negativa, los cuales oscilan entre el 50% y el 85%.</p>
<div id="resumen-23" class="section level3 unnumbered infobox_resume">
<h3>Resumen<a class="anchor" aria-label="anchor" href="#resumen-23"><i class="fas fa-link"></i></a>
</h3>
<p>En este capítulo se introduce al lector en el algoritmo de aprendizaje supervisado conocido como k-vecinos más próximos, destacando:</p>
<ul>
<li>Las decisiones a tener en cuenta antes de entrenar el modelo de k-vecinos más próximos.</li>
<li>Se exponen algunas de las distancias más utilizadas para el entrenamiento de este modelo.</li>
<li>Se especifican las ventajas y desventajas del número de vecinos a tener en cuenta.</li>
</ul>
</div>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="cap-svm.html"><span class="header-section-number">25</span> Máquinas de vector soporte</a></div>
<div class="next"><a href="cap-naive-bayes.html"><span class="header-section-number">27</span> Naive Bayes</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="Índice capítulo"><h2>Índice capítulo</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#cap-knn"><span class="header-section-number">26</span> Clasificador k-vecinos más próximos</a></li>
<li><a class="nav-link" href="#introducci%C3%B3n-12"><span class="header-section-number">26.1</span> Introducción</a></li>
<li>
<a class="nav-link" href="#decisiones-a-tener-en-cuenta"><span class="header-section-number">26.2</span> Decisiones a tener en cuenta</a><ul class="nav navbar-nav">
<li><a class="nav-link" href="#funci%C3%B3n-de-distancia-a-utilizar"><span class="header-section-number">26.2.1</span> Función de distancia a utilizar</a></li>
<li><a class="nav-link" href="#n%C3%BAmero-de-vecinos-k-seleccionados"><span class="header-section-number">26.2.2</span> Número de vecinos (k) seleccionados</a></li>
</ul>
</li>
<li><a class="nav-link" href="#procedimiento-con-r-la-funci%C3%B3n-knn"><span class="header-section-number">26.3</span> Procedimiento con R: la función knn()</a></li>
<li>
<a class="nav-link" href="#aplicaci%C3%B3n-del-modelo-knn-en-r"><span class="header-section-number">26.4</span> Aplicación del modelo KNN en R</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#resumen-23">Resumen</a></li></ul>
</li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Fundamentos de ciencia de datos con R</strong>" coordinado por <a href="https://blog.uclm.es/gemafaviles/" class="text-light">Gema Fernández-Avilés y José-María Montero</a>. Generado por última vez el día 2023-06-16.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>Este libro ha sido generado con el paquete de R <a class="text-light" href="https://bookdown.org">bookdown</a>.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
