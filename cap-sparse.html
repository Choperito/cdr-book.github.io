<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 18 Modelos sparse y métodos penalizados de regresión | Ciencia de datos con R</title>
  <meta name="description" content="Falta hacer" />
  <meta name="generator" content="bookdown 0.28 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 18 Modelos sparse y métodos penalizados de regresión | Ciencia de datos con R" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Falta hacer" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 18 Modelos sparse y métodos penalizados de regresión | Ciencia de datos con R" />
  
  <meta name="twitter:description" content="Falta hacer" />
  

<meta name="author" content="Gema Fernández-Avilés y José-María Montero" />


<meta name="date" content="2022-12-15" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="cap-mxm.html"/>
<link rel="next" href="cap-series-temp.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<link href="libs/wordcloud2-0.0.1/wordcloud.css" rel="stylesheet" />
<script src="libs/wordcloud2-0.0.1/wordcloud2-all.js"></script>
<script src="libs/wordcloud2-0.0.1/hover.js"></script>
<script src="libs/wordcloud2-binding-0.2.1/wordcloud2.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-33KQ1S5ZCJ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-33KQ1S5ZCJ');
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"> Ciencia de datos con <strong>R</strong></a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html"><i class="fa fa-check"></i>Prefacio</a>
<ul>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html#los-autores"><i class="fa fa-check"></i>Los autores</a></li>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html#por-qué-este-libro"><i class="fa fa-check"></i>¿Por qué este libro?</a></li>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html#características"><i class="fa fa-check"></i>Características</a></li>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html#el-paquete-cdr"><i class="fa fa-check"></i>El paquete <code>CDR</code></a></li>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html#a-quién-va-dirigido"><i class="fa fa-check"></i>¿A quién va dirigido?</a></li>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html#agradecimientos"><i class="fa fa-check"></i>Agradecimientos</a></li>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html#información-del-software"><i class="fa fa-check"></i>Información del software</a></li>
</ul></li>
<li class="part"><span><b>I Introducción</b></span></li>
<li class="chapter" data-level="1" data-path="ciencia-datos.html"><a href="ciencia-datos.html"><i class="fa fa-check"></i><b>1</b> ¿Es la Ciencia de datos una Ciencia?</a>
<ul>
<li class="chapter" data-level="1.1" data-path="ciencia-datos.html"><a href="ciencia-datos.html#ciencia"><i class="fa fa-check"></i><b>1.1</b> ¿Qué se entiende por Ciencia?</a></li>
<li class="chapter" data-level="1.2" data-path="ciencia-datos.html"><a href="ciencia-datos.html#qué-es-la-ciencia-de-datos"><i class="fa fa-check"></i><b>1.2</b> ¿Qué es la Ciencia de Datos?</a></li>
<li class="chapter" data-level="1.3" data-path="ciencia-datos.html"><a href="ciencia-datos.html#lo-científico-de-la-ciencia-de-datos"><i class="fa fa-check"></i><b>1.3</b> Lo científico de la Ciencia de datos</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="metodología.html"><a href="metodología.html"><i class="fa fa-check"></i><b>2</b> Metodología para la Ciencia de datos</a>
<ul>
<li class="chapter" data-level="2.1" data-path="metodología.html"><a href="metodología.html#preliminares"><i class="fa fa-check"></i><b>2.1</b> Preliminares</a></li>
<li class="chapter" data-level="2.2" data-path="metodología.html"><a href="metodología.html#principales-metodologías-en-ciencia-de-datos"><i class="fa fa-check"></i><b>2.2</b> Principales metodologías en Ciencia de datos</a></li>
<li class="chapter" data-level="2.3" data-path="metodología.html"><a href="metodología.html#met-crisp-dm"><i class="fa fa-check"></i><b>2.3</b> CRISP-DM para Ciencia de datos</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ch-110003.html"><a href="ch-110003.html"><i class="fa fa-check"></i><b>3</b> R para ciencia de datos</a>
<ul>
<li class="chapter" data-level="3.1" data-path="ch-110003.html"><a href="ch-110003.html#introducción"><i class="fa fa-check"></i><b>3.1</b> Introducción</a></li>
<li class="chapter" data-level="3.2" data-path="ch-110003.html"><a href="ch-110003.html#id_110003-bases"><i class="fa fa-check"></i><b>3.2</b> La sesión de <strong>R</strong></a></li>
<li class="chapter" data-level="3.3" data-path="ch-110003.html"><a href="ch-110003.html#instalación-de-r"><i class="fa fa-check"></i><b>3.3</b> Instalación de <strong>R</strong></a></li>
<li class="chapter" data-level="3.4" data-path="ch-110003.html"><a href="ch-110003.html#id_110003-proyectos"><i class="fa fa-check"></i><b>3.4</b> Trabajar con proyectos de RStudio</a></li>
<li class="chapter" data-level="3.5" data-path="ch-110003.html"><a href="ch-110003.html#tratamiento-de-datos-con-r"><i class="fa fa-check"></i><b>3.5</b> Tratamiento de datos con <strong>R</strong></a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="ch-110003.html"><a href="ch-110003.html#id_110003-estructuras"><i class="fa fa-check"></i><b>3.5.1</b> Estructuras y tipos de datos</a></li>
<li class="chapter" data-level="3.5.2" data-path="ch-110003.html"><a href="ch-110003.html#id_110003-importacion"><i class="fa fa-check"></i><b>3.5.2</b> Importación de datos</a></li>
<li class="chapter" data-level="3.5.3" data-path="ch-110003.html"><a href="ch-110003.html#exportación-y-archivos-de-datos-de-r"><i class="fa fa-check"></i><b>3.5.3</b> Exportación y archivos de datos de R</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="ch-110003.html"><a href="ch-110003.html#id_110003-tidyverse"><i class="fa fa-check"></i><b>3.6</b> Organización de datos con el <em>tidyverse</em></a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="ch-110003.html"><a href="ch-110003.html#el-tidyverse-y-su-flujo-de-trabajo"><i class="fa fa-check"></i><b>3.6.1</b> El <em>tidyverse</em> y su flujo de trabajo</a></li>
<li class="chapter" data-level="3.6.2" data-path="ch-110003.html"><a href="ch-110003.html#transformación-de-datos-con-dplyr"><i class="fa fa-check"></i><b>3.6.2</b> Transformación de datos con <code>dplyr</code></a></li>
<li class="chapter" data-level="3.6.3" data-path="ch-110003.html"><a href="ch-110003.html#combinación-de-datos"><i class="fa fa-check"></i><b>3.6.3</b> Combinación de datos</a></li>
<li class="chapter" data-level="3.6.4" data-path="ch-110003.html"><a href="ch-110003.html#reorganización-de-datos"><i class="fa fa-check"></i><b>3.6.4</b> Reorganización de datos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="cap-etica.html"><a href="cap-etica.html"><i class="fa fa-check"></i><b>4</b> La ciencia de datos y la ética</a>
<ul>
<li class="chapter" data-level="4.1" data-path="cap-etica.html"><a href="cap-etica.html#por-que-la-ética-en-la-ciencia-de-datos"><i class="fa fa-check"></i><b>4.1</b> ¿Por que la ética en la ciencia de datos?</a></li>
<li class="chapter" data-level="4.2" data-path="cap-etica.html"><a href="cap-etica.html#los-principios-éticos"><i class="fa fa-check"></i><b>4.2</b> Los principios éticos</a></li>
<li class="chapter" data-level="4.3" data-path="cap-etica.html"><a href="cap-etica.html#la-importancia-de-los-sesgos"><i class="fa fa-check"></i><b>4.3</b> La importancia de los sesgos</a></li>
<li class="chapter" data-level="4.4" data-path="cap-etica.html"><a href="cap-etica.html#es-necesaria-la-explicabilidad"><i class="fa fa-check"></i><b>4.4</b> ¿Es necesaria la explicabilidad?</a></li>
<li class="chapter" data-level="4.5" data-path="cap-etica.html"><a href="cap-etica.html#recursos-en-r-parar-trabajar-en-sesgos-y-explicabilidad"><i class="fa fa-check"></i><b>4.5</b> Recursos en R parar trabajar en sesgos y explicabilidad</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="datos-sql.html"><a href="datos-sql.html"><i class="fa fa-check"></i><b>5</b> Gestión y operación de datos con bases de datos relacionales</a>
<ul>
<li class="chapter" data-level="5.1" data-path="datos-sql.html"><a href="datos-sql.html#introducción-1"><i class="fa fa-check"></i><b>5.1</b> Introducción</a></li>
<li class="chapter" data-level="5.2" data-path="datos-sql.html"><a href="datos-sql.html#concepto-de-base-de-datos"><i class="fa fa-check"></i><b>5.2</b> Concepto de Base de datos</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="datos-sql.html"><a href="datos-sql.html#gestión-de-los-datos-en-una-base-o-repositorio-de-datos"><i class="fa fa-check"></i><b>5.2.1</b> Gestión de los datos en una base o repositorio de datos</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="datos-sql.html"><a href="datos-sql.html#el-lenguaje-estructurado-de-consulta-sql"><i class="fa fa-check"></i><b>5.3</b> El Lenguaje Estructurado de Consulta (SQL)</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="datos-sql.html"><a href="datos-sql.html#sql-como-lenguaje-de-definición-de-datos-ldd"><i class="fa fa-check"></i><b>5.3.1</b> SQL como Lenguaje de Definición de Datos (LDD)</a></li>
<li class="chapter" data-level="5.3.2" data-path="datos-sql.html"><a href="datos-sql.html#sql-como-lenguaje-de-manipulación-de-datos-lmd"><i class="fa fa-check"></i><b>5.3.2</b> SQL como Lenguaje de Manipulación de Datos (LMD)</a></li>
<li class="chapter" data-level="5.3.3" data-path="datos-sql.html"><a href="datos-sql.html#sql-como-lenguaje-de-administración-de-datos-lad"><i class="fa fa-check"></i><b>5.3.3</b> SQL como Lenguaje de Administración de Datos (LAD)</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="datos-sql.html"><a href="datos-sql.html#usando-bases-de-datos-desde-r"><i class="fa fa-check"></i><b>5.4</b> Usando bases de datos desde R</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="datos-sql.html"><a href="datos-sql.html#conexión-a-una-base-de-datos"><i class="fa fa-check"></i><b>5.4.1</b> Conexión a una base de datos</a></li>
<li class="chapter" data-level="5.4.2" data-path="datos-sql.html"><a href="datos-sql.html#operaciones-de-lectura-selección-read-de-datos"><i class="fa fa-check"></i><b>5.4.2</b> Operaciones de lectura / selección (<em>read</em>) de datos</a></li>
<li class="chapter" data-level="5.4.3" data-path="datos-sql.html"><a href="datos-sql.html#operaciones-de-inserción-create-y-actualización-update-de-datos"><i class="fa fa-check"></i><b>5.4.3</b> Operaciones de inserción (<em>create</em>) y actualización (<em>update</em>) de datos</a></li>
<li class="chapter" data-level="5.4.4" data-path="datos-sql.html"><a href="datos-sql.html#operaciones-de-borrado-de-datos-delete"><i class="fa fa-check"></i><b>5.4.4</b> Operaciones de Borrado de datos (<em>delete</em>)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="datos-no-sql.html"><a href="datos-no-sql.html"><i class="fa fa-check"></i><b>6</b> Gestión y operación de datos masivos (BigData) con bases de datos NoSQL</a>
<ul>
<li class="chapter" data-level="6.1" data-path="datos-no-sql.html"><a href="datos-no-sql.html#introducción-al-big-data"><i class="fa fa-check"></i><b>6.1</b> Introducción al Big Data</a></li>
<li class="chapter" data-level="6.2" data-path="datos-no-sql.html"><a href="datos-no-sql.html#VsBigData"><i class="fa fa-check"></i><b>6.2</b> Las V’s del Big Data</a></li>
<li class="chapter" data-level="6.3" data-path="datos-no-sql.html"><a href="datos-no-sql.html#fuentes-de-datos-en-entornos-big-data"><i class="fa fa-check"></i><b>6.3</b> Fuentes de Datos en entornos Big Data</a></li>
<li class="chapter" data-level="6.4" data-path="datos-no-sql.html"><a href="datos-no-sql.html#bases-de-datos-relacionales-vs.-nosql"><i class="fa fa-check"></i><b>6.4</b> Bases de datos Relacionales vs. NoSQL</a></li>
<li class="chapter" data-level="6.5" data-path="datos-no-sql.html"><a href="datos-no-sql.html#bases-de-datos-nosql"><i class="fa fa-check"></i><b>6.5</b> Bases de datos NoSQL</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="datos-no-sql.html"><a href="datos-no-sql.html#definición-de-bases-de-datos-nosql"><i class="fa fa-check"></i><b>6.5.1</b> Definición de bases de datos NoSQL</a></li>
<li class="chapter" data-level="6.5.2" data-path="datos-no-sql.html"><a href="datos-no-sql.html#necesidades-no-cubiertas-por-las-bases-de-datos-relacionales"><i class="fa fa-check"></i><b>6.5.2</b> Necesidades no cubiertas por las bases de datos relacionales</a></li>
<li class="chapter" data-level="6.5.3" data-path="datos-no-sql.html"><a href="datos-no-sql.html#tipos-de-almacenamiento-en-bases-de-datos-nosql"><i class="fa fa-check"></i><b>6.5.3</b> Tipos de almacenamiento en bases de datos NoSQL</a></li>
<li class="chapter" data-level="6.5.4" data-path="datos-no-sql.html"><a href="datos-no-sql.html#limitaciones-de-las-bases-de-datos-nosql"><i class="fa fa-check"></i><b>6.5.4</b> Limitaciones de las bases de datos NoSQL</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="datos-no-sql.html"><a href="datos-no-sql.html#ejemplo-de-integración-de-una-base-de-datos-nosql-y-análisis-de-datos-en-r"><i class="fa fa-check"></i><b>6.6</b> Ejemplo de integración de una base de datos NoSQL y análisis de datos en R</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="datos-no-sql.html"><a href="datos-no-sql.html#introMongo"><i class="fa fa-check"></i><b>6.6.1</b> Introducción a MongoDB</a></li>
<li class="chapter" data-level="6.6.2" data-path="datos-no-sql.html"><a href="datos-no-sql.html#paquetesCaso"><i class="fa fa-check"></i><b>6.6.2</b> Plataforma tecnológica para el caso práctico</a></li>
<li class="chapter" data-level="6.6.3" data-path="datos-no-sql.html"><a href="datos-no-sql.html#conexionMongo"><i class="fa fa-check"></i><b>6.6.3</b> Conexión y acceso a MongoDB desde R</a></li>
<li class="chapter" data-level="6.6.4" data-path="datos-no-sql.html"><a href="datos-no-sql.html#consultaViajes"><i class="fa fa-check"></i><b>6.6.4</b> Obtención de datos en R desde MongoDB</a></li>
<li class="chapter" data-level="6.6.5" data-path="datos-no-sql.html"><a href="datos-no-sql.html#analisisViajes"><i class="fa fa-check"></i><b>6.6.5</b> Analizando datos de MongoDB en R</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Manipulación de datos con R. Técnicas y herramientas</b></span></li>
<li class="chapter" data-level="7" data-path="id_120006-aed.html"><a href="id_120006-aed.html"><i class="fa fa-check"></i><b>7</b> Análisis exploratorio de datos</a>
<ul>
<li class="chapter" data-level="7.1" data-path="id_120006-aed.html"><a href="id_120006-aed.html#introducción-2"><i class="fa fa-check"></i><b>7.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="id_120006-aed.html"><a href="id_120006-aed.html#el-cuarterto-de-anscombe"><i class="fa fa-check"></i><b>7.1.1</b> El cuarterto de Anscombe</a></li>
<li class="chapter" data-level="7.1.2" data-path="id_120006-aed.html"><a href="id_120006-aed.html#conceptos-generales"><i class="fa fa-check"></i><b>7.1.2</b> Conceptos generales</a></li>
<li class="chapter" data-level="7.1.3" data-path="id_120006-aed.html"><a href="id_120006-aed.html#componentes-de-un-gráfico-y-su-representación-en-r"><i class="fa fa-check"></i><b>7.1.3</b> Componentes de un gráfico y su representación en R</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="id_120006-aed.html"><a href="id_120006-aed.html#id_120006-aeduni"><i class="fa fa-check"></i><b>7.2</b> Análisis exploratorio de una característica</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="id_120006-aed.html"><a href="id_120006-aed.html#variables-cualitativas"><i class="fa fa-check"></i><b>7.2.1</b> Variables cualitativas</a></li>
<li class="chapter" data-level="7.2.2" data-path="id_120006-aed.html"><a href="id_120006-aed.html#variables-cuantitativas"><i class="fa fa-check"></i><b>7.2.2</b> Variables cuantitativas</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="id_120006-aed.html"><a href="id_120006-aed.html#id_120006-aedmulti"><i class="fa fa-check"></i><b>7.3</b> Análisis exploratorio de varias características</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="id_120006-aed.html"><a href="id_120006-aed.html#variables-cualitativas-1"><i class="fa fa-check"></i><b>7.3.1</b> Variables cualitativas</a></li>
<li class="chapter" data-level="7.3.2" data-path="id_120006-aed.html"><a href="id_120006-aed.html#variables-cuantitativas-1"><i class="fa fa-check"></i><b>7.3.2</b> Variables cuantitativas</a></li>
<li class="chapter" data-level="7.3.3" data-path="id_120006-aed.html"><a href="id_120006-aed.html#variables-cualitativas-y-cuantitativas"><i class="fa fa-check"></i><b>7.3.3</b> Variables cualitativas y cuantitativas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="DGDQM.html"><a href="DGDQM.html"><i class="fa fa-check"></i><b>8</b> Gobierno y gestión de calidad de Datos</a>
<ul>
<li class="chapter" data-level="8.1" data-path="DGDQM.html"><a href="DGDQM.html#introducción-3"><i class="fa fa-check"></i><b>8.1</b> Introducción</a></li>
<li class="chapter" data-level="8.2" data-path="DGDQM.html"><a href="DGDQM.html#concepto-de-gobierno-de-datos"><i class="fa fa-check"></i><b>8.2</b> Concepto de Gobierno de datos</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="DGDQM.html"><a href="DGDQM.html#beneficiosDG"><i class="fa fa-check"></i><b>8.2.1</b> Beneficios del Gobierno de Datos</a></li>
<li class="chapter" data-level="8.2.2" data-path="DGDQM.html"><a href="DGDQM.html#artefactosDG"><i class="fa fa-check"></i><b>8.2.2</b> Artefactos de un sistema de Gobierno de Datos</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="DGDQM.html"><a href="DGDQM.html#marcos-y-metodologías-existentes-de-gobierno-de-datos"><i class="fa fa-check"></i><b>8.3</b> Marcos y metodologías existentes de Gobierno de Datos</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="DGDQM.html"><a href="DGDQM.html#modelo-alarcos-de-mejora-de-datos-mamd"><i class="fa fa-check"></i><b>8.3.1</b> Modelo Alarcos de Mejora de Datos (MAMD)</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="DGDQM.html"><a href="DGDQM.html#gestión-de-calidad-de-datos"><i class="fa fa-check"></i><b>8.4</b> Gestión de calidad de datos</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="DGDQM.html"><a href="DGDQM.html#medición-de-calidad-de-datos-vs-perfilado-de-datos"><i class="fa fa-check"></i><b>8.4.1</b> Medición de calidad de datos vs perfilado de datos</a></li>
<li class="chapter" data-level="8.4.2" data-path="DGDQM.html"><a href="DGDQM.html#mejora-de-datos"><i class="fa fa-check"></i><b>8.4.2</b> Mejora de datos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="id_130009.html"><a href="id_130009.html"><i class="fa fa-check"></i><b>9</b> Integración y limpieza de datos</a>
<ul>
<li class="chapter" data-level="9.1" data-path="id_130009.html"><a href="id_130009.html#introducción-4"><i class="fa fa-check"></i><b>9.1</b> Introducción</a></li>
<li class="chapter" data-level="9.2" data-path="id_130009.html"><a href="id_130009.html#problemas-de-calidad-de-datos"><i class="fa fa-check"></i><b>9.2</b> Problemas de calidad de datos</a></li>
<li class="chapter" data-level="9.3" data-path="id_130009.html"><a href="id_130009.html#niveles-inadecuados-de-completitud-valores-missing"><i class="fa fa-check"></i><b>9.3</b> Niveles inadecuados de completitud: Valores <em>missing</em></a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="id_130009.html"><a href="id_130009.html#visualización"><i class="fa fa-check"></i><b>9.3.1</b> Visualización</a></li>
<li class="chapter" data-level="9.3.2" data-path="id_130009.html"><a href="id_130009.html#imputacion"><i class="fa fa-check"></i><b>9.3.2</b> Técnicas de Imputación</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="id_130009.html"><a href="id_130009.html#mejorando-la-exactitud-y-la-precisión-eliminación-del-ruido-estadístico"><i class="fa fa-check"></i><b>9.4</b> Mejorando la exactitud y la precisión: eliminación del ruido estadístico</a></li>
<li class="chapter" data-level="9.5" data-path="id_130009.html"><a href="id_130009.html#integración-de-datos"><i class="fa fa-check"></i><b>9.5</b> Integración de datos </a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="id_130010.html"><a href="id_130010.html"><i class="fa fa-check"></i><b>10</b> Feature Selection and Engineering</a>
<ul>
<li class="chapter" data-level="10.1" data-path="id_130010.html"><a href="id_130010.html#introducción-5"><i class="fa fa-check"></i><b>10.1</b> Introducción</a></li>
<li class="chapter" data-level="10.2" data-path="id_130010.html"><a href="id_130010.html#feature-selection-selección-de-variables"><i class="fa fa-check"></i><b>10.2</b> <em>Feature Selection</em> (Selección de variables)</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="id_130010.html"><a href="id_130010.html#métodos-de-selección-tipo-filtro"><i class="fa fa-check"></i><b>10.2.1</b> Métodos de selección tipo Filtro</a></li>
<li class="chapter" data-level="10.2.2" data-path="id_130010.html"><a href="id_130010.html#métodos-de-selección-de-variables-tipo-wrapper"><i class="fa fa-check"></i><b>10.2.2</b> Métodos de selección de variables tipo <em>wrapper</em></a></li>
<li class="chapter" data-level="10.2.3" data-path="id_130010.html"><a href="id_130010.html#métodos-de-selección-tipo-embedded"><i class="fa fa-check"></i><b>10.2.3</b> Métodos de selección tipo Embedded </a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="id_130010.html"><a href="id_130010.html#transformaciones-de-escala-y-de-la-distribución-de-la-variable-objetivo"><i class="fa fa-check"></i><b>10.3</b> Transformaciones de escala y de la distribución de la variable objetivo</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="id_130010.html"><a href="id_130010.html#id_31"><i class="fa fa-check"></i><b>10.3.1</b> Transformaciones de la variable objetivo</a></li>
<li class="chapter" data-level="10.3.2" data-path="id_130010.html"><a href="id_130010.html#escalado-de-datos"><i class="fa fa-check"></i><b>10.3.2</b> Escalado de datos</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="id_130010.html"><a href="id_130010.html#feature-engineering"><i class="fa fa-check"></i><b>10.4</b> <em>Feature engineering</em></a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="id_130010.html"><a href="id_130010.html#binning"><i class="fa fa-check"></i><b>10.4.1</b> <em>Binning</em> </a></li>
<li class="chapter" data-level="10.4.2" data-path="id_130010.html"><a href="id_130010.html#codificación"><i class="fa fa-check"></i><b>10.4.2</b> Codificación </a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="id_130010.html"><a href="id_130010.html#reducción-de-dimensionalidad"><i class="fa fa-check"></i><b>10.5</b> Reducción de dimensionalidad</a></li>
<li class="chapter" data-level="10.6" data-path="id_130010.html"><a href="id_130010.html#otras-transformaciones"><i class="fa fa-check"></i><b>10.6</b> Otras transformaciones</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="id_130010.html"><a href="id_130010.html#particionado-de-datos"><i class="fa fa-check"></i><b>10.6.1</b> Particionado de datos </a></li>
<li class="chapter" data-level="10.6.2" data-path="id_130010.html"><a href="id_130010.html#técnicas-para-manejar-datos-no-balanceados"><i class="fa fa-check"></i><b>10.6.2</b> Técnicas para manejar datos no balanceados </a></li>
<li class="chapter" data-level="10.6.3" data-path="id_130010.html"><a href="id_130010.html#métodos-de-remuestreo"><i class="fa fa-check"></i><b>10.6.3</b> Métodos de remuestreo </a></li>
<li class="chapter" data-level="10.6.4" data-path="id_130010.html"><a href="id_130010.html#ajuste-de-hiperparámetros"><i class="fa fa-check"></i><b>10.6.4</b> Ajuste de hiperparámetros</a></li>
<li class="chapter" data-level="10.6.5" data-path="id_130010.html"><a href="id_130010.html#evaluación-de-modelos"><i class="fa fa-check"></i><b>10.6.5</b> Evaluación de modelos</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Modelización estadística</b></span></li>
<li class="chapter" data-level="11" data-path="Funda-probab.html"><a href="Funda-probab.html"><i class="fa fa-check"></i><b>11</b> Fundamentos de probabilidad</a>
<ul>
<li class="chapter" data-level="11.1" data-path="Funda-probab.html"><a href="Funda-probab.html#introducción-a-la-probabilidad"><i class="fa fa-check"></i><b>11.1</b> Introducción a la probabilidad</a></li>
<li class="chapter" data-level="11.2" data-path="Funda-probab.html"><a href="Funda-probab.html#probabilidad-elementos-básicos-definición-y-teoremas"><i class="fa fa-check"></i><b>11.2</b> Probabilidad: elementos básicos, definición y teoremas</a></li>
<li class="chapter" data-level="11.3" data-path="Funda-probab.html"><a href="Funda-probab.html#variable-aleatoria-y-su-distribución-tipos-de-variables-aleatorias"><i class="fa fa-check"></i><b>11.3</b> Variable aleatoria y su distribución: tipos de variables aleatorias</a></li>
<li class="chapter" data-level="11.4" data-path="Funda-probab.html"><a href="Funda-probab.html#modelos-de-distribución-de-probabilidad"><i class="fa fa-check"></i><b>11.4</b> Modelos de distribución de probabilidad</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="Funda-probab.html"><a href="Funda-probab.html#modelos-discretos"><i class="fa fa-check"></i><b>11.4.1</b> Modelos discretos</a></li>
<li class="chapter" data-level="11.4.2" data-path="Funda-probab.html"><a href="Funda-probab.html#modelos-continuos"><i class="fa fa-check"></i><b>11.4.2</b> Modelos continuos</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="Funda-probab.html"><a href="Funda-probab.html#tcl"><i class="fa fa-check"></i><b>11.5</b> Teorema central del límite (TCL)</a></li>
<li class="chapter" data-level="11.6" data-path="Funda-probab.html"><a href="Funda-probab.html#ejemplo-de-distribuciones-usando-r"><i class="fa fa-check"></i><b>11.6</b> Ejemplo de distribuciones usando <strong>R</strong></a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="Fundainfer.html"><a href="Fundainfer.html"><i class="fa fa-check"></i><b>12</b> Fundamentos de Inferencia Estadística</a>
<ul>
<li class="chapter" data-level="12.1" data-path="Fundainfer.html"><a href="Fundainfer.html#introinfer"><i class="fa fa-check"></i><b>12.1</b> Introducción a la Inferencia Estadística</a></li>
<li class="chapter" data-level="12.2" data-path="Fundainfer.html"><a href="Fundainfer.html#mas"><i class="fa fa-check"></i><b>12.2</b> Muestreo aleatorio simple</a></li>
<li class="chapter" data-level="12.3" data-path="Fundainfer.html"><a href="Fundainfer.html#estimpuntual"><i class="fa fa-check"></i><b>12.3</b> Estimación puntual</a></li>
<li class="chapter" data-level="12.4" data-path="Fundainfer.html"><a href="Fundainfer.html#estimintervalos"><i class="fa fa-check"></i><b>12.4</b> Estimación por intervalos</a></li>
<li class="chapter" data-level="12.5" data-path="Fundainfer.html"><a href="Fundainfer.html#contrhip"><i class="fa fa-check"></i><b>12.5</b> Contrastes de hipótesis</a></li>
<li class="chapter" data-level="12.6" data-path="Fundainfer.html"><a href="Fundainfer.html#pobnormales"><i class="fa fa-check"></i><b>12.6</b> Inferencia estadística paramétrica sobre poblaciones normales</a></li>
<li class="chapter" data-level="12.7" data-path="Fundainfer.html"><a href="Fundainfer.html#ejemplopobnorm"><i class="fa fa-check"></i><b>12.7</b> Inferencia sobre poblaciones normales con <strong>R</strong></a></li>
<li class="chapter" data-level="12.8" data-path="Fundainfer.html"><a href="Fundainfer.html#contrnormalidad"><i class="fa fa-check"></i><b>12.8</b> Inferencia estadística no paramétrica: contrastes de normalidad</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="muestreo.html"><a href="muestreo.html"><i class="fa fa-check"></i><b>13</b> Métodos de muestreo y remuestreo</a>
<ul>
<li class="chapter" data-level="13.1" data-path="muestreo.html"><a href="muestreo.html#introducción-al-muestreo"><i class="fa fa-check"></i><b>13.1</b> Introducción al muestreo</a></li>
<li class="chapter" data-level="13.2" data-path="muestreo.html"><a href="muestreo.html#muestreo-aleatorio-simple-1"><i class="fa fa-check"></i><b>13.2</b> Muestreo aleatorio simple</a></li>
<li class="chapter" data-level="13.3" data-path="muestreo.html"><a href="muestreo.html#muestestra"><i class="fa fa-check"></i><b>13.3</b> Muestreo estratificado</a></li>
<li class="chapter" data-level="13.4" data-path="muestreo.html"><a href="muestreo.html#otros-tipos-de-muestreo-probabilístico"><i class="fa fa-check"></i><b>13.4</b> Otros tipos de muestreo probabilístico</a></li>
<li class="chapter" data-level="13.5" data-path="muestreo.html"><a href="muestreo.html#técnicas-de-remuestreo-bootstrap."><i class="fa fa-check"></i><b>13.5</b> Técnicas de remuestreo: Bootstrap.</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="cap-lm.html"><a href="cap-lm.html"><i class="fa fa-check"></i><b>14</b> Modelización lineal</a>
<ul>
<li class="chapter" data-level="14.1" data-path="cap-lm.html"><a href="cap-lm.html#modelización"><i class="fa fa-check"></i><b>14.1</b> Modelización</a></li>
<li class="chapter" data-level="14.2" data-path="cap-lm.html"><a href="cap-lm.html#procedimiento-de-modelización"><i class="fa fa-check"></i><b>14.2</b> Procedimiento de modelización</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="cap-lm.html"><a href="cap-lm.html#Bondad"><i class="fa fa-check"></i><b>14.2.1</b> Estimación del modelo</a></li>
<li class="chapter" data-level="14.2.2" data-path="cap-lm.html"><a href="cap-lm.html#validación-del-modelo"><i class="fa fa-check"></i><b>14.2.2</b> Validación del modelo</a></li>
<li class="chapter" data-level="14.2.3" data-path="cap-lm.html"><a href="cap-lm.html#interpretación-de-los-coeficientes"><i class="fa fa-check"></i><b>14.2.3</b> Interpretación de los coeficientes</a></li>
<li class="chapter" data-level="14.2.4" data-path="cap-lm.html"><a href="cap-lm.html#predicción"><i class="fa fa-check"></i><b>14.2.4</b> Predicción</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="cap-lm.html"><a href="cap-lm.html#procedimiento-con-r-la-función-lm"><i class="fa fa-check"></i><b>14.3</b> Procedimiento con R: la función <code>lm</code></a></li>
<li class="chapter" data-level="14.4" data-path="cap-lm.html"><a href="cap-lm.html#Casos"><i class="fa fa-check"></i><b>14.4</b> Casos prácticos</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="cap-lm.html"><a href="cap-lm.html#estimación-de-los-coeficientes"><i class="fa fa-check"></i><b>14.4.1</b> Estimación de los coeficientes</a></li>
<li class="chapter" data-level="14.4.2" data-path="cap-lm.html"><a href="cap-lm.html#validación"><i class="fa fa-check"></i><b>14.4.2</b> Validación</a></li>
<li class="chapter" data-level="14.4.3" data-path="cap-lm.html"><a href="cap-lm.html#interpretación-de-los-coeficientes-1"><i class="fa fa-check"></i><b>14.4.3</b> Interpretación de los coeficientes</a></li>
<li class="chapter" data-level="14.4.4" data-path="cap-lm.html"><a href="cap-lm.html#predicción-1"><i class="fa fa-check"></i><b>14.4.4</b> Predicción</a></li>
<li class="chapter" data-level="14.4.5" data-path="cap-lm.html"><a href="cap-lm.html#nuevo-ajuste-con-logozone"><i class="fa fa-check"></i><b>14.4.5</b> Nuevo ajuste con <code>log(Ozone)</code></a></li>
<li class="chapter" data-level="14.4.6" data-path="cap-lm.html"><a href="cap-lm.html#coeficientes-de-variables-categóricas"><i class="fa fa-check"></i><b>14.4.6</b> Coeficientes de variables categóricas</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="cap-lm.html"><a href="cap-lm.html#comentarios-finales"><i class="fa fa-check"></i><b>14.5</b> Comentarios finales</a>
<ul>
<li class="chapter" data-level="" data-path="cap-lm.html"><a href="cap-lm.html#resumen"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="cap-glm.html"><a href="cap-glm.html"><i class="fa fa-check"></i><b>15</b> Modelos lineales generalizados</a>
<ul>
<li class="chapter" data-level="15.1" data-path="cap-glm.html"><a href="cap-glm.html#motivación"><i class="fa fa-check"></i><b>15.1</b> Motivación</a></li>
<li class="chapter" data-level="15.2" data-path="cap-glm.html"><a href="cap-glm.html#modelo-y-sus-componentes"><i class="fa fa-check"></i><b>15.2</b> Modelo y sus componentes</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="cap-glm.html"><a href="cap-glm.html#función-enlace"><i class="fa fa-check"></i><b>15.2.1</b> Función enlace </a></li>
<li class="chapter" data-level="15.2.2" data-path="cap-glm.html"><a href="cap-glm.html#glms-en-r"><i class="fa fa-check"></i><b>15.2.2</b> GLMs en <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="cap-glm.html"><a href="cap-glm.html#regresión-logística"><i class="fa fa-check"></i><b>15.3</b> Regresión logística</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="cap-glm.html"><a href="cap-glm.html#procedimiento-de-ajuste"><i class="fa fa-check"></i><b>15.3.1</b> Procedimiento de ajuste</a></li>
<li class="chapter" data-level="15.3.2" data-path="cap-glm.html"><a href="cap-glm.html#adecuación-del-modelo"><i class="fa fa-check"></i><b>15.3.2</b> Adecuación del modelo</a></li>
<li class="chapter" data-level="15.3.3" data-path="cap-glm.html"><a href="cap-glm.html#SECCinterp"><i class="fa fa-check"></i><b>15.3.3</b> Interpretación de resultados</a></li>
<li class="chapter" data-level="15.3.4" data-path="cap-glm.html"><a href="cap-glm.html#predicción.-curva-roc-y-auc"><i class="fa fa-check"></i><b>15.3.4</b> Predicción. Curva ROC y AUC</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="cap-glm.html"><a href="cap-glm.html#regresión-de-poisson"><i class="fa fa-check"></i><b>15.4</b> Regresión de Poisson</a></li>
<li class="chapter" data-level="15.5" data-path="cap-glm.html"><a href="cap-glm.html#casos-prácticos"><i class="fa fa-check"></i><b>15.5</b> Casos prácticos</a>
<ul>
<li class="chapter" data-level="15.5.1" data-path="cap-glm.html"><a href="cap-glm.html#ejemplos-de-regresión-logística"><i class="fa fa-check"></i><b>15.5.1</b> Ejemplos de regresión logística</a></li>
<li class="chapter" data-level="15.5.2" data-path="cap-glm.html"><a href="cap-glm.html#ejemplo-de-regresión-de-poisson"><i class="fa fa-check"></i><b>15.5.2</b> Ejemplo de regresión de Poisson</a></li>
<li class="chapter" data-level="" data-path="cap-glm.html"><a href="cap-glm.html#resumen-1"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="cap-gam.html"><a href="cap-gam.html"><i class="fa fa-check"></i><b>16</b> Modelos aditivos generalizados</a>
<ul>
<li class="chapter" data-level="16.1" data-path="cap-gam.html"><a href="cap-gam.html#introducción-6"><i class="fa fa-check"></i><b>16.1</b> Introducción</a></li>
<li class="chapter" data-level="16.2" data-path="cap-gam.html"><a href="cap-gam.html#splines-con-penalizaciones"><i class="fa fa-check"></i><b>16.2</b> Splines con penalizaciones</a></li>
<li class="chapter" data-level="16.3" data-path="cap-gam.html"><a href="cap-gam.html#aspectos-metodológicos"><i class="fa fa-check"></i><b>16.3</b> Aspectos metodológicos</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="cap-gam.html"><a href="cap-gam.html#estimación-de-los-paraámetros-del-modelo"><i class="fa fa-check"></i><b>16.3.1</b> Estimación de los paraámetros del modelo</a></li>
<li class="chapter" data-level="16.3.2" data-path="cap-gam.html"><a href="cap-gam.html#inferencia-sobre-las-funciones-suaves"><i class="fa fa-check"></i><b>16.3.2</b> Inferencia sobre las funciones suaves</a></li>
<li class="chapter" data-level="16.3.3" data-path="cap-gam.html"><a href="cap-gam.html#suavizado-mutidimensional-y-para-datos-no-gaussianos"><i class="fa fa-check"></i><b>16.3.3</b> Suavizado mutidimensional y para datos no Gaussianos</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="cap-gam.html"><a href="cap-gam.html#la-función-gam-del-paquete-mgcv"><i class="fa fa-check"></i><b>16.4</b> La función <code>gam</code> del paquete <code>mgcv</code></a></li>
<li class="chapter" data-level="16.5" data-path="cap-gam.html"><a href="cap-gam.html#casos-prácticos-1"><i class="fa fa-check"></i><b>16.5</b> Casos prácticos</a>
<ul>
<li class="chapter" data-level="16.5.1" data-path="cap-gam.html"><a href="cap-gam.html#modelo-unidimensional-con-fossil"><i class="fa fa-check"></i><b>16.5.1</b> Modelo unidimensional con <code>fossil</code></a></li>
<li class="chapter" data-level="16.5.2" data-path="cap-gam.html"><a href="cap-gam.html#modelo-aditivo-con-airquality"><i class="fa fa-check"></i><b>16.5.2</b> Modelo aditivo con <code>airquality</code></a></li>
<li class="chapter" data-level="16.5.3" data-path="cap-gam.html"><a href="cap-gam.html#modelo-semiparamétrico-con-onions"><i class="fa fa-check"></i><b>16.5.3</b> Modelo semiparamétrico con <code>onions</code></a></li>
<li class="chapter" data-level="16.5.4" data-path="cap-gam.html"><a href="cap-gam.html#modelo-aditivo-generalizado-y-multidimensional-con-smacker"><i class="fa fa-check"></i><b>16.5.4</b> Modelo aditivo generalizado y multidimensional, con <code>smacker</code></a></li>
<li class="chapter" data-level="" data-path="cap-gam.html"><a href="cap-gam.html#resumen-2"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="cap-mxm.html"><a href="cap-mxm.html"><i class="fa fa-check"></i><b>17</b> Modelos mixtos</a>
<ul>
<li class="chapter" data-level="17.1" data-path="cap-mxm.html"><a href="cap-mxm.html#conceptos-básicos"><i class="fa fa-check"></i><b>17.1</b> Conceptos básicos</a>
<ul>
<li class="chapter" data-level="17.1.1" data-path="cap-mxm.html"><a href="cap-mxm.html#tipo-y-estructura-de-los-datos"><i class="fa fa-check"></i><b>17.1.1</b> Tipo y estructura de los datos</a></li>
<li class="chapter" data-level="17.1.2" data-path="cap-mxm.html"><a href="cap-mxm.html#efectos-fijos-o-aleatorios"><i class="fa fa-check"></i><b>17.1.2</b> ¿Efectos fijos o aleatorios?</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="cap-mxm.html"><a href="cap-mxm.html#formulación-del-modelo-con-efectos-aleatorios-o-modelos-mixtos"><i class="fa fa-check"></i><b>17.2</b> Formulación del modelo con efectos aleatorios o modelos mixtos</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="cap-mxm.html"><a href="cap-mxm.html#formulación-general"><i class="fa fa-check"></i><b>17.2.1</b> Formulación general</a></li>
<li class="chapter" data-level="17.2.2" data-path="cap-mxm.html"><a href="cap-mxm.html#inferencia-y-selección-del-modelo"><i class="fa fa-check"></i><b>17.2.2</b> Inferencia y selección del modelo</a></li>
<li class="chapter" data-level="17.2.3" data-path="cap-mxm.html"><a href="cap-mxm.html#diagnosis-del-modelo"><i class="fa fa-check"></i><b>17.2.3</b> Diagnosis del modelo</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="cap-mxm.html"><a href="cap-mxm.html#funciones-de-r-para-ajustar-modelos-mixtos"><i class="fa fa-check"></i><b>17.3</b> Funciones de <code>R</code> para ajustar modelos mixtos</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="cap-mxm.html"><a href="cap-mxm.html#la-función-lmer"><i class="fa fa-check"></i><b>17.3.1</b> La función <code>lmer()</code></a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="cap-mxm.html"><a href="cap-mxm.html#caso-práctico"><i class="fa fa-check"></i><b>17.4</b> Caso práctico</a>
<ul>
<li class="chapter" data-level="17.4.1" data-path="cap-mxm.html"><a href="cap-mxm.html#modelo-con-ordenada-en-el-origen-aleatoria"><i class="fa fa-check"></i><b>17.4.1</b> Modelo con ordenada en el origen aleatoria</a></li>
<li class="chapter" data-level="17.4.2" data-path="cap-mxm.html"><a href="cap-mxm.html#modelo-con-pendiente-aleatoria"><i class="fa fa-check"></i><b>17.4.2</b> Modelo con pendiente aleatoria</a></li>
<li class="chapter" data-level="17.4.3" data-path="cap-mxm.html"><a href="cap-mxm.html#cómo-construir-el-modelo-en-la-práctica"><i class="fa fa-check"></i><b>17.4.3</b> ¿Cómo construir el modelo en la práctica?</a></li>
<li class="chapter" data-level="" data-path="cap-mxm.html"><a href="cap-mxm.html#resumen-3"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="cap-sparse.html"><a href="cap-sparse.html"><i class="fa fa-check"></i><b>18</b> Modelos sparse y métodos penalizados de regresión</a>
<ul>
<li class="chapter" data-level="18.1" data-path="cap-sparse.html"><a href="cap-sparse.html#introducción-7"><i class="fa fa-check"></i><b>18.1</b> Introducción</a></li>
<li class="chapter" data-level="18.2" data-path="cap-sparse.html"><a href="cap-sparse.html#selección-del-mejor-subconjunto"><i class="fa fa-check"></i><b>18.2</b> Selección del mejor subconjunto</a>
<ul>
<li class="chapter" data-level="18.2.1" data-path="cap-sparse.html"><a href="cap-sparse.html#ejemplo-sueldo-de-jugadores-de-béisbol"><i class="fa fa-check"></i><b>18.2.1</b> Ejemplo: Sueldo de jugadores de béisbol</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="cap-sparse.html"><a href="cap-sparse.html#selección-stepwise"><i class="fa fa-check"></i><b>18.3</b> Selección <em>Stepwise</em></a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="cap-sparse.html"><a href="cap-sparse.html#forward-stepwise"><i class="fa fa-check"></i><b>18.3.1</b> Forward stepwise</a></li>
<li class="chapter" data-level="18.3.2" data-path="cap-sparse.html"><a href="cap-sparse.html#backward-stepwise"><i class="fa fa-check"></i><b>18.3.2</b> Backward stepwise</a></li>
<li class="chapter" data-level="18.3.3" data-path="cap-sparse.html"><a href="cap-sparse.html#ejemplo-sueldo-de-jugadores-de-béisbol-1"><i class="fa fa-check"></i><b>18.3.3</b> Ejemplo: Sueldo de jugadores de béisbol</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="cap-sparse.html"><a href="cap-sparse.html#métodos-shrinkage"><i class="fa fa-check"></i><b>18.4</b> Métodos Shrinkage</a>
<ul>
<li class="chapter" data-level="18.4.1" data-path="cap-sparse.html"><a href="cap-sparse.html#regresión-ridge"><i class="fa fa-check"></i><b>18.4.1</b> Regresión ridge</a></li>
<li class="chapter" data-level="18.4.2" data-path="cap-sparse.html"><a href="cap-sparse.html#selección-del-parámetro-de-tuneado"><i class="fa fa-check"></i><b>18.4.2</b> Selección del parámetro de tuneado</a></li>
<li class="chapter" data-level="18.4.3" data-path="cap-sparse.html"><a href="cap-sparse.html#regresión-lasso"><i class="fa fa-check"></i><b>18.4.3</b> Regresión Lasso</a></li>
<li class="chapter" data-level="18.4.4" data-path="cap-sparse.html"><a href="cap-sparse.html#elastic-net"><i class="fa fa-check"></i><b>18.4.4</b> Elastic net </a></li>
<li class="chapter" data-level="" data-path="cap-sparse.html"><a href="cap-sparse.html#resumen-4"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="cap-series-temp.html"><a href="cap-series-temp.html"><i class="fa fa-check"></i><b>19</b> Modelización de series temporales</a>
<ul>
<li class="chapter" data-level="19.1" data-path="cap-series-temp.html"><a href="cap-series-temp.html#conceptos-básicos-1"><i class="fa fa-check"></i><b>19.1</b> Conceptos básicos</a></li>
<li class="chapter" data-level="19.2" data-path="cap-series-temp.html"><a href="cap-series-temp.html#modelos-arima"><i class="fa fa-check"></i><b>19.2</b> Modelos ARIMA</a></li>
<li class="chapter" data-level="19.3" data-path="cap-series-temp.html"><a href="cap-series-temp.html#análisis-de-series-temporales-con-r"><i class="fa fa-check"></i><b>19.3</b> Análisis de series temporales con R</a>
<ul>
<li class="chapter" data-level="19.3.1" data-path="cap-series-temp.html"><a href="cap-series-temp.html#identificación-o-especificación-del-modelo"><i class="fa fa-check"></i><b>19.3.1</b> Identificación o especificación del modelo</a></li>
<li class="chapter" data-level="19.3.2" data-path="cap-series-temp.html"><a href="cap-series-temp.html#estimación-del-modelo"><i class="fa fa-check"></i><b>19.3.2</b> Estimación del modelo</a></li>
<li class="chapter" data-level="19.3.3" data-path="cap-series-temp.html"><a href="cap-series-temp.html#diagnosis-validación-y-contrastación"><i class="fa fa-check"></i><b>19.3.3</b> Diagnosis, validación y contrastación</a></li>
<li class="chapter" data-level="19.3.4" data-path="cap-series-temp.html"><a href="cap-series-temp.html#predicción-2"><i class="fa fa-check"></i><b>19.3.4</b> Predicción</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="20" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html"><i class="fa fa-check"></i><b>20</b> Análisis de tablas de contingencia</a>
<ul>
<li class="chapter" data-level="20.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#introducción-8"><i class="fa fa-check"></i><b>20.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="20.1.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#motiv"><i class="fa fa-check"></i><b>20.1.1</b> Motivación</a></li>
<li class="chapter" data-level="20.1.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#notac"><i class="fa fa-check"></i><b>20.1.2</b> Notación</a></li>
<li class="chapter" data-level="20.1.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#diseños-experimentales-o-procedimientos-de-muestreo-que-dan-lugar-a-una-tabla-de-contingencia"><i class="fa fa-check"></i><b>20.1.3</b> Diseños experimentales o procedimientos de muestreo que dan lugar a una tabla de contingencia</a></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contraste-de-independencia-en-tablas-2times-2"><i class="fa fa-check"></i><b>20.2</b> Contraste de independencia en tablas <span class="math inline">\((2\times 2)\)</span></a>
<ul>
<li class="chapter" data-level="20.2.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#introducción-9"><i class="fa fa-check"></i><b>20.2.1</b> Introducción</a></li>
<li class="chapter" data-level="20.2.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#plantgen"><i class="fa fa-check"></i><b>20.2.2</b> Planteamiento general del contraste exacto de independencia</a></li>
<li class="chapter" data-level="20.2.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#algoritmo"><i class="fa fa-check"></i><b>20.2.3</b> Algoritmo para la realización del contraste exacto de independencia</a></li>
<li class="chapter" data-level="20.2.4" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contraste-de-independencia-diseño-tipo-1"><i class="fa fa-check"></i><b>20.2.4</b> Contraste de independencia: Diseño Tipo 1</a></li>
<li class="chapter" data-level="20.2.5" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#dise"><i class="fa fa-check"></i><b>20.2.5</b> Contraste de independencia: Diseños Tipo 2 y Tipo 3</a></li>
</ul></li>
<li class="chapter" data-level="20.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contraste-de-independencia-en-tablas-rtimes-c"><i class="fa fa-check"></i><b>20.3</b> Contraste de independencia en tablas <span class="math inline">\(R\times C\)</span></a>
<ul>
<li class="chapter" data-level="20.3.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#IntroRxC"><i class="fa fa-check"></i><b>20.3.1</b> Introducción</a></li>
<li class="chapter" data-level="20.3.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contaprox"><i class="fa fa-check"></i><b>20.3.2</b> Contrastes aproximados</a></li>
<li class="chapter" data-level="20.3.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contraste-aproximado-con-corrección-de-continuidad-1"><i class="fa fa-check"></i><b>20.3.3</b> Contraste aproximado con corrección de continuidad</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#medidas"><i class="fa fa-check"></i><b>20.4</b> Medidas de asociación en tablas <span class="math inline">\(2\times 2\)</span></a>
<ul>
<li class="chapter" data-level="20.4.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#introducción-10"><i class="fa fa-check"></i><b>20.4.1</b> Introducción</a></li>
<li class="chapter" data-level="20.4.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#la-hatq-de-yule"><i class="fa fa-check"></i><b>20.4.2</b> La <span class="math inline">\(\hat{Q}\)</span> de Yule</a></li>
<li class="chapter" data-level="20.4.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#otras-medidas-de-asociación-para-tablas-2times-2"><i class="fa fa-check"></i><b>20.4.3</b> Otras medidas de asociación para tablas <span class="math inline">\(2\times 2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="20.5" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#medidas-de-asociación-en-tablas-rtimes-c"><i class="fa fa-check"></i><b>20.5</b> Medidas de asociación en tablas <span class="math inline">\(R\times C\)</span></a>
<ul>
<li class="chapter" data-level="20.5.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#introducción-11"><i class="fa fa-check"></i><b>20.5.1</b> Introducción</a></li>
<li class="chapter" data-level="20.5.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#medidas-derivadas-del-estadístico-chi-cuadrado"><i class="fa fa-check"></i><b>20.5.2</b> Medidas derivadas del estadístico Chi-cuadrado</a></li>
<li class="chapter" data-level="20.5.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#medidas-basadas-en-la-reducción-proporcional-del-error-lambda-de-goodman-y-kruskal"><i class="fa fa-check"></i><b>20.5.3</b> Medidas basadas en la reducción proporcional del error: <span class="math inline">\(\lambda\)</span> de Goodman y Kruskal</a></li>
<li class="chapter" data-level="20.5.4" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#determinación-de-las-fuentes-de-asociación"><i class="fa fa-check"></i><b>20.5.4</b> Determinación de las fuentes de asociación</a></li>
</ul></li>
<li class="chapter" data-level="20.6" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contrastes-de-independencia-en-tablas-multidimensionales"><i class="fa fa-check"></i><b>20.6</b> Contrastes de independencia en tablas multidimensionales</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="correspondencias.html"><a href="correspondencias.html"><i class="fa fa-check"></i><b>21</b> Análisis de correspondencias</a>
<ul>
<li class="chapter" data-level="21.1" data-path="correspondencias.html"><a href="correspondencias.html#introducción-12"><i class="fa fa-check"></i><b>21.1</b> Introducción</a></li>
<li class="chapter" data-level="21.2" data-path="correspondencias.html"><a href="correspondencias.html#metodología-del-análisis-de-correspondencias"><i class="fa fa-check"></i><b>21.2</b> Metodología del análisis de correspondencias</a>
<ul>
<li class="chapter" data-level="21.2.1" data-path="correspondencias.html"><a href="correspondencias.html#proyecciones-fila-columna-y-simétrica"><i class="fa fa-check"></i><b>21.2.1</b> Proyecciones fila, columna y simétrica</a></li>
</ul></li>
<li class="chapter" data-level="21.3" data-path="correspondencias.html"><a href="correspondencias.html#ejemplos-de-análisis-de-correspondencias-con-r"><i class="fa fa-check"></i><b>21.3</b> Ejemplos de análisis de correspondencias con <strong>R</strong></a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="cap-conjunto.html"><a href="cap-conjunto.html"><i class="fa fa-check"></i><b>22</b> Análisis conjunto</a>
<ul>
<li class="chapter" data-level="22.1" data-path="cap-conjunto.html"><a href="cap-conjunto.html#introducción-conceptos-clave-y-tipos-de-análisis"><i class="fa fa-check"></i><b>22.1</b> Introducción, conceptos clave y tipos de análisis</a></li>
<li class="chapter" data-level="22.2" data-path="cap-conjunto.html"><a href="cap-conjunto.html#aplicación-del-análisis-conjunto-etapas"><i class="fa fa-check"></i><b>22.2</b> Aplicación del Análisis Conjunto (etapas):</a></li>
<li class="chapter" data-level="22.3" data-path="cap-conjunto.html"><a href="cap-conjunto.html#ejemplo-utilizando-r"><i class="fa fa-check"></i><b>22.3</b> Ejemplo utilizando R:</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="cap-discriminante.html"><a href="cap-discriminante.html"><i class="fa fa-check"></i><b>23</b> Análisis discriminante</a>
<ul>
<li class="chapter" data-level="23.1" data-path="cap-discriminante.html"><a href="cap-discriminante.html#introducción-13"><i class="fa fa-check"></i><b>23.1</b> Introducción</a></li>
<li class="chapter" data-level="23.2" data-path="cap-discriminante.html"><a href="cap-discriminante.html#tipos-de-análisis-discriminantes"><i class="fa fa-check"></i><b>23.2</b> Tipos de análisis discriminantes:</a></li>
<li class="chapter" data-level="23.3" data-path="cap-discriminante.html"><a href="cap-discriminante.html#ejemplos"><i class="fa fa-check"></i><b>23.3</b> Ejemplos:</a></li>
</ul></li>
<li class="part"><span><b>IV Machine learning supervisado</b></span></li>
<li class="chapter" data-level="24" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html"><i class="fa fa-check"></i><b>24</b> Árboles de clasificación y regresión </a>
<ul>
<li class="chapter" data-level="24.1" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#introducción-14"><i class="fa fa-check"></i><b>24.1</b> Introducción </a></li>
<li class="chapter" data-level="24.2" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#aprendizaje-con-árboles-de-decisión"><i class="fa fa-check"></i><b>24.2</b> Aprendizaje con árboles de decisión</a></li>
<li class="chapter" data-level="24.3" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#cómo-se-va-dividiendo-el-árbol"><i class="fa fa-check"></i><b>24.3</b> ¿Cómo se va dividiendo el árbol? </a>
<ul>
<li class="chapter" data-level="24.3.1" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#impureza-de-gini"><i class="fa fa-check"></i><b>24.3.1</b> Impureza de Gini</a></li>
<li class="chapter" data-level="24.3.2" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#entropía"><i class="fa fa-check"></i><b>24.3.2</b> Entropía </a></li>
<li class="chapter" data-level="24.3.3" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#ganancia-de-información"><i class="fa fa-check"></i><b>24.3.3</b> Ganancia de información</a></li>
<li class="chapter" data-level="24.3.4" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#suma-residual-de-cuadrados-mínima"><i class="fa fa-check"></i><b>24.3.4</b> Suma residual de cuadrados mínima</a></li>
</ul></li>
<li class="chapter" data-level="24.4" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#sobreajuste"><i class="fa fa-check"></i><b>24.4</b> Sobreajuste </a></li>
<li class="chapter" data-level="24.5" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#cuánto-debe-crecer-un-árbol"><i class="fa fa-check"></i><b>24.5</b> ¿Cuánto debe crecer un árbol? </a>
<ul>
<li class="chapter" data-level="24.5.1" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#la-parada-temprana"><i class="fa fa-check"></i><b>24.5.1</b> La parada temprana </a></li>
<li class="chapter" data-level="24.5.2" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#la-poda"><i class="fa fa-check"></i><b>24.5.2</b> La poda </a></li>
</ul></li>
<li class="chapter" data-level="24.6" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#el-algoritmo-id3-para-la-construcción-de-un-árbol-de-decisión"><i class="fa fa-check"></i><b>24.6</b> El algoritmo ID3 para la construcción de un árbol de decisión</a></li>
<li class="chapter" data-level="24.7" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#procedimiento-con-r-la-funcion-rpart"><i class="fa fa-check"></i><b>24.7</b> Procedimiento con R: la funcion <code>rpart</code></a></li>
<li class="chapter" data-level="24.8" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#aplicaciones-de-los-árboles-de-decisión"><i class="fa fa-check"></i><b>24.8</b> Aplicaciones de los árboles de decisión</a>
<ul>
<li class="chapter" data-level="24.8.1" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#el-caso-de-negocio"><i class="fa fa-check"></i><b>24.8.1</b> El caso de negocio</a></li>
<li class="chapter" data-level="24.8.2" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#árbol-de-clasificación-para-determinar-la-intención-de-compra"><i class="fa fa-check"></i><b>24.8.2</b> Árbol de clasificación para determinar la intención de compra</a></li>
<li class="chapter" data-level="24.8.3" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#árbol-de-regresión-para-estimar-el-número-de-días-hospitalizado"><i class="fa fa-check"></i><b>24.8.3</b> Árbol de regresión para estimar el número de días hospitalizado</a></li>
<li class="chapter" data-level="" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#resumen-5"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="25" data-path="cap-svm.html"><a href="cap-svm.html"><i class="fa fa-check"></i><b>25</b> Máquinas de Vector Soporte</a>
<ul>
<li class="chapter" data-level="25.1" data-path="cap-svm.html"><a href="cap-svm.html#introducción-15"><i class="fa fa-check"></i><b>25.1</b> Introducción</a></li>
<li class="chapter" data-level="25.2" data-path="cap-svm.html"><a href="cap-svm.html#algoritmo-svm-para-clasificación-binaria"><i class="fa fa-check"></i><b>25.2</b> Algoritmo SVM para clasificación binaria</a></li>
<li class="chapter" data-level="25.3" data-path="cap-svm.html"><a href="cap-svm.html#y-si-tengo-más-de-dos-clases"><i class="fa fa-check"></i><b>25.3</b> ¿Y si tengo más de dos clases?</a></li>
<li class="chapter" data-level="25.4" data-path="cap-svm.html"><a href="cap-svm.html#truco-del-kernel-tratando-con-la-no-linearidad"><i class="fa fa-check"></i><b>25.4</b> Truco del Kernel: Tratando con la no linearidad</a>
<ul>
<li class="chapter" data-level="25.4.1" data-path="cap-svm.html"><a href="cap-svm.html#algunos-kernels-populares"><i class="fa fa-check"></i><b>25.4.1</b> Algunos kernels populares</a></li>
</ul></li>
<li class="chapter" data-level="25.5" data-path="cap-svm.html"><a href="cap-svm.html#procedimiento-con-r-la-funcion-svm"><i class="fa fa-check"></i><b>25.5</b> Procedimiento con R: la funcion <code>svm</code></a></li>
<li class="chapter" data-level="25.6" data-path="cap-svm.html"><a href="cap-svm.html#aplicación-de-un-modelo-svm-radial-con-ajuste-automático-en-r"><i class="fa fa-check"></i><b>25.6</b> Aplicación de un modelo SVM Radial con ajuste automático en R</a>
<ul>
<li class="chapter" data-level="25.6.1" data-path="cap-svm.html"><a href="cap-svm.html#importancia-de-las-variables"><i class="fa fa-check"></i><b>25.6.1</b> Importancia de las variables</a></li>
<li class="chapter" data-level="" data-path="cap-svm.html"><a href="cap-svm.html#resumen-6"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="26" data-path="cap-knn.html"><a href="cap-knn.html"><i class="fa fa-check"></i><b>26</b> Clasificador k-vecinos más próximos</a>
<ul>
<li class="chapter" data-level="26.1" data-path="cap-knn.html"><a href="cap-knn.html#introducción-16"><i class="fa fa-check"></i><b>26.1</b> Introducción</a></li>
<li class="chapter" data-level="26.2" data-path="cap-knn.html"><a href="cap-knn.html#decisiones-a-tener-en-cuenta"><i class="fa fa-check"></i><b>26.2</b> Decisiones a tener en cuenta</a>
<ul>
<li class="chapter" data-level="26.2.1" data-path="cap-knn.html"><a href="cap-knn.html#función-de-distancia-a-utilizar"><i class="fa fa-check"></i><b>26.2.1</b> Función de distancia a utilizar</a></li>
<li class="chapter" data-level="26.2.2" data-path="cap-knn.html"><a href="cap-knn.html#número-de-vecinos-k-seleccionados"><i class="fa fa-check"></i><b>26.2.2</b> Número de vecinos (k) seleccionados</a></li>
</ul></li>
<li class="chapter" data-level="26.3" data-path="cap-knn.html"><a href="cap-knn.html#procedimiento-con-r-la-funcion-knn"><i class="fa fa-check"></i><b>26.3</b> Procedimiento con R: la funcion knn</a></li>
<li class="chapter" data-level="26.4" data-path="cap-knn.html"><a href="cap-knn.html#aplicación-del-modelo-knn-en-r"><i class="fa fa-check"></i><b>26.4</b> Aplicación del modelo KNN en R</a>
<ul>
<li class="chapter" data-level="" data-path="cap-knn.html"><a href="cap-knn.html#resumen-7"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="27" data-path="cap-naive-bayes.html"><a href="cap-naive-bayes.html"><i class="fa fa-check"></i><b>27</b> Naive Bayes</a>
<ul>
<li class="chapter" data-level="27.1" data-path="cap-naive-bayes.html"><a href="cap-naive-bayes.html#introducción-17"><i class="fa fa-check"></i><b>27.1</b> Introducción</a></li>
<li class="chapter" data-level="27.2" data-path="cap-naive-bayes.html"><a href="cap-naive-bayes.html#teorema-de-bayes"><i class="fa fa-check"></i><b>27.2</b> Teorema de Bayes</a></li>
<li class="chapter" data-level="27.3" data-path="cap-naive-bayes.html"><a href="cap-naive-bayes.html#el-algoritmo-naive-bayes"><i class="fa fa-check"></i><b>27.3</b> El algoritmo Naive Bayes</a></li>
<li class="chapter" data-level="27.4" data-path="cap-naive-bayes.html"><a href="cap-naive-bayes.html#procedimiento-con-r-la-funcion-naive_bayes"><i class="fa fa-check"></i><b>27.4</b> Procedimiento con R: la funcion <code>naive_bayes</code></a></li>
<li class="chapter" data-level="27.5" data-path="cap-naive-bayes.html"><a href="cap-naive-bayes.html#aplicación-del-modelo-naive-bayes"><i class="fa fa-check"></i><b>27.5</b> Aplicación del modelo Naive Bayes</a>
<ul>
<li class="chapter" data-level="" data-path="cap-naive-bayes.html"><a href="cap-naive-bayes.html#resumen-8"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="28" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html"><i class="fa fa-check"></i><b>28</b> Bagging. Random Forest </a>
<ul>
<li class="chapter" data-level="28.1" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#introducción-metodos-de-ensamble"><i class="fa fa-check"></i><b>28.1</b> Introducción: Metodos de Ensamble</a></li>
<li class="chapter" data-level="28.2" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#bagging"><i class="fa fa-check"></i><b>28.2</b> Bagging</a></li>
<li class="chapter" data-level="28.3" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#procedimiento-con-r-la-función-bagging"><i class="fa fa-check"></i><b>28.3</b> Procedimiento con R: la función <code>bagging</code> </a></li>
<li class="chapter" data-level="28.4" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#implementando-bagging-en-r"><i class="fa fa-check"></i><b>28.4</b> Implementando bagging en R</a>
<ul>
<li class="chapter" data-level="28.4.1" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#interpretación-de-variables-en-el-bagging"><i class="fa fa-check"></i><b>28.4.1</b> Interpretación de variables en el bagging</a></li>
</ul></li>
<li class="chapter" data-level="28.5" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#random-forest"><i class="fa fa-check"></i><b>28.5</b> Random Forest</a>
<ul>
<li class="chapter" data-level="28.5.1" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#número-de-árboles-k"><i class="fa fa-check"></i><b>28.5.1</b> Número de árboles (<span class="math inline">\(K\)</span>)</a></li>
<li class="chapter" data-level="28.5.2" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#número-de-variables-a-considerar-mtry"><i class="fa fa-check"></i><b>28.5.2</b> Número de variables a considerar (<span class="math inline">\(mtry\)</span>)</a></li>
<li class="chapter" data-level="28.5.3" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#complejidad-de-los-árboles"><i class="fa fa-check"></i><b>28.5.3</b> Complejidad de los árboles</a></li>
<li class="chapter" data-level="28.5.4" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#esquema-de-muestreo"><i class="fa fa-check"></i><b>28.5.4</b> Esquema de muestreo</a></li>
<li class="chapter" data-level="28.5.5" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#regla-de-división"><i class="fa fa-check"></i><b>28.5.5</b> Regla de división</a></li>
</ul></li>
<li class="chapter" data-level="28.6" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#procedimiento-con-r-la-función-randomforest"><i class="fa fa-check"></i><b>28.6</b> Procedimiento con R: la función <code>randomForest</code></a></li>
<li class="chapter" data-level="28.7" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#aplicación-del-modelo-random-forest-en-r"><i class="fa fa-check"></i><b>28.7</b> Aplicación del modelo Random Forest en R</a>
<ul>
<li class="chapter" data-level="28.7.1" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#aplicación-del-random-forest"><i class="fa fa-check"></i><b>28.7.1</b> Aplicación del Random Forest</a></li>
<li class="chapter" data-level="" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#resumen-9"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="29" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html"><i class="fa fa-check"></i><b>29</b> Boosting. XGBoost.</a>
<ul>
<li class="chapter" data-level="29.1" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#introducción.-boosting."><i class="fa fa-check"></i><b>29.1</b> Introducción. Boosting.</a></li>
<li class="chapter" data-level="29.2" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#gradient-boosting"><i class="fa fa-check"></i><b>29.2</b> Gradient Boosting</a>
<ul>
<li class="chapter" data-level="29.2.1" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#hiperparámetros-del-modelo-gradient-boosting"><i class="fa fa-check"></i><b>29.2.1</b> Hiperparámetros del modelo gradient boosting</a></li>
<li class="chapter" data-level="29.2.2" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#estrategia-de-ajuste-de-hiperparametros"><i class="fa fa-check"></i><b>29.2.2</b> Estrategia de ajuste de hiperparametros</a></li>
</ul></li>
<li class="chapter" data-level="29.3" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#procedimiento-con-r-la-funcion-gbm"><i class="fa fa-check"></i><b>29.3</b> Procedimiento con R: la funcion <code>gbm</code></a></li>
<li class="chapter" data-level="29.4" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#aplicación-del-modelo-gbm-en-r"><i class="fa fa-check"></i><b>29.4</b> Aplicación del modelo GBM en R</a>
<ul>
<li class="chapter" data-level="29.4.1" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#gbm-con-ajuste-automático"><i class="fa fa-check"></i><b>29.4.1</b> GBM con ajuste automático</a></li>
</ul></li>
<li class="chapter" data-level="29.5" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#extreme-gradient-boosting-xgb"><i class="fa fa-check"></i><b>29.5</b> eXtreme Gradient Boosting (XGB)</a>
<ul>
<li class="chapter" data-level="29.5.1" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#hiperparametros-del-modelo-xgboost"><i class="fa fa-check"></i><b>29.5.1</b> Hiperparametros del modelo XGBoost</a></li>
</ul></li>
<li class="chapter" data-level="29.6" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#procedimiento-con-r-la-funcion-xgboost"><i class="fa fa-check"></i><b>29.6</b> Procedimiento con R: la funcion <code>xgboost</code></a></li>
<li class="chapter" data-level="29.7" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#aplicación-del-módelo-xgboost-en-r"><i class="fa fa-check"></i><b>29.7</b> Aplicación del módelo XGBoost en R</a>
<ul>
<li class="chapter" data-level="29.7.1" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#xgboost-y-ajuste-automático"><i class="fa fa-check"></i><b>29.7.1</b> XGBoost y ajuste automático</a></li>
<li class="chapter" data-level="" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#resumen-10"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>V Machine learning no supervisado</b></span></li>
<li class="chapter" data-level="30" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html"><i class="fa fa-check"></i><b>30</b> Análisis cluster: clusterización jerárquica</a>
<ul>
<li class="chapter" data-level="30.1" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#origen-cluster"><i class="fa fa-check"></i><b>30.1</b> Introducción</a></li>
<li class="chapter" data-level="30.2" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#selección-de-las-variables"><i class="fa fa-check"></i><b>30.2</b> Selección de las variables</a></li>
<li class="chapter" data-level="30.3" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#elección-de-la-distancia-entre-elementos"><i class="fa fa-check"></i><b>30.3</b> Elección de la distancia entre elementos</a></li>
<li class="chapter" data-level="30.4" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#técnicas-de-agrupación-jerárquicas"><i class="fa fa-check"></i><b>30.4</b> Técnicas de agrupación jerárquicas</a>
<ul>
<li class="chapter" data-level="30.4.1" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#introac"><i class="fa fa-check"></i><b>30.4.1</b> Introducción</a></li>
<li class="chapter" data-level="30.4.2" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#técnicas-jerárquicas-aglomerativas"><i class="fa fa-check"></i><b>30.4.2</b> Técnicas jerárquicas aglomerativas</a></li>
<li class="chapter" data-level="30.4.3" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#técnicas-jerárquicas-divisivas"><i class="fa fa-check"></i><b>30.4.3</b> Técnicas jerárquicas divisivas</a></li>
</ul></li>
<li class="chapter" data-level="30.5" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#calidad-de-la-agrupación-y-número-de-clusters"><i class="fa fa-check"></i><b>30.5</b> Calidad de la agrupación y número de clusters</a>
<ul>
<li class="chapter" data-level="30.5.1" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#el-coeficiente-de-correlación-lineal-cofenético"><i class="fa fa-check"></i><b>30.5.1</b> El coeficiente de correlación lineal cofenético</a></li>
<li class="chapter" data-level="30.5.2" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#número-óptimo-de-clusters"><i class="fa fa-check"></i><b>30.5.2</b> Número óptimo de clusters</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="31" data-path="no-jerarquico.html"><a href="no-jerarquico.html"><i class="fa fa-check"></i><b>31</b> Análisis cluster: clusterización no jerárquica</a>
<ul>
<li class="chapter" data-level="31.1" data-path="no-jerarquico.html"><a href="no-jerarquico.html#métodos-de-reasignación"><i class="fa fa-check"></i><b>31.1</b> Métodos de reasignación</a>
<ul>
<li class="chapter" data-level="31.1.1" data-path="no-jerarquico.html"><a href="no-jerarquico.html#técnicas-basadas-en-centroides-métodos-de-forgy-y-bf-k-medias"><i class="fa fa-check"></i><b>31.1.1</b> Técnicas basadas en centroides: métodos de Forgy y <span class="math inline">\(\bf k\)</span>-medias</a></li>
<li class="chapter" data-level="31.1.2" data-path="no-jerarquico.html"><a href="no-jerarquico.html#técnicas-basadas-en-medoides"><i class="fa fa-check"></i><b>31.1.2</b> Técnicas basadas en medoides</a></li>
<li class="chapter" data-level="31.1.3" data-path="no-jerarquico.html"><a href="no-jerarquico.html#técnicas-basadas-en-medianas-bf-k-medianas"><i class="fa fa-check"></i><b>31.1.3</b> Técnicas basadas en medianas: <span class="math inline">\(\bf k\)</span>-medianas</a></li>
</ul></li>
<li class="chapter" data-level="31.2" data-path="no-jerarquico.html"><a href="no-jerarquico.html#métodos-basados-en-la-densidad-de-puntos"><i class="fa fa-check"></i><b>31.2</b> Métodos basados en la densidad de puntos</a></li>
<li class="chapter" data-level="31.3" data-path="no-jerarquico.html"><a href="no-jerarquico.html#otros-métodos"><i class="fa fa-check"></i><b>31.3</b> Otros métodos</a></li>
<li class="chapter" data-level="31.4" data-path="no-jerarquico.html"><a href="no-jerarquico.html#nota-final"><i class="fa fa-check"></i><b>31.4</b> Nota final</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="acp.html"><a href="acp.html"><i class="fa fa-check"></i><b>32</b> Análisis de componentes principales</a>
<ul>
<li class="chapter" data-level="32.1" data-path="acp.html"><a href="acp.html#introducción-18"><i class="fa fa-check"></i><b>32.1</b> Introducción</a></li>
<li class="chapter" data-level="32.2" data-path="acp.html"><a href="acp.html#obtención-de-las-componentes-principales"><i class="fa fa-check"></i><b>32.2</b> Obtención de las componentes principales</a>
<ul>
<li class="chapter" data-level="32.2.1" data-path="acp.html"><a href="acp.html#descripción-formal-del-proceso"><i class="fa fa-check"></i><b>32.2.1</b> Descripción formal del proceso</a></li>
<li class="chapter" data-level="32.2.2" data-path="acp.html"><a href="acp.html#cuestiones-importantes-en-el-análisis-de-componentes-principales"><i class="fa fa-check"></i><b>32.2.2</b> Cuestiones importantes en el análisis de componentes principales</a></li>
</ul></li>
<li class="chapter" data-level="32.3" data-path="acp.html"><a href="acp.html#estimación-de-las-componentes-principales"><i class="fa fa-check"></i><b>32.3</b> Estimación de las componentes principales</a></li>
<li class="chapter" data-level="32.4" data-path="acp.html"><a href="acp.html#numcomp"><i class="fa fa-check"></i><b>32.4</b> Número de componentes a retener</a></li>
<li class="chapter" data-level="32.5" data-path="acp.html"><a href="acp.html#interpretación-de-las-componentes-principales"><i class="fa fa-check"></i><b>32.5</b> Interpretación de las componentes principales</a></li>
<li class="chapter" data-level="32.6" data-path="acp.html"><a href="acp.html#reproducción-de-los-datos-tipificados-y-de-r-a-partir-de-las-componentes-principales"><i class="fa fa-check"></i><b>32.6</b> Reproducción de los datos tipificados y de R a partir de las componentes principales</a></li>
<li class="chapter" data-level="32.7" data-path="acp.html"><a href="acp.html#limitaciones-del-análisis-de-componentes-principales"><i class="fa fa-check"></i><b>32.7</b> Limitaciones del análisis de componentes principales</a></li>
</ul></li>
<li class="chapter" data-level="33" data-path="análisis-factorial.html"><a href="análisis-factorial.html"><i class="fa fa-check"></i><b>33</b> Análisis factorial</a>
<ul>
<li class="chapter" data-level="33.1" data-path="análisis-factorial.html"><a href="análisis-factorial.html#introaf"><i class="fa fa-check"></i><b>33.1</b> Introducción</a></li>
<li class="chapter" data-level="33.2" data-path="análisis-factorial.html"><a href="análisis-factorial.html#elementos-teóricos-del-análisis-factorial"><i class="fa fa-check"></i><b>33.2</b> Elementos teóricos del análisis factorial</a>
<ul>
<li class="chapter" data-level="33.2.1" data-path="análisis-factorial.html"><a href="análisis-factorial.html#modelobasicoaf"><i class="fa fa-check"></i><b>33.2.1</b> Modelo básico y terminología</a></li>
<li class="chapter" data-level="33.2.2" data-path="análisis-factorial.html"><a href="análisis-factorial.html#patrón-y-estructura-factoriales"><i class="fa fa-check"></i><b>33.2.2</b> Patrón y estructura factoriales</a></li>
</ul></li>
<li class="chapter" data-level="33.3" data-path="análisis-factorial.html"><a href="análisis-factorial.html#el-análisis-factorial-en-la-práctica"><i class="fa fa-check"></i><b>33.3</b> El análisis factorial en la práctica</a>
<ul>
<li class="chapter" data-level="33.3.1" data-path="análisis-factorial.html"><a href="análisis-factorial.html#pre-análisis-factorial"><i class="fa fa-check"></i><b>33.3.1</b> Pre-análisis factorial</a></li>
<li class="chapter" data-level="33.3.2" data-path="análisis-factorial.html"><a href="análisis-factorial.html#análisis-factorial-1"><i class="fa fa-check"></i><b>33.3.2</b> Análisis factorial</a></li>
<li class="chapter" data-level="33.3.3" data-path="análisis-factorial.html"><a href="análisis-factorial.html#postanalisis"><i class="fa fa-check"></i><b>33.3.3</b> Post-análisis factorial</a></li>
<li class="chapter" data-level="33.3.4" data-path="análisis-factorial.html"><a href="análisis-factorial.html#puntuaciones-factoriales."><i class="fa fa-check"></i><b>33.3.4</b> Puntuaciones factoriales.</a></li>
</ul></li>
<li class="chapter" data-level="33.4" data-path="análisis-factorial.html"><a href="análisis-factorial.html#relaciones-y-diferencias-entre-el-análisis-factorial-y-el-de-componentes-principales"><i class="fa fa-check"></i><b>33.4</b> Relaciones y diferencias entre el análisis factorial y el de componentes principales</a></li>
</ul></li>
<li class="chapter" data-level="34" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html"><i class="fa fa-check"></i><b>34</b> Escalamiento multidimensional</a>
<ul>
<li class="chapter" data-level="34.1" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html#introducción-19"><i class="fa fa-check"></i><b>34.1</b> Introducción</a></li>
<li class="chapter" data-level="34.2" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html#medición-de-distancias-y-similitudes"><i class="fa fa-check"></i><b>34.2</b> Medición de distancias y similitudes</a></li>
<li class="chapter" data-level="34.3" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html#modelo-escalamiento-multidimensional."><i class="fa fa-check"></i><b>34.3</b> Modelo escalamiento multidimensional.</a></li>
<li class="chapter" data-level="34.4" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html#tipos-de-escalamiento-multidimensional"><i class="fa fa-check"></i><b>34.4</b> Tipos de escalamiento multidimensional</a>
<ul>
<li class="chapter" data-level="34.4.1" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html#escalado-multidimensional-métrico"><i class="fa fa-check"></i><b>34.4.1</b> Escalado multidimensional métrico</a></li>
<li class="chapter" data-level="34.4.2" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html#escalado-multidimensional-no-métrico"><i class="fa fa-check"></i><b>34.4.2</b> Escalado multidimensional no-métrico</a></li>
</ul></li>
<li class="chapter" data-level="34.5" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html#biblio"><i class="fa fa-check"></i><b>34.5</b> Referencias bibliográficas</a></li>
</ul></li>
<li class="part"><span><b>VI Deep learning</b></span></li>
<li class="chapter" data-level="35" data-path="capNN.html"><a href="capNN.html"><i class="fa fa-check"></i><b>35</b> Redes neuronales artificiales</a>
<ul>
<li class="chapter" data-level="35.1" data-path="capNN.html"><a href="capNN.html#qué-es-el-deep-learning"><i class="fa fa-check"></i><b>35.1</b> ¿Qué es el <em>deep learning</em>?</a>
<ul>
<li class="chapter" data-level="35.1.1" data-path="capNN.html"><a href="capNN.html#diferencias-entre-las-técnicas-de-machine-learning-tradicional-y-el-deep-learning"><i class="fa fa-check"></i><b>35.1.1</b> Diferencias entre las técnicas de <em>machine learning</em> tradicional y el <em>deep learning</em></a></li>
</ul></li>
<li class="chapter" data-level="35.2" data-path="capNN.html"><a href="capNN.html#aplicaciones-del-deep-learning"><i class="fa fa-check"></i><b>35.2</b> Aplicaciones del <em>deep learning</em></a></li>
<li class="chapter" data-level="35.3" data-path="capNN.html"><a href="capNN.html#redes-neuronales"><i class="fa fa-check"></i><b>35.3</b> Redes Neuronales</a></li>
<li class="chapter" data-level="35.4" data-path="capNN.html"><a href="capNN.html#perceptrón-o-neurona"><i class="fa fa-check"></i><b>35.4</b> Perceptrón o Neurona</a>
<ul>
<li class="chapter" data-level="35.4.1" data-path="capNN.html"><a href="capNN.html#aprendizaje"><i class="fa fa-check"></i><b>35.4.1</b> Aprendizaje</a></li>
<li class="chapter" data-level="35.4.2" data-path="capNN.html"><a href="capNN.html#convergencia"><i class="fa fa-check"></i><b>35.4.2</b> Convergencia</a></li>
</ul></li>
<li class="chapter" data-level="35.5" data-path="capNN.html"><a href="capNN.html#perceptrón-multiclase"><i class="fa fa-check"></i><b>35.5</b> Perceptrón Multiclase</a></li>
<li class="chapter" data-level="35.6" data-path="capNN.html"><a href="capNN.html#funciones-de-activación"><i class="fa fa-check"></i><b>35.6</b> Funciones de activación</a></li>
<li class="chapter" data-level="35.7" data-path="capNN.html"><a href="capNN.html#perceptrón-multicapa"><i class="fa fa-check"></i><b>35.7</b> Perceptrón Multicapa</a>
<ul>
<li class="chapter" data-level="35.7.1" data-path="capNN.html"><a href="capNN.html#aprendizaje-1"><i class="fa fa-check"></i><b>35.7.1</b> Aprendizaje</a></li>
</ul></li>
<li class="chapter" data-level="35.8" data-path="capNN.html"><a href="capNN.html#instalación-de-librerías-de-deep-learning-en-r-tensorflowkeras"><i class="fa fa-check"></i><b>35.8</b> Instalación de librerías de <em>deep learning</em> en <strong>R</strong>: Tensorflow/Keras</a></li>
<li class="chapter" data-level="35.9" data-path="capNN.html"><a href="capNN.html#ejemplo-de-red-para-clasificación"><i class="fa fa-check"></i><b>35.9</b> Ejemplo de red para clasificación</a>
<ul>
<li class="chapter" data-level="35.9.1" data-path="capNN.html"><a href="capNN.html#carga-y-visualización-de-los-datos"><i class="fa fa-check"></i><b>35.9.1</b> Carga y visualización de los datos</a></li>
<li class="chapter" data-level="35.9.2" data-path="capNN.html"><a href="capNN.html#preprocesamiento"><i class="fa fa-check"></i><b>35.9.2</b> Preprocesamiento</a></li>
<li class="chapter" data-level="35.9.3" data-path="capNN.html"><a href="capNN.html#nngen"><i class="fa fa-check"></i><b>35.9.3</b> Generación de la red neuronal</a></li>
<li class="chapter" data-level="35.9.4" data-path="capNN.html"><a href="capNN.html#nntrain"><i class="fa fa-check"></i><b>35.9.4</b> Entrenamiento</a></li>
<li class="chapter" data-level="35.9.5" data-path="capNN.html"><a href="capNN.html#test"><i class="fa fa-check"></i><b>35.9.5</b> Test</a></li>
<li class="chapter" data-level="35.9.6" data-path="capNN.html"><a href="capNN.html#guardado-y-reutilización-del-modelo"><i class="fa fa-check"></i><b>35.9.6</b> Guardado y reutilización del modelo</a></li>
</ul></li>
<li class="chapter" data-level="35.10" data-path="capNN.html"><a href="capNN.html#ejemplo-de-red-para-regresión"><i class="fa fa-check"></i><b>35.10</b> Ejemplo de red para regresión</a>
<ul>
<li class="chapter" data-level="35.10.1" data-path="capNN.html"><a href="capNN.html#carga-y-visualización-de-los-datos-1"><i class="fa fa-check"></i><b>35.10.1</b> Carga y visualización de los datos</a></li>
<li class="chapter" data-level="35.10.2" data-path="capNN.html"><a href="capNN.html#preprocesamiento-1"><i class="fa fa-check"></i><b>35.10.2</b> Preprocesamiento</a></li>
<li class="chapter" data-level="35.10.3" data-path="capNN.html"><a href="capNN.html#generación-de-la-red-neuronal"><i class="fa fa-check"></i><b>35.10.3</b> Generación de la red neuronal</a></li>
<li class="chapter" data-level="35.10.4" data-path="capNN.html"><a href="capNN.html#entrenamiento"><i class="fa fa-check"></i><b>35.10.4</b> Entrenamiento</a></li>
<li class="chapter" data-level="35.10.5" data-path="capNN.html"><a href="capNN.html#test-1"><i class="fa fa-check"></i><b>35.10.5</b> Test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="36" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html"><i class="fa fa-check"></i><b>36</b> Redes neuronales convolucionales</a>
<ul>
<li class="chapter" data-level="36.1" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#introducción-20"><i class="fa fa-check"></i><b>36.1</b> Introducción</a></li>
<li class="chapter" data-level="36.2" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#convolución"><i class="fa fa-check"></i><b>36.2</b> Convolución</a></li>
<li class="chapter" data-level="36.3" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#neuronas-convolucionales"><i class="fa fa-check"></i><b>36.3</b> Neuronas convolucionales</a></li>
<li class="chapter" data-level="36.4" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#relleno-del-borde"><i class="fa fa-check"></i><b>36.4</b> Relleno del borde</a>
<ul>
<li class="chapter" data-level="36.4.1" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#desplazamiento"><i class="fa fa-check"></i><b>36.4.1</b> Desplazamiento</a></li>
</ul></li>
<li class="chapter" data-level="36.5" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#capas-de-agrupación"><i class="fa fa-check"></i><b>36.5</b> Capas de agrupación</a></li>
<li class="chapter" data-level="36.6" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#desvanecimiento-del-gradiente"><i class="fa fa-check"></i><b>36.6</b> Desvanecimiento del gradiente</a></li>
<li class="chapter" data-level="36.7" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#sobreajuste-1"><i class="fa fa-check"></i><b>36.7</b> Sobreajuste</a></li>
<li class="chapter" data-level="36.8" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#generación-de-datos-de-entrenamiento-artificiales"><i class="fa fa-check"></i><b>36.8</b> Generación de datos de entrenamiento artificiales</a></li>
<li class="chapter" data-level="36.9" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#ejemplo-para-el-conjunto-de-datos-cifar10"><i class="fa fa-check"></i><b>36.9</b> Ejemplo para el conjunto de datos CIFAR10</a>
<ul>
<li class="chapter" data-level="36.9.1" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#visualizacion"><i class="fa fa-check"></i><b>36.9.1</b> Carga y visualización de los datos</a></li>
<li class="chapter" data-level="36.9.2" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#preprocesamiento-2"><i class="fa fa-check"></i><b>36.9.2</b> Preprocesamiento</a></li>
<li class="chapter" data-level="36.9.3" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#generación-de-la-red-neuronal-1"><i class="fa fa-check"></i><b>36.9.3</b> Generación de la red neuronal</a></li>
<li class="chapter" data-level="36.9.4" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#entrenamiento-1"><i class="fa fa-check"></i><b>36.9.4</b> Entrenamiento</a></li>
<li class="chapter" data-level="36.9.5" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#test-2"><i class="fa fa-check"></i><b>36.9.5</b> Test</a></li>
<li class="chapter" data-level="36.9.6" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#otros-ejemplos-de-interés"><i class="fa fa-check"></i><b>36.9.6</b> Otros ejemplos de interés</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>VII Ciencia de datos espaciales</b></span></li>
<li class="chapter" data-level="37" data-path="datos-espaciles.html"><a href="datos-espaciles.html"><i class="fa fa-check"></i><b>37</b> Trabajando con datos espaciales</a>
<ul>
<li class="chapter" data-level="37.1" data-path="datos-espaciles.html"><a href="datos-espaciles.html#conceptos-clave"><i class="fa fa-check"></i><b>37.1</b> Conceptos clave</a>
<ul>
<li class="chapter" data-level="37.1.1" data-path="datos-espaciles.html"><a href="datos-espaciles.html#CRS"><i class="fa fa-check"></i><b>37.1.1</b> Sistema de Referencia de Coordenadas</a></li>
<li class="chapter" data-level="37.1.2" data-path="datos-espaciles.html"><a href="datos-espaciles.html#formatos"><i class="fa fa-check"></i><b>37.1.2</b> Formatos de datos espaciales</a></li>
</ul></li>
<li class="chapter" data-level="37.2" data-path="datos-espaciles.html"><a href="datos-espaciles.html#primer-mapa"><i class="fa fa-check"></i><b>37.2</b> Mi primer mapa</a></li>
<li class="chapter" data-level="37.3" data-path="datos-espaciles.html"><a href="datos-espaciles.html#no-mentir"><i class="fa fa-check"></i><b>37.3</b> ¿Cómo (no) mentir con la visualización?</a></li>
<li class="chapter" data-level="37.4" data-path="datos-espaciles.html"><a href="datos-espaciles.html#mapas-espacio-temporales"><i class="fa fa-check"></i><b>37.4</b> Mapas espacio-temporales</a></li>
<li class="chapter" data-level="37.5" data-path="datos-espaciles.html"><a href="datos-espaciles.html#mapas-interactivos"><i class="fa fa-check"></i><b>37.5</b> Mapas interactivos</a></li>
<li class="chapter" data-level="37.6" data-path="datos-espaciles.html"><a href="datos-espaciles.html#estadística-para-datos-espaciales"><i class="fa fa-check"></i><b>37.6</b> Estadística para datos espaciales</a></li>
</ul></li>
<li class="chapter" data-level="38" data-path="geo.html"><a href="geo.html"><i class="fa fa-check"></i><b>38</b> Geoestadística</a>
<ul>
<li class="chapter" data-level="38.1" data-path="geo.html"><a href="geo.html#introducción-21"><i class="fa fa-check"></i><b>38.1</b> Introducción</a></li>
<li class="chapter" data-level="38.2" data-path="geo.html"><a href="geo.html#preliminares-geo"><i class="fa fa-check"></i><b>38.2</b> Preliminares</a></li>
<li class="chapter" data-level="38.3" data-path="geo.html"><a href="geo.html#ana-estructural"><i class="fa fa-check"></i><b>38.3</b> Análisis estructural de la dependencia espacial</a>
<ul>
<li class="chapter" data-level="38.3.1" data-path="geo.html"><a href="geo.html#semivariograma"><i class="fa fa-check"></i><b>38.3.1</b> Semivariograma</a></li>
<li class="chapter" data-level="38.3.2" data-path="geo.html"><a href="geo.html#modelos-de-semivariogramas-válidos"><i class="fa fa-check"></i><b>38.3.2</b> Modelos de semivariogramas válidos</a></li>
<li class="chapter" data-level="38.3.3" data-path="geo.html"><a href="geo.html#semivariograma-empírico"><i class="fa fa-check"></i><b>38.3.3</b> Semivariograma empírico</a></li>
<li class="chapter" data-level="38.3.4" data-path="geo.html"><a href="geo.html#ajuste-semivariográfico"><i class="fa fa-check"></i><b>38.3.4</b> Ajuste semivariográfico</a></li>
</ul></li>
<li class="chapter" data-level="38.4" data-path="geo.html"><a href="geo.html#kriging"><i class="fa fa-check"></i><b>38.4</b> Kriging</a></li>
</ul></li>
<li class="chapter" data-level="39" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html"><i class="fa fa-check"></i><b>39</b> Procesos de punto</a>
<ul>
<li class="chapter" data-level="39.1" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html#spatial-point-patterns-on-mathbb-r2"><i class="fa fa-check"></i><b>39.1</b> Spatial point patterns on <span class="math inline">\(\mathbb R^2\)</span></a>
<ul>
<li class="chapter" data-level="39.1.1" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html#kernel-based-intensity-estimation"><i class="fa fa-check"></i><b>39.1.1</b> Kernel-based intensity estimation</a></li>
<li class="chapter" data-level="39.1.2" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html#practical-examples"><i class="fa fa-check"></i><b>39.1.2</b> Practical examples</a></li>
<li class="chapter" data-level="39.1.3" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html#kernel-based-intensity-estimation-over-irregular-domains"><i class="fa fa-check"></i><b>39.1.3</b> Kernel-based intensity estimation over irregular domains</a></li>
<li class="chapter" data-level="39.1.4" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html#voronoi-based-intensity-estimators"><i class="fa fa-check"></i><b>39.1.4</b> Voronoi-based intensity estimators</a></li>
<li class="chapter" data-level="39.1.5" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html#second-order-summary-statistics"><i class="fa fa-check"></i><b>39.1.5</b> Second-order summary statistics</a></li>
</ul></li>
<li class="chapter" data-level="39.2" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html#spatial-point-patterns-on-linear-networks"><i class="fa fa-check"></i><b>39.2</b> Spatial point patterns on linear networks</a></li>
</ul></li>
<li class="chapter" data-level="40" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html"><i class="fa fa-check"></i><b>40</b> Modelos econométricos espaciales</a>
<ul>
<li class="chapter" data-level="40.1" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#la-dependencia-espacial"><i class="fa fa-check"></i><b>40.1</b> La dependencia espacial </a>
<ul>
<li class="chapter" data-level="40.1.1" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#modelización-del-espacio-la-matriz-w"><i class="fa fa-check"></i><b>40.1.1</b> Modelización del espacio: La matriz W</a></li>
</ul></li>
<li class="chapter" data-level="40.2" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#medidas-de-autocorrelación"><i class="fa fa-check"></i><b>40.2</b> Medidas de Autocorrelación </a>
<ul>
<li class="chapter" data-level="40.2.1" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#el-indicador-i-de-moran"><i class="fa fa-check"></i><b>40.2.1</b> El indicador <em>I</em> de Moran</a></li>
</ul></li>
<li class="chapter" data-level="40.3" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#modelos-econométricos-espaciales-de-corte-transversal"><i class="fa fa-check"></i><b>40.3</b> Modelos econométricos espaciales de corte transversal </a>
<ul>
<li class="chapter" data-level="40.3.1" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#estimación-sar"><i class="fa fa-check"></i><b>40.3.1</b> Estimación SAR</a></li>
<li class="chapter" data-level="40.3.2" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#comparando-sar-contra-sdm"><i class="fa fa-check"></i><b>40.3.2</b> Comparando SAR contra SDM</a></li>
<li class="chapter" data-level="40.3.3" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#interpretación-de-los-estimadores-de-los-modelos-de-autocorrelación-espacial"><i class="fa fa-check"></i><b>40.3.3</b> Interpretación de los estimadores de los modelos de autocorrelación espacial </a></li>
<li class="chapter" data-level="40.3.4" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#impacto-del-sar"><i class="fa fa-check"></i><b>40.3.4</b> Impacto del SAR</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>VIII Otros tipos de datos</b></span></li>
<li class="chapter" data-level="41" data-path="mineria-textos.html"><a href="mineria-textos.html"><i class="fa fa-check"></i><b>41</b> Minería de textos</a>
<ul>
<li class="chapter" data-level="41.1" data-path="mineria-textos.html"><a href="mineria-textos.html#introducción-22"><i class="fa fa-check"></i><b>41.1</b> Introducción</a></li>
<li class="chapter" data-level="41.2" data-path="mineria-textos.html"><a href="mineria-textos.html#secCONCEPTOS"><i class="fa fa-check"></i><b>41.2</b> Conceptos y tareas fundamentales</a>
<ul>
<li class="chapter" data-level="41.2.1" data-path="mineria-textos.html"><a href="mineria-textos.html#preparación-de-los-datos"><i class="fa fa-check"></i><b>41.2.1</b> Preparación de los datos</a></li>
<li class="chapter" data-level="41.2.2" data-path="mineria-textos.html"><a href="mineria-textos.html#secTOKEN"><i class="fa fa-check"></i><b>41.2.2</b> Segmentación del texto: tokenización</a></li>
<li class="chapter" data-level="41.2.3" data-path="mineria-textos.html"><a href="mineria-textos.html#secESTILOM"><i class="fa fa-check"></i><b>41.2.3</b> Campos de aplicación de la minería de textos</a></li>
<li class="chapter" data-level="41.2.4" data-path="mineria-textos.html"><a href="mineria-textos.html#minería-de-textos-en-r"><i class="fa fa-check"></i><b>41.2.4</b> Minería de textos en <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="41.3" data-path="mineria-textos.html"><a href="mineria-textos.html#secSENTIM"><i class="fa fa-check"></i><b>41.3</b> Análisis de sentimientos</a></li>
<li class="chapter" data-level="41.4" data-path="mineria-textos.html"><a href="mineria-textos.html#caso-de-aplicación"><i class="fa fa-check"></i><b>41.4</b> Caso de aplicación</a>
<ul>
<li class="chapter" data-level="41.4.1" data-path="mineria-textos.html"><a href="mineria-textos.html#declaración-institucional-del-estado-de-alarma-2020"><i class="fa fa-check"></i><b>41.4.1</b> Declaración institucional del estado de alarma 2020</a></li>
<li class="chapter" data-level="41.4.2" data-path="mineria-textos.html"><a href="mineria-textos.html#segmentación-en-palabras-y-oraciones"><i class="fa fa-check"></i><b>41.4.2</b> Segmentación en palabras y oraciones</a></li>
<li class="chapter" data-level="41.4.3" data-path="mineria-textos.html"><a href="mineria-textos.html#análisis-exploratorio"><i class="fa fa-check"></i><b>41.4.3</b> Análisis exploratorio</a></li>
<li class="chapter" data-level="41.4.4" data-path="mineria-textos.html"><a href="mineria-textos.html#secSENTYEMO"><i class="fa fa-check"></i><b>41.4.4</b> Análisis de sentimientos y detección de emociones</a></li>
<li class="chapter" data-level="41.4.5" data-path="mineria-textos.html"><a href="mineria-textos.html#n-gramas"><i class="fa fa-check"></i><b>41.4.5</b> <em>N-gramas</em></a></li>
<li class="chapter" data-level="41.4.6" data-path="mineria-textos.html"><a href="mineria-textos.html#análisis-de-redes"><i class="fa fa-check"></i><b>41.4.6</b> Análisis de redes</a></li>
<li class="chapter" data-level="" data-path="mineria-textos.html"><a href="mineria-textos.html#resumen-11"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="42" data-path="grafos.html"><a href="grafos.html"><i class="fa fa-check"></i><b>42</b> Análisis de grafos y redes sociales</a>
<ul>
<li class="chapter" data-level="42.1" data-path="grafos.html"><a href="grafos.html#introducción-23"><i class="fa fa-check"></i><b>42.1</b> Introducción</a></li>
<li class="chapter" data-level="42.2" data-path="grafos.html"><a href="grafos.html#teoría-de-grafos"><i class="fa fa-check"></i><b>42.2</b> Teoría de grafos</a></li>
<li class="chapter" data-level="42.3" data-path="grafos.html"><a href="grafos.html#elementos-de-un-grafo"><i class="fa fa-check"></i><b>42.3</b> Elementos de un grafo</a></li>
<li class="chapter" data-level="42.4" data-path="grafos.html"><a href="grafos.html#el-paquete-igraph"><i class="fa fa-check"></i><b>42.4</b> El paquete <code>igraph</code></a></li>
<li class="chapter" data-level="42.5" data-path="grafos.html"><a href="grafos.html#análisis-de-influencia-en-un-grafo-aplicado-a-redes-sociales"><i class="fa fa-check"></i><b>42.5</b> Análisis de influencia en un grafo aplicado a redes sociales</a></li>
<li class="chapter" data-level="42.6" data-path="grafos.html"><a href="grafos.html#otras-utilidades-de-grafos"><i class="fa fa-check"></i><b>42.6</b> Otras utilidades de grafos</a></li>
</ul></li>
<li class="part"><span><b>IX Tópicos en ciencia de datos</b></span></li>
<li class="chapter" data-level="43" data-path="shiny.html"><a href="shiny.html"><i class="fa fa-check"></i><b>43</b> Aplicaciones webs interactivas con Shiny</a>
<ul>
<li class="chapter" data-level="43.1" data-path="shiny.html"><a href="shiny.html#introducción-24"><i class="fa fa-check"></i><b>43.1</b> Introducción</a></li>
<li class="chapter" data-level="43.2" data-path="shiny.html"><a href="shiny.html#partes-mínimas-de-una-aplicación-shiny-y-disposición-básica"><i class="fa fa-check"></i><b>43.2</b> Partes mínimas de una aplicación <code>Shiny</code> y disposición básica</a></li>
<li class="chapter" data-level="43.3" data-path="shiny.html"><a href="shiny.html#diseño-de-una-aplicación-shiny"><i class="fa fa-check"></i><b>43.3</b> Diseño de una aplicación <code>Shiny</code></a>
<ul>
<li class="chapter" data-level="43.3.1" data-path="shiny.html"><a href="shiny.html#diseño-de-las-páginas-fluidpage"><i class="fa fa-check"></i><b>43.3.1</b> Diseño de las páginas: fluidPage()</a></li>
<li class="chapter" data-level="43.3.2" data-path="shiny.html"><a href="shiny.html#segmentación-de-diseños-tabsetpanel-y-navlistpanel"><i class="fa fa-check"></i><b>43.3.2</b> Segmentación de diseños: tabsetPanel() y navlistPanel()</a></li>
</ul></li>
<li class="chapter" data-level="43.4" data-path="shiny.html"><a href="shiny.html#elementos-para-entrada-de-datos"><i class="fa fa-check"></i><b>43.4</b> Elementos para entrada de datos</a>
<ul>
<li class="chapter" data-level="43.4.1" data-path="shiny.html"><a href="shiny.html#lectura-de-ficheros-de-datos"><i class="fa fa-check"></i><b>43.4.1</b> Lectura de ficheros de datos</a></li>
</ul></li>
<li class="chapter" data-level="43.5" data-path="shiny.html"><a href="shiny.html#elementos-para-visualización-salida"><i class="fa fa-check"></i><b>43.5</b> Elementos para visualización (salida)</a></li>
<li class="chapter" data-level="43.6" data-path="shiny.html"><a href="shiny.html#reactividad"><i class="fa fa-check"></i><b>43.6</b> Reactividad</a>
<ul>
<li class="chapter" data-level="43.6.1" data-path="shiny.html"><a href="shiny.html#conductores-reactivos-y-control-de-la-reactividad"><i class="fa fa-check"></i><b>43.6.1</b> Conductores reactivos y control de la reactividad</a></li>
</ul></li>
<li class="chapter" data-level="43.7" data-path="shiny.html"><a href="shiny.html#publicación-de-la-aplicación-en-la-web"><i class="fa fa-check"></i><b>43.7</b> Publicación de la aplicación en la web</a></li>
<li class="chapter" data-level="43.8" data-path="shiny.html"><a href="shiny.html#extensiones-de-shiny"><i class="fa fa-check"></i><b>43.8</b> Extensiones de <code>Shiny</code></a></li>
</ul></li>
<li class="chapter" data-level="44" data-path="id_120007-informes.html"><a href="id_120007-informes.html"><i class="fa fa-check"></i><b>44</b> Informes reproducibles con R Markdown y Quarto</a>
<ul>
<li class="chapter" data-level="44.1" data-path="id_120007-informes.html"><a href="id_120007-informes.html#introducción-25"><i class="fa fa-check"></i><b>44.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="44.1.1" data-path="id_120007-informes.html"><a href="id_120007-informes.html#por-qué-informes-reproducibles"><i class="fa fa-check"></i><b>44.1.1</b> ¿Por qué informes reproducibles?</a></li>
<li class="chapter" data-level="44.1.2" data-path="id_120007-informes.html"><a href="id_120007-informes.html#markdown-r-markdown-quarto-y-rstudio"><i class="fa fa-check"></i><b>44.1.2</b> Markdown, R Markdown, Quarto y RStudio</a></li>
</ul></li>
<li class="chapter" data-level="44.2" data-path="id_120007-informes.html"><a href="id_120007-informes.html#documentos-quarto"><i class="fa fa-check"></i><b>44.2</b> Documentos Quarto</a>
<ul>
<li class="chapter" data-level="44.2.1" data-path="id_120007-informes.html"><a href="id_120007-informes.html#encabezado-yaml-y-configuración"><i class="fa fa-check"></i><b>44.2.1</b> Encabezado YAML y configuración</a></li>
<li class="chapter" data-level="44.2.2" data-path="id_120007-informes.html"><a href="id_120007-informes.html#formateado-de-texto"><i class="fa fa-check"></i><b>44.2.2</b> Formateado de texto</a></li>
<li class="chapter" data-level="44.2.3" data-path="id_120007-informes.html"><a href="id_120007-informes.html#inclusión-de-código-en-el-documento"><i class="fa fa-check"></i><b>44.2.3</b> Inclusión de código en el documento</a></li>
<li class="chapter" data-level="44.2.4" data-path="id_120007-informes.html"><a href="id_120007-informes.html#opciones-de-los-bloques-de-código-chunks"><i class="fa fa-check"></i><b>44.2.4</b> Opciones de los bloques de código (<em>chunks</em>)</a></li>
<li class="chapter" data-level="44.2.5" data-path="id_120007-informes.html"><a href="id_120007-informes.html#referencias-cruzadas-y-formateo-de-tablas"><i class="fa fa-check"></i><b>44.2.5</b> Referencias cruzadas y formateo de tablas</a></li>
</ul></li>
<li class="chapter" data-level="44.3" data-path="id_120007-informes.html"><a href="id_120007-informes.html#otros-formatos"><i class="fa fa-check"></i><b>44.3</b> Otros formatos</a></li>
</ul></li>
<li class="chapter" data-level="45" data-path="github.html"><a href="github.html"><i class="fa fa-check"></i><b>45</b> Git y GitHub en R</a>
<ul>
<li class="chapter" data-level="45.1" data-path="github.html"><a href="github.html#qué-es-git"><i class="fa fa-check"></i><b>45.1</b> ¿Qué es Git?</a></li>
<li class="chapter" data-level="45.2" data-path="github.html"><a href="github.html#qué-es-github"><i class="fa fa-check"></i><b>45.2</b> ¿Qué es GitHub?</a></li>
<li class="chapter" data-level="45.3" data-path="github.html"><a href="github.html#por-qué-usar-git-y-github"><i class="fa fa-check"></i><b>45.3</b> ¿Por qué usar Git y GitHub?</a></li>
<li class="chapter" data-level="45.4" data-path="github.html"><a href="github.html#configuración"><i class="fa fa-check"></i><b>45.4</b> Configuración</a></li>
<li class="chapter" data-level="45.5" data-path="github.html"><a href="github.html#configurar-git"><i class="fa fa-check"></i><b>45.5</b> Configurar git</a></li>
<li class="chapter" data-level="45.6" data-path="github.html"><a href="github.html#workflow"><i class="fa fa-check"></i><b>45.6</b> Workflow</a></li>
</ul></li>
<li class="chapter" data-level="46" data-path="cap-geoprocesamiento.html"><a href="cap-geoprocesamiento.html"><i class="fa fa-check"></i><b>46</b> Geoprocesamiento en nube</a>
<ul>
<li class="chapter" data-level="46.1" data-path="cap-geoprocesamiento.html"><a href="cap-geoprocesamiento.html#sintaxis-de-google-earth-engine"><i class="fa fa-check"></i><b>46.1</b> Sintaxis de Google Earth Engine</a></li>
<li class="chapter" data-level="46.2" data-path="cap-geoprocesamiento.html"><a href="cap-geoprocesamiento.html#primeros-pasos"><i class="fa fa-check"></i><b>46.2</b> Primeros pasos</a></li>
<li class="chapter" data-level="46.3" data-path="cap-geoprocesamiento.html"><a href="cap-geoprocesamiento.html#cálculo-de-anomalias"><i class="fa fa-check"></i><b>46.3</b> Cálculo de anomalias</a>
<ul>
<li class="chapter" data-level="46.3.1" data-path="cap-geoprocesamiento.html"><a href="cap-geoprocesamiento.html#definiciones-previas"><i class="fa fa-check"></i><b>46.3.1</b> Definiciones previas</a></li>
<li class="chapter" data-level="46.3.2" data-path="cap-geoprocesamiento.html"><a href="cap-geoprocesamiento.html#promedio-estival"><i class="fa fa-check"></i><b>46.3.2</b> Promedio estival</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>X Casos de estudio en ciencia de datos</b></span></li>
<li class="chapter" data-level="47" data-path="cap-crimen.html"><a href="cap-crimen.html"><i class="fa fa-check"></i><b>47</b> Análisis de una red criminal</a>
<ul>
<li class="chapter" data-level="47.1" data-path="cap-crimen.html"><a href="cap-crimen.html#el-dataset-oversize"><i class="fa fa-check"></i><b>47.1</b> El <em>dataset Oversize</em></a></li>
<li class="chapter" data-level="47.2" data-path="cap-crimen.html"><a href="cap-crimen.html#creación-del-grafo"><i class="fa fa-check"></i><b>47.2</b> Creación del grafo</a></li>
<li class="chapter" data-level="47.3" data-path="cap-crimen.html"><a href="cap-crimen.html#visualización-del-grafo"><i class="fa fa-check"></i><b>47.3</b> Visualización del grafo</a></li>
<li class="chapter" data-level="47.4" data-path="cap-crimen.html"><a href="cap-crimen.html#importancia-de-los-actores"><i class="fa fa-check"></i><b>47.4</b> Importancia de los actores</a></li>
<li class="chapter" data-level="47.5" data-path="cap-crimen.html"><a href="cap-crimen.html#identificación-de-comunidades"><i class="fa fa-check"></i><b>47.5</b> Identificación de comunidades</a></li>
<li class="chapter" data-level="47.6" data-path="cap-crimen.html"><a href="cap-crimen.html#visualización-de-comunidades"><i class="fa fa-check"></i><b>47.6</b> Visualización de comunidades</a></li>
</ul></li>
<li class="chapter" data-level="48" data-path="cap-publidiad.html"><a href="cap-publidiad.html"><i class="fa fa-check"></i><b>48</b> Optimizando las inversiones publicitarias a través de ciencia de datos</a>
<ul>
<li class="chapter" data-level="48.1" data-path="cap-publidiad.html"><a href="cap-publidiad.html#metodologías-para-optimizar-las-inversiones-publicitarias"><i class="fa fa-check"></i><b>48.1</b> Metodologías para optimizar las inversiones publicitarias</a></li>
<li class="chapter" data-level="48.2" data-path="cap-publidiad.html"><a href="cap-publidiad.html#robyn-como-alternativa-open-source-en-r"><i class="fa fa-check"></i><b>48.2</b> Robyn como alternativa open-source en R</a></li>
</ul></li>
<li class="chapter" data-level="49" data-path="paro-clm.html"><a href="paro-clm.html"><i class="fa fa-check"></i><b>49</b> Cambios en la estructura del paro registrado en Castilla-La Mancha</a>
<ul>
<li class="chapter" data-level="49.1" data-path="paro-clm.html"><a href="paro-clm.html#planteamiento"><i class="fa fa-check"></i><b>49.1</b> Planteamiento</a></li>
<li class="chapter" data-level="49.2" data-path="paro-clm.html"><a href="paro-clm.html#evolución-del-número-total-de-parados"><i class="fa fa-check"></i><b>49.2</b> Evolución del número total de parados</a></li>
<li class="chapter" data-level="49.3" data-path="paro-clm.html"><a href="paro-clm.html#evolución-de-la-edad-y-el-sexo-en-la-población-parada"><i class="fa fa-check"></i><b>49.3</b> Evolución de la edad y el sexo en la población parada</a></li>
<li class="chapter" data-level="49.4" data-path="paro-clm.html"><a href="paro-clm.html#evolución-del-tiempo-de-búsqueda-de-empleo-en-la-población-parada"><i class="fa fa-check"></i><b>49.4</b> Evolución del tiempo de búsqueda de empleo en la población parada</a></li>
<li class="chapter" data-level="49.5" data-path="paro-clm.html"><a href="paro-clm.html#evolución-del-paro-registrado-según-sexo-edad-y-sector-de-procedencia"><i class="fa fa-check"></i><b>49.5</b> Evolución del paro registrado según sexo, edad y sector de procedencia</a></li>
<li class="chapter" data-level="49.6" data-path="paro-clm.html"><a href="paro-clm.html#conclusiones"><i class="fa fa-check"></i><b>49.6</b> Conclusiones</a></li>
</ul></li>
<li class="chapter" data-level="50" data-path="cap-rfm.html"><a href="cap-rfm.html"><i class="fa fa-check"></i><b>50</b> Segmentación de clientes en retail</a>
<ul>
<li class="chapter" data-level="50.1" data-path="cap-rfm.html"><a href="cap-rfm.html#motivación-y-conceptos-clave"><i class="fa fa-check"></i><b>50.1</b> Motivación y conceptos clave</a></li>
<li class="chapter" data-level="50.2" data-path="cap-rfm.html"><a href="cap-rfm.html#del-modelo-rfm-tradicional-al-modelo-rfm-extendido-mejoras-propuestas"><i class="fa fa-check"></i><b>50.2</b> Del Modelo RFM tradicional al Modelo RFM extendido, mejoras propuestas</a></li>
<li class="chapter" data-level="50.3" data-path="cap-rfm.html"><a href="cap-rfm.html#modelo-rfm-extendido"><i class="fa fa-check"></i><b>50.3</b> Modelo RFM extendido</a>
<ul>
<li class="chapter" data-level="50.3.1" data-path="cap-rfm.html"><a href="cap-rfm.html#recopilación-y-comprensión-de-los-datos"><i class="fa fa-check"></i><b>50.3.1</b> Recopilación y comprensión de los datos</a></li>
<li class="chapter" data-level="50.3.2" data-path="cap-rfm.html"><a href="cap-rfm.html#cálculo-de-las-variables-del-modelo-rfm"><i class="fa fa-check"></i><b>50.3.2</b> Cálculo de las variables del Modelo RFM</a></li>
<li class="chapter" data-level="50.3.3" data-path="cap-rfm.html"><a href="cap-rfm.html#breve-análisis-exploratorio-de-las-variables-del-modelo-rfm"><i class="fa fa-check"></i><b>50.3.3</b> Breve análisis exploratorio de las variables del Modelo RFM</a></li>
<li class="chapter" data-level="50.3.4" data-path="cap-rfm.html"><a href="cap-rfm.html#cálculo-del-ranking-de-percentiles"><i class="fa fa-check"></i><b>50.3.4</b> Cálculo del Ranking de percentiles</a></li>
<li class="chapter" data-level="50.3.5" data-path="cap-rfm.html"><a href="cap-rfm.html#modelado-rfm-mediante-k-means"><i class="fa fa-check"></i><b>50.3.5</b> Modelado: RFM mediante k-means</a></li>
<li class="chapter" data-level="50.3.6" data-path="cap-rfm.html"><a href="cap-rfm.html#descriptivos-e-interpretación-de-los-segmentos"><i class="fa fa-check"></i><b>50.3.6</b> Descriptivos e interpretación de los segmentos</a></li>
<li class="chapter" data-level="50.3.7" data-path="cap-rfm.html"><a href="cap-rfm.html#puesta-en-producción"><i class="fa fa-check"></i><b>50.3.7</b> Puesta en producción</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="51" data-path="cap-medicina.html"><a href="cap-medicina.html"><i class="fa fa-check"></i><b>51</b> Ciencia de datos en medicina</a>
<ul>
<li class="chapter" data-level="51.1" data-path="cap-medicina.html"><a href="cap-medicina.html#justificación"><i class="fa fa-check"></i><b>51.1</b> Justificación</a></li>
<li class="chapter" data-level="51.2" data-path="cap-medicina.html"><a href="cap-medicina.html#mecovid"><i class="fa fa-check"></i><b>51.2</b> MeCOVID</a>
<ul>
<li class="chapter" data-level="51.2.1" data-path="cap-medicina.html"><a href="cap-medicina.html#artículos-de-investigación"><i class="fa fa-check"></i><b>51.2.1</b> Artículos de investigación</a></li>
<li class="chapter" data-level="51.2.2" data-path="cap-medicina.html"><a href="cap-medicina.html#análisis-de-supervivencia"><i class="fa fa-check"></i><b>51.2.2</b> Análisis de supervivencia</a></li>
</ul></li>
<li class="chapter" data-level="51.3" data-path="cap-medicina.html"><a href="cap-medicina.html#conclusión"><i class="fa fa-check"></i><b>51.3</b> Conclusión</a></li>
</ul></li>
<li class="chapter" data-level="52" data-path="cap-idealista.html"><a href="cap-idealista.html"><i class="fa fa-check"></i><b>52</b> Valoración del precio de la vivienda, una aproximación espacial bayesiana</a>
<ul>
<li class="chapter" data-level="52.1" data-path="cap-idealista.html"><a href="cap-idealista.html#introducción-26"><i class="fa fa-check"></i><b>52.1</b> Introducción</a></li>
<li class="chapter" data-level="52.2" data-path="cap-idealista.html"><a href="cap-idealista.html#conjunto-de-datos"><i class="fa fa-check"></i><b>52.2</b> Conjunto de datos</a></li>
<li class="chapter" data-level="52.3" data-path="cap-idealista.html"><a href="cap-idealista.html#estimación-del-modelo-1"><i class="fa fa-check"></i><b>52.3</b> Estimación del Modelo</a></li>
</ul></li>
<li class="chapter" data-level="53" data-path="cap-climatico.html"><a href="cap-climatico.html"><i class="fa fa-check"></i><b>53</b> Lo que nos cuentan los datos sobre el cambio climático</a>
<ul>
<li class="chapter" data-level="53.1" data-path="cap-climatico.html"><a href="cap-climatico.html#consideraciones-iniciales"><i class="fa fa-check"></i><b>53.1</b> Consideraciones iniciales</a></li>
<li class="chapter" data-level="53.2" data-path="cap-climatico.html"><a href="cap-climatico.html#paquetes"><i class="fa fa-check"></i><b>53.2</b> Paquetes</a></li>
<li class="chapter" data-level="53.3" data-path="cap-climatico.html"><a href="cap-climatico.html#visualización-de-mapas-de-pequeños-múltiples"><i class="fa fa-check"></i><b>53.3</b> Visualización de mapas de pequeños múltiples</a>
<ul>
<li class="chapter" data-level="53.3.1" data-path="cap-climatico.html"><a href="cap-climatico.html#datos"><i class="fa fa-check"></i><b>53.3.1</b> Datos</a></li>
<li class="chapter" data-level="53.3.2" data-path="cap-climatico.html"><a href="cap-climatico.html#preparar-los-datos"><i class="fa fa-check"></i><b>53.3.2</b> Preparar los datos</a></li>
<li class="chapter" data-level="53.3.3" data-path="cap-climatico.html"><a href="cap-climatico.html#construir-el-gráfico-de-múltiples-mapas"><i class="fa fa-check"></i><b>53.3.3</b> Construir el gráfico de múltiples mapas</a></li>
<li class="chapter" data-level="53.3.4" data-path="cap-climatico.html"><a href="cap-climatico.html#mapa-de-orientación"><i class="fa fa-check"></i><b>53.3.4</b> Mapa de orientación</a></li>
<li class="chapter" data-level="53.3.5" data-path="cap-climatico.html"><a href="cap-climatico.html#exportar-mapa-final"><i class="fa fa-check"></i><b>53.3.5</b> Exportar mapa final</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="54" data-path="cap-ree.html"><a href="cap-ree.html"><i class="fa fa-check"></i><b>54</b> Predicción de demanda eléctrica con deep learning</a>
<ul>
<li class="chapter" data-level="54.1" data-path="cap-ree.html"><a href="cap-ree.html#motivación-1"><i class="fa fa-check"></i><b>54.1</b> Motivación</a></li>
<li class="chapter" data-level="54.2" data-path="cap-ree.html"><a href="cap-ree.html#datos-de-entrada"><i class="fa fa-check"></i><b>54.2</b> Datos de entrada</a></li>
<li class="chapter" data-level="54.3" data-path="cap-ree.html"><a href="cap-ree.html#caso-de-estudio"><i class="fa fa-check"></i><b>54.3</b> Caso de estudio</a></li>
</ul></li>
<li class="chapter" data-level="55" data-path="implementación-de-un-sistema-experto-en-el-ámbito-pediátrico.html"><a href="implementación-de-un-sistema-experto-en-el-ámbito-pediátrico.html"><i class="fa fa-check"></i><b>55</b> Implementación de un sistema experto en el ámbito pediátrico</a>
<ul>
<li class="chapter" data-level="55.1" data-path="implementación-de-un-sistema-experto-en-el-ámbito-pediátrico.html"><a href="implementación-de-un-sistema-experto-en-el-ámbito-pediátrico.html#introducción-27"><i class="fa fa-check"></i><b>55.1</b> Introducción</a></li>
<li class="chapter" data-level="55.2" data-path="implementación-de-un-sistema-experto-en-el-ámbito-pediátrico.html"><a href="implementación-de-un-sistema-experto-en-el-ámbito-pediátrico.html#marco-teórico"><i class="fa fa-check"></i><b>55.2</b> Marco teórico</a>
<ul>
<li class="chapter" data-level="55.2.1" data-path="implementación-de-un-sistema-experto-en-el-ámbito-pediátrico.html"><a href="implementación-de-un-sistema-experto-en-el-ámbito-pediátrico.html#razonamiento"><i class="fa fa-check"></i><b>55.2.1</b> Razonamiento</a></li>
</ul></li>
<li class="chapter" data-level="55.3" data-path="implementación-de-un-sistema-experto-en-el-ámbito-pediátrico.html"><a href="implementación-de-un-sistema-experto-en-el-ámbito-pediátrico.html#sistema-experto-para-el-ámbito-pediátrico-en-atención-primaria"><i class="fa fa-check"></i><b>55.3</b> Sistema experto para el ámbito pediátrico en atención primaria</a></li>
</ul></li>
<li class="chapter" data-level="56" data-path="procesamiento-del-lenguaje-natural-para-identificar-tendencias-de-moda-en-textil.html"><a href="procesamiento-del-lenguaje-natural-para-identificar-tendencias-de-moda-en-textil.html"><i class="fa fa-check"></i><b>56</b> Procesamiento del lenguaje natural para identificar tendencias de moda en textil</a></li>
<li class="chapter" data-level="57" data-path="cap-fraude.html"><a href="cap-fraude.html"><i class="fa fa-check"></i><b>57</b> Dectectando el fraude en tarjetas de crédito</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="divider"></li>
<li><a href="https://cdr-book.github.io/"> Ciencia de datos con R </a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Ciencia de datos con R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="cap-sparse" class="section level1 hasAnchor" number="18">
<h1><span class="header-section-number">Capítulo 18</span> Modelos sparse y métodos penalizados de regresión<a href="cap-sparse.html#cap-sparse" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><em>María Durbán</em></p>
<div id="introducción-7" class="section level2 hasAnchor" number="18.1">
<h2><span class="header-section-number">18.1</span> Introducción<a href="cap-sparse.html#introducción-7" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El modelo de regresión lineal múltiple: <span class="math inline">\(y=\beta_0+\beta_1 X_1+\ldots + \beta_pX_p+\varepsilon,\)</span> visto en el Capítulo 16, a pesar de su simplicidad, tiene importantes ventajas como la <strong>interpretabilidad</strong> y su buen poder <strong>predictivo</strong> en muchas situaciones.</p>
<p>En este Capítulo se va a ver cómo se puede hacer el modelo más interpretable y mejor predictor, y para conseguirlo se reemplazará el método de mínimos cuadrados (utilizado hasta ahora para la estimación de los parámetros) por un método alternativo.</p>
<p>Por lo tanto el objetivo de este Capítulo aprender técnicas para mejorar:</p>
<ul>
<li><strong>Precisión de la predicción:</strong> en particular cuando el número de variables es mayor que el número de observaciones: <span class="math inline">\(p&gt;n\)</span> (algo que ocurre con mucha frecuencia hoy en día). En este caso no se pueden utilizar mínimos cuadrados ya que la matriz de diseño no es de rango completo, y por lo tanto, no se puede encontrar una solución al problema de minimización. Por lo tanto, se necesita reducir el número de variables, que además, evitará que se sobreajusten los datos.</li>
<li><strong>Interpretabilidad del modelo:</strong> Al eliminar las variables irrelevantes (es decir, haciendo cero los correspondientes coeficientes) se obtendrá un modelo que es más fácil de interpretar. Por lo tanto, se presentarán varios métodos para llevar a cabo de forma automática la <em>selección de variables</em>.</li>
</ul>
<p>Los métodos para reducir el número de variables en el modelo serían:</p>
<ul>
<li><strong>Selección del mejor subconjunto:</strong> Su objetivo es identificar un subconjunto de entre los <span class="math inline">\(p\)</span> predictores que se considera que son los que están relacionados con la variable respuesta.</li>
<li><strong>Shrinkage:</strong> En este caso no se quieren seleccionar variables explícitamente, sino que se añade una penalización que penaliza el número de coeficientes o su tamaño.</li>
<li><strong>Reducción de la dimensión:</strong> El objetivo es proyectar los <span class="math inline">\(p\)</span>-predictores en un subespacio de dimensión más pequeña (mediante el uso de combinaciones lineales de variables, las cuales se usarán como predictores. Esto es lo que se llama <em>Componentes principales</em> que se desarrolla en el Capítulo 11.</li>
</ul>
<p>Por lo tanto, en este Capítulo se ven los dos primeros métodos.</p>
</div>
<div id="selección-del-mejor-subconjunto" class="section level2 hasAnchor" number="18.2">
<h2><span class="header-section-number">18.2</span> Selección del mejor subconjunto<a href="cap-sparse.html#selección-del-mejor-subconjunto" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Supóngase que se tiene acceso a <span class="math inline">\(p\)</span> variables predictoras, pero se quiere un modelo más simple que involucre solo a un subconjunto de esos <span class="math inline">\(p\)</span> predictores. La forma lógica de conseguirlo es considerar todos los posibles subconjuntos de los <span class="math inline">\(p\)</span> predictores y elegir el mejor modelo de entre todos los modelos calculados con cada uno de los subconjuntos de variables. Los pasos a seguir serían:</p>
<ol style="list-style-type: decimal">
<li>Se crea el modelo <strong>nulo</strong>, <span class="math inline">\(M_0\)</span>, que es aquel que solo contiene la ordenada en el origen y ningún predictor. Este modelo simplemente predice la media muestral para cada observación</li>
<li>Para cada valor de <span class="math inline">\(k=1,2,\ldots , p\)</span> se calcula los <span class="math inline">\(\binom{p}{k}\)</span> modelos que contienen <span class="math inline">\(k\)</span> predictores. Es decir los <span class="math inline">\(p\)</span> modelos que contienen 1 predictor, los <span class="math inline">\(p\times (p-1)/2\)</span> modelos que contienen 2 predictores, etc.</li>
<li>Para cada valor de <span class="math inline">\(k\)</span>, se elige el mejor entre los <span class="math inline">\(\binom{p}{k}=\frac{p!}{(p-k)!k!}\)</span> posibles modelos y se denota por <span class="math inline">\(M_k\)</span>. Es decir <span class="math inline">\(M_1\)</span> sería el mejor modelo entre los <span class="math inline">\(p\)</span> modelos con una sola variable, <span class="math inline">\(M_2\)</span> sería el mejor modelo entre los modelos con dos variables, etc. En este caso el <strong>mejor</strong> modelo sería aquel cuyo <span class="math inline">\(RSS\)</span> (suma de residuos al cuadrado) sea menor, o equivalentemente, aquel cuyo <span class="math inline">\(R^2\)</span> es mayor.</li>
<li>Elegir entre los modelos: <span class="math inline">\(M_1,\ldots ,M_p\)</span> aquel que es mejor utilizando una criterio como AIC, BIC o <span class="math inline">\(R^2\)</span> ajustado.</li>
</ol>
<p>Este método se puede usar también en el caso de GLMs, en cuyo caso se usará el <em>deviance</em> en vez de <span class="math inline">\(RSS\)</span>.</p>
<div id="ejemplo-sueldo-de-jugadores-de-béisbol" class="section level3 hasAnchor" number="18.2.1">
<h3><span class="header-section-number">18.2.1</span> Ejemplo: Sueldo de jugadores de béisbol<a href="cap-sparse.html#ejemplo-sueldo-de-jugadores-de-béisbol" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Se va a aplicar el método descrito al conjunto de datos <code>Hitters</code> del paquete <code>ISRL2</code>. El objetivo es predecir el sueldo, <code>Salary</code>, de jugadores de béisbol a partir de varias variables asociadas con su rendimiento el año anterior.</p>
<p>La variable <code>Salary</code> no está disponible para alguno de los jugadores, se pueden identificar utilizando la función <code>is.na()</code>. Y la función <code>sum()</code> permite ver cuántas hay. Se utilizará <code>na.omit()</code> para eliminarlas</p>
<div class="sourceCode" id="cb216"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb216-1"><a href="cap-sparse.html#cb216-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ISLR2)</span>
<span id="cb216-2"><a href="cap-sparse.html#cb216-2" aria-hidden="true" tabindex="-1"></a>Hitters <span class="ot">&lt;-</span> <span class="fu">na.omit</span>(Hitters)</span></code></pre></div>
<p>La función <code>regsubsets()</code> del paquete <code>leaps()</code> lleva a cabo la selección del mejor subconjunto de variables identificando el mejor modelo que contiene un número dado de variables (1,2,3, etc.) atendiendo a <span class="math inline">\(RSS\)</span>. La sintaxis usada es similar a la de la función <code>lm()</code>.</p>
<div class="sourceCode" id="cb217"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb217-1"><a href="cap-sparse.html#cb217-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(leaps)</span>
<span id="cb217-2"><a href="cap-sparse.html#cb217-2" aria-hidden="true" tabindex="-1"></a>regfit.full <span class="ot">&lt;-</span> <span class="fu">regsubsets</span>(Salary <span class="sc">~</span> ., Hitters)</span></code></pre></div>
<p>Los resultados se pueden ver usando <code>summary()</code> donde se muestra el mejor modelo para cada subconjunto de variables. Con un asterisco indica las variables incluidas en cada modelo. Por ejemplo, el mejor modelo con dos variables incluye <code>Hits</code> y <code>CRBI</code>.
Por defecto, <code>regsubsets()</code> solo muestra los resultados de los modelos que contienen hasta ocho variables. La opción <code>nvmax</code> se puede usar para incrementar esta cantidad, por ejemplo hasta 19 variables (que es el número de variables predictoras en el conjunto de datos):</p>
<div class="sourceCode" id="cb218"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb218-1"><a href="cap-sparse.html#cb218-1" aria-hidden="true" tabindex="-1"></a>regfit.full <span class="ot">&lt;-</span> <span class="fu">regsubsets</span>(Salary <span class="sc">~</span> .,</span>
<span id="cb218-2"><a href="cap-sparse.html#cb218-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> Hitters,</span>
<span id="cb218-3"><a href="cap-sparse.html#cb218-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">nvmax =</span> <span class="dv">19</span></span>
<span id="cb218-4"><a href="cap-sparse.html#cb218-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb218-5"><a href="cap-sparse.html#cb218-5" aria-hidden="true" tabindex="-1"></a>reg.summary <span class="ot">&lt;-</span> <span class="fu">summary</span>(regfit.full)</span></code></pre></div>
<p>La función <code>summary()</code> devuelve diferentes medias de bondad de ajuste <span class="math inline">\(R^2\)</span>, <span class="math inline">\(RSS\)</span>, <span class="math inline">\(R^2\)</span> ajustado, <span class="math inline">\(C_p\)</span> y <span class="math inline">\(BIC\)</span>. Se utiliza esta información para elegir el <em>mejor</em> de entre todos los modelos.</p>
<div class="sourceCode" id="cb219"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb219-1"><a href="cap-sparse.html#cb219-1" aria-hidden="true" tabindex="-1"></a><span class="fu">names</span>(reg.summary)</span>
<span id="cb219-2"><a href="cap-sparse.html#cb219-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] &quot;which&quot;  &quot;rsq&quot;    &quot;rss&quot;    &quot;adjr2&quot;  &quot;cp&quot;     &quot;bic&quot;    &quot;outmat&quot; &quot;obj&quot;</span></span>
<span id="cb219-3"><a href="cap-sparse.html#cb219-3" aria-hidden="true" tabindex="-1"></a>reg.summary<span class="sc">$</span>adjr2</span>
<span id="cb219-4"><a href="cap-sparse.html#cb219-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] 0.3188503 0.4208024 0.4450753 0.4672734 0.4808971 0.4972001 0.5007849</span></span>
<span id="cb219-5"><a href="cap-sparse.html#cb219-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [8] 0.5137083 0.5180572 0.5222606 0.5225706 0.5217245 0.5206736 0.5195431</span></span>
<span id="cb219-6"><a href="cap-sparse.html#cb219-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [15] 0.5178661 0.5162219 0.5144464 0.5126097 0.5106270</span></span></code></pre></div>
<p>Por ejemplo el <span class="math inline">\(R^2\)</span> ajustado mayor corresponde al modelo con 11 variables. Se pueden también visualizar los resultados y dibujar simultáneamente por ejemplo, los valores de <span class="math inline">\(RSS\)</span>, y <span class="math inline">\(R^2\)</span> ajustado de todos los modelos.</p>
<p><img src="Ciencia_de_datos_con_r_files/figure-html/chunk7-1.png" width="60%" style="display: block; margin: auto;" /></p>
<p>Otra manera de visualizar los resultados es:</p>
<div class="sourceCode" id="cb220"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb220-1"><a href="cap-sparse.html#cb220-1" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb220-2"><a href="cap-sparse.html#cb220-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(regfit.full, <span class="at">scale =</span> <span class="st">&quot;adjr2&quot;</span>)</span></code></pre></div>
<p><img src="Ciencia_de_datos_con_r_files/figure-html/chunk10-1.png" width="60%" style="display: block; margin: auto;" /></p>
<p>La primera fila tiene un cuadrado negro en cada una de las variables elegidas de acuerdo al modelo con mayor <span class="math inline">\(R^2\)</span> ajustado (en este caso, sería similar para los otros criterios).</p>
<p>En este caso, varios modelos tienen un valor de <span class="math inline">\(R^2\)</span> ajustado próximo a <span class="math inline">\(0.52\)</span>, pero es el modelo con 11 variables, el que alcanza el mayor valor. La función <code>coef()</code> permite ver los coeficientes estimados de este modelo.</p>
<div class="sourceCode" id="cb221"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb221-1"><a href="cap-sparse.html#cb221-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(regfit.full, <span class="dv">11</span>)</span>
<span id="cb221-2"><a href="cap-sparse.html#cb221-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  (Intercept)        AtBat         Hits        Walks       CAtBat        CRuns </span></span>
<span id="cb221-3"><a href="cap-sparse.html#cb221-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  135.7512195   -2.1277482    6.9236994    5.6202755   -0.1389914    1.4553310 </span></span>
<span id="cb221-4"><a href="cap-sparse.html#cb221-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;         CRBI       CWalks      LeagueN    DivisionW      PutOuts      Assists </span></span>
<span id="cb221-5"><a href="cap-sparse.html#cb221-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    0.7852528   -0.8228559   43.1116152 -111.1460252    0.2894087    0.2688277</span></span></code></pre></div>
</div>
</div>
<div id="selección-stepwise" class="section level2 hasAnchor" number="18.3">
<h2><span class="header-section-number">18.3</span> Selección <em>Stepwise</em><a href="cap-sparse.html#selección-stepwise" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Cuando el número de variables predictoras, <span class="math inline">\(p\)</span>, es grande, el método anterior es computacionalmente muy costoso ya que el número de posibles combinaciones de variables crece de una manera alarmante. En general, la función <code>regsubset</code> puede lidiar con hasta 30-40 variables predictoras. Además otro problema es el sobre-ajuste. Si se tienen 40 variables, se estarían ajustando millones de modelos, y puede que el modelo elegido funcione muy bien en los datos utilizados para su construcción, pero no tan bien en un nuevo conjunto de datos. Una alternativa es el método <strong>stepwise</strong>.
La idea detrás de este método es similar a la anterior, pero solo se mira un conjunto mucho más pequeño de modelos.</p>
<p>Hay dos posibilidades de hacer stepwise: <strong>forward</strong> y <strong>backward</strong>. Ambas son bastante similares, la principal diferencia es el modelo del que se parte: del modelo sin ninguna variable predictora o del modelo con todas ellas</p>
<div id="forward-stepwise" class="section level3 hasAnchor" number="18.3.1">
<h3><span class="header-section-number">18.3.1</span> Forward stepwise<a href="cap-sparse.html#forward-stepwise" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En este caso se comienza con el modelo <em>nulo</em>, <span class="math inline">\(M_0\)</span> y se van añadiendo variables secuencialmente. En particular, en cada paso (<em>step</em>) la variable que proporciona la mayor mejora al ajuste es la que se añade al modelo. Los pasos a seguir serían:</p>
<ol style="list-style-type: decimal">
<li>Se crea el modelo <strong>nulo</strong>, <span class="math inline">\(M_0\)</span>.</li>
<li>Para cada valor de <span class="math inline">\(k=0,1,2,\ldots , p\)</span>:
<ol style="list-style-type: lower-roman">
<li>Se consideran todos los <span class="math inline">\(p-k\)</span> modelos que surgen de aumentar el modelo <span class="math inline">\(M_k\)</span> con un predictor.</li>
<li>Se elige el <strong>mejor</strong> de esos <span class="math inline">\(p-k\)</span> modelos, que se denotará <span class="math inline">\(M_{k+1}\)</span>. Donde <strong>mejor</strong> significa tener el <span class="math inline">\(RSS\)</span> más bajo o el <span class="math inline">\(R^2\)</span> más alto</li>
</ol></li>
<li>Se elige entre los modelos: <span class="math inline">\(M_0,\ldots ,M_p\)</span> aquel que es mejor utilizando una criterio como AIC, BIC o <span class="math inline">\(R^2\)</span> ajustado.</li>
</ol>
<p>Este enfoque tiene ventajas computacionales claras, ya que el número de modelos ajustados es mucho menor, pero no garantiza que el modelo elegido sea el mejor modelo posible, especialmente si existe correlación entre las variables predictoras.</p>
</div>
<div id="backward-stepwise" class="section level3 hasAnchor" number="18.3.2">
<h3><span class="header-section-number">18.3.2</span> Backward stepwise<a href="cap-sparse.html#backward-stepwise" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En este caso se comienza con el modelo que incluye todas (<span class="math inline">\(p\)</span>) las variables predictoras y se van eliminando de forma iterativa hasta llegar al modelo nulo (<span class="math inline">\(M_0\)</span>). Los pasos serían:</p>
<ol style="list-style-type: decimal">
<li>Se ajusta el modelo, <span class="math inline">\(M_p\)</span>, que contiene todas (<span class="math inline">\(p\)</span>) las variable predictoras</li>
<li>Para cada valor de <span class="math inline">\(k=p,p-1,\ldots , 1\)</span>:
<ol style="list-style-type: lower-roman">
<li>Se consideran todos los <span class="math inline">\(k\)</span> modelos que surgen de reducir en el modelo <span class="math inline">\(M_k\)</span> un predictor, es decir, modelos con <span class="math inline">\(k-1\)</span> variables predictoras.</li>
<li>Se elige el <strong>mejor</strong> de esos <span class="math inline">\(k\)</span> modelos, que se denotará <span class="math inline">\(M_{k-1}\)</span>. Donde <strong>mejor</strong> significa tener el <span class="math inline">\(RSS\)</span> más bajo o el <span class="math inline">\(R^2\)</span> más alto</li>
</ol></li>
<li>Se elige entre los modelos: <span class="math inline">\(M_0,\ldots ,M_p\)</span> aquel que es mejor utilizando una criterio como AIC, BIC o <span class="math inline">\(R^2\)</span> ajustado.</li>
</ol>
<p>Tanto en el caso de forward como backward stepwise, se busca el mejor modelo sólo entre <span class="math inline">\(1+p(p+1)/2\)</span> modelos, lo que permite su uso cuando <span class="math inline">\(p\)</span> es demasiado grande para seleccionarlos mediante la búsqueda del mejor subconjunto.</p>
<p>El método backward necesita que el número de observaciones <span class="math inline">\(n\)</span> sea mayor que el de variables predictoras <span class="math inline">\(p\)</span> (ya que se necesita ajustar el modelo con todas las variables). Por el contrario, el método forward se puede usar incluso cuando <span class="math inline">\(n&lt;p\)</span></p>
</div>
<div id="ejemplo-sueldo-de-jugadores-de-béisbol-1" class="section level3 hasAnchor" number="18.3.3">
<h3><span class="header-section-number">18.3.3</span> Ejemplo: Sueldo de jugadores de béisbol<a href="cap-sparse.html#ejemplo-sueldo-de-jugadores-de-béisbol-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La función <code>regsubset</code> permite utilizar el método backward y forward, usando el argumento <code>method = "forward"</code>
o <code>method = "backward"</code></p>
<div class="sourceCode" id="cb222"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb222-1"><a href="cap-sparse.html#cb222-1" aria-hidden="true" tabindex="-1"></a>regfit.fwd <span class="ot">&lt;-</span> <span class="fu">regsubsets</span>(Salary <span class="sc">~</span> .,</span>
<span id="cb222-2"><a href="cap-sparse.html#cb222-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> Hitters,</span>
<span id="cb222-3"><a href="cap-sparse.html#cb222-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">nvmax =</span> <span class="dv">19</span>, <span class="at">method =</span> <span class="st">&quot;forward&quot;</span></span>
<span id="cb222-4"><a href="cap-sparse.html#cb222-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb222-5"><a href="cap-sparse.html#cb222-5" aria-hidden="true" tabindex="-1"></a>regfit.bwd <span class="ot">&lt;-</span> <span class="fu">regsubsets</span>(Salary <span class="sc">~</span> .,</span>
<span id="cb222-6"><a href="cap-sparse.html#cb222-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> Hitters,</span>
<span id="cb222-7"><a href="cap-sparse.html#cb222-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">nvmax =</span> <span class="dv">19</span>, <span class="at">method =</span> <span class="st">&quot;backward&quot;</span></span>
<span id="cb222-8"><a href="cap-sparse.html#cb222-8" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>A continuación se ve como, por ejemplo, para el caso del mejor modelo con 2 variables los tres métodos: mejor subconjunto, forward y backward dan lugar conjuntos de variables diferentes</p>
<div class="sourceCode" id="cb223"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb223-1"><a href="cap-sparse.html#cb223-1" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(regfit.full, <span class="dv">2</span>)</span>
<span id="cb223-2"><a href="cap-sparse.html#cb223-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; (Intercept)        Hits        CRBI </span></span>
<span id="cb223-3"><a href="cap-sparse.html#cb223-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; -47.9559022   3.3008446   0.6898994</span></span>
<span id="cb223-4"><a href="cap-sparse.html#cb223-4" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(regfit.fwd, <span class="dv">2</span>)</span>
<span id="cb223-5"><a href="cap-sparse.html#cb223-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; (Intercept)        Hits        CRBI </span></span>
<span id="cb223-6"><a href="cap-sparse.html#cb223-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; -47.9559022   3.3008446   0.6898994</span></span>
<span id="cb223-7"><a href="cap-sparse.html#cb223-7" aria-hidden="true" tabindex="-1"></a><span class="fu">coef</span>(regfit.bwd, <span class="dv">2</span>)</span>
<span id="cb223-8"><a href="cap-sparse.html#cb223-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; (Intercept)        Hits       CRuns </span></span>
<span id="cb223-9"><a href="cap-sparse.html#cb223-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; -50.8174029   3.2257212   0.6614168</span></span></code></pre></div>
<p>Hay que decidir un criterio para elegir el mejor modelo: <span class="math inline">\(R^2\)</span> ajustado, <span class="math inline">\(BIC\)</span>, etc. Si se usa <span class="math inline">\(R^2\)</span> ajustado, en ambos casos el mejor modelo es el que tiene 11 variables:</p>
<div class="sourceCode" id="cb224"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb224-1"><a href="cap-sparse.html#cb224-1" aria-hidden="true" tabindex="-1"></a><span class="fu">which.max</span>(<span class="fu">summary</span>(regfit.fwd)<span class="sc">$</span>adjr2)</span>
<span id="cb224-2"><a href="cap-sparse.html#cb224-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 11</span></span>
<span id="cb224-3"><a href="cap-sparse.html#cb224-3" aria-hidden="true" tabindex="-1"></a><span class="fu">which.max</span>(<span class="fu">summary</span>(regfit.bwd)<span class="sc">$</span>adjr2)</span>
<span id="cb224-4"><a href="cap-sparse.html#cb224-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 11</span></span></code></pre></div>
<p>Con <span class="math inline">\(BIC\)</span>, el modelo elegido no tiene el mismo número de variables:</p>
<div class="sourceCode" id="cb225"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb225-1"><a href="cap-sparse.html#cb225-1" aria-hidden="true" tabindex="-1"></a><span class="fu">which.min</span>(<span class="fu">summary</span>(regfit.fwd)<span class="sc">$</span>bic)</span>
<span id="cb225-2"><a href="cap-sparse.html#cb225-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 6</span></span>
<span id="cb225-3"><a href="cap-sparse.html#cb225-3" aria-hidden="true" tabindex="-1"></a><span class="fu">which.min</span>(<span class="fu">summary</span>(regfit.bwd)<span class="sc">$</span>bic)</span>
<span id="cb225-4"><a href="cap-sparse.html#cb225-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 8</span></span></code></pre></div>
<p>Otra posibilidad es utilizar como criterio el error de predicción y para ello se puede utilizar algún esquema de validación cruzada. A continuación se ilustra el caso en el que se divide la muestra en dos subconjuntos: <em>training</em> y <em>testing</em>, pero se puede utilizar cualquier otro método (k-fold, etc.).</p>
<div class="sourceCode" id="cb226"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb226-1"><a href="cap-sparse.html#cb226-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb226-2"><a href="cap-sparse.html#cb226-2" aria-hidden="true" tabindex="-1"></a>entreno <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="fu">c</span>(<span class="cn">TRUE</span>, <span class="cn">FALSE</span>), <span class="fu">nrow</span>(Hitters), <span class="at">replace =</span> <span class="cn">TRUE</span>)</span>
<span id="cb226-3"><a href="cap-sparse.html#cb226-3" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> (<span class="sc">!</span>entreno)</span></code></pre></div>
<p>Usando <code>regsubsets()</code> en la muestra de entrenamiento:</p>
<div class="sourceCode" id="cb227"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb227-1"><a href="cap-sparse.html#cb227-1" aria-hidden="true" tabindex="-1"></a>regfit.best <span class="ot">&lt;-</span> <span class="fu">regsubsets</span>(Salary <span class="sc">~</span> ., <span class="at">data =</span> Hitters[entreno, ], <span class="at">nvmax =</span> <span class="dv">19</span>)</span></code></pre></div>
<p>Para calcular el error de predicción, dado que la función <code>regsubset</code> no tiene asociada una función <code>predict</code>, se han de calcular “manualmente” los valores predichos para la muestra de testeo. Para eso se necesita la matriz de diseño del modelo.</p>
<div class="sourceCode" id="cb228"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb228-1"><a href="cap-sparse.html#cb228-1" aria-hidden="true" tabindex="-1"></a>test.mat <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(Salary <span class="sc">~</span> ., <span class="at">data =</span> Hitters[test, ])</span></code></pre></div>
<p>Ahora para cada modelo de tamaño <span class="math inline">\(k\)</span>, se extraen los coeficientes de
<code>regfit.best</code> para el mejor modelo de ese tamaño, se multiplica el vector de coeficientes por la matriz de diseño y se obtienen las predicciones, a continuación se calcula el error cuadrático medio (<span class="math inline">\(MSE\)</span>).</p>
<div class="sourceCode" id="cb229"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb229-1"><a href="cap-sparse.html#cb229-1" aria-hidden="true" tabindex="-1"></a>val.errors <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="cn">NA</span>, <span class="dv">19</span>)</span>
<span id="cb229-2"><a href="cap-sparse.html#cb229-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">19</span>) {</span>
<span id="cb229-3"><a href="cap-sparse.html#cb229-3" aria-hidden="true" tabindex="-1"></a>  coefi <span class="ot">&lt;-</span> <span class="fu">coef</span>(regfit.best, <span class="at">id =</span> i)</span>
<span id="cb229-4"><a href="cap-sparse.html#cb229-4" aria-hidden="true" tabindex="-1"></a>  pred <span class="ot">&lt;-</span> test.mat[, <span class="fu">names</span>(coefi)] <span class="sc">%*%</span> coefi</span>
<span id="cb229-5"><a href="cap-sparse.html#cb229-5" aria-hidden="true" tabindex="-1"></a>  val.errors[i] <span class="ot">&lt;-</span> <span class="fu">mean</span>((Hitters<span class="sc">$</span>Salary[test] <span class="sc">-</span> pred)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb229-6"><a href="cap-sparse.html#cb229-6" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>El mejor modelo es el que contiene 7 variables:</p>
<div class="sourceCode" id="cb230"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb230-1"><a href="cap-sparse.html#cb230-1" aria-hidden="true" tabindex="-1"></a>val.errors</span>
<span id="cb230-2"><a href="cap-sparse.html#cb230-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [1] 164377.3 144405.5 152175.7 145198.4 137902.1 139175.7 126849.0 136191.4</span></span>
<span id="cb230-3"><a href="cap-sparse.html#cb230-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;  [9] 132889.6 135434.9 136963.3 140694.9 140690.9 141951.2 141508.2 142164.4</span></span>
<span id="cb230-4"><a href="cap-sparse.html#cb230-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [17] 141767.4 142339.6 142238.2</span></span></code></pre></div>
</div>
</div>
<div id="métodos-shrinkage" class="section level2 hasAnchor" number="18.4">
<h2><span class="header-section-number">18.4</span> Métodos Shrinkage<a href="cap-sparse.html#métodos-shrinkage" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Los métodos anteriores se basan en el ajuste de modelos mediante mínimos cuadrados. Ahora se trabajará con un método diferente: <strong>shrinkage</strong>. Este método se basa en una modificación de mínimos cuadrados añadiendo una penalización que <em>encoje</em> los coeficientes del modelo típicamente hacia <span class="math inline">\(0\)</span>. Una de las ventajas de este método es que reduce la varianza de los coeficientes estimados.</p>
<div id="regresión-ridge" class="section level3 hasAnchor" number="18.4.1">
<h3><span class="header-section-number">18.4.1</span> Regresión ridge<a href="cap-sparse.html#regresión-ridge" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Se recuerda que el ajuste por mínimos cuadrados estima <span class="math inline">\(\beta_0, \beta_1, \ldots , \beta_p\)</span> mediante los valores que minimizan:
<span class="math display">\[RSS=\sum_{i=1}^n \left ( y_i-\beta_0-\sum_{j=1}^p \beta_jx_{ij}\right )^2.\]</span>
La <strong>regresión ridge</strong> añade un término de penalización controlado por un parámetro (que habrá que elegir) que penalizará los coeficientes que se hacen demasiado grandes. Cuanto más grande es el coeficiente, mayor es la penalización:
<span class="math display">\[\sum_{i=1}^n \left ( y_i-\beta_0-\sum_{j=1}^p \beta_jx_{ij}\right )^2+\lambda \sum_{j=1}^p \beta_j^2=RSS+\lambda \sum_{j=1}^p \beta_j^2.\]</span>
En realidad lo que se está haciendo es hacer pagar al modelo un precio por el hecho de que los coeficientes no sean cero, y el precio será mayor cuanto mayor sea la magnitud del coeficiente. A esta penalización se le llama <strong>penalización shrinkage</strong> porque anima a los coeficientes a que se <em>contraigan</em> hacia <span class="math inline">\(0\)</span>, y la cantidad que fuerza a esos coeficientes a contraerse hacia cero está determinada por <span class="math inline">\(\lambda\)</span>, el <em>parámetro de tuneado</em>. Si <span class="math inline">\(\lambda=0\)</span> se está en el caso de mínimos cuadrados, y cuanto mayor sea <span class="math inline">\(\lambda\)</span>, mayor será el precio a pagar para que esos coeficientes sean distintos de <span class="math inline">\(0\)</span>. Si <span class="math inline">\(\lambda\)</span> es extremadamente grande los coeficientes estarán muy próximos a <span class="math inline">\(0\)</span> para poder hacer este término pequeño (recuérdese que se quiere minimizar <span class="math inline">\(RSS\)</span> más la penalización). Aunque valores más grandes de los coeficientes den un mejor ajuste (y por lo tanto un menor <span class="math inline">\(RSS\)</span>), el término de penalización se hará grande y no se alcanzará el mínimo. Por lo tanto <span class="math inline">\(\lambda\)</span> sirve como equilibrio entre un buen ajuste del modelo y el tamaño de los coeficientes (y por lo tanto el número de coeficientes distintos de cero).</p>
<p>Elegir un buen valor de <span class="math inline">\(\lambda\)</span> es crítico. Se utilizará la validación cruzada para elegirlo.</p>
<div id="escalado-de-variables-predictoras" class="section level4 hasAnchor" number="18.4.1.1">
<h4><span class="header-section-number">18.4.1.1</span> Escalado de variables predictoras<a href="cap-sparse.html#escalado-de-variables-predictoras" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Un punto importante en regresión ridge es si las variables predictoras están escaladas o no.</p>
<p>En el caso de mínimos cuadrados, el método es <em>invariante a la escala</em> (scale-invariant), esto quiere decir que si se multiplica una variable predictora <span class="math inline">\(X_j\)</span> por una constante <span class="math inline">\(c\)</span>, esto solo implica que el coeficiente estimado se ve multiplicado por <span class="math inline">\(1/c\)</span>, pero <span class="math inline">\(X_j\hat \beta_j\)</span> no cambia. Sin embargo, en el caso de la regresión ridge los coeficientes estimados pueden cambiar sustancialmente si se multiplica una variable predictora por una constante ya que aparecen todos juntos en el término de penalización. Por lo tanto, antes de utilizar la regresión ridge (o cualquier método de regularización) es importante <strong>estandarizar las variables predictoras</strong>, dividiendo cada variable por su desviación estándar, de forma que todas tengan desviación estándar igual a <span class="math inline">\(1\)</span>.
<span class="math display">\[\tilde x_{ij}= \frac{x_{ij}}{\sqrt{\frac{1}{n}\sum_{i=1}^n (x_{ij}-\overline{x}_{ij})^2}}\]</span>
Con esto se consigue que los coeficientes sean comparables.</p>
<p>Regresión ridge en muchas ocasiones da lugar a un menor <span class="math inline">\(MSE\)</span> que el obtenido con mínimos cuadrados ordinarios. Sin embargo, por muy grande que sea <span class="math inline">\(\lambda\)</span> los coeficientes no son <span class="math inline">\(0\)</span>, estarán próximos a cero, por lo que este método no es realmente un método de selección de variables.</p>
<p>La regresión ridge puede ser muy útil cuando hay variables predictoras altamente correlacionadas, pero es de interés mantener todas en el modelo. En estos casos, la regresión ridge soluciona los problemas de multicolinealidad.</p>
</div>
<div id="ajuste-de-regresión-ridge-en-r" class="section level4 hasAnchor" number="18.4.1.2">
<h4><span class="header-section-number">18.4.1.2</span> Ajuste de regresión ridge en R<a href="cap-sparse.html#ajuste-de-regresión-ridge-en-r" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>El paquete que se va a usar para regresión ridge (y para otros métodos regresión shrinkage) es <code>glmnet</code> .
La función principal en este paquete se llama también <code>glmnet()</code>. Esta función tiene una sintaxis un poco diferente a las funciones usuales para el ajuste de distintos modelos en <code>R</code>. Es necesario pasarle la matriz <span class="math inline">\(X\)</span> de variables predictoras (sin la columna correspondiente a la ordenada en el origen), y el vector <span class="math inline">\(y\)</span> con la variable respuesta. Para ilustrar su uso se utilizarán los datos anteriores sobre béisbol.</p>
<div class="sourceCode" id="cb231"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb231-1"><a href="cap-sparse.html#cb231-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">model.matrix</span>(Salary <span class="sc">~</span> ., Hitters)[, <span class="sc">-</span><span class="dv">1</span>]</span>
<span id="cb231-2"><a href="cap-sparse.html#cb231-2" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> Hitters<span class="sc">$</span>Salary</span></code></pre></div>
<p>La función <code>glmnet()</code> tiene un argumento, <code>alpha</code>, que determina el tipo de penalización que se añade en el modelo. En el caso de regresión ridge <code>alpha=0</code>.</p>
<p>Por defecto, la función <code>glmnet()</code> elige de forma automática el rango de valores de <span class="math inline">\(\lambda\)</span>. Sin embargo, a modo ilustrativo, se va a elegir la rejilla de valores, desde <span class="math inline">\(\lambda=10^{10}\)</span> hasta <span class="math inline">\(\lambda=10^{-2}\)</span>, cubriendo de esta forma una gran gama de escenarios, desde el modelo nulo (solo la ordenada en el origen), hasta el caso de mínimos cuadrados. Se verá más adelante que se puede calcular el ajuste para un valor determinado de <span class="math inline">\(\lambda\)</span> que no esté entre los de la rejilla inicial.</p>
<div class="sourceCode" id="cb232"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb232-1"><a href="cap-sparse.html#cb232-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(glmnet)</span>
<span id="cb232-2"><a href="cap-sparse.html#cb232-2" aria-hidden="true" tabindex="-1"></a>grid <span class="ot">&lt;-</span> <span class="dv">10</span><span class="sc">^</span><span class="fu">seq</span>(<span class="dv">10</span>, <span class="sc">-</span><span class="dv">2</span>, <span class="at">length =</span> <span class="dv">100</span>)</span>
<span id="cb232-3"><a href="cap-sparse.html#cb232-3" aria-hidden="true" tabindex="-1"></a>ridge.mod <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(x, y, <span class="at">alpha =</span> <span class="dv">0</span>, <span class="at">lambda =</span> grid)</span></code></pre></div>
<p>Por defecto, la función <code>glmnet()</code> estandariza las variables predictoras para que estén en la misma escala. Si por alguna razón no se quisiera hacer, se usaría <code>standardize = FALSE</code>.</p>
<p>Asociado con cada valor de <span class="math inline">\(\lambda\)</span> hay un vector de coeficientes estimados mediante regresión ridge almacenados en un matriz accesible utilizando <code>coef()</code>. En este caso, el tamaño de la matriz es <span class="math inline">\(20 \times 100\)</span>, las <span class="math inline">\(20\)</span> filas corresponden a cada uno de los predictores más la ordenada en el origen, y 100 columnas (una para cada valor de <span class="math inline">\(\lambda\)</span>). Lo esperable es que los coeficientes estimados sean más pequeños cuanto mayor sea el valor de <span class="math inline">\(\lambda\)</span>. A continuación se muestra el valor de los coeficientes cuando <span class="math inline">\(\lambda=11.498\)</span>, y su suma al cuadrado, <span class="math inline">\(\sum_{j=1}^p\beta_j^2\)</span>:</p>
<div class="sourceCode" id="cb233"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb233-1"><a href="cap-sparse.html#cb233-1" aria-hidden="true" tabindex="-1"></a>ridge.mod<span class="sc">$</span>lambda[<span class="dv">50</span>]</span>
<span id="cb233-2"><a href="cap-sparse.html#cb233-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 11497.57</span></span>
<span id="cb233-3"><a href="cap-sparse.html#cb233-3" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">coef</span>(ridge.mod)[<span class="sc">-</span><span class="dv">1</span>, <span class="dv">50</span>]<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb233-4"><a href="cap-sparse.html#cb233-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 40.45739</span></span></code></pre></div>
<p>Por el contrario, si <span class="math inline">\(\lambda\)</span> es más pequeño, <span class="math inline">\(705\)</span>, el valor es mucho mayor.</p>
<div class="sourceCode" id="cb234"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb234-1"><a href="cap-sparse.html#cb234-1" aria-hidden="true" tabindex="-1"></a>ridge.mod<span class="sc">$</span>lambda[<span class="dv">60</span>]</span>
<span id="cb234-2"><a href="cap-sparse.html#cb234-2" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 705.4802</span></span>
<span id="cb234-3"><a href="cap-sparse.html#cb234-3" aria-hidden="true" tabindex="-1"></a><span class="fu">sum</span>(<span class="fu">coef</span>(ridge.mod)[<span class="sc">-</span><span class="dv">1</span>, <span class="dv">60</span>]<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb234-4"><a href="cap-sparse.html#cb234-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 3261.554</span></span></code></pre></div>
<p>A continuación se dibuja el efecto de <span class="math inline">\(\lambda\)</span> en los coeficientes:</p>
<div class="sourceCode" id="cb235"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb235-1"><a href="cap-sparse.html#cb235-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(ridge.mod, <span class="at">xvar =</span> <span class="st">&quot;lambda&quot;</span>, <span class="at">label =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<p><img src="Ciencia_de_datos_con_r_files/figure-html/chunk29.2-1.png" width="60%" style="display: block; margin: auto;" /></p>
<p>El lado izquierdo del gráfico corresponde a un valor de <span class="math inline">\(\lambda\)</span> muy pequeño, y por lo tanto no existen restricciones sobre los coeficientes. Conforme aumenta el valor de <span class="math inline">\(\lambda\)</span> los coeficientes se aproximan a cero, ya que el precio a pagar por ser distinto de cero es cada vez mayor. Pero no todos se aproximan a cero de la misma manera: hay un conjunto de variables cuyo coeficiente es prácticamente cero para cualquier valor de <span class="math inline">\(\lambda\)</span> y para un valor de <span class="math inline">\(log(\lambda)=3\)</span> parece que hay solo <span class="math inline">\(4\)</span> coeficientes distintos de <span class="math inline">\(0\)</span>.</p>
<p>La función <code>predict()</code> se puede utilizar con diferentes propósitos. Por ejemplo, se pueden obtener los coeficientes de la regresión ridge para un valor específico de <span class="math inline">\(\lambda\)</span>, por ejemplo, <span class="math inline">\(\lambda=50\)</span>:</p>
<div class="sourceCode" id="cb236"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb236-1"><a href="cap-sparse.html#cb236-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(ridge.mod, <span class="at">s =</span> <span class="dv">50</span>, <span class="at">type =</span> <span class="st">&quot;coefficients&quot;</span>)[<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>, ]</span></code></pre></div>
<p>Ahora se va a dividir los datos en una muestra de entrenamiento y otra de testeo para estimar el error de predicción de la regresión ridge.</p>
<div class="sourceCode" id="cb237"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb237-1"><a href="cap-sparse.html#cb237-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb237-2"><a href="cap-sparse.html#cb237-2" aria-hidden="true" tabindex="-1"></a>entreno <span class="ot">&lt;-</span> <span class="fu">sample</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">nrow</span>(x), <span class="fu">nrow</span>(x) <span class="sc">/</span> <span class="dv">2</span>)</span>
<span id="cb237-3"><a href="cap-sparse.html#cb237-3" aria-hidden="true" tabindex="-1"></a>test <span class="ot">&lt;-</span> (<span class="sc">-</span>entreno)</span>
<span id="cb237-4"><a href="cap-sparse.html#cb237-4" aria-hidden="true" tabindex="-1"></a>y.test <span class="ot">&lt;-</span> y[test]</span></code></pre></div>
<p>Se ajusta la regresión ridge a la muestra de entrenamiento usando un valor de lambda (por ejemplo <span class="math inline">\(\lambda=4\)</span>), y se evalúa su <span class="math inline">\(MSE\)</span> en la muestra de testeo. Para eso se usará la función <code>predict()</code>. En este caso, para obtener las predicciones para la muestra de testeo, se reemplaza <code>type =</code> <code>"coefficients"</code> por el argumento <code>newx</code>.</p>
<div class="sourceCode" id="cb238"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb238-1"><a href="cap-sparse.html#cb238-1" aria-hidden="true" tabindex="-1"></a>ridge.mod <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(x[entreno, ], y[entreno], <span class="at">alpha =</span> <span class="dv">0</span>, <span class="at">lambda =</span> grid)</span>
<span id="cb238-2"><a href="cap-sparse.html#cb238-2" aria-hidden="true" tabindex="-1"></a>ridge.pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(ridge.mod, <span class="at">s =</span> <span class="dv">4</span>, <span class="at">newx =</span> x[test, ])</span>
<span id="cb238-3"><a href="cap-sparse.html#cb238-3" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>((ridge.pred <span class="sc">-</span> y.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb238-4"><a href="cap-sparse.html#cb238-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 142226.5</span></span></code></pre></div>
<p>El <span class="math inline">\(MSE\)</span> es <span class="math inline">\(142{,}199\)</span>. Si se usa un valor muy alto de <span class="math inline">\(\lambda\)</span>, por ejemplo, <span class="math inline">\(10^{10}\)</span> (esto sería equivalente a ajustar un modelo solo con la ordenada en el origen), el resultado es muy distinto:</p>
<div class="sourceCode" id="cb239"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb239-1"><a href="cap-sparse.html#cb239-1" aria-hidden="true" tabindex="-1"></a>ridge.pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(ridge.mod, <span class="at">s =</span> <span class="fl">1e10</span>, <span class="at">newx =</span> x[test, ])</span>
<span id="cb239-2"><a href="cap-sparse.html#cb239-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>((ridge.pred <span class="sc">-</span> y.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb239-3"><a href="cap-sparse.html#cb239-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 224669.8</span></span></code></pre></div>
<p>Por lo tanto, en este caso, ajustar un modelo de regresión ridge con <span class="math inline">\(\lambda=4\)</span> da un <span class="math inline">\(MSE\)</span> mucho menor que el obtenido cuando el modelo sólo contiene la ordenada en el origen.</p>
<p>A continuación se compara el resultado para <span class="math inline">\(\lambda=4\)</span> con el obtenido utilizando mínimos cuadrados (<span class="math inline">\(\lambda=0\)</span>).</p>
<div class="sourceCode" id="cb240"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb240-1"><a href="cap-sparse.html#cb240-1" aria-hidden="true" tabindex="-1"></a>ridge.pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(ridge.mod, <span class="at">s =</span> <span class="dv">0</span>, <span class="at">newx =</span> x[test, ], <span class="at">exact =</span> T, <span class="at">x =</span> x[entreno, ], <span class="at">y =</span> y[entreno])</span>
<span id="cb240-2"><a href="cap-sparse.html#cb240-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>((ridge.pred <span class="sc">-</span> y.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb240-3"><a href="cap-sparse.html#cb240-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 167018.2</span></span></code></pre></div>
<p>Se ve que el error es menor cuando se usa regresión ridge (con <span class="math inline">\(\lambda=4\)</span>) que cuando se usan mínimos cuadrados.</p>
<p>Hasta ahora se ha elegido el valor <span class="math inline">\(\lambda=4\)</span> de forma arbitraria, en la siguiente Sección se ve cómo seleccionar dicho parámetro de una forma automática.</p>
</div>
</div>
<div id="selección-del-parámetro-de-tuneado" class="section level3 hasAnchor" number="18.4.2">
<h3><span class="header-section-number">18.4.2</span> Selección del parámetro de tuneado<a href="cap-sparse.html#selección-del-parámetro-de-tuneado" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Se ha visto que el valor de <span class="math inline">\(\lambda\)</span> tienen un gran impacto en los resultados obtenidos cuando se utiliza un modelo con penalización.</p>
<p>Una buena manera de elegir <span class="math inline">\(\lambda\)</span> es usar validación cruzada, por ejemplo, se puede usar <em>k-fold cross-validation</em>:</p>
<ul>
<li>Se dividen los datos en <span class="math inline">\(k\)</span> grupos, se ajusta el modelo ridge a <span class="math inline">\(k-1\)</span> de esos grupos (para una rejilla de valores de <span class="math inline">\(\lambda\)</span>) y se calcula el error de predicción para el otro grupo.</li>
<li>Se repite tomando como muestra de testeo cada uno de los <span class="math inline">\(k\)</span> grupos y se suman los errores de predicción.</li>
<li>Al final se dispondrá de una curva con los errores para cada valor de <span class="math inline">\(\lambda\)</span> y se elegirá el que dé el mínimo error.</li>
</ul>
<p>En la práctica, se puede hacer con la función <code>cv.glmnet()</code>. Por defecto, esta función usa un <span class="math inline">\(10\)</span>-fold cross-validation, pero se puede cambiar usando el argumento <code>nfolds</code>.</p>
<p>En el ejemplo del béisbol:</p>
<div class="sourceCode" id="cb241"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb241-1"><a href="cap-sparse.html#cb241-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb241-2"><a href="cap-sparse.html#cb241-2" aria-hidden="true" tabindex="-1"></a>cv.out <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(x[entreno, ], y[entreno], <span class="at">alpha =</span> <span class="dv">0</span>)</span>
<span id="cb241-3"><a href="cap-sparse.html#cb241-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cv.out)</span></code></pre></div>
<p><img src="Ciencia_de_datos_con_r_files/figure-html/chunk36-1.png" width="60%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb242"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb242-1"><a href="cap-sparse.html#cb242-1" aria-hidden="true" tabindex="-1"></a>mejorlam <span class="ot">&lt;-</span> cv.out<span class="sc">$</span>lambda.min</span>
<span id="cb242-2"><a href="cap-sparse.html#cb242-2" aria-hidden="true" tabindex="-1"></a>mejorlam</span>
<span id="cb242-3"><a href="cap-sparse.html#cb242-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 326.0828</span></span></code></pre></div>
<p>En este gráfico los puntos rojos corresponden a la media del <span class="math inline">\(MSE\)</span> para los <span class="math inline">\(k\)</span>-folds y las barras superior e inferior corresponden a esa cantidad más/menos una desviación estándar (el ancho será menor cuanto mayor se <span class="math inline">\(k\)</span> en el <span class="math inline">\(k\)</span>-fold). La primera línea vertical corresponde al valor de <span class="math inline">\(\lambda\)</span> que hace mínimo el <span class="math inline">\(MSE\)</span> y la segunda es el valor que corresponde al <span class="math inline">\(MSE\)</span> más una desviación típica.</p>
<p>Se calcula el valor mínimo del <span class="math inline">\(MSE\)</span>:</p>
<div class="sourceCode" id="cb243"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb243-1"><a href="cap-sparse.html#cb243-1" aria-hidden="true" tabindex="-1"></a>ridge.pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(ridge.mod, <span class="at">s =</span> mejorlam, <span class="at">newx =</span> x[test, ])</span>
<span id="cb243-2"><a href="cap-sparse.html#cb243-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>((ridge.pred <span class="sc">-</span> y.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb243-3"><a href="cap-sparse.html#cb243-3" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 139833.6</span></span></code></pre></div>
<p>Esto representa una mejora sobre el error de predicción que se había obtenido cuando <span class="math inline">\(\lambda=4\)</span>.</p>
</div>
<div id="regresión-lasso" class="section level3 hasAnchor" number="18.4.3">
<h3><span class="header-section-number">18.4.3</span> Regresión Lasso<a href="cap-sparse.html#regresión-lasso" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Uno de los puntos débiles de la regresión ridge es que no hace selección de variables (los coeficientes pueden ser próximos a cero pero no exactamente cero). En el modelo final se incluyen todos los coeficientes, por lo tanto <strong>la regresión ridge es útil cuando la mayoría de las variables predictoras son útiles</strong>.</p>
<p>La regresión <em>lasso</em> es una alternativa a la regresión ridge cuyo objetivo es precisamente eliminar esa desventaja de la regresión ridge, fue introducida por <span class="citation">R. Tibshirani (<a href="#ref-Tibshirani96" role="doc-biblioref">1996</a>)</span>. <strong>La regresión lasso es útil cuando las mayoría de las variables predictoras no son útiles</strong>. Los coeficientes lasso, <span class="math inline">\(\hat \beta^L\)</span> minimizan la siguiente cantidad:
<span class="math display">\[\sum_{i=1}^n \left ( y_i-\beta_0-\sum_{j=1}^p \beta_jx_{ij}\right )^2+\lambda \sum_{j=1}^p |\beta_j|=RSS+\lambda \sum_{j=1}^p |\beta_j|\]</span>
Ahora los coeficientes se <em>contraen</em> hacia cero utilizando el valor absoluto en vez de la suma de cuadrados. A esta norma se le llama <span class="math inline">\(l_1\)</span>, <span class="math inline">\(\|\beta\|_1=\sum_{j=1}^p|\beta_j|\)</span>. El cambio que supone es sutil pero importante. En ambos casos los coeficientes se contraen hacia <span class="math inline">\(0\)</span> pero cuando <span class="math inline">\(\lambda\)</span> es suficientemente grande los coeficientes serán <span class="math inline">\(0\)</span>, de modo que se estará haciendo selección de variables. Es decir, hará los coeficientes exactamente igual a <span class="math inline">\(0\)</span> si esas variables no son importantes y <span class="math inline">\(\lambda\)</span> es suficientemente grande. En este sentido <span class="math inline">\(lasso\)</span> es lo que se llama un <strong>modelo sparse</strong>.</p>
<p><strong>¿Por qué lasso hace que los coeficiente se contraigan exactamente hacia cero?</strong>
Para entenderlo se va a ver una formulación equivalente de los mínimos cuadrados penalizados en el caso de la regresión lasso:
<span class="math display">\[\sum_{i=1}^n \left ( y_i-\beta_0-\sum_{j=1}^p \beta_jx_{ij}\right )^2\quad \text{sujeto a} \quad \sum_{j=1}^p |\beta_j|&lt;s\]</span>
Se esta utilizando mínimos cuadrados con una restricción, o lo que es lo mismo con un <em>presupuesto</em>, en la norma <span class="math inline">\(l_1\)</span> sobre los coeficientes. Las dos formulaciones son equivalentes en el sentido de que si tengo un <em>presupuesto</em> <span class="math inline">\(s\)</span>, habrá un <span class="math inline">\(\lambda\)</span> que corresponda en la formulación previa que corresponda al mismo problema y viceversa.
Supóngase que se hacen mínimos cuadrados y se obtienen unos ciertos parámetros estimados, y supóngase que la suma de los valores absolutos de los coeficientes es <span class="math inline">\(10\)</span>, pero alguien dice que nuestro <em>presupuesto</em> es <span class="math inline">\(5\)</span> (la suma de los valores absolutos de los coeficientes no puede ser mayor que esa cantidad). Ahora hay que resolver el problema de mínimos cuadrados pero los coeficientes no pueden tomar cualquier valor, ya que se tiene una restricción sobre los mismos. Cuanto más pequeño sea el <em>presupuesto</em>, más próximos a cero serán los coeficientes. Si mi <em>presupuesto</em> es <span class="math inline">\(0\)</span>, todos los coeficientes serán también <span class="math inline">\(0\)</span>. Si el presupuesto es muy alto, hay libertad para que los coeficientes tomen el valor que quieran, y se estaría en el caso de mínimos cuadrados. El <em>presupuesto</em> impone que haya un equilibrio entre el ajuste a los datos y el tamaño de los coeficientes.</p>
<p>La Figura <a href="cap-sparse.html#fig:lassoridge">18.1</a> (tomada de <span class="citation">G. James et al. (<a href="#ref-james2013introduction" role="doc-biblioref">2013</a>)</span>) muestra por qué lasso es <em>sparse</em>:</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:lassoridge"></span>
<img src="img/lasso_ridge.png" alt="Contornos (rojo) de $RSS$ y regiones de restricción (en azul) para lasso (izquierda) y ridge (derecha)." width="60%" />
<p class="caption">
Figura 18.1: Contornos (rojo) de <span class="math inline">\(RSS\)</span> y regiones de restricción (en azul) para lasso (izquierda) y ridge (derecha).
</p>
</div>
<p>El gráfico corresponde a un modelo de regresión con dos variables predictoras. El punto donde está el vector de coeficientes, <span class="math inline">\(\boldsymbol{\beta}\)</span>, es donde se alcanzaría el valor mínimo de los mínimos cuadrados (<span class="math inline">\(RSS\)</span>), los contornos serían combinaciones de valores de <span class="math inline">\(\beta_1\)</span> y <span class="math inline">\(\beta_2\)</span> que dan lugar al mismo valor de <span class="math inline">\(RSS\)</span> pero que ya no sería el mínimo. Las regiones de restricción son <span class="math inline">\(|\beta_1|+|\beta_2|&lt;s\)</span> (lasso) y <span class="math inline">\(\beta_1^2 +\beta_2^2&lt;s\)</span> (ridge). En el caso de ridge, el <em>presupuesto</em> sería el radio del círculo, y la regresión ridge busca el primer lugar en el que el contorno toca a la región de restricción, pero al ser un círculo, difícilmente uno u otro parámetro va a ser <span class="math inline">\(0\)</span>. En el caso de lasso la región es un diamante, y por lo tanto tiene vértices, en la Figura el contorno toca a la región de restricción en el caso en que <span class="math inline">\(\beta_1=0\)</span>.</p>
<p>Se vuelve al ejemplo del béisbol para mostrar la regresión lasso, en este caso el argumento <span class="math inline">\(\alpha\)</span> toma valor <span class="math inline">\(1\)</span>:</p>
<div class="sourceCode" id="cb244"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb244-1"><a href="cap-sparse.html#cb244-1" aria-hidden="true" tabindex="-1"></a>lasso.mod <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(x[entreno, ], y[entreno], <span class="at">alpha =</span> <span class="dv">1</span>, <span class="at">lambda =</span> grid)</span>
<span id="cb244-2"><a href="cap-sparse.html#cb244-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lasso.mod)</span></code></pre></div>
<p><img src="Ciencia_de_datos_con_r_files/figure-html/chunk39-1.png" width="60%" style="display: block; margin: auto;" /></p>
<p>Se puede ver que dependiendo del valor del parámetro de tuneado, algunos de los coeficientes se hacen exactamente <span class="math inline">\(0\)</span>. Ahora se va a elegir mediante validación cruzada y se calcula el error de predicción:</p>
<div class="sourceCode" id="cb245"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb245-1"><a href="cap-sparse.html#cb245-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb245-2"><a href="cap-sparse.html#cb245-2" aria-hidden="true" tabindex="-1"></a>cv.out <span class="ot">&lt;-</span> <span class="fu">cv.glmnet</span>(x[entreno, ], y[entreno], <span class="at">alpha =</span> <span class="dv">1</span>)</span>
<span id="cb245-3"><a href="cap-sparse.html#cb245-3" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(cv.out)</span></code></pre></div>
<p><img src="Ciencia_de_datos_con_r_files/figure-html/chunk40-1.png" width="60%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb246"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb246-1"><a href="cap-sparse.html#cb246-1" aria-hidden="true" tabindex="-1"></a>mejorlab <span class="ot">&lt;-</span> cv.out<span class="sc">$</span>lambda.min</span>
<span id="cb246-2"><a href="cap-sparse.html#cb246-2" aria-hidden="true" tabindex="-1"></a>lasso.pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(lasso.mod, <span class="at">s =</span> mejorlab, <span class="at">newx =</span> x[test, ])</span>
<span id="cb246-3"><a href="cap-sparse.html#cb246-3" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>((lasso.pred <span class="sc">-</span> y.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb246-4"><a href="cap-sparse.html#cb246-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 143673.6</span></span></code></pre></div>
<p>Este valor es bastante más bajo que <span class="math inline">\(MSE\)</span> en la muestra de testeo en el caso de mínimos cuadrados (<span class="math inline">\(224669.8\)</span>), y bastante parecido al obtenido con regresión ridge (cuando el parámetro de tuneado se elige mediante validación cruzada, <span class="math inline">\(139856.6\)</span>).</p>
<p>Sin embargo, lasso tiene una ventaja importante con respecto a la regresión ridge ya que los coeficientes estimados son <em>sparse</em>. Aquí se ve que 10 de los 20 coeficientes estimados son <span class="math inline">\(0\)</span>. Por lo tanto el modelo lasso con <span class="math inline">\(\lambda\)</span> elegido mediante validación cruzada contiene solo nueve variables predictoras.</p>
<div class="sourceCode" id="cb247"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb247-1"><a href="cap-sparse.html#cb247-1" aria-hidden="true" tabindex="-1"></a>out <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(x, y, <span class="at">alpha =</span> <span class="dv">1</span>)</span>
<span id="cb247-2"><a href="cap-sparse.html#cb247-2" aria-hidden="true" tabindex="-1"></a>lasso.coef <span class="ot">&lt;-</span> <span class="fu">predict</span>(out, <span class="at">type =</span> <span class="st">&quot;coefficients&quot;</span>, <span class="at">s =</span> mejorlab)[<span class="dv">1</span><span class="sc">:</span><span class="dv">20</span>, ]</span>
<span id="cb247-3"><a href="cap-sparse.html#cb247-3" aria-hidden="true" tabindex="-1"></a>lasso.coef[lasso.coef <span class="sc">!=</span> <span class="dv">0</span>]</span>
<span id="cb247-4"><a href="cap-sparse.html#cb247-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   (Intercept)          Hits         Walks        CHmRun         CRuns </span></span>
<span id="cb247-5"><a href="cap-sparse.html#cb247-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   -3.04787656    2.02551572    2.26853781    0.01647106    0.21177390 </span></span>
<span id="cb247-6"><a href="cap-sparse.html#cb247-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;          CRBI       LeagueN     DivisionW       PutOuts        Errors </span></span>
<span id="cb247-7"><a href="cap-sparse.html#cb247-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;    0.41944632   20.48456551 -116.59062083    0.23718459   -0.94739923</span></span></code></pre></div>
</div>
<div id="elastic-net" class="section level3 hasAnchor" number="18.4.4">
<h3><span class="header-section-number">18.4.4</span> Elastic net <a href="cap-sparse.html#elastic-net" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Uno de los problemas de la regresión lasso es cuando hay variables predictoras correladas entre sí, pues elegirá una de ellas (y los coeficientes de las demás los hará cero) sin un criterio objetivo. Además, supóngase que se está en una situación en la que el número de variables <span class="math inline">\(p\)</span> es mayor que el número de observaciones <span class="math inline">\(n\)</span>, en este caso lasso elegiría como mucho <span class="math inline">\(p\)</span> variables, aunque haya más de <span class="math inline">\(p\)</span> relevantes; mientras que la regresión ridge las utilizaría todas, aunque disminuye la complejidad del modelo (esto en algunos casos puede ser lo deseable o no). Elastic net <span class="citation">(<a href="#ref-Zou2005" role="doc-biblioref">Zou and Hastie 2005</a>)</span> es una generalización de los métodos anteriores que combinan la penalización ridge y la lasso:
<span class="math display">\[\sum_{i=1}^n \left ( y_i-\beta_0-\sum_{j=1}^p \beta_jx_{ij}\right )^2+\lambda_1 \sum_{j=1}^p \beta_j^2+\lambda_2 \sum_{j=1}^p |\beta_j|\]</span>
También aparece en muchas ocasiones de esta otra forma:
<span class="math display">\[\sum_{i=1}^n \left ( y_i-\beta_0-\sum_{j=1}^p \beta_jx_{ij}\right )^2+\lambda \left [ \frac{1}{2} (1-\alpha)\sum_{j=1}^p \beta_j^2+\alpha \sum_{j=1}^p |\beta_j|\right ]\]</span>
donde <span class="math inline">\(\alpha\in [0,1]\)</span>. Se puede ver <span class="math inline">\(\alpha\)</span> como el parámetro que controla la mezcla entre las dos penalizaciones y <span class="math inline">\(\lambda\)</span> como el que controla la cantidad de penalización. Si <span class="math inline">\(\alpha=0\)</span> se está en el caso de regresión ridge, y si <span class="math inline">\(\alpha=1\)</span> en el caso de regresión lasso.</p>
<p>La función <code>glmnet</code> también sirve para ajustar elastic net, pero el parámetro <span class="math inline">\(\alpha\)</span> hay que elegirlo a priori (eso es lo que se ha hecho para usar regresión ridge o lasso). Otra opción es utilizar el paquete <code>caret</code> para hacer validación cruzada sobre <span class="math inline">\(\alpha\)</span> y <span class="math inline">\(\lambda\)</span> simultáneamente:</p>
<div class="sourceCode" id="cb248"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb248-1"><a href="cap-sparse.html#cb248-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb248-2"><a href="cap-sparse.html#cb248-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(caret)</span>
<span id="cb248-3"><a href="cap-sparse.html#cb248-3" aria-hidden="true" tabindex="-1"></a>cv_glmnet <span class="ot">&lt;-</span> <span class="fu">train</span>(</span>
<span id="cb248-4"><a href="cap-sparse.html#cb248-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> x[entreno, ],</span>
<span id="cb248-5"><a href="cap-sparse.html#cb248-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">y =</span> y[entreno],</span>
<span id="cb248-6"><a href="cap-sparse.html#cb248-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">&quot;glmnet&quot;</span>,</span>
<span id="cb248-7"><a href="cap-sparse.html#cb248-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">trControl =</span> <span class="fu">trainControl</span>(<span class="at">method =</span> <span class="st">&quot;cv&quot;</span>, <span class="at">number =</span> <span class="dv">10</span>),</span>
<span id="cb248-8"><a href="cap-sparse.html#cb248-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">tuneLength =</span> <span class="dv">10</span></span>
<span id="cb248-9"><a href="cap-sparse.html#cb248-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb248-10"><a href="cap-sparse.html#cb248-10" aria-hidden="true" tabindex="-1"></a><span class="co"># modelo con el MSE más pequeño</span></span>
<span id="cb248-11"><a href="cap-sparse.html#cb248-11" aria-hidden="true" tabindex="-1"></a>cv_glmnet<span class="sc">$</span>bestTune</span>
<span id="cb248-12"><a href="cap-sparse.html#cb248-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;   alpha   lambda</span></span>
<span id="cb248-13"><a href="cap-sparse.html#cb248-13" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 9   0.1 99.12337</span></span>
<span id="cb248-14"><a href="cap-sparse.html#cb248-14" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(cv_glmnet)</span></code></pre></div>
<p><img src="Ciencia_de_datos_con_r_files/figure-html/chunk46-1.png" width="60%" style="display: block; margin: auto;" /></p>
<p>En el gráfico se ve cómo la combinación de <span class="math inline">\(\alpha\)</span> y <span class="math inline">\(\lambda\)</span> da lugar a diferentes <span class="math inline">\(MSE\)</span> (aquí aparece el <span class="math inline">\(RMSE\)</span>, o sea, su raíz cuadrada). Cada línea corresponde a un valor de <span class="math inline">\(\lambda\)</span> distinto, y en el eje <span class="math inline">\(x\)</span> se representa los valores de <span class="math inline">\(\alpha\)</span>.</p>
<p>Se calcula el error de predicción para estos dos valores de los parámetros de tuneado:</p>
<div class="sourceCode" id="cb249"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb249-1"><a href="cap-sparse.html#cb249-1" aria-hidden="true" tabindex="-1"></a>elastic.mod <span class="ot">&lt;-</span> <span class="fu">glmnet</span>(x[entreno, ], y[entreno], <span class="at">alpha =</span> cv_glmnet<span class="sc">$</span>bestTune<span class="sc">$</span>alpha)</span>
<span id="cb249-2"><a href="cap-sparse.html#cb249-2" aria-hidden="true" tabindex="-1"></a>elastic.pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(elastic.mod, <span class="at">newx =</span> x[test, ], <span class="at">s =</span> cv_glmnet<span class="sc">$</span>bestTune<span class="sc">$</span>lambda)</span>
<span id="cb249-3"><a href="cap-sparse.html#cb249-3" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>((elastic.pred <span class="sc">-</span> y.test)<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb249-4"><a href="cap-sparse.html#cb249-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 141626.1</span></span></code></pre></div>
<p>Se ve que es peor que el de la regresión ridge, pero mejor que el de lasso. Si no se quiere hacer ningún tipo de selección, en este caso se elegiría ridge, pero si se quiere reducir al máximo las variables se usaría lasso (a costa de que el error de predicción aumente) y el equilibrio vendría con el uso de elastic-net que hace selección de variables pero no aumenta el error de predicción.</p>
<p>Existen otros métodos de regularización que se derivan de estos, como el <em>group lasso</em>, <em>sparse group-lasso</em>, etc. Se puede encontrar información de estos métodos en <span class="citation">(<a href="#ref-hastiebook2015" role="doc-biblioref">Hastie and Tibshirani 2015</a>)</span>.</p>
</div>
<div id="resumen-4" class="section level3 unnumbered hasAnchor infobox_resume">
<h3>Resumen<a href="cap-sparse.html#resumen-4" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En este capítulo se han introducido técnicas para mejorar la predicción y la interpretabilidad de los modelos de regresión, en particular:</p>
<ul>
<li>Se ha mostrado el uso de la técnica de selección del mejor subconjunto de variables en el modelo, así como los métodos <em>stepwise</em>.</li>
<li>Se han presentado 3 métodos tipo <em>shrinkage</em>: regresión ridge, lasso y elastic net, bien para la selección de variables, o para solventar problemas de multicolinealidad en el modelo.</li>
<li>Se ha mostrado como seleccionar los parámetros de tuneado que controlan la regresión penalizada.</li>
<li>Se ha ilustrado el uso de todas las metodologías propuesta en el capítulo mediante el análisis de un caso práctico.</li>
</ul>
</div>

</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-hastiebook2015" class="csl-entry">
Hastie, T., and R. Tibshirani. 2015. <em>Statistical Learning with Sparsity: The Lasso and Generalizations</em>. Monographs on Statistics &amp; Applied Probability. Chapman; Hall/CRC. <a href="https://doi.org/10.1201/b18401">https://doi.org/10.1201/b18401</a>.
</div>
<div id="ref-james2013introduction" class="csl-entry">
James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2013. <em>An Introduction to Statistical Learning</em>. Vol. 112. Springer. <a href="https://doi.org/10.1007/978-1-4614-7138-7">https://doi.org/10.1007/978-1-4614-7138-7</a>.
</div>
<div id="ref-Tibshirani96" class="csl-entry">
Tibshirani, R. 1996. <span>“Regression Shrinkage and Selection via the Lasso.”</span> <em>Journal of the Royal Statistical Society. Series B</em> 58: 267–88. <a href="https://doi.org/10.1111/j.2517-6161.1996.tb02080.x">https://doi.org/10.1111/j.2517-6161.1996.tb02080.x</a>.
</div>
<div id="ref-Zou2005" class="csl-entry">
Zou, H., and T. Hastie. 2005. <span>“Regularization and Variable Selection via the Elastic Net.”</span> <em>Journal of the Royal Statistical Society. Series B</em> 67: 301–20. <a href="https://doi.org/10.1111/j.1467-9868.2005.00503.x">https://doi.org/10.1111/j.1467-9868.2005.00503.x</a>.
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="cap-mxm.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="cap-series-temp.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Ciencia_de_datos_con_r.pdf", "Ciencia_de_datos_con_r.epub"],
"search": {
"engine": "lunr",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
