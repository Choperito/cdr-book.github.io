<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 30 Análisis cluster: clusterización jerárquica | Ciencia de datos con R</title>
  <meta name="description" content="Falta hacer" />
  <meta name="generator" content="bookdown 0.28 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 30 Análisis cluster: clusterización jerárquica | Ciencia de datos con R" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Falta hacer" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 30 Análisis cluster: clusterización jerárquica | Ciencia de datos con R" />
  
  <meta name="twitter:description" content="Falta hacer" />
  

<meta name="author" content="Gema Fernández-Avilés y José-María Montero" />


<<<<<<< HEAD
<meta name="date" content="2022-12-22" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="cap-boosting-xgboost.html"/>
<link rel="next" href="no-jerarquico.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<link href="libs/wordcloud2-0.0.1/wordcloud.css" rel="stylesheet" />
<script src="libs/wordcloud2-0.0.1/wordcloud2-all.js"></script>
<script src="libs/wordcloud2-0.0.1/hover.js"></script>
<script src="libs/wordcloud2-binding-0.2.1/wordcloud2.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-33KQ1S5ZCJ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-33KQ1S5ZCJ');
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"> Ciencia de datos con <strong>R</strong></a></li>

<li class="divider"></li>
<li class="chapter" data-level="1" data-path="normas-cdr-book-v0.2.html"><a href="normas-cdr-book-v0.2.html"><i class="fa fa-check"></i><b>1</b> Normas CDR-book-v0.2.0</a>
<ul>
<li class="chapter" data-level="1.1" data-path="normas-cdr-book-v0.2.html"><a href="normas-cdr-book-v0.2.html#notas-importantes"><i class="fa fa-check"></i><b>1.1</b> Notas importantes</a></li>
<li class="chapter" data-level="1.2" data-path="normas-cdr-book-v0.2.html"><a href="normas-cdr-book-v0.2.html#notas-relativas-a-r"><i class="fa fa-check"></i><b>1.2</b> Notas relativas a R</a></li>
<li class="chapter" data-level="1.3" data-path="normas-cdr-book-v0.2.html"><a href="normas-cdr-book-v0.2.html#notas-de-estilo"><i class="fa fa-check"></i><b>1.3</b> Notas de estilo</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="normas-cdr-book-v0.2.html"><a href="normas-cdr-book-v0.2.html#títulos"><i class="fa fa-check"></i><b>1.3.1</b> Títulos</a></li>
<li class="chapter" data-level="1.3.2" data-path="normas-cdr-book-v0.2.html"><a href="normas-cdr-book-v0.2.html#figuras"><i class="fa fa-check"></i><b>1.3.2</b> Figuras</a></li>
<li class="chapter" data-level="1.3.3" data-path="normas-cdr-book-v0.2.html"><a href="normas-cdr-book-v0.2.html#tablas"><i class="fa fa-check"></i><b>1.3.3</b> Tablas</a></li>
<li class="chapter" data-level="1.3.4" data-path="normas-cdr-book-v0.2.html"><a href="normas-cdr-book-v0.2.html#otros"><i class="fa fa-check"></i><b>1.3.4</b> Otros</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html"><i class="fa fa-check"></i>Prefacio</a>
<ul>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html#los-autores"><i class="fa fa-check"></i>Los autores</a></li>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html#por-qué-este-libro"><i class="fa fa-check"></i>¿Por qué este libro?</a></li>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html#características"><i class="fa fa-check"></i>Características</a></li>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html#el-paquete-cdr"><i class="fa fa-check"></i>El paquete <code>CDR</code></a></li>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html#a-quién-va-dirigido"><i class="fa fa-check"></i>¿A quién va dirigido?</a></li>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html#agradecimientos"><i class="fa fa-check"></i>Agradecimientos</a></li>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html#información-del-software"><i class="fa fa-check"></i>Información del software</a></li>
</ul></li>
<li class="part"><span><b>I Ciencia, datos, software… y científicos</b></span></li>
<li class="chapter" data-level="2" data-path="ciencia-datos.html"><a href="ciencia-datos.html"><i class="fa fa-check"></i><b>2</b> ¿Es la ciencia de datos una ciencia?</a>
<ul>
<li class="chapter" data-level="2.1" data-path="ciencia-datos.html"><a href="ciencia-datos.html#ciencia"><i class="fa fa-check"></i><b>2.1</b> ¿Qué se entiende por ciencia?</a></li>
<li class="chapter" data-level="2.2" data-path="ciencia-datos.html"><a href="ciencia-datos.html#qué-diablos-es-la-ciencia-de-datos"><i class="fa fa-check"></i><b>2.2</b> ¿Qué diablos es la ciencia de datos?</a></li>
<li class="chapter" data-level="2.3" data-path="ciencia-datos.html"><a href="ciencia-datos.html#lo-científico-de-la-ciencia-de-datos"><i class="fa fa-check"></i><b>2.3</b> Lo científico de la ciencia de datos</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="metodología.html"><a href="metodología.html"><i class="fa fa-check"></i><b>3</b> Metodología en ciencia de datos</a>
<ul>
<li class="chapter" data-level="3.1" data-path="metodología.html"><a href="metodología.html#preliminares"><i class="fa fa-check"></i><b>3.1</b> Preliminares</a></li>
<li class="chapter" data-level="3.2" data-path="metodología.html"><a href="metodología.html#principales-metodologías-en-ciencia-de-datos"><i class="fa fa-check"></i><b>3.2</b> Principales metodologías en ciencia de datos</a></li>
<li class="chapter" data-level="3.3" data-path="metodología.html"><a href="metodología.html#met-crisp-dm"><i class="fa fa-check"></i><b>3.3</b> CRISP-DM para ciencia de datos</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="ch-110003.html"><a href="ch-110003.html"><i class="fa fa-check"></i><b>4</b> Ciencia de datos con R</a>
<ul>
<li class="chapter" data-level="4.1" data-path="ch-110003.html"><a href="ch-110003.html#introducción"><i class="fa fa-check"></i><b>4.1</b> Introducción</a></li>
<li class="chapter" data-level="4.2" data-path="ch-110003.html"><a href="ch-110003.html#id_110003-bases"><i class="fa fa-check"></i><b>4.2</b> La sesión de <strong>R</strong></a></li>
<li class="chapter" data-level="4.3" data-path="ch-110003.html"><a href="ch-110003.html#instalación-de-r"><i class="fa fa-check"></i><b>4.3</b> Instalación de <strong>R</strong></a></li>
<li class="chapter" data-level="4.4" data-path="ch-110003.html"><a href="ch-110003.html#id_110003-proyectos"><i class="fa fa-check"></i><b>4.4</b> Trabajar con proyectos de RStudio</a></li>
<li class="chapter" data-level="4.5" data-path="ch-110003.html"><a href="ch-110003.html#tratamiento-de-datos-con-r"><i class="fa fa-check"></i><b>4.5</b> Tratamiento de datos con <strong>R</strong></a>
<ul>
<li class="chapter" data-level="4.5.1" data-path="ch-110003.html"><a href="ch-110003.html#id_110003-estructuras"><i class="fa fa-check"></i><b>4.5.1</b> Estructuras y tipos de datos</a></li>
<li class="chapter" data-level="4.5.2" data-path="ch-110003.html"><a href="ch-110003.html#id_110003-importacion"><i class="fa fa-check"></i><b>4.5.2</b> Importación de datos</a></li>
<li class="chapter" data-level="4.5.3" data-path="ch-110003.html"><a href="ch-110003.html#exportación-y-archivos-de-datos-de-r"><i class="fa fa-check"></i><b>4.5.3</b> Exportación y archivos de datos de R</a></li>
</ul></li>
<li class="chapter" data-level="4.6" data-path="ch-110003.html"><a href="ch-110003.html#id_110003-tidyverse"><i class="fa fa-check"></i><b>4.6</b> Organización de datos con el <em>tidyverse</em></a>
<ul>
<li class="chapter" data-level="4.6.1" data-path="ch-110003.html"><a href="ch-110003.html#el-tidyverse-y-su-flujo-de-trabajo"><i class="fa fa-check"></i><b>4.6.1</b> El <em>tidyverse</em> y su flujo de trabajo</a></li>
<li class="chapter" data-level="4.6.2" data-path="ch-110003.html"><a href="ch-110003.html#transformación-de-datos-con-dplyr"><i class="fa fa-check"></i><b>4.6.2</b> Transformación de datos con <code>dplyr</code></a></li>
<li class="chapter" data-level="4.6.3" data-path="ch-110003.html"><a href="ch-110003.html#combinación-de-datos"><i class="fa fa-check"></i><b>4.6.3</b> Combinación de datos</a></li>
<li class="chapter" data-level="4.6.4" data-path="ch-110003.html"><a href="ch-110003.html#reorganización-de-datos"><i class="fa fa-check"></i><b>4.6.4</b> Reorganización de datos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="cap-etica.html"><a href="cap-etica.html"><i class="fa fa-check"></i><b>5</b> Ética en la ciencia de datos</a>
<ul>
<li class="chapter" data-level="5.1" data-path="cap-etica.html"><a href="cap-etica.html#por-que-la-ética-en-la-ciencia-de-datos"><i class="fa fa-check"></i><b>5.1</b> ¿Por que la ética en la ciencia de datos?</a></li>
<li class="chapter" data-level="5.2" data-path="cap-etica.html"><a href="cap-etica.html#los-principios-éticos"><i class="fa fa-check"></i><b>5.2</b> Los principios éticos</a></li>
<li class="chapter" data-level="5.3" data-path="cap-etica.html"><a href="cap-etica.html#la-importancia-de-los-sesgos"><i class="fa fa-check"></i><b>5.3</b> La importancia de los sesgos</a></li>
<li class="chapter" data-level="5.4" data-path="cap-etica.html"><a href="cap-etica.html#es-necesaria-la-explicabilidad"><i class="fa fa-check"></i><b>5.4</b> ¿Es necesaria la explicabilidad?</a></li>
<li class="chapter" data-level="5.5" data-path="cap-etica.html"><a href="cap-etica.html#sesgos-y-explicabilidad-en-r"><i class="fa fa-check"></i><b>5.5</b> Sesgos y explicabilidad en R</a></li>
</ul></li>
<li class="part"><span><b>II Bienvenido a la jungla de datos</b></span></li>
<li class="chapter" data-level="6" data-path="datos-sql.html"><a href="datos-sql.html"><i class="fa fa-check"></i><b>6</b> Gestión de bases de datos relacionales</a>
<ul>
<li class="chapter" data-level="6.1" data-path="datos-sql.html"><a href="datos-sql.html#introducción-1"><i class="fa fa-check"></i><b>6.1</b> Introducción</a></li>
<li class="chapter" data-level="6.2" data-path="datos-sql.html"><a href="datos-sql.html#concepto-de-base-de-datos"><i class="fa fa-check"></i><b>6.2</b> Concepto de Base de datos</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="datos-sql.html"><a href="datos-sql.html#gestión-de-los-datos-en-una-base-o-repositorio-de-datos"><i class="fa fa-check"></i><b>6.2.1</b> Gestión de los datos en una base o repositorio de datos</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="datos-sql.html"><a href="datos-sql.html#el-lenguaje-estructurado-de-consulta-sql"><i class="fa fa-check"></i><b>6.3</b> El Lenguaje Estructurado de Consulta (SQL)</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="datos-sql.html"><a href="datos-sql.html#sql-como-lenguaje-de-definición-de-datos-ldd"><i class="fa fa-check"></i><b>6.3.1</b> SQL como Lenguaje de Definición de Datos (LDD)</a></li>
<li class="chapter" data-level="6.3.2" data-path="datos-sql.html"><a href="datos-sql.html#sql-como-lenguaje-de-manipulación-de-datos-lmd"><i class="fa fa-check"></i><b>6.3.2</b> SQL como Lenguaje de Manipulación de Datos (LMD)</a></li>
<li class="chapter" data-level="6.3.3" data-path="datos-sql.html"><a href="datos-sql.html#sql-como-lenguaje-de-administración-de-datos-lad"><i class="fa fa-check"></i><b>6.3.3</b> SQL como Lenguaje de Administración de Datos (LAD)</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="datos-sql.html"><a href="datos-sql.html#usando-bases-de-datos-desde-r"><i class="fa fa-check"></i><b>6.4</b> Usando bases de datos desde R</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="datos-sql.html"><a href="datos-sql.html#conexión-a-una-base-de-datos"><i class="fa fa-check"></i><b>6.4.1</b> Conexión a una base de datos</a></li>
<li class="chapter" data-level="6.4.2" data-path="datos-sql.html"><a href="datos-sql.html#operaciones-de-lectura-selección-read-de-datos"><i class="fa fa-check"></i><b>6.4.2</b> Operaciones de lectura / selección (<em>read</em>) de datos</a></li>
<li class="chapter" data-level="6.4.3" data-path="datos-sql.html"><a href="datos-sql.html#operaciones-de-inserción-create-y-actualización-update-de-datos"><i class="fa fa-check"></i><b>6.4.3</b> Operaciones de inserción (<em>create</em>) y actualización (<em>update</em>) de datos</a></li>
<li class="chapter" data-level="6.4.4" data-path="datos-sql.html"><a href="datos-sql.html#operaciones-de-borrado-de-datos-delete"><i class="fa fa-check"></i><b>6.4.4</b> Operaciones de Borrado de datos (<em>delete</em>)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="datos-no-sql.html"><a href="datos-no-sql.html"><i class="fa fa-check"></i><b>7</b> Gesitón de bases de datos NoSQL</a>
<ul>
<li class="chapter" data-level="7.1" data-path="datos-no-sql.html"><a href="datos-no-sql.html#introducción-al-big-data"><i class="fa fa-check"></i><b>7.1</b> Introducción al Big Data</a></li>
<li class="chapter" data-level="7.2" data-path="datos-no-sql.html"><a href="datos-no-sql.html#VsBigData"><i class="fa fa-check"></i><b>7.2</b> Las V’s del Big Data</a></li>
<li class="chapter" data-level="7.3" data-path="datos-no-sql.html"><a href="datos-no-sql.html#fuentes-de-datos-en-entornos-big-data"><i class="fa fa-check"></i><b>7.3</b> Fuentes de Datos en entornos Big Data</a></li>
<li class="chapter" data-level="7.4" data-path="datos-no-sql.html"><a href="datos-no-sql.html#bases-de-datos-relacionales-vs.-nosql"><i class="fa fa-check"></i><b>7.4</b> Bases de datos Relacionales vs. NoSQL</a></li>
<li class="chapter" data-level="7.5" data-path="datos-no-sql.html"><a href="datos-no-sql.html#bases-de-datos-nosql"><i class="fa fa-check"></i><b>7.5</b> Bases de datos NoSQL</a>
<ul>
<li class="chapter" data-level="7.5.1" data-path="datos-no-sql.html"><a href="datos-no-sql.html#definición-de-bases-de-datos-nosql"><i class="fa fa-check"></i><b>7.5.1</b> Definición de bases de datos NoSQL</a></li>
<li class="chapter" data-level="7.5.2" data-path="datos-no-sql.html"><a href="datos-no-sql.html#necesidades-no-cubiertas-por-las-bases-de-datos-relacionales"><i class="fa fa-check"></i><b>7.5.2</b> Necesidades no cubiertas por las bases de datos relacionales</a></li>
<li class="chapter" data-level="7.5.3" data-path="datos-no-sql.html"><a href="datos-no-sql.html#tipos-de-almacenamiento-en-bases-de-datos-nosql"><i class="fa fa-check"></i><b>7.5.3</b> Tipos de almacenamiento en bases de datos NoSQL</a></li>
<li class="chapter" data-level="7.5.4" data-path="datos-no-sql.html"><a href="datos-no-sql.html#limitaciones-de-las-bases-de-datos-nosql"><i class="fa fa-check"></i><b>7.5.4</b> Limitaciones de las bases de datos NoSQL</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="datos-no-sql.html"><a href="datos-no-sql.html#ejemplo-de-integración-de-una-base-de-datos-nosql-y-análisis-de-datos-en-r"><i class="fa fa-check"></i><b>7.6</b> Ejemplo de integración de una base de datos NoSQL y análisis de datos en R</a>
<ul>
<li class="chapter" data-level="7.6.1" data-path="datos-no-sql.html"><a href="datos-no-sql.html#introMongo"><i class="fa fa-check"></i><b>7.6.1</b> Introducción a MongoDB</a></li>
<li class="chapter" data-level="7.6.2" data-path="datos-no-sql.html"><a href="datos-no-sql.html#paquetesCaso"><i class="fa fa-check"></i><b>7.6.2</b> Plataforma tecnológica para el caso práctico</a></li>
<li class="chapter" data-level="7.6.3" data-path="datos-no-sql.html"><a href="datos-no-sql.html#conexionMongo"><i class="fa fa-check"></i><b>7.6.3</b> Conexión y acceso a MongoDB desde R</a></li>
<li class="chapter" data-level="7.6.4" data-path="datos-no-sql.html"><a href="datos-no-sql.html#consultaViajes"><i class="fa fa-check"></i><b>7.6.4</b> Obtención de datos en R desde MongoDB</a></li>
<li class="chapter" data-level="7.6.5" data-path="datos-no-sql.html"><a href="datos-no-sql.html#analisisViajes"><i class="fa fa-check"></i><b>7.6.5</b> Analizando datos de MongoDB en R</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="DGDQM.html"><a href="DGDQM.html"><i class="fa fa-check"></i><b>8</b> Gobierno y gestión de calidad de datos</a>
<ul>
<li class="chapter" data-level="8.1" data-path="DGDQM.html"><a href="DGDQM.html#introducción-2"><i class="fa fa-check"></i><b>8.1</b> Introducción</a></li>
<li class="chapter" data-level="8.2" data-path="DGDQM.html"><a href="DGDQM.html#concepto-de-gobierno-de-datos"><i class="fa fa-check"></i><b>8.2</b> Concepto de Gobierno de datos</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="DGDQM.html"><a href="DGDQM.html#beneficiosDG"><i class="fa fa-check"></i><b>8.2.1</b> Beneficios del Gobierno de Datos</a></li>
<li class="chapter" data-level="8.2.2" data-path="DGDQM.html"><a href="DGDQM.html#artefactosDG"><i class="fa fa-check"></i><b>8.2.2</b> Artefactos de un sistema de Gobierno de Datos</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="DGDQM.html"><a href="DGDQM.html#marcos-y-metodologías-existentes-de-gobierno-de-datos"><i class="fa fa-check"></i><b>8.3</b> Marcos y metodologías existentes de Gobierno de Datos</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="DGDQM.html"><a href="DGDQM.html#modelo-alarcos-de-mejora-de-datos-mamd"><i class="fa fa-check"></i><b>8.3.1</b> Modelo Alarcos de Mejora de Datos (MAMD)</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="DGDQM.html"><a href="DGDQM.html#gestión-de-calidad-de-datos"><i class="fa fa-check"></i><b>8.4</b> Gestión de calidad de datos</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="DGDQM.html"><a href="DGDQM.html#medición-de-calidad-de-datos-vs-perfilado-de-datos"><i class="fa fa-check"></i><b>8.4.1</b> Medición de calidad de datos vs perfilado de datos</a></li>
<li class="chapter" data-level="8.4.2" data-path="DGDQM.html"><a href="DGDQM.html#mejora-de-datos"><i class="fa fa-check"></i><b>8.4.2</b> Mejora de datos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="id_130009.html"><a href="id_130009.html"><i class="fa fa-check"></i><b>9</b> Integración y limpieza de datos</a>
<ul>
<li class="chapter" data-level="9.1" data-path="id_130009.html"><a href="id_130009.html#introducción-3"><i class="fa fa-check"></i><b>9.1</b> Introducción</a></li>
<li class="chapter" data-level="9.2" data-path="id_130009.html"><a href="id_130009.html#problemas-de-calidad-de-datos"><i class="fa fa-check"></i><b>9.2</b> Problemas de calidad de datos</a></li>
<li class="chapter" data-level="9.3" data-path="id_130009.html"><a href="id_130009.html#niveles-inadecuados-de-completitud-valores-missing"><i class="fa fa-check"></i><b>9.3</b> Niveles inadecuados de completitud: Valores <em>missing</em></a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="id_130009.html"><a href="id_130009.html#visualización"><i class="fa fa-check"></i><b>9.3.1</b> Visualización</a></li>
<li class="chapter" data-level="9.3.2" data-path="id_130009.html"><a href="id_130009.html#imputacion"><i class="fa fa-check"></i><b>9.3.2</b> Técnicas de Imputación</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="id_130009.html"><a href="id_130009.html#mejorando-la-exactitud-y-la-precisión-eliminación-del-ruido-estadístico"><i class="fa fa-check"></i><b>9.4</b> Mejorando la exactitud y la precisión: eliminación del ruido estadístico</a></li>
<li class="chapter" data-level="9.5" data-path="id_130009.html"><a href="id_130009.html#integración-de-datos"><i class="fa fa-check"></i><b>9.5</b> Integración de datos </a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="id_120006-aed.html"><a href="id_120006-aed.html"><i class="fa fa-check"></i><b>10</b> Análisis exploratorio de datos</a>
<ul>
<li class="chapter" data-level="10.1" data-path="id_120006-aed.html"><a href="id_120006-aed.html#introducción-4"><i class="fa fa-check"></i><b>10.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="10.1.1" data-path="id_120006-aed.html"><a href="id_120006-aed.html#el-cuarterto-de-anscombe"><i class="fa fa-check"></i><b>10.1.1</b> El cuarterto de Anscombe</a></li>
<li class="chapter" data-level="10.1.2" data-path="id_120006-aed.html"><a href="id_120006-aed.html#conceptos-generales"><i class="fa fa-check"></i><b>10.1.2</b> Conceptos generales</a></li>
<li class="chapter" data-level="10.1.3" data-path="id_120006-aed.html"><a href="id_120006-aed.html#componentes-de-un-gráfico-y-su-representación-en-r"><i class="fa fa-check"></i><b>10.1.3</b> Componentes de un gráfico y su representación en R</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="id_120006-aed.html"><a href="id_120006-aed.html#id_120006-aeduni"><i class="fa fa-check"></i><b>10.2</b> Análisis exploratorio de una característica</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="id_120006-aed.html"><a href="id_120006-aed.html#variables-cualitativas"><i class="fa fa-check"></i><b>10.2.1</b> Variables cualitativas</a></li>
<li class="chapter" data-level="10.2.2" data-path="id_120006-aed.html"><a href="id_120006-aed.html#variables-cuantitativas"><i class="fa fa-check"></i><b>10.2.2</b> Variables cuantitativas</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="id_120006-aed.html"><a href="id_120006-aed.html#id_120006-aedmulti"><i class="fa fa-check"></i><b>10.3</b> Análisis exploratorio de varias características</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="id_120006-aed.html"><a href="id_120006-aed.html#variables-cualitativas-1"><i class="fa fa-check"></i><b>10.3.1</b> Variables cualitativas</a></li>
<li class="chapter" data-level="10.3.2" data-path="id_120006-aed.html"><a href="id_120006-aed.html#variables-cuantitativas-1"><i class="fa fa-check"></i><b>10.3.2</b> Variables cuantitativas</a></li>
<li class="chapter" data-level="10.3.3" data-path="id_120006-aed.html"><a href="id_120006-aed.html#variables-cualitativas-y-cuantitativas"><i class="fa fa-check"></i><b>10.3.3</b> Variables cualitativas y cuantitativas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="chap-feature.html"><a href="chap-feature.html"><i class="fa fa-check"></i><b>11</b> Feature selection and engineering</a>
<ul>
<li class="chapter" data-level="11.1" data-path="chap-feature.html"><a href="chap-feature.html#introducción-5"><i class="fa fa-check"></i><b>11.1</b> Introducción</a></li>
<li class="chapter" data-level="11.2" data-path="chap-feature.html"><a href="chap-feature.html#feature-selection-selección-de-variables"><i class="fa fa-check"></i><b>11.2</b> <em>Feature Selection</em> (Selección de variables)</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="chap-feature.html"><a href="chap-feature.html#métodos-de-selección-tipo-filtro"><i class="fa fa-check"></i><b>11.2.1</b> Métodos de selección tipo Filtro</a></li>
<li class="chapter" data-level="11.2.2" data-path="chap-feature.html"><a href="chap-feature.html#métodos-de-selección-de-variables-tipo-wrapper"><i class="fa fa-check"></i><b>11.2.2</b> Métodos de selección de variables tipo <em>wrapper</em></a></li>
<li class="chapter" data-level="11.2.3" data-path="chap-feature.html"><a href="chap-feature.html#métodos-de-selección-tipo-embedded"><i class="fa fa-check"></i><b>11.2.3</b> Métodos de selección tipo Embedded </a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="chap-feature.html"><a href="chap-feature.html#transformaciones-de-escala-y-de-la-distribución-de-la-variable-objetivo"><i class="fa fa-check"></i><b>11.3</b> Transformaciones de escala y de la distribución de la variable objetivo</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="chap-feature.html"><a href="chap-feature.html#id_31"><i class="fa fa-check"></i><b>11.3.1</b> Transformaciones de la variable objetivo</a></li>
<li class="chapter" data-level="11.3.2" data-path="chap-feature.html"><a href="chap-feature.html#escalado-de-datos"><i class="fa fa-check"></i><b>11.3.2</b> Escalado de datos</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="chap-feature.html"><a href="chap-feature.html#feature-engineering"><i class="fa fa-check"></i><b>11.4</b> <em>Feature engineering</em></a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="chap-feature.html"><a href="chap-feature.html#binning"><i class="fa fa-check"></i><b>11.4.1</b> <em>Binning</em> </a></li>
<li class="chapter" data-level="11.4.2" data-path="chap-feature.html"><a href="chap-feature.html#codificación"><i class="fa fa-check"></i><b>11.4.2</b> Codificación </a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="chap-feature.html"><a href="chap-feature.html#reducción-de-dimensionalidad"><i class="fa fa-check"></i><b>11.5</b> Reducción de dimensionalidad</a></li>
<li class="chapter" data-level="11.6" data-path="chap-feature.html"><a href="chap-feature.html#otras-transformaciones"><i class="fa fa-check"></i><b>11.6</b> Otras transformaciones</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="chap-feature.html"><a href="chap-feature.html#particionado-de-datos"><i class="fa fa-check"></i><b>11.6.1</b> Particionado de datos </a></li>
<li class="chapter" data-level="11.6.2" data-path="chap-feature.html"><a href="chap-feature.html#técnicas-para-manejar-datos-no-balanceados"><i class="fa fa-check"></i><b>11.6.2</b> Técnicas para manejar datos no balanceados </a></li>
<li class="chapter" data-level="11.6.3" data-path="chap-feature.html"><a href="chap-feature.html#métodos-de-remuestreo"><i class="fa fa-check"></i><b>11.6.3</b> Métodos de remuestreo </a></li>
<li class="chapter" data-level="11.6.4" data-path="chap-feature.html"><a href="chap-feature.html#ajuste-de-hiperparámetros"><i class="fa fa-check"></i><b>11.6.4</b> Ajuste de hiperparámetros</a></li>
<li class="chapter" data-level="11.6.5" data-path="chap-feature.html"><a href="chap-feature.html#evaluación-de-modelos"><i class="fa fa-check"></i><b>11.6.5</b> Evaluación de modelos</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Fundamentos de estadística</b></span></li>
<li class="chapter" data-level="12" data-path="Funda-probab.html"><a href="Funda-probab.html"><i class="fa fa-check"></i><b>12</b> Probabilidad</a>
<ul>
<li class="chapter" data-level="12.1" data-path="Funda-probab.html"><a href="Funda-probab.html#introducción-a-la-probabilidad"><i class="fa fa-check"></i><b>12.1</b> Introducción a la probabilidad</a></li>
<li class="chapter" data-level="12.2" data-path="Funda-probab.html"><a href="Funda-probab.html#probabilidad-elementos-básicos-definición-y-teoremas"><i class="fa fa-check"></i><b>12.2</b> Probabilidad: elementos básicos, definición y teoremas</a></li>
<li class="chapter" data-level="12.3" data-path="Funda-probab.html"><a href="Funda-probab.html#variable-aleatoria-y-su-distribución-tipos-de-variables-aleatorias"><i class="fa fa-check"></i><b>12.3</b> Variable aleatoria y su distribución: tipos de variables aleatorias</a></li>
<li class="chapter" data-level="12.4" data-path="Funda-probab.html"><a href="Funda-probab.html#modelos-de-distribución-de-probabilidad"><i class="fa fa-check"></i><b>12.4</b> Modelos de distribución de probabilidad</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="Funda-probab.html"><a href="Funda-probab.html#modelos-discretos"><i class="fa fa-check"></i><b>12.4.1</b> Modelos discretos</a></li>
<li class="chapter" data-level="12.4.2" data-path="Funda-probab.html"><a href="Funda-probab.html#modelos-continuos"><i class="fa fa-check"></i><b>12.4.2</b> Modelos continuos</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="Funda-probab.html"><a href="Funda-probab.html#tcl"><i class="fa fa-check"></i><b>12.5</b> Teorema central del límite</a></li>
<li class="chapter" data-level="12.6" data-path="Funda-probab.html"><a href="Funda-probab.html#distribuciones-de-probabilidad-en-r"><i class="fa fa-check"></i><b>12.6</b> Distribuciones de probabilidad en <strong>R</strong></a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="Fundainfer.html"><a href="Fundainfer.html"><i class="fa fa-check"></i><b>13</b> Inferencia estadística</a>
<ul>
<li class="chapter" data-level="13.1" data-path="Fundainfer.html"><a href="Fundainfer.html#introinfer"><i class="fa fa-check"></i><b>13.1</b> Introducción a la Inferencia Estadística</a></li>
<li class="chapter" data-level="13.2" data-path="Fundainfer.html"><a href="Fundainfer.html#mas"><i class="fa fa-check"></i><b>13.2</b> Muestreo aleatorio simple</a></li>
<li class="chapter" data-level="13.3" data-path="Fundainfer.html"><a href="Fundainfer.html#estimpuntual"><i class="fa fa-check"></i><b>13.3</b> Estimación puntual</a></li>
<li class="chapter" data-level="13.4" data-path="Fundainfer.html"><a href="Fundainfer.html#estimintervalos"><i class="fa fa-check"></i><b>13.4</b> Estimación por intervalos</a></li>
<li class="chapter" data-level="13.5" data-path="Fundainfer.html"><a href="Fundainfer.html#contrhip"><i class="fa fa-check"></i><b>13.5</b> Contrastes de hipótesis</a></li>
<li class="chapter" data-level="13.6" data-path="Fundainfer.html"><a href="Fundainfer.html#pobnormales"><i class="fa fa-check"></i><b>13.6</b> Inferencia estadística paramétrica sobre poblaciones normales</a></li>
<li class="chapter" data-level="13.7" data-path="Fundainfer.html"><a href="Fundainfer.html#ejemplopobnorm"><i class="fa fa-check"></i><b>13.7</b> Inferencia sobre poblaciones normales con <strong>R</strong></a></li>
<li class="chapter" data-level="13.8" data-path="Fundainfer.html"><a href="Fundainfer.html#contrnormalidad"><i class="fa fa-check"></i><b>13.8</b> Inferencia estadística no paramétrica: contrastes de normalidad</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="muestreo.html"><a href="muestreo.html"><i class="fa fa-check"></i><b>14</b> Muestreo y remuestreo</a>
<ul>
<li class="chapter" data-level="14.1" data-path="muestreo.html"><a href="muestreo.html#introducción-al-muestreo"><i class="fa fa-check"></i><b>14.1</b> Introducción al muestreo</a></li>
<li class="chapter" data-level="14.2" data-path="muestreo.html"><a href="muestreo.html#muestreo-aleatorio-simple-1"><i class="fa fa-check"></i><b>14.2</b> Muestreo aleatorio simple</a></li>
<li class="chapter" data-level="14.3" data-path="muestreo.html"><a href="muestreo.html#muestestra"><i class="fa fa-check"></i><b>14.3</b> Muestreo estratificado</a></li>
<li class="chapter" data-level="14.4" data-path="muestreo.html"><a href="muestreo.html#otros-tipos-de-muestreo-probabilístico"><i class="fa fa-check"></i><b>14.4</b> Otros tipos de muestreo probabilístico</a></li>
<li class="chapter" data-level="14.5" data-path="muestreo.html"><a href="muestreo.html#técnicas-de-remuestreo-bootstrap."><i class="fa fa-check"></i><b>14.5</b> Técnicas de remuestreo: Bootstrap.</a></li>
</ul></li>
<li class="part"><span><b>IV Modelización estadística</b></span></li>
<li class="chapter" data-level="15" data-path="cap-lm.html"><a href="cap-lm.html"><i class="fa fa-check"></i><b>15</b> Modelización lineal</a>
<ul>
<li class="chapter" data-level="15.1" data-path="cap-lm.html"><a href="cap-lm.html#modelización"><i class="fa fa-check"></i><b>15.1</b> Modelización</a></li>
<li class="chapter" data-level="15.2" data-path="cap-lm.html"><a href="cap-lm.html#procedimiento-de-modelización"><i class="fa fa-check"></i><b>15.2</b> Procedimiento de modelización</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="cap-lm.html"><a href="cap-lm.html#Bondad"><i class="fa fa-check"></i><b>15.2.1</b> Estimación del modelo</a></li>
<li class="chapter" data-level="15.2.2" data-path="cap-lm.html"><a href="cap-lm.html#validación-del-modelo"><i class="fa fa-check"></i><b>15.2.2</b> Validación del modelo</a></li>
<li class="chapter" data-level="15.2.3" data-path="cap-lm.html"><a href="cap-lm.html#interpretación-de-los-coeficientes"><i class="fa fa-check"></i><b>15.2.3</b> Interpretación de los coeficientes</a></li>
<li class="chapter" data-level="15.2.4" data-path="cap-lm.html"><a href="cap-lm.html#predicción"><i class="fa fa-check"></i><b>15.2.4</b> Predicción</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="cap-lm.html"><a href="cap-lm.html#procedimiento-con-r-la-función-lm"><i class="fa fa-check"></i><b>15.3</b> Procedimiento con R: la función <code>lm</code></a></li>
<li class="chapter" data-level="15.4" data-path="cap-lm.html"><a href="cap-lm.html#Casos"><i class="fa fa-check"></i><b>15.4</b> Casos prácticos</a>
<ul>
<li class="chapter" data-level="15.4.1" data-path="cap-lm.html"><a href="cap-lm.html#estimación-de-los-coeficientes"><i class="fa fa-check"></i><b>15.4.1</b> Estimación de los coeficientes</a></li>
<li class="chapter" data-level="15.4.2" data-path="cap-lm.html"><a href="cap-lm.html#validación"><i class="fa fa-check"></i><b>15.4.2</b> Validación</a></li>
<li class="chapter" data-level="15.4.3" data-path="cap-lm.html"><a href="cap-lm.html#interpretación-de-los-coeficientes-1"><i class="fa fa-check"></i><b>15.4.3</b> Interpretación de los coeficientes</a></li>
<li class="chapter" data-level="15.4.4" data-path="cap-lm.html"><a href="cap-lm.html#predicción-1"><i class="fa fa-check"></i><b>15.4.4</b> Predicción</a></li>
<li class="chapter" data-level="15.4.5" data-path="cap-lm.html"><a href="cap-lm.html#nuevo-ajuste-con-logozone"><i class="fa fa-check"></i><b>15.4.5</b> Nuevo ajuste con <code>log(Ozone)</code></a></li>
<li class="chapter" data-level="15.4.6" data-path="cap-lm.html"><a href="cap-lm.html#coeficientes-de-variables-categóricas"><i class="fa fa-check"></i><b>15.4.6</b> Coeficientes de variables categóricas</a></li>
</ul></li>
<li class="chapter" data-level="15.5" data-path="cap-lm.html"><a href="cap-lm.html#comentarios-finales"><i class="fa fa-check"></i><b>15.5</b> Comentarios finales</a>
<ul>
<li class="chapter" data-level="" data-path="cap-lm.html"><a href="cap-lm.html#resumen"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="cap-glm.html"><a href="cap-glm.html"><i class="fa fa-check"></i><b>16</b> Modelos lineales generalizados</a>
<ul>
<li class="chapter" data-level="16.1" data-path="cap-glm.html"><a href="cap-glm.html#motivación"><i class="fa fa-check"></i><b>16.1</b> Motivación</a></li>
<li class="chapter" data-level="16.2" data-path="cap-glm.html"><a href="cap-glm.html#modelo-y-sus-componentes"><i class="fa fa-check"></i><b>16.2</b> Modelo y sus componentes</a>
<ul>
<li class="chapter" data-level="16.2.1" data-path="cap-glm.html"><a href="cap-glm.html#función-enlace"><i class="fa fa-check"></i><b>16.2.1</b> Función enlace </a></li>
<li class="chapter" data-level="16.2.2" data-path="cap-glm.html"><a href="cap-glm.html#glms-en-r"><i class="fa fa-check"></i><b>16.2.2</b> GLMs en <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="cap-glm.html"><a href="cap-glm.html#regresión-logística"><i class="fa fa-check"></i><b>16.3</b> Regresión logística</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="cap-glm.html"><a href="cap-glm.html#procedimiento-de-ajuste"><i class="fa fa-check"></i><b>16.3.1</b> Procedimiento de ajuste</a></li>
<li class="chapter" data-level="16.3.2" data-path="cap-glm.html"><a href="cap-glm.html#adecuación-del-modelo"><i class="fa fa-check"></i><b>16.3.2</b> Adecuación del modelo</a></li>
<li class="chapter" data-level="16.3.3" data-path="cap-glm.html"><a href="cap-glm.html#SECCinterp"><i class="fa fa-check"></i><b>16.3.3</b> Interpretación de resultados</a></li>
<li class="chapter" data-level="16.3.4" data-path="cap-glm.html"><a href="cap-glm.html#predicción.-curva-roc-y-auc"><i class="fa fa-check"></i><b>16.3.4</b> Predicción. Curva ROC y AUC</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="cap-glm.html"><a href="cap-glm.html#regresión-de-poisson"><i class="fa fa-check"></i><b>16.4</b> Regresión de Poisson</a></li>
<li class="chapter" data-level="16.5" data-path="cap-glm.html"><a href="cap-glm.html#casos-prácticos"><i class="fa fa-check"></i><b>16.5</b> Casos prácticos</a>
<ul>
<li class="chapter" data-level="16.5.1" data-path="cap-glm.html"><a href="cap-glm.html#ejemplos-de-regresión-logística"><i class="fa fa-check"></i><b>16.5.1</b> Ejemplos de regresión logística</a></li>
<li class="chapter" data-level="16.5.2" data-path="cap-glm.html"><a href="cap-glm.html#ejemplo-de-regresión-de-poisson"><i class="fa fa-check"></i><b>16.5.2</b> Ejemplo de regresión de Poisson</a></li>
<li class="chapter" data-level="" data-path="cap-glm.html"><a href="cap-glm.html#resumen-1"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="cap-gam.html"><a href="cap-gam.html"><i class="fa fa-check"></i><b>17</b> Modelos aditivos generalizados</a>
<ul>
<li class="chapter" data-level="17.1" data-path="cap-gam.html"><a href="cap-gam.html#introducción-6"><i class="fa fa-check"></i><b>17.1</b> Introducción</a></li>
<li class="chapter" data-level="17.2" data-path="cap-gam.html"><a href="cap-gam.html#splines-con-penalizaciones"><i class="fa fa-check"></i><b>17.2</b> Splines con penalizaciones</a></li>
<li class="chapter" data-level="17.3" data-path="cap-gam.html"><a href="cap-gam.html#aspectos-metodológicos"><i class="fa fa-check"></i><b>17.3</b> Aspectos metodológicos</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="cap-gam.html"><a href="cap-gam.html#estimación-de-los-paraámetros-del-modelo"><i class="fa fa-check"></i><b>17.3.1</b> Estimación de los paraámetros del modelo</a></li>
<li class="chapter" data-level="17.3.2" data-path="cap-gam.html"><a href="cap-gam.html#inferencia-sobre-las-funciones-suaves"><i class="fa fa-check"></i><b>17.3.2</b> Inferencia sobre las funciones suaves</a></li>
<li class="chapter" data-level="17.3.3" data-path="cap-gam.html"><a href="cap-gam.html#suavizado-mutidimensional-y-para-datos-no-gaussianos"><i class="fa fa-check"></i><b>17.3.3</b> Suavizado mutidimensional y para datos no Gaussianos</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="cap-gam.html"><a href="cap-gam.html#la-función-gam-del-paquete-mgcv"><i class="fa fa-check"></i><b>17.4</b> La función <code>gam</code> del paquete <code>mgcv</code></a></li>
<li class="chapter" data-level="17.5" data-path="cap-gam.html"><a href="cap-gam.html#casos-prácticos-1"><i class="fa fa-check"></i><b>17.5</b> Casos prácticos</a>
<ul>
<li class="chapter" data-level="17.5.1" data-path="cap-gam.html"><a href="cap-gam.html#modelo-unidimensional-con-fossil"><i class="fa fa-check"></i><b>17.5.1</b> Modelo unidimensional con <code>fossil</code></a></li>
<li class="chapter" data-level="17.5.2" data-path="cap-gam.html"><a href="cap-gam.html#modelo-aditivo-con-airquality"><i class="fa fa-check"></i><b>17.5.2</b> Modelo aditivo con <code>airquality</code></a></li>
<li class="chapter" data-level="17.5.3" data-path="cap-gam.html"><a href="cap-gam.html#modelo-semiparamétrico-con-onions"><i class="fa fa-check"></i><b>17.5.3</b> Modelo semiparamétrico con <code>onions</code></a></li>
<li class="chapter" data-level="17.5.4" data-path="cap-gam.html"><a href="cap-gam.html#modelo-aditivo-generalizado-y-multidimensional-con-smacker"><i class="fa fa-check"></i><b>17.5.4</b> Modelo aditivo generalizado y multidimensional, con <code>smacker</code></a></li>
<li class="chapter" data-level="" data-path="cap-gam.html"><a href="cap-gam.html#resumen-2"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="cap-mxm.html"><a href="cap-mxm.html"><i class="fa fa-check"></i><b>18</b> Modelos mixtos</a>
<ul>
<li class="chapter" data-level="18.1" data-path="cap-mxm.html"><a href="cap-mxm.html#conceptos-básicos"><i class="fa fa-check"></i><b>18.1</b> Conceptos básicos</a>
<ul>
<li class="chapter" data-level="18.1.1" data-path="cap-mxm.html"><a href="cap-mxm.html#tipo-y-estructura-de-los-datos"><i class="fa fa-check"></i><b>18.1.1</b> Tipo y estructura de los datos</a></li>
<li class="chapter" data-level="18.1.2" data-path="cap-mxm.html"><a href="cap-mxm.html#efectos-fijos-o-aleatorios"><i class="fa fa-check"></i><b>18.1.2</b> ¿Efectos fijos o aleatorios?</a></li>
</ul></li>
<li class="chapter" data-level="18.2" data-path="cap-mxm.html"><a href="cap-mxm.html#formulación-del-modelo-con-efectos-aleatorios-o-modelos-mixtos"><i class="fa fa-check"></i><b>18.2</b> Formulación del modelo con efectos aleatorios o modelos mixtos</a>
<ul>
<li class="chapter" data-level="18.2.1" data-path="cap-mxm.html"><a href="cap-mxm.html#formulación-general"><i class="fa fa-check"></i><b>18.2.1</b> Formulación general</a></li>
<li class="chapter" data-level="18.2.2" data-path="cap-mxm.html"><a href="cap-mxm.html#inferencia-y-selección-del-modelo"><i class="fa fa-check"></i><b>18.2.2</b> Inferencia y selección del modelo</a></li>
<li class="chapter" data-level="18.2.3" data-path="cap-mxm.html"><a href="cap-mxm.html#diagnosis-del-modelo"><i class="fa fa-check"></i><b>18.2.3</b> Diagnosis del modelo</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="cap-mxm.html"><a href="cap-mxm.html#funciones-de-r-para-ajustar-modelos-mixtos"><i class="fa fa-check"></i><b>18.3</b> Funciones de <code>R</code> para ajustar modelos mixtos</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="cap-mxm.html"><a href="cap-mxm.html#la-función-lmer"><i class="fa fa-check"></i><b>18.3.1</b> La función <code>lmer()</code></a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="cap-mxm.html"><a href="cap-mxm.html#caso-práctico"><i class="fa fa-check"></i><b>18.4</b> Caso práctico</a>
<ul>
<li class="chapter" data-level="18.4.1" data-path="cap-mxm.html"><a href="cap-mxm.html#modelo-con-ordenada-en-el-origen-aleatoria"><i class="fa fa-check"></i><b>18.4.1</b> Modelo con ordenada en el origen aleatoria</a></li>
<li class="chapter" data-level="18.4.2" data-path="cap-mxm.html"><a href="cap-mxm.html#modelo-con-pendiente-aleatoria"><i class="fa fa-check"></i><b>18.4.2</b> Modelo con pendiente aleatoria</a></li>
<li class="chapter" data-level="18.4.3" data-path="cap-mxm.html"><a href="cap-mxm.html#cómo-construir-el-modelo-en-la-práctica"><i class="fa fa-check"></i><b>18.4.3</b> ¿Cómo construir el modelo en la práctica?</a></li>
<li class="chapter" data-level="" data-path="cap-mxm.html"><a href="cap-mxm.html#resumen-3"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="cap-sparse.html"><a href="cap-sparse.html"><i class="fa fa-check"></i><b>19</b> Modelos sparse y métodos penalizados de regresión</a>
<ul>
<li class="chapter" data-level="19.1" data-path="cap-sparse.html"><a href="cap-sparse.html#introducción-7"><i class="fa fa-check"></i><b>19.1</b> Introducción</a></li>
<li class="chapter" data-level="19.2" data-path="cap-sparse.html"><a href="cap-sparse.html#selección-del-mejor-subconjunto"><i class="fa fa-check"></i><b>19.2</b> Selección del mejor subconjunto</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="cap-sparse.html"><a href="cap-sparse.html#ejemplo-sueldo-de-jugadores-de-béisbol"><i class="fa fa-check"></i><b>19.2.1</b> Ejemplo: Sueldo de jugadores de béisbol</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="cap-sparse.html"><a href="cap-sparse.html#selección-stepwise"><i class="fa fa-check"></i><b>19.3</b> Selección <em>Stepwise</em></a>
<ul>
<li class="chapter" data-level="19.3.1" data-path="cap-sparse.html"><a href="cap-sparse.html#forward-stepwise"><i class="fa fa-check"></i><b>19.3.1</b> Forward stepwise</a></li>
<li class="chapter" data-level="19.3.2" data-path="cap-sparse.html"><a href="cap-sparse.html#backward-stepwise"><i class="fa fa-check"></i><b>19.3.2</b> Backward stepwise</a></li>
<li class="chapter" data-level="19.3.3" data-path="cap-sparse.html"><a href="cap-sparse.html#ejemplo-sueldo-de-jugadores-de-béisbol-1"><i class="fa fa-check"></i><b>19.3.3</b> Ejemplo: Sueldo de jugadores de béisbol</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="cap-sparse.html"><a href="cap-sparse.html#métodos-shrinkage"><i class="fa fa-check"></i><b>19.4</b> Métodos Shrinkage</a>
<ul>
<li class="chapter" data-level="19.4.1" data-path="cap-sparse.html"><a href="cap-sparse.html#regresión-ridge"><i class="fa fa-check"></i><b>19.4.1</b> Regresión ridge</a></li>
<li class="chapter" data-level="19.4.2" data-path="cap-sparse.html"><a href="cap-sparse.html#selección-del-parámetro-de-tuneado"><i class="fa fa-check"></i><b>19.4.2</b> Selección del parámetro de tuneado</a></li>
<li class="chapter" data-level="19.4.3" data-path="cap-sparse.html"><a href="cap-sparse.html#regresión-lasso"><i class="fa fa-check"></i><b>19.4.3</b> Regresión Lasso</a></li>
<li class="chapter" data-level="19.4.4" data-path="cap-sparse.html"><a href="cap-sparse.html#elastic-net"><i class="fa fa-check"></i><b>19.4.4</b> Elastic net </a></li>
<li class="chapter" data-level="" data-path="cap-sparse.html"><a href="cap-sparse.html#resumen-4"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="20" data-path="cap-series-temp.html"><a href="cap-series-temp.html"><i class="fa fa-check"></i><b>20</b> Modelización de series temporales</a>
<ul>
<li class="chapter" data-level="20.1" data-path="cap-series-temp.html"><a href="cap-series-temp.html#conceptos-básicos-1"><i class="fa fa-check"></i><b>20.1</b> Conceptos básicos</a></li>
<li class="chapter" data-level="20.2" data-path="cap-series-temp.html"><a href="cap-series-temp.html#modelos-arima"><i class="fa fa-check"></i><b>20.2</b> Modelos ARIMA</a></li>
<li class="chapter" data-level="20.3" data-path="cap-series-temp.html"><a href="cap-series-temp.html#análisis-de-series-temporales-con-r"><i class="fa fa-check"></i><b>20.3</b> Análisis de series temporales con <strong>R</strong></a>
<ul>
<li class="chapter" data-level="20.3.1" data-path="cap-series-temp.html"><a href="cap-series-temp.html#identificación-o-especificación-del-modelo"><i class="fa fa-check"></i><b>20.3.1</b> Identificación o especificación del modelo</a></li>
<li class="chapter" data-level="20.3.2" data-path="cap-series-temp.html"><a href="cap-series-temp.html#estimación-del-modelo"><i class="fa fa-check"></i><b>20.3.2</b> Estimación del modelo</a></li>
<li class="chapter" data-level="20.3.3" data-path="cap-series-temp.html"><a href="cap-series-temp.html#diagnosis-validación-y-contrastación"><i class="fa fa-check"></i><b>20.3.3</b> Diagnosis, validación y contrastación</a></li>
<li class="chapter" data-level="20.3.4" data-path="cap-series-temp.html"><a href="cap-series-temp.html#predicción-2"><i class="fa fa-check"></i><b>20.3.4</b> Predicción</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="21" data-path="cap-discriminante.html"><a href="cap-discriminante.html"><i class="fa fa-check"></i><b>21</b> Análisis discriminante</a>
<ul>
<li class="chapter" data-level="21.1" data-path="cap-discriminante.html"><a href="cap-discriminante.html#introducción-8"><i class="fa fa-check"></i><b>21.1</b> Introducción</a></li>
<li class="chapter" data-level="21.2" data-path="cap-discriminante.html"><a href="cap-discriminante.html#tipos-de-análisis-discriminantes"><i class="fa fa-check"></i><b>21.2</b> Tipos de análisis discriminantes:</a></li>
<li class="chapter" data-level="21.3" data-path="cap-discriminante.html"><a href="cap-discriminante.html#procedimiento-con-r-las-funciones-lda-qda-y-mda"><i class="fa fa-check"></i><b>21.3</b> Procedimiento con <strong>R</strong>: las funciones <code>lda()</code>, <code>qda()</code> y <code>mda()</code></a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="cap-conjunto.html"><a href="cap-conjunto.html"><i class="fa fa-check"></i><b>22</b> Análisis conjunto</a>
<ul>
<li class="chapter" data-level="22.1" data-path="cap-conjunto.html"><a href="cap-conjunto.html#introducción-conceptos-clave-y-tipos-de-análisis"><i class="fa fa-check"></i><b>22.1</b> Introducción, conceptos clave y tipos de análisis</a></li>
<li class="chapter" data-level="22.2" data-path="cap-conjunto.html"><a href="cap-conjunto.html#aplicación-del-análisis-conjunto-etapas"><i class="fa fa-check"></i><b>22.2</b> Aplicación del Análisis Conjunto (etapas):</a></li>
<li class="chapter" data-level="22.3" data-path="cap-conjunto.html"><a href="cap-conjunto.html#procedimiento-con-r-la-función-conjoint"><i class="fa fa-check"></i><b>22.3</b> Procedimiento con <strong>R</strong>: la función <code>Conjoint()</code></a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html"><i class="fa fa-check"></i><b>23</b> Análisis de tablas de contingencia</a>
<ul>
<li class="chapter" data-level="23.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#introducción-9"><i class="fa fa-check"></i><b>23.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="23.1.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#motiv"><i class="fa fa-check"></i><b>23.1.1</b> Motivación</a></li>
<li class="chapter" data-level="23.1.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#notac"><i class="fa fa-check"></i><b>23.1.2</b> Notación</a></li>
<li class="chapter" data-level="23.1.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#diseños-experimentales-o-procedimientos-de-muestreo-que-dan-lugar-a-una-tabla-de-contingencia"><i class="fa fa-check"></i><b>23.1.3</b> Diseños experimentales o procedimientos de muestreo que dan lugar a una tabla de contingencia</a></li>
</ul></li>
<li class="chapter" data-level="23.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contraste-de-independencia-en-tablas-2times-2"><i class="fa fa-check"></i><b>23.2</b> Contraste de independencia en tablas <span class="math inline">\(2\times 2\)</span></a>
<ul>
<li class="chapter" data-level="23.2.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#introducción-10"><i class="fa fa-check"></i><b>23.2.1</b> Introducción</a></li>
<li class="chapter" data-level="23.2.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#plantgen"><i class="fa fa-check"></i><b>23.2.2</b> Planteamiento general del contraste exacto de independencia</a></li>
<li class="chapter" data-level="23.2.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#algoritmo"><i class="fa fa-check"></i><b>23.2.3</b> Algoritmo para la realización del contraste exacto de independencia</a></li>
<li class="chapter" data-level="23.2.4" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contraste-de-independencia-diseño-tipo-1"><i class="fa fa-check"></i><b>23.2.4</b> Contraste de independencia: Diseño Tipo 1</a></li>
<li class="chapter" data-level="23.2.5" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#dise"><i class="fa fa-check"></i><b>23.2.5</b> Contraste de independencia: Diseños Tipo 2 y Tipo 3</a></li>
</ul></li>
<li class="chapter" data-level="23.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contraste-de-independencia-en-tablas-rtimes-c"><i class="fa fa-check"></i><b>23.3</b> Contraste de independencia en tablas <span class="math inline">\(R\times C\)</span></a>
<ul>
<li class="chapter" data-level="23.3.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#IntroRxC"><i class="fa fa-check"></i><b>23.3.1</b> Introducción</a></li>
<li class="chapter" data-level="23.3.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contaprox"><i class="fa fa-check"></i><b>23.3.2</b> Contrastes aproximados</a></li>
<li class="chapter" data-level="23.3.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contraste-aproximado-con-corrección-de-continuidad-1"><i class="fa fa-check"></i><b>23.3.3</b> Contraste aproximado con corrección de continuidad</a></li>
</ul></li>
<li class="chapter" data-level="23.4" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#medidas"><i class="fa fa-check"></i><b>23.4</b> Medidas de asociación en tablas <span class="math inline">\(2\times 2\)</span></a>
<ul>
<li class="chapter" data-level="23.4.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#introducción-11"><i class="fa fa-check"></i><b>23.4.1</b> Introducción</a></li>
<li class="chapter" data-level="23.4.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#la-hatq-de-yule"><i class="fa fa-check"></i><b>23.4.2</b> La <span class="math inline">\(\hat{Q}\)</span> de Yule</a></li>
<li class="chapter" data-level="23.4.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#otras-medidas-de-asociación-para-tablas-2times-2"><i class="fa fa-check"></i><b>23.4.3</b> Otras medidas de asociación para tablas <span class="math inline">\(2\times 2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="23.5" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#medidas-de-asociación-en-tablas-rtimes-c"><i class="fa fa-check"></i><b>23.5</b> Medidas de asociación en tablas <span class="math inline">\(R\times C\)</span></a>
<ul>
<li class="chapter" data-level="23.5.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#introducción-12"><i class="fa fa-check"></i><b>23.5.1</b> Introducción</a></li>
<li class="chapter" data-level="23.5.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#medidas-derivadas-del-estadístico-chi-cuadrado"><i class="fa fa-check"></i><b>23.5.2</b> Medidas derivadas del estadístico Chi-cuadrado</a></li>
<li class="chapter" data-level="23.5.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#medidas-basadas-en-la-reducción-proporcional-del-error-lambda-de-goodman-y-kruskal"><i class="fa fa-check"></i><b>23.5.3</b> Medidas basadas en la reducción proporcional del error: <span class="math inline">\(\lambda\)</span> de Goodman y Kruskal</a></li>
<li class="chapter" data-level="23.5.4" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#determinación-de-las-fuentes-de-asociación"><i class="fa fa-check"></i><b>23.5.4</b> Determinación de las fuentes de asociación</a></li>
</ul></li>
<li class="chapter" data-level="23.6" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contrastes-de-independencia-en-tablas-multidimensionales"><i class="fa fa-check"></i><b>23.6</b> Contrastes de independencia en tablas multidimensionales</a></li>
</ul></li>
<li class="part"><span><b>V Machine learning supervisado</b></span></li>
<li class="chapter" data-level="24" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html"><i class="fa fa-check"></i><b>24</b> Árboles de clasificación y regresión </a>
<ul>
<li class="chapter" data-level="24.1" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#introducción-13"><i class="fa fa-check"></i><b>24.1</b> Introducción </a></li>
<li class="chapter" data-level="24.2" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#aprendizaje-con-árboles-de-decisión"><i class="fa fa-check"></i><b>24.2</b> Aprendizaje con árboles de decisión</a></li>
<li class="chapter" data-level="24.3" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#cómo-se-va-dividiendo-el-árbol"><i class="fa fa-check"></i><b>24.3</b> ¿Cómo se va dividiendo el árbol? </a>
<ul>
<li class="chapter" data-level="24.3.1" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#impureza-de-gini"><i class="fa fa-check"></i><b>24.3.1</b> Impureza de Gini</a></li>
<li class="chapter" data-level="24.3.2" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#entropía"><i class="fa fa-check"></i><b>24.3.2</b> Entropía </a></li>
<li class="chapter" data-level="24.3.3" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#ganancia-de-información"><i class="fa fa-check"></i><b>24.3.3</b> Ganancia de información</a></li>
<li class="chapter" data-level="24.3.4" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#suma-residual-de-cuadrados-mínima"><i class="fa fa-check"></i><b>24.3.4</b> Suma residual de cuadrados mínima</a></li>
</ul></li>
<li class="chapter" data-level="24.4" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#sobreajuste"><i class="fa fa-check"></i><b>24.4</b> Sobreajuste </a></li>
<li class="chapter" data-level="24.5" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#cuánto-debe-crecer-un-árbol"><i class="fa fa-check"></i><b>24.5</b> ¿Cuánto debe crecer un árbol? </a>
<ul>
<li class="chapter" data-level="24.5.1" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#la-parada-temprana"><i class="fa fa-check"></i><b>24.5.1</b> La parada temprana </a></li>
<li class="chapter" data-level="24.5.2" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#la-poda"><i class="fa fa-check"></i><b>24.5.2</b> La poda </a></li>
</ul></li>
<li class="chapter" data-level="24.6" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#el-algoritmo-id3-para-la-construcción-de-un-árbol-de-decisión"><i class="fa fa-check"></i><b>24.6</b> El algoritmo ID3 para la construcción de un árbol de decisión</a></li>
<li class="chapter" data-level="24.7" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#procedimiento-con-r-la-funcion-rpart"><i class="fa fa-check"></i><b>24.7</b> Procedimiento con R: la funcion <code>rpart</code></a></li>
<li class="chapter" data-level="24.8" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#aplicaciones-de-los-árboles-de-decisión"><i class="fa fa-check"></i><b>24.8</b> Aplicaciones de los árboles de decisión</a>
<ul>
<li class="chapter" data-level="24.8.1" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#el-caso-de-negocio"><i class="fa fa-check"></i><b>24.8.1</b> El caso de negocio</a></li>
<li class="chapter" data-level="24.8.2" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#árbol-de-clasificación-para-determinar-la-intención-de-compra"><i class="fa fa-check"></i><b>24.8.2</b> Árbol de clasificación para determinar la intención de compra</a></li>
<li class="chapter" data-level="24.8.3" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#árbol-de-regresión-para-estimar-el-número-de-días-hospitalizado"><i class="fa fa-check"></i><b>24.8.3</b> Árbol de regresión para estimar el número de días hospitalizado</a></li>
<li class="chapter" data-level="" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#resumen-5"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="25" data-path="cap-svm.html"><a href="cap-svm.html"><i class="fa fa-check"></i><b>25</b> Máquinas de vector soporte</a>
<ul>
<li class="chapter" data-level="25.1" data-path="cap-svm.html"><a href="cap-svm.html#introducción-14"><i class="fa fa-check"></i><b>25.1</b> Introducción</a></li>
<li class="chapter" data-level="25.2" data-path="cap-svm.html"><a href="cap-svm.html#algoritmo-svm-para-clasificación-binaria"><i class="fa fa-check"></i><b>25.2</b> Algoritmo SVM para clasificación binaria</a></li>
<li class="chapter" data-level="25.3" data-path="cap-svm.html"><a href="cap-svm.html#y-si-tengo-más-de-dos-clases"><i class="fa fa-check"></i><b>25.3</b> ¿Y si tengo más de dos clases?</a></li>
<li class="chapter" data-level="25.4" data-path="cap-svm.html"><a href="cap-svm.html#truco-del-kernel-tratando-con-la-no-linearidad"><i class="fa fa-check"></i><b>25.4</b> Truco del Kernel: Tratando con la no linearidad</a>
<ul>
<li class="chapter" data-level="25.4.1" data-path="cap-svm.html"><a href="cap-svm.html#algunos-kernels-populares"><i class="fa fa-check"></i><b>25.4.1</b> Algunos kernels populares</a></li>
</ul></li>
<li class="chapter" data-level="25.5" data-path="cap-svm.html"><a href="cap-svm.html#procedimiento-con-r-la-funcion-svm"><i class="fa fa-check"></i><b>25.5</b> Procedimiento con R: la funcion <code>svm</code></a></li>
<li class="chapter" data-level="25.6" data-path="cap-svm.html"><a href="cap-svm.html#aplicación-de-un-modelo-svm-radial-con-ajuste-automático-en-r"><i class="fa fa-check"></i><b>25.6</b> Aplicación de un modelo SVM Radial con ajuste automático en R</a>
<ul>
<li class="chapter" data-level="25.6.1" data-path="cap-svm.html"><a href="cap-svm.html#importancia-de-las-variables"><i class="fa fa-check"></i><b>25.6.1</b> Importancia de las variables</a></li>
<li class="chapter" data-level="" data-path="cap-svm.html"><a href="cap-svm.html#resumen-6"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="26" data-path="cap-knn.html"><a href="cap-knn.html"><i class="fa fa-check"></i><b>26</b> Clasificador k-vecinos más próximos</a>
<ul>
<li class="chapter" data-level="26.1" data-path="cap-knn.html"><a href="cap-knn.html#introducción-15"><i class="fa fa-check"></i><b>26.1</b> Introducción</a></li>
<li class="chapter" data-level="26.2" data-path="cap-knn.html"><a href="cap-knn.html#decisiones-a-tener-en-cuenta"><i class="fa fa-check"></i><b>26.2</b> Decisiones a tener en cuenta</a>
<ul>
<li class="chapter" data-level="26.2.1" data-path="cap-knn.html"><a href="cap-knn.html#función-de-distancia-a-utilizar"><i class="fa fa-check"></i><b>26.2.1</b> Función de distancia a utilizar</a></li>
<li class="chapter" data-level="26.2.2" data-path="cap-knn.html"><a href="cap-knn.html#número-de-vecinos-k-seleccionados"><i class="fa fa-check"></i><b>26.2.2</b> Número de vecinos (k) seleccionados</a></li>
</ul></li>
<li class="chapter" data-level="26.3" data-path="cap-knn.html"><a href="cap-knn.html#procedimiento-con-r-la-funcion-knn"><i class="fa fa-check"></i><b>26.3</b> Procedimiento con R: la funcion knn</a></li>
<li class="chapter" data-level="26.4" data-path="cap-knn.html"><a href="cap-knn.html#aplicación-del-modelo-knn-en-r"><i class="fa fa-check"></i><b>26.4</b> Aplicación del modelo KNN en R</a>
<ul>
<li class="chapter" data-level="" data-path="cap-knn.html"><a href="cap-knn.html#resumen-7"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="27" data-path="cap-naive-bayes.html"><a href="cap-naive-bayes.html"><i class="fa fa-check"></i><b>27</b> Naive Bayes</a>
<ul>
<li class="chapter" data-level="27.1" data-path="cap-naive-bayes.html"><a href="cap-naive-bayes.html#introducción-16"><i class="fa fa-check"></i><b>27.1</b> Introducción</a></li>
<li class="chapter" data-level="27.2" data-path="cap-naive-bayes.html"><a href="cap-naive-bayes.html#teorema-de-bayes"><i class="fa fa-check"></i><b>27.2</b> Teorema de Bayes</a></li>
<li class="chapter" data-level="27.3" data-path="cap-naive-bayes.html"><a href="cap-naive-bayes.html#el-algoritmo-naive-bayes"><i class="fa fa-check"></i><b>27.3</b> El algoritmo Naive Bayes</a></li>
<li class="chapter" data-level="27.4" data-path="cap-naive-bayes.html"><a href="cap-naive-bayes.html#procedimiento-con-r-la-funcion-naive_bayes"><i class="fa fa-check"></i><b>27.4</b> Procedimiento con R: la funcion <code>naive_bayes</code></a></li>
<li class="chapter" data-level="27.5" data-path="cap-naive-bayes.html"><a href="cap-naive-bayes.html#aplicación-del-modelo-naive-bayes"><i class="fa fa-check"></i><b>27.5</b> Aplicación del modelo Naive Bayes</a>
<ul>
<li class="chapter" data-level="" data-path="cap-naive-bayes.html"><a href="cap-naive-bayes.html#resumen-8"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="28" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html"><i class="fa fa-check"></i><b>28</b> Bagging. Random Forest </a>
<ul>
<li class="chapter" data-level="28.1" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#introducción-metodos-de-ensamble"><i class="fa fa-check"></i><b>28.1</b> Introducción: Metodos de Ensamble</a></li>
<li class="chapter" data-level="28.2" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#bagging"><i class="fa fa-check"></i><b>28.2</b> Bagging</a></li>
<li class="chapter" data-level="28.3" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#procedimiento-con-r-la-función-bagging"><i class="fa fa-check"></i><b>28.3</b> Procedimiento con R: la función <code>bagging</code> </a></li>
<li class="chapter" data-level="28.4" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#implementando-bagging-en-r"><i class="fa fa-check"></i><b>28.4</b> Implementando bagging en R</a>
<ul>
<li class="chapter" data-level="28.4.1" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#interpretación-de-variables-en-el-bagging"><i class="fa fa-check"></i><b>28.4.1</b> Interpretación de variables en el bagging</a></li>
</ul></li>
<li class="chapter" data-level="28.5" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#random-forest"><i class="fa fa-check"></i><b>28.5</b> Random Forest</a>
<ul>
<li class="chapter" data-level="28.5.1" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#número-de-árboles-k"><i class="fa fa-check"></i><b>28.5.1</b> Número de árboles (<span class="math inline">\(K\)</span>)</a></li>
<li class="chapter" data-level="28.5.2" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#número-de-variables-a-considerar-mtry"><i class="fa fa-check"></i><b>28.5.2</b> Número de variables a considerar (<span class="math inline">\(mtry\)</span>)</a></li>
<li class="chapter" data-level="28.5.3" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#complejidad-de-los-árboles"><i class="fa fa-check"></i><b>28.5.3</b> Complejidad de los árboles</a></li>
<li class="chapter" data-level="28.5.4" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#esquema-de-muestreo"><i class="fa fa-check"></i><b>28.5.4</b> Esquema de muestreo</a></li>
<li class="chapter" data-level="28.5.5" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#regla-de-división"><i class="fa fa-check"></i><b>28.5.5</b> Regla de división</a></li>
</ul></li>
<li class="chapter" data-level="28.6" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#procedimiento-con-r-la-función-randomforest"><i class="fa fa-check"></i><b>28.6</b> Procedimiento con R: la función <code>randomForest</code></a></li>
<li class="chapter" data-level="28.7" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#aplicación-del-modelo-random-forest-en-r"><i class="fa fa-check"></i><b>28.7</b> Aplicación del modelo Random Forest en R</a>
<ul>
<li class="chapter" data-level="28.7.1" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#aplicación-del-random-forest"><i class="fa fa-check"></i><b>28.7.1</b> Aplicación del Random Forest</a></li>
<li class="chapter" data-level="" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#resumen-9"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="29" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html"><i class="fa fa-check"></i><b>29</b> Boosting. XGBoost</a>
<ul>
<li class="chapter" data-level="29.1" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#introducción.-boosting."><i class="fa fa-check"></i><b>29.1</b> Introducción. Boosting.</a></li>
<li class="chapter" data-level="29.2" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#gradient-boosting"><i class="fa fa-check"></i><b>29.2</b> Gradient Boosting</a>
<ul>
<li class="chapter" data-level="29.2.1" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#hiperparámetros-del-modelo-gradient-boosting"><i class="fa fa-check"></i><b>29.2.1</b> Hiperparámetros del modelo gradient boosting</a></li>
<li class="chapter" data-level="29.2.2" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#estrategia-de-ajuste-de-hiperparametros"><i class="fa fa-check"></i><b>29.2.2</b> Estrategia de ajuste de hiperparametros</a></li>
</ul></li>
<li class="chapter" data-level="29.3" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#procedimiento-con-r-la-funcion-gbm"><i class="fa fa-check"></i><b>29.3</b> Procedimiento con R: la funcion <code>gbm</code></a></li>
<li class="chapter" data-level="29.4" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#aplicación-del-modelo-gbm-en-r"><i class="fa fa-check"></i><b>29.4</b> Aplicación del modelo GBM en R</a>
<ul>
<li class="chapter" data-level="29.4.1" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#gbm-con-ajuste-automático"><i class="fa fa-check"></i><b>29.4.1</b> GBM con ajuste automático</a></li>
</ul></li>
<li class="chapter" data-level="29.5" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#extreme-gradient-boosting-xgb"><i class="fa fa-check"></i><b>29.5</b> eXtreme Gradient Boosting (XGB)</a>
<ul>
<li class="chapter" data-level="29.5.1" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#hiperparametros-del-modelo-xgboost"><i class="fa fa-check"></i><b>29.5.1</b> Hiperparametros del modelo XGBoost</a></li>
</ul></li>
<li class="chapter" data-level="29.6" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#procedimiento-con-r-la-funcion-xgboost"><i class="fa fa-check"></i><b>29.6</b> Procedimiento con R: la funcion <code>xgboost</code></a></li>
<li class="chapter" data-level="29.7" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#aplicación-del-módelo-xgboost-en-r"><i class="fa fa-check"></i><b>29.7</b> Aplicación del módelo XGBoost en R</a>
<ul>
<li class="chapter" data-level="29.7.1" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#xgboost-y-ajuste-automático"><i class="fa fa-check"></i><b>29.7.1</b> XGBoost y ajuste automático</a></li>
<li class="chapter" data-level="" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#resumen-10"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>VI Machine learning no supervisado</b></span></li>
<li class="chapter" data-level="30" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html"><i class="fa fa-check"></i><b>30</b> Análisis cluster: clusterización jerárquica</a>
<ul>
<li class="chapter" data-level="30.1" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#origen-cluster"><i class="fa fa-check"></i><b>30.1</b> Introducción</a></li>
<li class="chapter" data-level="30.2" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#selección-de-las-variables"><i class="fa fa-check"></i><b>30.2</b> Selección de las variables</a></li>
<li class="chapter" data-level="30.3" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#elección-de-la-distancia-entre-elementos"><i class="fa fa-check"></i><b>30.3</b> Elección de la distancia entre elementos</a></li>
<li class="chapter" data-level="30.4" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#técnicas-de-agrupación-jerárquicas"><i class="fa fa-check"></i><b>30.4</b> Técnicas de agrupación jerárquicas</a>
<ul>
<li class="chapter" data-level="30.4.1" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#introac"><i class="fa fa-check"></i><b>30.4.1</b> Introducción</a></li>
<li class="chapter" data-level="30.4.2" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#técnicas-jerárquicas-aglomerativas"><i class="fa fa-check"></i><b>30.4.2</b> Técnicas jerárquicas aglomerativas</a></li>
<li class="chapter" data-level="30.4.3" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#técnicas-jerárquicas-divisivas"><i class="fa fa-check"></i><b>30.4.3</b> Técnicas jerárquicas divisivas</a></li>
</ul></li>
<li class="chapter" data-level="30.5" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#calidad-de-la-agrupación-y-número-de-clusters"><i class="fa fa-check"></i><b>30.5</b> Calidad de la agrupación y número de clusters</a>
<ul>
<li class="chapter" data-level="30.5.1" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#el-coeficiente-de-correlación-lineal-cofenético"><i class="fa fa-check"></i><b>30.5.1</b> El coeficiente de correlación lineal cofenético</a></li>
<li class="chapter" data-level="30.5.2" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#número-óptimo-de-clusters"><i class="fa fa-check"></i><b>30.5.2</b> Número óptimo de clusters</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="31" data-path="no-jerarquico.html"><a href="no-jerarquico.html"><i class="fa fa-check"></i><b>31</b> Análisis cluster: clusterización no jerárquica</a>
<ul>
<li class="chapter" data-level="31.1" data-path="no-jerarquico.html"><a href="no-jerarquico.html#métodos-de-reasignación"><i class="fa fa-check"></i><b>31.1</b> Métodos de reasignación</a>
<ul>
<li class="chapter" data-level="31.1.1" data-path="no-jerarquico.html"><a href="no-jerarquico.html#técnicas-basadas-en-centroides-métodos-de-forgy-y-bf-k-medias"><i class="fa fa-check"></i><b>31.1.1</b> Técnicas basadas en centroides: métodos de Forgy y <span class="math inline">\(\bf k\)</span>-medias</a></li>
<li class="chapter" data-level="31.1.2" data-path="no-jerarquico.html"><a href="no-jerarquico.html#técnicas-basadas-en-medoides"><i class="fa fa-check"></i><b>31.1.2</b> Técnicas basadas en medoides</a></li>
<li class="chapter" data-level="31.1.3" data-path="no-jerarquico.html"><a href="no-jerarquico.html#técnicas-basadas-en-medianas-bf-k-medianas"><i class="fa fa-check"></i><b>31.1.3</b> Técnicas basadas en medianas: <span class="math inline">\(\bf k\)</span>-medianas</a></li>
</ul></li>
<li class="chapter" data-level="31.2" data-path="no-jerarquico.html"><a href="no-jerarquico.html#métodos-basados-en-la-densidad-de-puntos"><i class="fa fa-check"></i><b>31.2</b> Métodos basados en la densidad de puntos</a></li>
<li class="chapter" data-level="31.3" data-path="no-jerarquico.html"><a href="no-jerarquico.html#otros-métodos"><i class="fa fa-check"></i><b>31.3</b> Otros métodos</a></li>
<li class="chapter" data-level="31.4" data-path="no-jerarquico.html"><a href="no-jerarquico.html#nota-final"><i class="fa fa-check"></i><b>31.4</b> Nota final</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="acp.html"><a href="acp.html"><i class="fa fa-check"></i><b>32</b> Análisis de componentes principales</a>
<ul>
<li class="chapter" data-level="32.1" data-path="acp.html"><a href="acp.html#introducción-17"><i class="fa fa-check"></i><b>32.1</b> Introducción</a></li>
<li class="chapter" data-level="32.2" data-path="acp.html"><a href="acp.html#obtención-de-las-componentes-principales"><i class="fa fa-check"></i><b>32.2</b> Obtención de las componentes principales</a>
<ul>
<li class="chapter" data-level="32.2.1" data-path="acp.html"><a href="acp.html#descripción-formal-del-proceso"><i class="fa fa-check"></i><b>32.2.1</b> Descripción formal del proceso</a></li>
<li class="chapter" data-level="32.2.2" data-path="acp.html"><a href="acp.html#cuestiones-importantes-en-el-acp"><i class="fa fa-check"></i><b>32.2.2</b> Cuestiones importantes en el ACP</a></li>
</ul></li>
<li class="chapter" data-level="32.3" data-path="acp.html"><a href="acp.html#estimación-de-las-componentes-principales"><i class="fa fa-check"></i><b>32.3</b> Estimación de las componentes principales</a></li>
<li class="chapter" data-level="32.4" data-path="acp.html"><a href="acp.html#numcomp"><i class="fa fa-check"></i><b>32.4</b> Número de componentes a retener</a></li>
<li class="chapter" data-level="32.5" data-path="acp.html"><a href="acp.html#interpretación-de-las-cp"><i class="fa fa-check"></i><b>32.5</b> Interpretación de las CP</a></li>
<li class="chapter" data-level="32.6" data-path="acp.html"><a href="acp.html#reproducción-de-los-datos-tipificados-y-de-r-a-partir-de-las-cp"><i class="fa fa-check"></i><b>32.6</b> Reproducción de los datos tipificados y de R a partir de las CP</a></li>
<li class="chapter" data-level="32.7" data-path="acp.html"><a href="acp.html#limitaciones-del-acp"><i class="fa fa-check"></i><b>32.7</b> Limitaciones del ACP</a></li>
</ul></li>
<li class="chapter" data-level="33" data-path="análisis-factorial.html"><a href="análisis-factorial.html"><i class="fa fa-check"></i><b>33</b> Análisis factorial</a>
<ul>
<li class="chapter" data-level="33.1" data-path="análisis-factorial.html"><a href="análisis-factorial.html#introaf"><i class="fa fa-check"></i><b>33.1</b> Introducción</a></li>
<li class="chapter" data-level="33.2" data-path="análisis-factorial.html"><a href="análisis-factorial.html#elementos-teóricos-del-análisis-factorial"><i class="fa fa-check"></i><b>33.2</b> Elementos teóricos del análisis factorial</a>
<ul>
<li class="chapter" data-level="33.2.1" data-path="análisis-factorial.html"><a href="análisis-factorial.html#modelobasicoaf"><i class="fa fa-check"></i><b>33.2.1</b> Modelo básico y terminología</a></li>
<li class="chapter" data-level="33.2.2" data-path="análisis-factorial.html"><a href="análisis-factorial.html#patrón-y-estructura-factoriales"><i class="fa fa-check"></i><b>33.2.2</b> Patrón y estructura factoriales</a></li>
</ul></li>
<li class="chapter" data-level="33.3" data-path="análisis-factorial.html"><a href="análisis-factorial.html#el-análisis-factorial-en-la-práctica"><i class="fa fa-check"></i><b>33.3</b> El análisis factorial en la práctica</a>
<ul>
<li class="chapter" data-level="33.3.1" data-path="análisis-factorial.html"><a href="análisis-factorial.html#pre-análisis-factorial"><i class="fa fa-check"></i><b>33.3.1</b> Pre-análisis factorial</a></li>
<li class="chapter" data-level="33.3.2" data-path="análisis-factorial.html"><a href="análisis-factorial.html#análisis-factorial-1"><i class="fa fa-check"></i><b>33.3.2</b> Análisis factorial</a></li>
<li class="chapter" data-level="33.3.3" data-path="análisis-factorial.html"><a href="análisis-factorial.html#postanalisis"><i class="fa fa-check"></i><b>33.3.3</b> Post-análisis factorial</a></li>
<li class="chapter" data-level="33.3.4" data-path="análisis-factorial.html"><a href="análisis-factorial.html#puntuaciones-factoriales."><i class="fa fa-check"></i><b>33.3.4</b> Puntuaciones factoriales.</a></li>
</ul></li>
<li class="chapter" data-level="33.4" data-path="análisis-factorial.html"><a href="análisis-factorial.html#relaciones-y-diferencias-entre-el-af-y-el-acp"><i class="fa fa-check"></i><b>33.4</b> Relaciones y diferencias entre el AF y el ACP</a></li>
</ul></li>
<li class="chapter" data-level="34" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html"><i class="fa fa-check"></i><b>34</b> Escalamiento multidimensional</a>
<ul>
<li class="chapter" data-level="34.1" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html#introducción-18"><i class="fa fa-check"></i><b>34.1</b> Introducción</a></li>
<li class="chapter" data-level="34.2" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html#medición-de-distancias-y-similitudes"><i class="fa fa-check"></i><b>34.2</b> Medición de distancias y similitudes</a></li>
<li class="chapter" data-level="34.3" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html#modelo-escalamiento-multidimensional."><i class="fa fa-check"></i><b>34.3</b> Modelo escalamiento multidimensional.</a></li>
<li class="chapter" data-level="34.4" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html#tipos-de-escalamiento-multidimensional"><i class="fa fa-check"></i><b>34.4</b> Tipos de escalamiento multidimensional</a>
<ul>
<li class="chapter" data-level="34.4.1" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html#escalado-multidimensional-métrico"><i class="fa fa-check"></i><b>34.4.1</b> Escalado multidimensional métrico</a></li>
<li class="chapter" data-level="34.4.2" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html#escalado-multidimensional-no-métrico"><i class="fa fa-check"></i><b>34.4.2</b> Escalado multidimensional no-métrico</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="35" data-path="correspondencias.html"><a href="correspondencias.html"><i class="fa fa-check"></i><b>35</b> Análisis de correspondencias</a>
<ul>
<li class="chapter" data-level="35.1" data-path="correspondencias.html"><a href="correspondencias.html#introducción-19"><i class="fa fa-check"></i><b>35.1</b> Introducción</a></li>
<li class="chapter" data-level="35.2" data-path="correspondencias.html"><a href="correspondencias.html#metodología-del-análisis-de-correspondencias"><i class="fa fa-check"></i><b>35.2</b> Metodología del análisis de correspondencias</a>
<ul>
<li class="chapter" data-level="35.2.1" data-path="correspondencias.html"><a href="correspondencias.html#proyecciones-fila-columna-y-simétrica"><i class="fa fa-check"></i><b>35.2.1</b> Proyecciones fila, columna y simétrica</a></li>
</ul></li>
<li class="chapter" data-level="35.3" data-path="correspondencias.html"><a href="correspondencias.html#procedimiento-con-r-la-función-ca"><i class="fa fa-check"></i><b>35.3</b> Procedimiento con <strong>R</strong>: la función <code>ca()</code></a></li>
</ul></li>
<li class="part"><span><b>VII Deep learning</b></span></li>
<li class="chapter" data-level="36" data-path="capNN.html"><a href="capNN.html"><i class="fa fa-check"></i><b>36</b> Redes neuronales artificiales</a>
<ul>
<li class="chapter" data-level="36.1" data-path="capNN.html"><a href="capNN.html#qué-es-el-deep-learning"><i class="fa fa-check"></i><b>36.1</b> ¿Qué es el <em>deep learning</em>?</a>
<ul>
<li class="chapter" data-level="36.1.1" data-path="capNN.html"><a href="capNN.html#diferencias-entre-las-técnicas-de-machine-learning-tradicional-y-el-deep-learning"><i class="fa fa-check"></i><b>36.1.1</b> Diferencias entre las técnicas de <em>machine learning</em> tradicional y el <em>deep learning</em></a></li>
</ul></li>
<li class="chapter" data-level="36.2" data-path="capNN.html"><a href="capNN.html#aplicaciones-del-deep-learning"><i class="fa fa-check"></i><b>36.2</b> Aplicaciones del <em>deep learning</em></a></li>
<li class="chapter" data-level="36.3" data-path="capNN.html"><a href="capNN.html#redes-neuronales"><i class="fa fa-check"></i><b>36.3</b> Redes Neuronales</a></li>
<li class="chapter" data-level="36.4" data-path="capNN.html"><a href="capNN.html#perceptrón-o-neurona"><i class="fa fa-check"></i><b>36.4</b> Perceptrón o Neurona</a>
<ul>
<li class="chapter" data-level="36.4.1" data-path="capNN.html"><a href="capNN.html#aprendizaje"><i class="fa fa-check"></i><b>36.4.1</b> Aprendizaje</a></li>
<li class="chapter" data-level="36.4.2" data-path="capNN.html"><a href="capNN.html#convergencia"><i class="fa fa-check"></i><b>36.4.2</b> Convergencia</a></li>
</ul></li>
<li class="chapter" data-level="36.5" data-path="capNN.html"><a href="capNN.html#perceptrón-multiclase"><i class="fa fa-check"></i><b>36.5</b> Perceptrón Multiclase</a></li>
<li class="chapter" data-level="36.6" data-path="capNN.html"><a href="capNN.html#funciones-de-activación"><i class="fa fa-check"></i><b>36.6</b> Funciones de activación</a></li>
<li class="chapter" data-level="36.7" data-path="capNN.html"><a href="capNN.html#perceptrón-multicapa"><i class="fa fa-check"></i><b>36.7</b> Perceptrón Multicapa</a>
<ul>
<li class="chapter" data-level="36.7.1" data-path="capNN.html"><a href="capNN.html#aprendizaje-1"><i class="fa fa-check"></i><b>36.7.1</b> Aprendizaje</a></li>
</ul></li>
<li class="chapter" data-level="36.8" data-path="capNN.html"><a href="capNN.html#instalación-de-librerías-de-deep-learning-en-r-tensorflowkeras"><i class="fa fa-check"></i><b>36.8</b> Instalación de librerías de <em>deep learning</em> en <strong>R</strong>: Tensorflow/Keras</a></li>
<li class="chapter" data-level="36.9" data-path="capNN.html"><a href="capNN.html#ejemplo-de-red-para-clasificación"><i class="fa fa-check"></i><b>36.9</b> Ejemplo de red para clasificación</a>
<ul>
<li class="chapter" data-level="36.9.1" data-path="capNN.html"><a href="capNN.html#carga-y-visualización-de-los-datos"><i class="fa fa-check"></i><b>36.9.1</b> Carga y visualización de los datos</a></li>
<li class="chapter" data-level="36.9.2" data-path="capNN.html"><a href="capNN.html#preprocesamiento"><i class="fa fa-check"></i><b>36.9.2</b> Preprocesamiento</a></li>
<li class="chapter" data-level="36.9.3" data-path="capNN.html"><a href="capNN.html#nngen"><i class="fa fa-check"></i><b>36.9.3</b> Generación de la red neuronal</a></li>
<li class="chapter" data-level="36.9.4" data-path="capNN.html"><a href="capNN.html#nntrain"><i class="fa fa-check"></i><b>36.9.4</b> Entrenamiento</a></li>
<li class="chapter" data-level="36.9.5" data-path="capNN.html"><a href="capNN.html#test"><i class="fa fa-check"></i><b>36.9.5</b> Test</a></li>
<li class="chapter" data-level="36.9.6" data-path="capNN.html"><a href="capNN.html#guardado-y-reutilización-del-modelo"><i class="fa fa-check"></i><b>36.9.6</b> Guardado y reutilización del modelo</a></li>
</ul></li>
<li class="chapter" data-level="36.10" data-path="capNN.html"><a href="capNN.html#ejemplo-de-red-para-regresión"><i class="fa fa-check"></i><b>36.10</b> Ejemplo de red para regresión</a>
<ul>
<li class="chapter" data-level="36.10.1" data-path="capNN.html"><a href="capNN.html#carga-y-visualización-de-los-datos-1"><i class="fa fa-check"></i><b>36.10.1</b> Carga y visualización de los datos</a></li>
<li class="chapter" data-level="36.10.2" data-path="capNN.html"><a href="capNN.html#preprocesamiento-1"><i class="fa fa-check"></i><b>36.10.2</b> Preprocesamiento</a></li>
<li class="chapter" data-level="36.10.3" data-path="capNN.html"><a href="capNN.html#generación-de-la-red-neuronal"><i class="fa fa-check"></i><b>36.10.3</b> Generación de la red neuronal</a></li>
<li class="chapter" data-level="36.10.4" data-path="capNN.html"><a href="capNN.html#entrenamiento"><i class="fa fa-check"></i><b>36.10.4</b> Entrenamiento</a></li>
<li class="chapter" data-level="36.10.5" data-path="capNN.html"><a href="capNN.html#test-1"><i class="fa fa-check"></i><b>36.10.5</b> Test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="37" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html"><i class="fa fa-check"></i><b>37</b> Redes neuronales convolucionales</a>
<ul>
<li class="chapter" data-level="37.1" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#introducción-20"><i class="fa fa-check"></i><b>37.1</b> Introducción</a></li>
<li class="chapter" data-level="37.2" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#convolución"><i class="fa fa-check"></i><b>37.2</b> Convolución</a></li>
<li class="chapter" data-level="37.3" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#neuronas-convolucionales"><i class="fa fa-check"></i><b>37.3</b> Neuronas convolucionales</a></li>
<li class="chapter" data-level="37.4" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#relleno-del-borde"><i class="fa fa-check"></i><b>37.4</b> Relleno del borde</a>
<ul>
<li class="chapter" data-level="37.4.1" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#desplazamiento"><i class="fa fa-check"></i><b>37.4.1</b> Desplazamiento</a></li>
</ul></li>
<li class="chapter" data-level="37.5" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#capas-de-agrupación"><i class="fa fa-check"></i><b>37.5</b> Capas de agrupación</a></li>
<li class="chapter" data-level="37.6" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#desvanecimiento-del-gradiente"><i class="fa fa-check"></i><b>37.6</b> Desvanecimiento del gradiente</a></li>
<li class="chapter" data-level="37.7" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#sobreajuste-1"><i class="fa fa-check"></i><b>37.7</b> Sobreajuste</a></li>
<li class="chapter" data-level="37.8" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#generación-de-datos-de-entrenamiento-artificiales"><i class="fa fa-check"></i><b>37.8</b> Generación de datos de entrenamiento artificiales</a></li>
<li class="chapter" data-level="37.9" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#ejemplo-para-el-conjunto-de-datos-cifar10"><i class="fa fa-check"></i><b>37.9</b> Ejemplo para el conjunto de datos <code>CIFAR10</code></a>
<ul>
<li class="chapter" data-level="37.9.1" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#visualizacion"><i class="fa fa-check"></i><b>37.9.1</b> Carga y visualización de los datos</a></li>
<li class="chapter" data-level="37.9.2" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#preprocesamiento-2"><i class="fa fa-check"></i><b>37.9.2</b> Preprocesamiento</a></li>
<li class="chapter" data-level="37.9.3" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#generación-de-la-red-neuronal-1"><i class="fa fa-check"></i><b>37.9.3</b> Generación de la red neuronal</a></li>
<li class="chapter" data-level="37.9.4" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#entrenamiento-1"><i class="fa fa-check"></i><b>37.9.4</b> Entrenamiento</a></li>
<li class="chapter" data-level="37.9.5" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#test-2"><i class="fa fa-check"></i><b>37.9.5</b> Test</a></li>
<li class="chapter" data-level="37.9.6" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#otros-ejemplos-de-interés"><i class="fa fa-check"></i><b>37.9.6</b> Otros ejemplos de interés</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>VIII Ciencia de datos de texto y redes</b></span></li>
<li class="chapter" data-level="38" data-path="mineria-textos.html"><a href="mineria-textos.html"><i class="fa fa-check"></i><b>38</b> Minería de textos</a>
<ul>
<li class="chapter" data-level="38.1" data-path="mineria-textos.html"><a href="mineria-textos.html#introducción-21"><i class="fa fa-check"></i><b>38.1</b> Introducción</a></li>
<li class="chapter" data-level="38.2" data-path="mineria-textos.html"><a href="mineria-textos.html#secCONCEPTOS"><i class="fa fa-check"></i><b>38.2</b> Conceptos y tareas fundamentales</a>
<ul>
<li class="chapter" data-level="38.2.1" data-path="mineria-textos.html"><a href="mineria-textos.html#preparación-de-los-datos"><i class="fa fa-check"></i><b>38.2.1</b> Preparación de los datos</a></li>
<li class="chapter" data-level="38.2.2" data-path="mineria-textos.html"><a href="mineria-textos.html#secTOKEN"><i class="fa fa-check"></i><b>38.2.2</b> Segmentación del texto: tokenización</a></li>
<li class="chapter" data-level="38.2.3" data-path="mineria-textos.html"><a href="mineria-textos.html#secESTILOM"><i class="fa fa-check"></i><b>38.2.3</b> Campos de aplicación de la minería de textos</a></li>
<li class="chapter" data-level="38.2.4" data-path="mineria-textos.html"><a href="mineria-textos.html#minería-de-textos-en-r"><i class="fa fa-check"></i><b>38.2.4</b> Minería de textos en <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="38.3" data-path="mineria-textos.html"><a href="mineria-textos.html#secSENTIM"><i class="fa fa-check"></i><b>38.3</b> Análisis de sentimientos</a></li>
<li class="chapter" data-level="38.4" data-path="mineria-textos.html"><a href="mineria-textos.html#caso-de-aplicación"><i class="fa fa-check"></i><b>38.4</b> Caso de aplicación</a>
<ul>
<li class="chapter" data-level="38.4.1" data-path="mineria-textos.html"><a href="mineria-textos.html#declaración-institucional-del-estado-de-alarma-2020"><i class="fa fa-check"></i><b>38.4.1</b> Declaración institucional del estado de alarma 2020</a></li>
<li class="chapter" data-level="38.4.2" data-path="mineria-textos.html"><a href="mineria-textos.html#segmentación-en-palabras-y-oraciones"><i class="fa fa-check"></i><b>38.4.2</b> Segmentación en palabras y oraciones</a></li>
<li class="chapter" data-level="38.4.3" data-path="mineria-textos.html"><a href="mineria-textos.html#análisis-exploratorio"><i class="fa fa-check"></i><b>38.4.3</b> Análisis exploratorio</a></li>
<li class="chapter" data-level="38.4.4" data-path="mineria-textos.html"><a href="mineria-textos.html#secSENTYEMO"><i class="fa fa-check"></i><b>38.4.4</b> Análisis de sentimientos y detección de emociones</a></li>
<li class="chapter" data-level="38.4.5" data-path="mineria-textos.html"><a href="mineria-textos.html#n-gramas"><i class="fa fa-check"></i><b>38.4.5</b> <em>N-gramas</em></a></li>
<li class="chapter" data-level="38.4.6" data-path="mineria-textos.html"><a href="mineria-textos.html#análisis-de-redes"><i class="fa fa-check"></i><b>38.4.6</b> Análisis de redes</a></li>
<li class="chapter" data-level="" data-path="mineria-textos.html"><a href="mineria-textos.html#resumen-11"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="39" data-path="grafos.html"><a href="grafos.html"><i class="fa fa-check"></i><b>39</b> Análisis de grafos y redes sociales</a>
<ul>
<li class="chapter" data-level="39.1" data-path="grafos.html"><a href="grafos.html#introducción-22"><i class="fa fa-check"></i><b>39.1</b> Introducción</a></li>
<li class="chapter" data-level="39.2" data-path="grafos.html"><a href="grafos.html#teoría-de-grafos"><i class="fa fa-check"></i><b>39.2</b> Teoría de grafos</a></li>
<li class="chapter" data-level="39.3" data-path="grafos.html"><a href="grafos.html#elementos-de-un-grafo"><i class="fa fa-check"></i><b>39.3</b> Elementos de un grafo</a></li>
<li class="chapter" data-level="39.4" data-path="grafos.html"><a href="grafos.html#el-paquete-igraph"><i class="fa fa-check"></i><b>39.4</b> El paquete <code>igraph</code></a></li>
<li class="chapter" data-level="39.5" data-path="grafos.html"><a href="grafos.html#análisis-de-influencia-en-un-grafo-aplicado-a-redes-sociales"><i class="fa fa-check"></i><b>39.5</b> Análisis de influencia en un grafo aplicado a redes sociales</a></li>
<li class="chapter" data-level="39.6" data-path="grafos.html"><a href="grafos.html#otras-utilidades-de-grafos"><i class="fa fa-check"></i><b>39.6</b> Otras utilidades de grafos</a></li>
</ul></li>
<li class="part"><span><b>IX Ciencia de datos espaciales</b></span></li>
<li class="chapter" data-level="40" data-path="datos-espaciales.html"><a href="datos-espaciales.html"><i class="fa fa-check"></i><b>40</b> Trabajando con datos espaciales</a>
<ul>
<li class="chapter" data-level="40.1" data-path="datos-espaciales.html"><a href="datos-espaciales.html#conceptos-clave"><i class="fa fa-check"></i><b>40.1</b> Conceptos clave</a>
<ul>
<li class="chapter" data-level="40.1.1" data-path="datos-espaciales.html"><a href="datos-espaciales.html#CRS"><i class="fa fa-check"></i><b>40.1.1</b> Sistema de Referencia de Coordenadas</a></li>
<li class="chapter" data-level="40.1.2" data-path="datos-espaciales.html"><a href="datos-espaciales.html#formatos"><i class="fa fa-check"></i><b>40.1.2</b> Formatos de datos espaciales</a></li>
</ul></li>
<li class="chapter" data-level="40.2" data-path="datos-espaciales.html"><a href="datos-espaciales.html#primer-mapa"><i class="fa fa-check"></i><b>40.2</b> Mi primer mapa</a></li>
<li class="chapter" data-level="40.3" data-path="datos-espaciales.html"><a href="datos-espaciales.html#no-mentir"><i class="fa fa-check"></i><b>40.3</b> ¿Cómo (no) mentir con la visualización?</a></li>
<li class="chapter" data-level="40.4" data-path="datos-espaciales.html"><a href="datos-espaciales.html#mapas-espacio-temporales"><i class="fa fa-check"></i><b>40.4</b> Mapas espacio-temporales</a></li>
<li class="chapter" data-level="40.5" data-path="datos-espaciales.html"><a href="datos-espaciales.html#mapas-interactivos"><i class="fa fa-check"></i><b>40.5</b> Mapas interactivos</a></li>
<li class="chapter" data-level="40.6" data-path="datos-espaciales.html"><a href="datos-espaciales.html#estadística-para-datos-espaciales"><i class="fa fa-check"></i><b>40.6</b> Estadística para datos espaciales</a></li>
</ul></li>
<li class="chapter" data-level="41" data-path="geo.html"><a href="geo.html"><i class="fa fa-check"></i><b>41</b> Geoestadística</a>
<ul>
<li class="chapter" data-level="41.1" data-path="geo.html"><a href="geo.html#introducción-23"><i class="fa fa-check"></i><b>41.1</b> Introducción</a></li>
<li class="chapter" data-level="41.2" data-path="geo.html"><a href="geo.html#preliminares-geo"><i class="fa fa-check"></i><b>41.2</b> Preliminares</a></li>
<li class="chapter" data-level="41.3" data-path="geo.html"><a href="geo.html#ana-estructural"><i class="fa fa-check"></i><b>41.3</b> Análisis estructural de la dependencia espacial</a>
<ul>
<li class="chapter" data-level="41.3.1" data-path="geo.html"><a href="geo.html#semivariograma"><i class="fa fa-check"></i><b>41.3.1</b> Semivariograma</a></li>
<li class="chapter" data-level="41.3.2" data-path="geo.html"><a href="geo.html#modelos-de-semivariogramas-válidos"><i class="fa fa-check"></i><b>41.3.2</b> Modelos de semivariogramas válidos</a></li>
<li class="chapter" data-level="41.3.3" data-path="geo.html"><a href="geo.html#semivariograma-empírico"><i class="fa fa-check"></i><b>41.3.3</b> Semivariograma empírico</a></li>
<li class="chapter" data-level="41.3.4" data-path="geo.html"><a href="geo.html#ajuste-semivariográfico"><i class="fa fa-check"></i><b>41.3.4</b> Ajuste semivariográfico</a></li>
</ul></li>
<li class="chapter" data-level="41.4" data-path="geo.html"><a href="geo.html#kriging"><i class="fa fa-check"></i><b>41.4</b> Kriging</a></li>
</ul></li>
<li class="chapter" data-level="42" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html"><i class="fa fa-check"></i><b>42</b> Modelos econométricos espaciales</a>
<ul>
<li class="chapter" data-level="42.1" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#la-dependencia-espacial"><i class="fa fa-check"></i><b>42.1</b> La dependencia espacial </a>
<ul>
<li class="chapter" data-level="42.1.1" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#modelización-del-espacio-la-matriz-w"><i class="fa fa-check"></i><b>42.1.1</b> Modelización del espacio: La matriz W</a></li>
</ul></li>
<li class="chapter" data-level="42.2" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#medidas-de-autocorrelación"><i class="fa fa-check"></i><b>42.2</b> Medidas de Autocorrelación </a>
<ul>
<li class="chapter" data-level="42.2.1" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#el-indicador-i-de-moran"><i class="fa fa-check"></i><b>42.2.1</b> El indicador <em>I</em> de Moran</a></li>
</ul></li>
<li class="chapter" data-level="42.3" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#modelos-econométricos-espaciales-de-corte-transversal"><i class="fa fa-check"></i><b>42.3</b> Modelos econométricos espaciales de corte transversal </a>
<ul>
<li class="chapter" data-level="42.3.1" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#estimación-sar"><i class="fa fa-check"></i><b>42.3.1</b> Estimación SAR</a></li>
<li class="chapter" data-level="42.3.2" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#comparando-sar-contra-sdm"><i class="fa fa-check"></i><b>42.3.2</b> Comparando SAR contra SDM</a></li>
<li class="chapter" data-level="42.3.3" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#interpretación-de-los-estimadores-de-los-modelos-de-autocorrelación-espacial"><i class="fa fa-check"></i><b>42.3.3</b> Interpretación de los estimadores de los modelos de autocorrelación espacial </a></li>
<li class="chapter" data-level="42.3.4" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#impacto-del-sar"><i class="fa fa-check"></i><b>42.3.4</b> Impacto del SAR</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="43" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html"><i class="fa fa-check"></i><b>43</b> Procesos de punto</a>
<ul>
<li class="chapter" data-level="43.1" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html#spatial-point-patterns-on-mathbb-r2"><i class="fa fa-check"></i><b>43.1</b> Spatial point patterns on <span class="math inline">\(\mathbb R^2\)</span></a>
<ul>
<li class="chapter" data-level="43.1.1" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html#kernel-based-intensity-estimation"><i class="fa fa-check"></i><b>43.1.1</b> Kernel-based intensity estimation</a></li>
<li class="chapter" data-level="43.1.2" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html#practical-examples"><i class="fa fa-check"></i><b>43.1.2</b> Practical examples</a></li>
<li class="chapter" data-level="43.1.3" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html#kernel-based-intensity-estimation-over-irregular-domains"><i class="fa fa-check"></i><b>43.1.3</b> Kernel-based intensity estimation over irregular domains</a></li>
<li class="chapter" data-level="43.1.4" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html#voronoi-based-intensity-estimators"><i class="fa fa-check"></i><b>43.1.4</b> Voronoi-based intensity estimators</a></li>
<li class="chapter" data-level="43.1.5" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html#second-order-summary-statistics"><i class="fa fa-check"></i><b>43.1.5</b> Second-order summary statistics</a></li>
</ul></li>
<li class="chapter" data-level="43.2" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html#spatial-point-patterns-on-linear-networks"><i class="fa fa-check"></i><b>43.2</b> Spatial point patterns on linear networks</a></li>
</ul></li>
<li class="part"><span><b>X Cómunica y colabora</b></span></li>
<li class="chapter" data-level="44" data-path="id_120007-informes.html"><a href="id_120007-informes.html"><i class="fa fa-check"></i><b>44</b> Informes reproducibles con R Markdown y Quarto</a>
<ul>
<li class="chapter" data-level="44.1" data-path="id_120007-informes.html"><a href="id_120007-informes.html#introducción-24"><i class="fa fa-check"></i><b>44.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="44.1.1" data-path="id_120007-informes.html"><a href="id_120007-informes.html#por-qué-informes-reproducibles"><i class="fa fa-check"></i><b>44.1.1</b> ¿Por qué informes reproducibles?</a></li>
<li class="chapter" data-level="44.1.2" data-path="id_120007-informes.html"><a href="id_120007-informes.html#markdown-r-markdown-quarto-y-rstudio"><i class="fa fa-check"></i><b>44.1.2</b> Markdown, R Markdown, Quarto y RStudio</a></li>
</ul></li>
<li class="chapter" data-level="44.2" data-path="id_120007-informes.html"><a href="id_120007-informes.html#documentos-quarto"><i class="fa fa-check"></i><b>44.2</b> Documentos Quarto</a>
<ul>
<li class="chapter" data-level="44.2.1" data-path="id_120007-informes.html"><a href="id_120007-informes.html#encabezado-yaml-y-configuración"><i class="fa fa-check"></i><b>44.2.1</b> Encabezado YAML y configuración</a></li>
<li class="chapter" data-level="44.2.2" data-path="id_120007-informes.html"><a href="id_120007-informes.html#formateado-de-texto"><i class="fa fa-check"></i><b>44.2.2</b> Formateado de texto</a></li>
<li class="chapter" data-level="44.2.3" data-path="id_120007-informes.html"><a href="id_120007-informes.html#inclusión-de-código-en-el-documento"><i class="fa fa-check"></i><b>44.2.3</b> Inclusión de código en el documento</a></li>
<li class="chapter" data-level="44.2.4" data-path="id_120007-informes.html"><a href="id_120007-informes.html#opciones-de-los-bloques-de-código-chunks"><i class="fa fa-check"></i><b>44.2.4</b> Opciones de los bloques de código (<em>chunks</em>)</a></li>
<li class="chapter" data-level="44.2.5" data-path="id_120007-informes.html"><a href="id_120007-informes.html#referencias-cruzadas-y-formateo-de-tablas"><i class="fa fa-check"></i><b>44.2.5</b> Referencias cruzadas y formateo de tablas</a></li>
</ul></li>
<li class="chapter" data-level="44.3" data-path="id_120007-informes.html"><a href="id_120007-informes.html#otros-formatos"><i class="fa fa-check"></i><b>44.3</b> Otros formatos</a></li>
</ul></li>
<li class="chapter" data-level="45" data-path="shiny.html"><a href="shiny.html"><i class="fa fa-check"></i><b>45</b> Aplicaciones webs interactivas con Shiny</a>
<ul>
<li class="chapter" data-level="45.1" data-path="shiny.html"><a href="shiny.html#introducción-25"><i class="fa fa-check"></i><b>45.1</b> Introducción</a></li>
<li class="chapter" data-level="45.2" data-path="shiny.html"><a href="shiny.html#partes-mínimas-de-una-aplicación-shiny-y-disposición-básica"><i class="fa fa-check"></i><b>45.2</b> Partes mínimas de una aplicación <code>Shiny</code> y disposición básica</a></li>
<li class="chapter" data-level="45.3" data-path="shiny.html"><a href="shiny.html#diseño-de-una-aplicación-shiny"><i class="fa fa-check"></i><b>45.3</b> Diseño de una aplicación <code>Shiny</code></a>
<ul>
<li class="chapter" data-level="45.3.1" data-path="shiny.html"><a href="shiny.html#diseño-de-las-páginas-fluidpage"><i class="fa fa-check"></i><b>45.3.1</b> Diseño de las páginas: fluidPage()</a></li>
<li class="chapter" data-level="45.3.2" data-path="shiny.html"><a href="shiny.html#segmentación-de-diseños-tabsetpanel-y-navlistpanel"><i class="fa fa-check"></i><b>45.3.2</b> Segmentación de diseños: tabsetPanel() y navlistPanel()</a></li>
</ul></li>
<li class="chapter" data-level="45.4" data-path="shiny.html"><a href="shiny.html#elementos-para-entrada-de-datos"><i class="fa fa-check"></i><b>45.4</b> Elementos para entrada de datos</a>
<ul>
<li class="chapter" data-level="45.4.1" data-path="shiny.html"><a href="shiny.html#lectura-de-ficheros-de-datos"><i class="fa fa-check"></i><b>45.4.1</b> Lectura de ficheros de datos</a></li>
</ul></li>
<li class="chapter" data-level="45.5" data-path="shiny.html"><a href="shiny.html#elementos-para-visualización-salida"><i class="fa fa-check"></i><b>45.5</b> Elementos para visualización (salida)</a></li>
<li class="chapter" data-level="45.6" data-path="shiny.html"><a href="shiny.html#reactividad"><i class="fa fa-check"></i><b>45.6</b> Reactividad</a>
<ul>
<li class="chapter" data-level="45.6.1" data-path="shiny.html"><a href="shiny.html#conductores-reactivos-y-control-de-la-reactividad"><i class="fa fa-check"></i><b>45.6.1</b> Conductores reactivos y control de la reactividad</a></li>
</ul></li>
<li class="chapter" data-level="45.7" data-path="shiny.html"><a href="shiny.html#publicación-de-la-aplicación-en-la-web"><i class="fa fa-check"></i><b>45.7</b> Publicación de la aplicación en la web</a></li>
<li class="chapter" data-level="45.8" data-path="shiny.html"><a href="shiny.html#extensiones-de-shiny"><i class="fa fa-check"></i><b>45.8</b> Extensiones de <code>Shiny</code></a></li>
</ul></li>
<li class="chapter" data-level="46" data-path="github.html"><a href="github.html"><i class="fa fa-check"></i><b>46</b> Git y GitHub en R</a>
<ul>
<li class="chapter" data-level="46.1" data-path="github.html"><a href="github.html#qué-es-git"><i class="fa fa-check"></i><b>46.1</b> ¿Qué es Git?</a></li>
<li class="chapter" data-level="46.2" data-path="github.html"><a href="github.html#qué-es-github"><i class="fa fa-check"></i><b>46.2</b> ¿Qué es GitHub?</a></li>
<li class="chapter" data-level="46.3" data-path="github.html"><a href="github.html#por-qué-usar-git-y-github"><i class="fa fa-check"></i><b>46.3</b> ¿Por qué usar Git y GitHub?</a></li>
<li class="chapter" data-level="46.4" data-path="github.html"><a href="github.html#configuración"><i class="fa fa-check"></i><b>46.4</b> Configuración</a></li>
<li class="chapter" data-level="46.5" data-path="github.html"><a href="github.html#configurar-git"><i class="fa fa-check"></i><b>46.5</b> Configurar git</a></li>
<li class="chapter" data-level="46.6" data-path="github.html"><a href="github.html#workflow"><i class="fa fa-check"></i><b>46.6</b> Workflow</a></li>
</ul></li>
<li class="chapter" data-level="47" data-path="cap-geoprocesamiento.html"><a href="cap-geoprocesamiento.html"><i class="fa fa-check"></i><b>47</b> Geoprocesamiento en nube</a>
<ul>
<li class="chapter" data-level="47.1" data-path="cap-geoprocesamiento.html"><a href="cap-geoprocesamiento.html#sintaxis-de-google-earth-engine"><i class="fa fa-check"></i><b>47.1</b> Sintaxis de Google Earth Engine</a></li>
<li class="chapter" data-level="47.2" data-path="cap-geoprocesamiento.html"><a href="cap-geoprocesamiento.html#primeros-pasos"><i class="fa fa-check"></i><b>47.2</b> Primeros pasos</a></li>
<li class="chapter" data-level="47.3" data-path="cap-geoprocesamiento.html"><a href="cap-geoprocesamiento.html#cálculo-de-anomalias"><i class="fa fa-check"></i><b>47.3</b> Cálculo de anomalias</a>
<ul>
<li class="chapter" data-level="47.3.1" data-path="cap-geoprocesamiento.html"><a href="cap-geoprocesamiento.html#definiciones-previas"><i class="fa fa-check"></i><b>47.3.1</b> Definiciones previas</a></li>
<li class="chapter" data-level="47.3.2" data-path="cap-geoprocesamiento.html"><a href="cap-geoprocesamiento.html#promedio-estival"><i class="fa fa-check"></i><b>47.3.2</b> Promedio estival</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>XI Casos de estudio en ciencia de datos</b></span></li>
<li class="chapter" data-level="48" data-path="cap-crimen.html"><a href="cap-crimen.html"><i class="fa fa-check"></i><b>48</b> Análisis de una red criminal</a>
<ul>
<li class="chapter" data-level="48.1" data-path="cap-crimen.html"><a href="cap-crimen.html#el-dataset-oversize"><i class="fa fa-check"></i><b>48.1</b> El <em>dataset Oversize</em></a></li>
<li class="chapter" data-level="48.2" data-path="cap-crimen.html"><a href="cap-crimen.html#creación-del-grafo"><i class="fa fa-check"></i><b>48.2</b> Creación del grafo</a></li>
<li class="chapter" data-level="48.3" data-path="cap-crimen.html"><a href="cap-crimen.html#visualización-del-grafo"><i class="fa fa-check"></i><b>48.3</b> Visualización del grafo</a></li>
<li class="chapter" data-level="48.4" data-path="cap-crimen.html"><a href="cap-crimen.html#importancia-de-los-actores"><i class="fa fa-check"></i><b>48.4</b> Importancia de los actores</a></li>
<li class="chapter" data-level="48.5" data-path="cap-crimen.html"><a href="cap-crimen.html#identificación-de-comunidades"><i class="fa fa-check"></i><b>48.5</b> Identificación de comunidades</a></li>
<li class="chapter" data-level="48.6" data-path="cap-crimen.html"><a href="cap-crimen.html#visualización-de-comunidades"><i class="fa fa-check"></i><b>48.6</b> Visualización de comunidades</a></li>
</ul></li>
<li class="chapter" data-level="49" data-path="cap-publidiad.html"><a href="cap-publidiad.html"><i class="fa fa-check"></i><b>49</b> Optimización de inversiones publicitarias</a>
<ul>
<li class="chapter" data-level="49.1" data-path="cap-publidiad.html"><a href="cap-publidiad.html#metodologías-para-optimizar-las-inversiones-publicitarias"><i class="fa fa-check"></i><b>49.1</b> Metodologías para optimizar las inversiones publicitarias</a></li>
<li class="chapter" data-level="49.2" data-path="cap-publidiad.html"><a href="cap-publidiad.html#robyn-como-alternativa-open-source-en-r"><i class="fa fa-check"></i><b>49.2</b> Robyn como alternativa open-source en R</a></li>
</ul></li>
<li class="chapter" data-level="50" data-path="cap-periodismo.html"><a href="cap-periodismo.html"><i class="fa fa-check"></i><b>50</b> Análisis electoral: de Rstudio a su periódico</a>
<ul>
<li class="chapter" data-level="50.1" data-path="cap-periodismo.html"><a href="cap-periodismo.html#obtención-de-los-datos"><i class="fa fa-check"></i><b>50.1</b> Obtención de los datos</a></li>
<li class="chapter" data-level="50.2" data-path="cap-periodismo.html"><a href="cap-periodismo.html#transformación-y-primeros-gráficos"><i class="fa fa-check"></i><b>50.2</b> Transformación y primeros gráficos</a></li>
</ul></li>
<li class="chapter" data-level="51" data-path="paro-clm.html"><a href="paro-clm.html"><i class="fa fa-check"></i><b>51</b> Evolución del paro registrado en Castilla-La Mancha</a>
<ul>
<li class="chapter" data-level="51.1" data-path="paro-clm.html"><a href="paro-clm.html#planteamiento"><i class="fa fa-check"></i><b>51.1</b> Planteamiento</a></li>
<li class="chapter" data-level="51.2" data-path="paro-clm.html"><a href="paro-clm.html#evolución-del-número-total-de-parados"><i class="fa fa-check"></i><b>51.2</b> Evolución del número total de parados</a></li>
<li class="chapter" data-level="51.3" data-path="paro-clm.html"><a href="paro-clm.html#evolución-de-la-edad-y-el-sexo-en-la-población-parada"><i class="fa fa-check"></i><b>51.3</b> Evolución de la edad y el sexo en la población parada</a></li>
<li class="chapter" data-level="51.4" data-path="paro-clm.html"><a href="paro-clm.html#evolución-del-tiempo-de-búsqueda-de-empleo-en-la-población-parada"><i class="fa fa-check"></i><b>51.4</b> Evolución del tiempo de búsqueda de empleo en la población parada</a></li>
<li class="chapter" data-level="51.5" data-path="paro-clm.html"><a href="paro-clm.html#evolución-del-paro-registrado-según-sexo-edad-y-sector-de-procedencia"><i class="fa fa-check"></i><b>51.5</b> Evolución del paro registrado según sexo, edad y sector de procedencia</a></li>
<li class="chapter" data-level="51.6" data-path="paro-clm.html"><a href="paro-clm.html#conclusiones"><i class="fa fa-check"></i><b>51.6</b> Conclusiones</a></li>
</ul></li>
<li class="chapter" data-level="52" data-path="cap-idealista.html"><a href="cap-idealista.html"><i class="fa fa-check"></i><b>52</b> Valoración del precio de la vivienda</a>
<ul>
<li class="chapter" data-level="52.1" data-path="cap-idealista.html"><a href="cap-idealista.html#introducción-26"><i class="fa fa-check"></i><b>52.1</b> Introducción</a></li>
<li class="chapter" data-level="52.2" data-path="cap-idealista.html"><a href="cap-idealista.html#conjunto-de-datos"><i class="fa fa-check"></i><b>52.2</b> Conjunto de datos</a></li>
<li class="chapter" data-level="52.3" data-path="cap-idealista.html"><a href="cap-idealista.html#estimación-del-modelo-1"><i class="fa fa-check"></i><b>52.3</b> Estimación del Modelo</a></li>
</ul></li>
<li class="chapter" data-level="53" data-path="cap-rfm.html"><a href="cap-rfm.html"><i class="fa fa-check"></i><b>53</b> Segmentación de clientes en retail</a>
<ul>
<li class="chapter" data-level="53.1" data-path="cap-rfm.html"><a href="cap-rfm.html#motivación-y-conceptos-clave"><i class="fa fa-check"></i><b>53.1</b> Motivación y conceptos clave</a></li>
<li class="chapter" data-level="53.2" data-path="cap-rfm.html"><a href="cap-rfm.html#del-modelo-rfm-tradicional-al-modelo-rfm-extendido-mejoras-propuestas"><i class="fa fa-check"></i><b>53.2</b> Del Modelo RFM tradicional al Modelo RFM extendido, mejoras propuestas</a></li>
<li class="chapter" data-level="53.3" data-path="cap-rfm.html"><a href="cap-rfm.html#modelo-rfm-extendido"><i class="fa fa-check"></i><b>53.3</b> Modelo RFM extendido</a>
<ul>
<li class="chapter" data-level="53.3.1" data-path="cap-rfm.html"><a href="cap-rfm.html#recopilación-y-comprensión-de-los-datos"><i class="fa fa-check"></i><b>53.3.1</b> Recopilación y comprensión de los datos</a></li>
<li class="chapter" data-level="53.3.2" data-path="cap-rfm.html"><a href="cap-rfm.html#cálculo-de-las-variables-del-modelo-rfm"><i class="fa fa-check"></i><b>53.3.2</b> Cálculo de las variables del Modelo RFM</a></li>
<li class="chapter" data-level="53.3.3" data-path="cap-rfm.html"><a href="cap-rfm.html#breve-análisis-exploratorio-de-las-variables-del-modelo-rfm"><i class="fa fa-check"></i><b>53.3.3</b> Breve análisis exploratorio de las variables del Modelo RFM</a></li>
<li class="chapter" data-level="53.3.4" data-path="cap-rfm.html"><a href="cap-rfm.html#cálculo-del-ranking-de-percentiles"><i class="fa fa-check"></i><b>53.3.4</b> Cálculo del Ranking de percentiles</a></li>
<li class="chapter" data-level="53.3.5" data-path="cap-rfm.html"><a href="cap-rfm.html#modelado-rfm-mediante-k-means"><i class="fa fa-check"></i><b>53.3.5</b> Modelado: RFM mediante k-means</a></li>
<li class="chapter" data-level="53.3.6" data-path="cap-rfm.html"><a href="cap-rfm.html#descriptivos-e-interpretación-de-los-segmentos"><i class="fa fa-check"></i><b>53.3.6</b> Descriptivos e interpretación de los segmentos</a></li>
<li class="chapter" data-level="53.3.7" data-path="cap-rfm.html"><a href="cap-rfm.html#puesta-en-producción"><i class="fa fa-check"></i><b>53.3.7</b> Puesta en producción</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="54" data-path="cap-medicina.html"><a href="cap-medicina.html"><i class="fa fa-check"></i><b>54</b> Ciencia de datos para la investigación y ensayos clínicos</a>
<ul>
<li class="chapter" data-level="54.1" data-path="cap-medicina.html"><a href="cap-medicina.html#justificación"><i class="fa fa-check"></i><b>54.1</b> Justificación</a></li>
<li class="chapter" data-level="54.2" data-path="cap-medicina.html"><a href="cap-medicina.html#introducción-al-uso-de-datos-en-investigación-clínica-y-ensayos-clínicos"><i class="fa fa-check"></i><b>54.2</b> Introducción al uso de datos en investigación clínica y ensayos clínicos</a>
<ul>
<li class="chapter" data-level="54.2.1" data-path="cap-medicina.html"><a href="cap-medicina.html#qué-es-un-ensayo-clínico"><i class="fa fa-check"></i><b>54.2.1</b> ¿Qué es un ensayo clínico?</a></li>
<li class="chapter" data-level="54.2.2" data-path="cap-medicina.html"><a href="cap-medicina.html#limitaciones-de-los-estudios-observacionales"><i class="fa fa-check"></i><b>54.2.2</b> Limitaciones de los estudios observacionales</a></li>
<li class="chapter" data-level="54.2.3" data-path="cap-medicina.html"><a href="cap-medicina.html#propensity-score"><i class="fa fa-check"></i><b>54.2.3</b> Propensity Score</a></li>
</ul></li>
<li class="chapter" data-level="54.3" data-path="cap-medicina.html"><a href="cap-medicina.html#ejemplo-práctico-de-un-estudio-observacional"><i class="fa fa-check"></i><b>54.3</b> Ejemplo práctico de un estudio observacional</a>
<ul>
<li class="chapter" data-level="54.3.1" data-path="cap-medicina.html"><a href="cap-medicina.html#análisis-de-supervivencia"><i class="fa fa-check"></i><b>54.3.1</b> Análisis de supervivencia</a></li>
<li class="chapter" data-level="54.3.2" data-path="cap-medicina.html"><a href="cap-medicina.html#estimación-y-comparación-de-curvas-de-supervivencia"><i class="fa fa-check"></i><b>54.3.2</b> Estimación y comparación de curvas de supervivencia</a></li>
<li class="chapter" data-level="54.3.3" data-path="cap-medicina.html"><a href="cap-medicina.html#regresión-de-cox"><i class="fa fa-check"></i><b>54.3.3</b> Regresión de COX</a></li>
</ul></li>
<li class="chapter" data-level="54.4" data-path="cap-medicina.html"><a href="cap-medicina.html#conclusión"><i class="fa fa-check"></i><b>54.4</b> Conclusión</a></li>
</ul></li>
<li class="chapter" data-level="55" data-path="cap-climatico.html"><a href="cap-climatico.html"><i class="fa fa-check"></i><b>55</b> Lo que nos cuentan los datos sobre el cambio climático</a>
<ul>
<li class="chapter" data-level="55.1" data-path="cap-climatico.html"><a href="cap-climatico.html#consideraciones-iniciales"><i class="fa fa-check"></i><b>55.1</b> Consideraciones iniciales</a></li>
<li class="chapter" data-level="55.2" data-path="cap-climatico.html"><a href="cap-climatico.html#paquetes"><i class="fa fa-check"></i><b>55.2</b> Paquetes</a></li>
<li class="chapter" data-level="55.3" data-path="cap-climatico.html"><a href="cap-climatico.html#visualización-de-mapas-de-pequeños-múltiples"><i class="fa fa-check"></i><b>55.3</b> Visualización de mapas de pequeños múltiples</a>
<ul>
<li class="chapter" data-level="55.3.1" data-path="cap-climatico.html"><a href="cap-climatico.html#datos"><i class="fa fa-check"></i><b>55.3.1</b> Datos</a></li>
<li class="chapter" data-level="55.3.2" data-path="cap-climatico.html"><a href="cap-climatico.html#preparar-los-datos"><i class="fa fa-check"></i><b>55.3.2</b> Preparar los datos</a></li>
<li class="chapter" data-level="55.3.3" data-path="cap-climatico.html"><a href="cap-climatico.html#construir-el-gráfico-de-múltiples-mapas"><i class="fa fa-check"></i><b>55.3.3</b> Construir el gráfico de múltiples mapas</a></li>
<li class="chapter" data-level="55.3.4" data-path="cap-climatico.html"><a href="cap-climatico.html#mapa-de-orientación"><i class="fa fa-check"></i><b>55.3.4</b> Mapa de orientación</a></li>
<li class="chapter" data-level="55.3.5" data-path="cap-climatico.html"><a href="cap-climatico.html#exportar-mapa-final"><i class="fa fa-check"></i><b>55.3.5</b> Exportar mapa final</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="56" data-path="cap-ree.html"><a href="cap-ree.html"><i class="fa fa-check"></i><b>56</b> Predicción de demanda eléctrica con deep learning</a>
<ul>
<li class="chapter" data-level="56.1" data-path="cap-ree.html"><a href="cap-ree.html#introducción-27"><i class="fa fa-check"></i><b>56.1</b> Introducción</a></li>
<li class="chapter" data-level="56.2" data-path="cap-ree.html"><a href="cap-ree.html#datos-de-entrada"><i class="fa fa-check"></i><b>56.2</b> Datos de entrada</a></li>
<li class="chapter" data-level="56.3" data-path="cap-ree.html"><a href="cap-ree.html#caso-de-estudio"><i class="fa fa-check"></i><b>56.3</b> Caso de estudio</a></li>
</ul></li>
<li class="chapter" data-level="57" data-path="cap-sist-experto.html"><a href="cap-sist-experto.html"><i class="fa fa-check"></i><b>57</b> Sistemas expertos en el ámbito pediátrico</a>
<ul>
<li class="chapter" data-level="57.1" data-path="cap-sist-experto.html"><a href="cap-sist-experto.html#introducción-28"><i class="fa fa-check"></i><b>57.1</b> Introducción</a></li>
<li class="chapter" data-level="57.2" data-path="cap-sist-experto.html"><a href="cap-sist-experto.html#marco-teórico"><i class="fa fa-check"></i><b>57.2</b> Marco teórico</a>
<ul>
<li class="chapter" data-level="57.2.1" data-path="cap-sist-experto.html"><a href="cap-sist-experto.html#razonamiento"><i class="fa fa-check"></i><b>57.2.1</b> Razonamiento</a></li>
</ul></li>
<li class="chapter" data-level="57.3" data-path="cap-sist-experto.html"><a href="cap-sist-experto.html#sistema-experto-para-el-ámbito-pediátrico-en-atención-primaria"><i class="fa fa-check"></i><b>57.3</b> Sistema experto para el ámbito pediátrico en atención primaria</a></li>
</ul></li>
<li class="chapter" data-level="58" data-path="nlp-textil.html"><a href="nlp-textil.html"><i class="fa fa-check"></i><b>58</b> El NLP y las tendencias en el mundo de la moda</a>
<ul>
<li class="chapter" data-level="58.1" data-path="nlp-textil.html"><a href="nlp-textil.html#introducción-29"><i class="fa fa-check"></i><b>58.1</b> Introducción</a></li>
<li class="chapter" data-level="58.2" data-path="nlp-textil.html"><a href="nlp-textil.html#nlp-para-tendencias-de-moda-en-textil"><i class="fa fa-check"></i><b>58.2</b> NLP para tendencias de moda en textil</a></li>
</ul></li>
<li class="chapter" data-level="59" data-path="cap-fraude.html"><a href="cap-fraude.html"><i class="fa fa-check"></i><b>59</b> Detección de fraude de tarjetas de crédito</a>
<ul>
<li class="chapter" data-level="59.1" data-path="cap-fraude.html"><a href="cap-fraude.html#introducción-30"><i class="fa fa-check"></i><b>59.1</b> Introducción</a></li>
<li class="chapter" data-level="59.2" data-path="cap-fraude.html"><a href="cap-fraude.html#modelización-del-fraude-en-la-compra-con-tarjetas-de-crérdito"><i class="fa fa-check"></i><b>59.2</b> Modelización del fraude en la compra con tarjetas de crérdito</a></li>
</ul></li>
<li class="chapter" data-level="" data-path=""><a href="#appendix-appendix"><i class="fa fa-check"></i>(APPENDIX) Appendix</a>
<ul>
<li class="chapter" data-level="59.3" data-path="cap-fraude.html"><a href="cap-fraude.html#información-de-la-sesión"><i class="fa fa-check"></i><b>59.3</b> Información de la sesión</a></li>
</ul></li>
<li class="divider"></li>
<li><a href="https://cdr-book.github.io/"> Ciencia de datos con R </a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Ciencia de datos con R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="análisis-cluster-clusterización-jerárquica" class="section level1 hasAnchor" number="30">
<h1><span class="header-section-number">Capítulo 30</span> Análisis cluster: clusterización jerárquica<a href="análisis-cluster-clusterización-jerárquica.html#análisis-cluster-clusterización-jerárquica" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><em>José-María Montero y Gema Fernández-Avilés</em></p>
<p></p>
<div id="origen-cluster" class="section level2 hasAnchor" number="30.1">
<h2><span class="header-section-number">30.1</span> Introducción<a href="análisis-cluster-clusterización-jerárquica.html#origen-cluster" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El origen de la actividad agrupatoria, hoy en día conocida como análisis cluster o de conglomerados (AC), taxonomía numérica o reconocimiento de patrones, entre otras denominaciones, se remonta a tiempos de Aristóteles y su discípulo Teofrasto. Por tanto, tiene unas profundas raíces y hoy en día se aplica en todos los campos del saber. Se ha evitado la palabra “clasificación” porque existe una pequeña diferencia entre agrupación y clasificación. En la actividad clasificatoria se conoce el número de grupos y qué observaciones del conjunto de datos pertenecen a cada uno, siendo el objetivo clasificar nuevas observaciones en los grupos ya existentes. En la actividad agrupatoria, el número de grupos puede ser conocido (normalmente no lo es), pero no las observaciones que pertenecen a cada uno de ellos, siendo el objetivo la asignación de dichas observaciones a diferentes grupos. Este y los dos siguientes capítulos se centran en este último problema y nos referiremos a él por su denominación más popular: AC.</p>
<p>AC está orientado a la síntesis de la información contenida en un conjunto de datos, normalmente una muestra relativa a objetos, individuos o, en general, elementos, definidos por una serie de características, con vistas a establecer una agrupación de los mismos en función de su mayor o menor homogeneidad. En otros términos, AC trata de agrupar dichos elementos en grupos mutuamente excluyentes, de tal forma que los elementos de cada grupo sean lo más parecidos posible entre sí y lo más diferentes posible de los pertenecientes a otros grupos (Fig. <a href="análisis-cluster-clusterización-jerárquica.html#fig:cluster-sim-ch27">30.1</a>).</p>
<div class="sourceCode" id="cb371"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb371-1"><a href="análisis-cluster-clusterización-jerárquica.html#cb371-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb371-2"><a href="análisis-cluster-clusterización-jerárquica.html#cb371-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1980</span>)</span>
<span id="cb371-3"><a href="análisis-cluster-clusterización-jerárquica.html#cb371-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rnorm</span>(<span class="dv">1500</span>, <span class="at">mean =</span> <span class="sc">-</span><span class="dv">4</span>), <span class="fu">rnorm</span>(<span class="dv">1500</span>, <span class="at">mean =</span> <span class="dv">0</span>))</span>
<span id="cb371-4"><a href="análisis-cluster-clusterización-jerárquica.html#cb371-4" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rnorm</span>(<span class="dv">1500</span>, <span class="at">mean =</span> <span class="dv">0</span>), <span class="fu">rnorm</span>(<span class="dv">1500</span>, <span class="at">mean =</span> <span class="fl">1.5</span>))</span>
<span id="cb371-5"><a href="análisis-cluster-clusterización-jerárquica.html#cb371-5" aria-hidden="true" tabindex="-1"></a>cluster <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(<span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">&quot;A&quot;</span>, <span class="dv">1500</span>), <span class="fu">rep</span>(<span class="st">&quot;B&quot;</span>, <span class="dv">1500</span>)))</span>
<span id="cb371-6"><a href="análisis-cluster-clusterización-jerárquica.html#cb371-6" aria-hidden="true" tabindex="-1"></a>xy <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(x, y, cluster)</span>
<span id="cb371-7"><a href="análisis-cluster-clusterización-jerárquica.html#cb371-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb371-8"><a href="análisis-cluster-clusterización-jerárquica.html#cb371-8" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> xy, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)) <span class="sc">+</span></span>
<span id="cb371-9"><a href="análisis-cluster-clusterización-jerárquica.html#cb371-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">color =</span> cluster)) <span class="sc">+</span></span>
<span id="cb371-10"><a href="análisis-cluster-clusterización-jerárquica.html#cb371-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:cluster-sim-ch27"></span>
<img src="Ciencia_de_datos_con_r_files/figure-html/cluster-sim-ch27-1.png" alt="Datos simulados que presentan clusters" width="60%" />
<p class="caption">
Figura 30.1: Datos simulados que presentan clusters
</p>
</div>
<p>Para llevar a cabo un AC, se deben tomar una serie de decisiones:</p>
<ul>
<li>Selección de las variables en función de las cuales se van a agrupar los elementos.</li>
<li>Elección del tipo de distancia o medida de similitud que se va a utilizar para medir la disimilitud entre los elementos objeto de clasificación.</li>
<li>Elección de la técnica para formar los grupos o conglomerados.</li>
<li>Determinación del número óptimo de clusters (si no se determina a priori).</li>
</ul>
<p>En este capítulo se abordarán la primera y, sobre todo, la segunda cuestión, dejando las otras dos para los dos capítulos siguientes.</p>
<p>Como ilustración práctica, se utilizará la base de datos <code>TIC2021</code> del paquete <code>cdr</code>, relativa a las estadísticas de uso de las TIC en la Unión Europea en 2021.</p>
<div class="sourceCode" id="cb372"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb372-1"><a href="análisis-cluster-clusterización-jerárquica.html#cb372-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(CDR)</span>
<span id="cb372-2"><a href="análisis-cluster-clusterización-jerárquica.html#cb372-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;TIC2021&quot;</span>)</span></code></pre></div>
</div>
<div id="selección-de-las-variables" class="section level2 hasAnchor" number="30.2">
<h2><span class="header-section-number">30.2</span> Selección de las variables<a href="análisis-cluster-clusterización-jerárquica.html#selección-de-las-variables" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La selección de las <span class="math inline">\(p\)</span> variables o características, <span class="math inline">\(\{X_1, X_2, ..., X_p\}\)</span>, en función de las cuales se va a proceder a la agrupación de los <span class="math inline">\(n\)</span> elementos disponibles es crucial, ya que determina la agrupación final, independientemente de los procedimientos técnicos utilizados. Una vez determinadas éstas, la información disponible, para los elementos objeto de agrupación será:</p>
<table>
<caption><span id="tab:info-muestral">Tabla 30.1: </span> Información muestral</caption>
<thead>
<tr class="header">
<th align="center"></th>
<th><span class="math inline">\(X_1\)</span></th>
<th><span class="math inline">\(X_2\)</span></th>
<th><span class="math inline">\(X_3\)</span></th>
<th><span class="math inline">\(\cdots\)</span></th>
<th><span class="math inline">\(X_p\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Elemento <span class="math inline">\(1\)</span></td>
<td><span class="math inline">\(x_{11}\)</span></td>
<td><span class="math inline">\(x_{12}\)</span></td>
<td><span class="math inline">\(x_{13}\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(x_{1p}\)</span></td>
</tr>
<tr class="even">
<td align="center">Elemento <span class="math inline">\(2\)</span></td>
<td><span class="math inline">\(x_{21}\)</span></td>
<td><span class="math inline">\(x_{22}\)</span></td>
<td><span class="math inline">\(x_{23}\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(x_{2p}\)</span></td>
</tr>
<tr class="odd">
<td align="center">Elemento <span class="math inline">\(3\)</span></td>
<td><span class="math inline">\(x_{31}\)</span></td>
<td><span class="math inline">\(x_{32}\)</span></td>
<td><span class="math inline">\(x_{33}\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(x_{3p}\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
</tr>
<tr class="odd">
<td align="center">Elemento <span class="math inline">\(n\)</span></td>
<td><span class="math inline">\(x_{n1}\)</span></td>
<td><span class="math inline">\(x_{n2}\)</span></td>
<td><span class="math inline">\(x_{n3}\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(x_{3p}\)</span></td>
</tr>
</tbody>
</table>
<p>En definitiva, la información de partida es una matriz <span class="math inline">\(\bf X_{\textit n\times \textit p}\)</span> donde cada elemento viene representado por un punto en el espacio <span class="math inline">\(p\)</span>-dimensional de variables, es decir, una matriz que proporciona los valores de las variables para cada elemento<a href="#fn72" class="footnote-ref" id="fnref72"><sup>72</sup></a>.</p>
<p>Una cuestión a tener en cuenta es el número de variables a considerar en el AC. La exclusión de variables relevantes generará una agrupación deficiente. La inclusión de variables irrelevantes complicará el proceso de agrupamiento sin procurar ganancias sustantivas. Dado que el miedo del investigador vendrá por el lado de la exclusión de variables relevantes, tenderá a incluir un número excesivo de variables (muchas de ellas correlacionadas). Por ello, se recomienda realizar previamente un ACP (véase Capítulo <a href="acp.html#acp">32</a>, lo que reduce la dimensionalidad del problema, y llevar a cabo el AC a partir de las componentes principales retenidas (incorreladas, evitando así redundancias). La eliminación de información redundante es una cuestión importante en el proceso de clusterización, porque dicha información estaría sobreponderada en el resultado obtenido. Una solución menos drástica a este problema es la utilización de la distancia de Mahalanobis, que, como se verá posteriormente, corrige estas redundancias.</p>
<p>Otra cuestión importante en este momento es decidir si las variables (o componentes principales en su caso) seleccionadas se utilizarán estandarizadas o no. No existe consenso sobre la cuestión, si bien se suele recomendar su estandarización para evitar consecuencias no deseadas derivadas de la distinta escala y/o unidades de medida. No obstante, autores tan relevantes como Edelborck (1979) y Everitt (1993), están en contra y proponen las siguientes alternativas: (<span class="math inline">\(i\)</span>) recategorizar todas las variables en variables binarias, y aplicar a éstas una distancia apropiada para ese tipo de medidas; <span class="math inline">\((ii)\)</span> realizar distintos AC con grupos de variables homogéneas (en cuanto a su métrica) y sintetizar después los diferentes resultados; y <span class="math inline">\((iii)\)</span> utilizar la distancia de Gower, que es aplicable con cualquier tipo de métrica.</p>
<div class="sourceCode" id="cb373"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb373-1"><a href="análisis-cluster-clusterización-jerárquica.html#cb373-1" aria-hidden="true" tabindex="-1"></a>tic <span class="ot">&lt;-</span> <span class="fu">scale</span>(TIC2021)</span></code></pre></div>
</div>
<div id="elección-de-la-distancia-entre-elementos" class="section level2 hasAnchor" number="30.3">
<h2><span class="header-section-number">30.3</span> Elección de la distancia entre elementos<a href="análisis-cluster-clusterización-jerárquica.html#elección-de-la-distancia-entre-elementos" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Una vez se dispone de la matriz de información <span class="math inline">\(\bf X_{\textit n\times \textit p}\)</span> , la segunda etapa en el AC consiste en la creación de una nueva matriz <span class="math inline">\(\bf D_{\textit n\times \textit n}\)</span> cuyos elementos <span class="math inline">\(\{d_{ij}\}\)</span> sean las distancias o disimilaridades entre los elementos objeto de agrupamiento.</p>
<p>En caso de variables cuantitativas, la distancia entre dos elementos en un espacio de <span class="math inline">\(p\)</span> dimensiones, <span class="math inline">\(d({\bf x}_i;{\bf{x}}_{j})\)</span>, se define como una función que a cada dos puntos de <span class="math inline">\(\mathbb{R}^{p}\)</span> le asocia un número real y que verifica:<a href="#fn73" class="footnote-ref" id="fnref73"><sup>73</sup></a></p>
<ul>
<li><p><span class="math inline">\(d({\bf x}_i;{\bf{x}}_{j}) \geq0\)</span>,</p></li>
<li><p><span class="math inline">\(d({\bf x}_i;{\bf{x}}_{j})=0\)</span> si y sólo si <span class="math inline">\({\bf{x}}_{i}={\bf x}_{j}\)</span>,</p></li>
<li><p><span class="math inline">\(d({\bf x}_i;{\bf{x}}_{j})=d({\bf x}_j;{\bf{x}}_{i})\)</span>,</p></li>
<li><p><span class="math inline">\(d({\bf x}_i;{\bf{x}}_{j})+d({\bf x}_j;{\bf{x}}_{k}) \geq d({\bf x}_i;{\bf{x}}_{k}), \quad \forall{\bf{x}}_{k} \in \mathbb{R}^{p}\)</span>,</p></li>
</ul>
<p>Con variables cualitativas, la similitud entre dos elementos, <span class="math inline">\(s({\bf x}_i;{\bf{x}}_{j})\)</span>, es una función que a cada dos puntos de <span class="math inline">\(\mathbb{R}^{p}\)</span> le asocia un número real, y que verifica:</p>
<ul>
<li><span class="math inline">\(s({\bf x}_i;{\bf{x}}_{j}) \leq s_0\)</span>, donde <span class="math inline">\(s_0\)</span> es un número real finito arbitrario (normalmente 1).</li>
<li><span class="math inline">\(s({\bf x}_i;{\bf{x}}_{j})=s_0\)</span> si y sólo si <span class="math inline">\({\bf{x}}_{i}={\bf x}_{j}\)</span>,</li>
<li><span class="math inline">\(s({\bf x}_i;{\bf{x}}_{j})=s({\bf x}_j;{\bf{x}}_{i})\)</span>,</li>
<li><span class="math inline">\(|s({\bf x}_i;{\bf{x}}_{j})+s({\bf x}_j;{\bf{x}}_{k})|s({\bf x}_i;{\bf{x}}_{z}) \geq d({\bf x}_i;{\bf{x}}_{k})s({\bf x}_j;{\bf{x}}_{k}) \in \mathbb{R}^{p}\)</span>.</li>
</ul>
<p>Son numerosas las formas de medir las distancias o similaridades entre dos elementos, que satisfacen las condiciones expuestas. Las más populares son las siguientes:</p>
<p><strong>Variables cuantitativas</strong></p>
<ul>
<li><strong>Distancia euclídea.</strong> Se define como: <span class="math display">\[\begin{equation}
d_{e}({\bf x}_i;{\bf{x}}_{j})=\sqrt{\sum_{k=1}^{p}\left(  x_{ik}-x_{jk}\right)  ^{2}}
\end{equation}\]</span></li>
</ul>
<p>Ignora las unidades de medida de las variables y, en consecuencia, aunque es invariante a los cambios de origen, no lo es a los cambios de escala. También ignora las relaciones entre ellas. Resulta de utilidad con variables cuantitativas incorreladas y medidas en las mismas unidades. El cuadrado de la distancia euclídea también suele utilizarse como distancia.</p>
<div class="sourceCode" id="cb374"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb374-1"><a href="análisis-cluster-clusterización-jerárquica.html#cb374-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(factoextra)</span>
<span id="cb374-2"><a href="análisis-cluster-clusterización-jerárquica.html#cb374-2" aria-hidden="true" tabindex="-1"></a>d_euclidea <span class="ot">&lt;-</span> <span class="fu">get_dist</span>(<span class="at">x =</span> tic, <span class="at">method =</span> <span class="st">&quot;euclidea&quot;</span>)</span>
<span id="cb374-3"><a href="análisis-cluster-clusterización-jerárquica.html#cb374-3" aria-hidden="true" tabindex="-1"></a><span class="fu">as.matrix</span>(d_euclidea)[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>]</span>
<span id="cb374-4"><a href="análisis-cluster-clusterización-jerárquica.html#cb374-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;          1        2        3        4        5</span></span>
<span id="cb374-5"><a href="análisis-cluster-clusterización-jerárquica.html#cb374-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 0.000000 6.421631 2.417212 1.870962 2.304686</span></span>
<span id="cb374-6"><a href="análisis-cluster-clusterización-jerárquica.html#cb374-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 6.421631 0.000000 4.616177 7.988106 4.871235</span></span>
<span id="cb374-7"><a href="análisis-cluster-clusterización-jerárquica.html#cb374-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 2.417212 4.616177 0.000000 3.765714 1.366011</span></span>
<span id="cb374-8"><a href="análisis-cluster-clusterización-jerárquica.html#cb374-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 1.870962 7.988106 3.765714 0.000000 3.607589</span></span>
<span id="cb374-9"><a href="análisis-cluster-clusterización-jerárquica.html#cb374-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 2.304686 4.871235 1.366011 3.607589 0.000000</span></span></code></pre></div>
<p>La Fig. <a href="análisis-cluster-clusterización-jerárquica.html#fig:plot-dist-euclidea">30.2</a> muestra un heatmap<a href="#fn74" class="footnote-ref" id="fnref74"><sup>74</sup></a> de distancias euclideas entre los países de la UE27 a partir deen la Uni las estadísticas de uso de las TIC en 2021.</p>
<div class="sourceCode" id="cb375"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb375-1"><a href="análisis-cluster-clusterización-jerárquica.html#cb375-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_dist</span>(<span class="at">dist.obj =</span> d_euclidea, <span class="at">lab_size =</span> <span class="dv">10</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:plot-dist-euclidea"></span>
<img src="Ciencia_de_datos_con_r_files/figure-html/plot-dist-euclidea-1.png" alt="Heatmap de  distancias euclídeas: datos `TIC2021` del paquete `cdr`" width="60%" />
<p class="caption">
Figura 30.2: Heatmap de distancias euclídeas: datos <code>TIC2021</code> del paquete <code>cdr</code>
</p>
</div>
<ul>
<li><strong>Distancia Manhattan o city block.</strong> Se define como: <span class="math display">\[\begin{equation}
d_{MAN}({\bf x}_i;{\bf{x}}_{j})=\sum_{k=1}^{p}\left\vert x_{ik}-x_{jk}\right\vert.
\end{equation}\]</span></li>
</ul>
<p>Viene afectada por los cambios de escala en alguna de las variables y es menos sensible que la distancia euclídea a los valores extremos. Por ello, es recomendable cuando las variables son cuantitativas, con las mismas unidades de medida, sin relaciones entre ellas y con valores extremos.</p>
<ul>
<li><strong>Distancia de Minkowski.</strong> Se define como: <span class="math display">\[\begin{equation}
d_{MIN}({\bf x}_i;{\bf{x}}_{j})=\left(  \sum_{k=1}^{p}\left\vert x_{ik}-x_{jk}\right\vert
^{\lambda}\right)  ^{\frac{1}{\lambda}}.
\end{equation}\]</span></li>
</ul>
<p>Las distancias euclídea y Manhattan son casos particulares de la distancia de Minkowski. En la distancia euclídea <span class="math inline">\(\lambda=2\)</span> y en la Manhattan <span class="math inline">\(\lambda=1.\)</span></p>
<ul>
<li><strong>Norma del supremo o distancia de Chebychev.</strong> Su expresión es: <span class="math display">\[\begin{equation}
d_{CHE}({\bf x}_i;{\bf{x}}_{j})=\max_{1\leq k\leq p}\sum_{k=1}^{p}\left\vert x_{ik}%
-x_{jk}\right\vert.
\end{equation}\]</span></li>
</ul>
<p>Únicamente influye en ella la variable con los valores más extremos y, en este sentido, es muy sensible a los cambios de escala en una de las variables.</p>
<ul>
<li><strong>Distancia de Mahalanobis.</strong> Se define como: <span class="math display">\[\begin{equation}
d_{MAH}=({\bf x}_i;{\bf{x}}_{j})=(\mathbf{x}_{i}-\mathbf{x}_{j})^{\prime}\mathbf{S}^{-1} (\mathbf{x}_{i}-\mathbf{x}_{j})
\end{equation}\]</span></li>
</ul>
<p>Coincide con la distancia euclídea calculada sobre las componentes principales. Es invariante a cambios de origen y de escala (por tanto, se puede sustituir <span class="math inline">\(\bf S\)</span> por <span class="math inline">\(\bf R\)</span>. Además, tiene en cuenta, explícitamente, las correlaciones lineales que puedan existir entre las variables, corrigiendo así el efecto redundancia. Es, por tanto, es apropiada con variables cuantitativas con relaciones aproximadamente lineales. Su principal desventaja es que <span class="math inline">\(\bf S\)</span> involucra, conjuntamente, a todos los elementos, y no únicamente, y de forma separada, a los elementos de cada cluster.</p>
<ul>
<li><strong>Coeficiente de correlación de Pearson.</strong> Se define como:
<span class="math display">\[\begin{equation}
d_{P}({\bf x}_i;{\bf{x}}_{j})=\frac{\sum_{k=1}^{p}\left(  x_{ik}-\overline{x}_{i}\right)  \left(  x_{jk}-\overline{x}_{j}\right)  }{\sqrt{\sum_{k=1}%
^{p}\left(  x_{ik}-\overline{x}_{i}\right)  ^{2}\sum_{k=1}^{p}\left(
x_{jk}-\overline{x}_{j}\right)  ^{2}}}.
\end{equation}\]</span></li>
</ul>
<p>No es una distancia sino un indicador de similitud. Por tanto, valores altos indican elementos similares y valores bajos elementos distintos.</p>
<p>Su campo de variación es <span class="math inline">\([-1,1]\)</span>, por lo que se toma su valor absoluto. Cuando las variables están centradas, se denomina coeficiente de congruencia o distancia coseno, puesto que coincide con el coseno formado por los vectores representativos de cada pareja de elementos. Tiene un inconveniente importante: un valor unitario no significa que los dos elementos sean iguales puesto que también pueden obtenerse valores unitarios cuando los valores de las <span class="math inline">\(p\)</span> variables en uno de los elementos sean combinación lineal de los valores de las <span class="math inline">\(p\)</span> variables del otro.</p>
<p>Se utiliza, en ocasiones, preferentemente con datos cuantitativos y con el algoritmo de distancia mínima. Los coeficientes de correlación por rangos de Kendall y Spearman se utilizan, también, en casos de variables ordinales.</p>
<p>A efectos prácticos, cambiando el argumento <code>method</code> de la función <code>get_dist</code> (<code>euclidea</code>, `<code>maximum</code>, <code>manhattan</code>, <code>minkowski</code>, <code>pearson</code>, <code>spearman</code>, <code>kendall</code>) se obtienen distintas matrices de distancias entre los elementos.</p>
<p><strong>Variables cualitativas (dicotómicas)</strong></p>
<p>En este caso, se pueden establecer distintas medidas de similaridad en base a la siguiente tabla de contingencia <span class="math inline">\(2\times 2\)</span>:</p>
<table>
<thead>
<tr class="header">
<th align="right"></th>
<th align="left"></th>
<th align="center">Elem. <span class="math inline">\(j\)</span></th>
<th align="center"></th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right"></td>
<td align="left"></td>
<td align="center">Presencia</td>
<td align="center">Ausencia</td>
<td align="center">Total</td>
</tr>
<tr class="even">
<td align="right">Elem. <span class="math inline">\(i\)</span></td>
<td align="left">Presencia</td>
<td align="center"><span class="math inline">\(n_{11}\)</span></td>
<td align="center"><span class="math inline">\(n_{12}\)</span></td>
<td align="center"><span class="math inline">\(n_{1\cdot}\)</span></td>
</tr>
<tr class="odd">
<td align="right"></td>
<td align="left">Ausencia</td>
<td align="center"><span class="math inline">\(n_{21}\)</span></td>
<td align="center"><span class="math inline">\(n_{22}\)</span></td>
<td align="center"><span class="math inline">\(n_{2\cdot}\)</span></td>
</tr>
<tr class="even">
<td align="right"></td>
<td align="left">Total</td>
<td align="center"><span class="math inline">\(n_{\cdot1}\)</span></td>
<td align="center"><span class="math inline">\(n_{\cdot2}\)</span></td>
<td align="center"><span class="math inline">\(p\)</span></td>
</tr>
</tbody>
</table>
<p>A partir de la tabla anterior, la similaridad entre dos elementos se puede medir a partir de las coincidencias, ya sea de presencias y ausencias como de solo presencias.</p>
<p>Entre las medidas de similaridad que involucran tanto presencias como ausencias comunes están:</p>
<ul>
<li>El <strong>coeficiente de coincidencias simple</strong>: <span class="math inline">\(c_{cs}=\frac{(n_{11} + n_{22})} {2}\)</span></li>
<li>El <strong>coeficiente de Rogers-Tanimoto</strong>: <span class="math inline">\(c_{RT}=\frac{(n_{11} + n_{22})} {2 (n_{11} + n_{22})+ n_{12}+n_{21}}\)</span></li>
</ul>
<p>Estos dos coeficientes tienen una relación monotónica (si la distancia entre dos elementos es igual o superior a la distancia entre otros dos con una de las medidas, también lo es con la otra). Esto es importante dado que algunos procedimientos de agrupación no se ven afectados por la medida utilizada siempre y cuando el ordenamiento establecido por ellas sea el mismo.</p>
<p>Entre aquellas que identifican similaridad con presencias destacan:</p>
<ul>
<li><p>El <strong>coeficiente de Jacard</strong>: <span class="math inline">\(c_J=\frac{n_{11}} {n_{11} + n_{12}+ n_{21}}\)</span></p></li>
<li><p>El <strong>coeficiente de Czekanowski</strong>: <span class="math inline">\(c_{C}=\frac{2 n_{11}} {2n_{11} + n_{12}+ n_{21}}\)</span></p></li>
<li><p>El <strong>coeficiente de Sokal y Sneath</strong>: <span class="math inline">\(c_{SS}=\frac{n_{11} } {n_{11} + 2(n_{12}+n_{21})}\)</span></p></li>
<li><p>El <strong>coeficiente de Russell y Rao</strong>: <span class="math inline">\(c_{RR}=\frac {n_{11}}{p}\)</span></p></li>
</ul>
<p>Los tres primeros coeficientes disfutan de la relación de monotonicidad en el sentido anteriormente apuntado, siendo las dos primeros las más utilizados en la práctica.</p>
<p>También se usan como indicadores de similitud las medidas de asociación para tablas <span class="math inline">\(2\times2\)</span>, sobre todo <span class="math inline">\(Q\)</span> y <span class="math inline">\(\phi\)</span> (capítulo <a href="tablas-contingencia.html#medidas">23.4</a>).</p>
<p><strong>Variables cualitativas (politómicas)</strong></p>
<p>Cuando todas las variables sean cualitativas y alguna sea politómica, se generan para estas ultimas tantas variables dicotómicas como categorías tienen, denotando con 1 la presencia y con 0 la ausencia.</p>
<p><strong>Variables cuantitativas y cualitativas</strong></p>
<p>Si las variables no son del mismo tipo, se utiliza la medida de similaridad de Gower:</p>
<p><span class="math display">\[\begin{equation}
    S_{ij}({\bf x}_i;{\bf{x}}_{j})=\frac{\sum_{k=1}^{p}s_{ij}}{\sum_{k=1}^{p}w_{ij}}
    \end{equation}\]</span></p>
<p>donde <span class="math inline">\(w_{ij}\)</span> vale siempre la unidad salvo para variables binarias si los dos elementos presentan el valor cero. En cuanto al valor de <span class="math inline">\(S_{ij}\)</span>, se distinguen tres casos:</p>
<ul>
<li>Variables cualitativas de más de dos niveles: 1 si ambos elementos son iguales en la <em>k</em>-ésima variable; 0 si son diferentes.</li>
<li>Variables dicotómicas: 1 si la variable considerada está presente en ambos elementos; 0 en los demás casos.</li>
<li>Variables cuantitativas: <span class="math inline">\(1-\frac {|x_{ik}-x_{jk}|}{R_k}\)</span>, donde <span class="math inline">\(R\)</span> es el rango de la variable <em>k</em>.</li>
</ul>
<p>No es recomendable cuando las variables cuantitativas sean muy asimétricas. En este caso, hay dos procedimientos aproximados: <span class="math inline">\((i)\)</span> calcular medidas separadas para las variables cuantitativas y cualitativas y combinarlas estableciendo algún tipo de de ponderación; <span class="math inline">\((ii)\)</span> pasar las variables cuantitativas a cualitativas y utilizar las medidas propuestas para este tipo de variables.</p>
</div>
<div id="técnicas-de-agrupación-jerárquicas" class="section level2 hasAnchor" number="30.4">
<h2><span class="header-section-number">30.4</span> Técnicas de agrupación jerárquicas<a href="análisis-cluster-clusterización-jerárquica.html#técnicas-de-agrupación-jerárquicas" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="introac" class="section level3 hasAnchor" number="30.4.1">
<h3><span class="header-section-number">30.4.1</span> Introducción<a href="análisis-cluster-clusterización-jerárquica.html#introac" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Una vez se han seleccionado las variables en función de las cuales se van a agrupar en clusters o conglomerados los elementos disponibles, así como se ha decidido qué distancia utilizar para tal propósito, el siguiente paso del AC es la selección de un criterio o técnica de agrupamiento para formar los conglomerados. Dichas técnicas se pueden clasificar en <span class="math inline">\((i)\)</span> jerárquicas y <span class="math inline">\((ii)\)</span> no jerárquicas.</p>
<div class="infobox">
<p><strong>TÉCNICAS DE CLUSTERIZACIÓN</strong>:</p>
<ol style="list-style-type: decimal">
<li><strong>Jerárquicas</strong>:
<ul>
<li><em>Aglomerativas</em>:
<ul>
<li>Vecino más cerano o encadenamiento simple</li>
<li>Vecino más lejano o encadenamiento completo</li>
<li>Método de la distancia media</li>
<li>Método de la distancia entre centroides</li>
<li>Método de la mediana</li>
<li>Método de Ward</li>
<li>Encadenamiento intragrupos</li>
<li>Método flexible de Lance y Williams</li>
</ul></li>
<li><em>Divisivas</em>:
<ul>
<li>Vecino más cerano o encadenamiento simple</li>
<li>Vecino más lejano o encadenamiento completo</li>
<li>Método de la distancia media</li>
<li>Método de la distancia entre centroides</li>
<li>Método de la mediana</li>
<li>Método de Ward</li>
<li>Encadenamiento intragrupos</li>
<li>Análisis de la asociación</li>
<li>Detector automático de interacciones</li>
</ul></li>
</ul></li>
<li><strong>No jerárquicas</strong>:
<ul>
<li><em>Técnicas de reasignación</em>:
<ul>
<li>Basadas en centroides: Método de Forgy, <span class="math inline">\(k\)</span>-medias</li>
<li>Basadas en medoides: <span class="math inline">\(k\)</span>-medoides, PAM, CLARA, CLARANS</li>
<li>Basadas en medianas: <span class="math inline">\(k\)</span>-medianas</li>
</ul></li>
<li><em>Técnicas basadas en la densidad de puntos (mode-seeking)</em>:
<ul>
<li>Aproximación tipológica: Análisis modal, métodos taxmap, de Fortin, de Gitman y Levine, de Catel y Coulter</li>
<li>Aproximación probabilística: método de Wolf</li>
<li>DBSCAN</li>
</ul></li>
<li><em>Otras técnicas no jerárquicas</em>
<ul>
<li>Métodos directos: block-; bi; co-; two-mode clustering</li>
<li>Métodos de reducción de la dimensionalidad: modelos
Q- y R-factorial</li>
<li>Clustering difuso</li>
<li>Métodos basados en mixturas de modelos</li>
</ul></li>
</ul></li>
</ol>
</div>
<p>Los procedimientos jerárquicos no particionan el conjunto de elementos de una sola vez, sino que realizan particiones sucesivas a distintos niveles de agrupamiento; es decir, establecen una jerarquía de clusters, de ahí su nombre. Forman los conglomerados, bien agrupando los elementos en grupos cada vez más grandes, fusionando grupos en cada paso, (jerárquicos aglomerativos), o bien desagregándolos en conglomerados cada vez más pequeños (jerárquicos divisivos).</p>
<p>Las técnicas no jerárquicas se caracterizan porque <span class="math inline">\((i)\)</span> el número de clusters se suele determinar a priori; <span class="math inline">\((ii)\)</span> utilizan directamente los datos originales, si necesidad de calcular una matriz de distancias o similaridades; y <span class="math inline">\((iii)\)</span> los clusters resultantes no están anidados unos en otros, sino que están separados. La caja informativa proporciona un detalle mayor de la tipología de técnicas de agrupación a la que nos vamos a referir<a href="#fn75" class="footnote-ref" id="fnref75"><sup>75</sup></a>. En lo que sigue, nos centramos en las técnicas jerárquicas, abordando las no jerárquicas en el Capítulo <a href="no-jerarquico.html#no-jerarquico">31</a>.</p>
</div>
<div id="técnicas-jerárquicas-aglomerativas" class="section level3 hasAnchor" number="30.4.2">
<h3><span class="header-section-number">30.4.2</span> Técnicas jerárquicas aglomerativas<a href="análisis-cluster-clusterización-jerárquica.html#técnicas-jerárquicas-aglomerativas" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Las técnicas jerárquicas aglomerativas, de amplia utilización, parten de tantos conglomerados como elementos y llegan a un único conglomerado final.</p>
<p>Se parte de un conglomerado constituido por los dos elementos más próximos, de tal manera que en la segunda etapa el conglomerado formado actuará a modo de elemento (como si se tuviesen <span class="math inline">\(n-1\)</span> elementos). En la segunda etapa, de nuevo se agrupan de nuevo los dos elementos más cercanos, que pueden ser dos elementos simples o uno simple y otro compuesto (el conglomerado anterior); en el primer caso se tendrían dos conglomerados (cada uno de ellos formado por dos elementos) y en el segundo, un conglomerado con tres elementos y otro con uno. Sea cual sea el caso, al final de la segunda etapa se tienen <span class="math inline">\(n-2\)</span> elementos, dos de los cuales son conglomerados. En las etapas siguientes se procede de idéntica manera: agrupación de los dos elementos (sean elementos simples o conglomerados formados en las etapas anteriores) más cercanos, y así sucesivamente hasta formar un único conglomerado integrado por todos los elementos. Es importante resaltar que un elemento, una vez forma parte de un conglomerado, ya no sale de él.</p>
<p>La pregunta que surge en este momento es: en el proceso de agrupamiento descrito, ¿cómo se mide la distancia de un elemento a un conglomerado, o entre dos conglomerados?<a href="#fn76" class="footnote-ref" id="fnref76"><sup>76</sup></a> Los métodos más populares son los siguientes:</p>
<ul>
<li><strong>Método del encadenamiento simple o vecino más cercano.</strong> </li>
</ul>
<p>Utiliza el criterio de “<em>la distancia mas cercana</em>”. Por tanto, <span class="math inline">\((i)\)</span> la distancia entre un elemento y un conglomerado es la menor de las distancias entre dicho elemento y cada uno de los elementos del conglomerado; <span class="math inline">\((ii)\)</span> la distancia entre dos conglomerados viene dada por la distancia entre sus dos elementos más cercanos. Una vez computada la matriz de distancias se seleccionan los conglomerados más cercanos.</p>
<ul>
<li><strong>Método del encadenamiento completo o vecino más lejano.</strong></li>
</ul>
<p>Funciona igual que el anterior, pero ahora el criterio es “<em>la distancia más lejana</em>”.</p>
<p>Nótese que mientras que con el método del vecino más cerano la distancia entre los elementos más próximos de un cluster es siempre menor que la distancia entre elementos de distintos clusters, con el criterio del vecino más lejano la distancia entre los dos elementos más alejados de un cluster es siempre menor que la distancia entre cualquiera de sus elementos y los elementos más alejados de los demás clusters. Nótese también que mientras que el método del vecino más lejano tiende a separar a los individuos en menor medida que la indicada por sus disimilaridades iniciales (es espacio-contractivo), el criterio del vecino más lejano es espacio-dilatante, es decir, tiende a separar a los individuos en mayor medida que la indicada por sus disimilaridades iniciales <span class="citation">(<a href="#ref-gallardoyvera2004" role="doc-biblioref">Gallardo-San Salvador and Vera-Vera 2004</a>)</span>.</p>
<ul>
<li><strong>Método de la distancia media.</strong></li>
</ul>
<p>Surge como una solución a la constricción o dilatación del espacio que provocan los dos métodos anteriores (por eso se dice que es espacio-conservativo y es muy utilizado), utilizando “<em>la distancia promedio</em>” , es decir, la distancia entre un elemento y un conglomerado es la media aritmética de las distancias de dicho elemento a cada uno de los elementos del conglomerado. En caso de dos conglomerados, la distancia entre ellos viene dada por el promedio aritmético de las distancias, dos a dos, un elemento de cada conglomerado. Igual que los dos métodos precedentes, es invariante a transformaciones monótonas de la distancia utilizada.</p>
<p>En la Fig. <a href="análisis-cluster-clusterización-jerárquica.html#fig:cluster-compara">30.3</a> se puede ver la constricción, dilatación y conservación del espacio que producen los métodos del vecino más cercano, más lejano y de la distancia media, respectivamente. En este caso se utiliza como representación gráfica el dendrograma(diagrama de árbol). En figuras posteriores se utilizarán otras alternativas al dendrograma, con el objetivo de mostrar las más populares.</p>
<div class="sourceCode" id="cb376"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb376-1"><a href="análisis-cluster-clusterización-jerárquica.html#cb376-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(factoextra)</span>
<span id="cb376-2"><a href="análisis-cluster-clusterización-jerárquica.html#cb376-2" aria-hidden="true" tabindex="-1"></a>hc_simple <span class="ot">&lt;-</span> <span class="fu">hcut</span>(tic, <span class="at">k =</span> <span class="dv">3</span>, <span class="at">hc_method =</span> <span class="st">&quot;single&quot;</span>)</span>
<span id="cb376-3"><a href="análisis-cluster-clusterización-jerárquica.html#cb376-3" aria-hidden="true" tabindex="-1"></a>hc_completo <span class="ot">&lt;-</span> <span class="fu">hcut</span>(tic, <span class="at">k =</span> <span class="dv">3</span>, <span class="at">hc_method =</span> <span class="st">&quot;complete&quot;</span>)</span>
<span id="cb376-4"><a href="análisis-cluster-clusterización-jerárquica.html#cb376-4" aria-hidden="true" tabindex="-1"></a>hc_promedio <span class="ot">&lt;-</span> <span class="fu">hcut</span>(tic, <span class="at">k =</span> <span class="dv">3</span>, <span class="at">hc_method =</span> <span class="st">&quot;average&quot;</span>)</span>
<span id="cb376-5"><a href="análisis-cluster-clusterización-jerárquica.html#cb376-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb376-6"><a href="análisis-cluster-clusterización-jerárquica.html#cb376-6" aria-hidden="true" tabindex="-1"></a>d1 <span class="ot">&lt;-</span> <span class="fu">fviz_dend</span>(hc_simple, <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">k =</span> <span class="dv">3</span>, <span class="at">main =</span> <span class="st">&quot;Vecino más cercano&quot;</span>)</span>
<span id="cb376-7"><a href="análisis-cluster-clusterización-jerárquica.html#cb376-7" aria-hidden="true" tabindex="-1"></a>d2 <span class="ot">&lt;-</span> <span class="fu">fviz_dend</span>(hc_completo, <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">k =</span> <span class="dv">3</span>, <span class="at">main =</span> <span class="st">&quot;Vecino más lejano&quot;</span>)</span>
<span id="cb376-8"><a href="análisis-cluster-clusterización-jerárquica.html#cb376-8" aria-hidden="true" tabindex="-1"></a>d3 <span class="ot">&lt;-</span> <span class="fu">fviz_dend</span>(hc_promedio, <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">k =</span> <span class="dv">3</span>, <span class="at">main =</span> <span class="st">&quot;Distancia promedio&quot;</span>)</span>
<span id="cb376-9"><a href="análisis-cluster-clusterización-jerárquica.html#cb376-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb376-10"><a href="análisis-cluster-clusterización-jerárquica.html#cb376-10" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb376-11"><a href="análisis-cluster-clusterización-jerárquica.html#cb376-11" aria-hidden="true" tabindex="-1"></a>d1 <span class="sc">+</span> d2 <span class="sc">+</span> d3</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:cluster-compara"></span>
<img src="Ciencia_de_datos_con_r_files/figure-html/cluster-compara-1.png" alt="Clusterización jerárquica con distancias euclídeas (dendrograma): métodos del vecino más cercano, vecino más lejano y distancia media" width="60%" />
<p class="caption">
Figura 30.3: Clusterización jerárquica con distancias euclídeas (dendrograma): métodos del vecino más cercano, vecino más lejano y distancia media
</p>
</div>
<ul>
<li><strong>Método de la distancia entre centroides.</strong></li>
</ul>
<p>Según este método, la distancia entre dos grupos o conglomerados es la distancia entre sus centroides, entendiendo por centroide del grupo <span class="math inline">\(g\)</span>: <span class="math inline">\(c_{g}=\left(\overline{x}_{1g},\overline{x}_{2g},...,\overline{x}_{pg}\right),\)</span> donde <span class="math inline">\(\overline{x}_{jg}\)</span> es la media de la <span class="math inline">\(j\)</span>-ésima variable en dicho grupo.</p>
<p>Igual que el método de la media, este método es también espacio-conservativo. Sin embargo, tiene la limitación de que cuando se agrupan dos conglomerados de diferente tamaño, el conglomerado resultante queda más cerca del conglomerado mayor y más alejado del menor, de forma proporcional a la diferencia de tamaños, lo que lleva a que a lo largo del proceso de clusterización se vayan perdiendo las propiedades de los conglomerados pequeños <span class="citation">(<a href="#ref-gallardo2022" role="doc-biblioref">Gallardo San-Salvador 2022</a>)</span>.</p>
<ul>
<li><strong>Método de la mediana.</strong></li>
</ul>
<p> Viene a superar la limitación del método del centroide. Para ello, la estrategia natural es suponer que los grupos son de igual tamaño. Dicha estrategia se plasma en suponer que la distancia entre un elemento (o un conglomerado, <span class="math inline">\(k\)</span>) y el conglomerado formado por la agrupación de los conglomerados <span class="math inline">\(i\)</span> y <span class="math inline">\(j\)</span> viene dada por la mediana del triángulo formado por sus centroides (de ahí su nombre). Se trata de un método espacio conservativo, pero, igual que el método del centroide, no es invariante a transformaciones monótonas de la distancia utilizada.</p>
<p>La Fig. <a href="análisis-cluster-clusterización-jerárquica.html#fig:cluster-compara2">30.4</a>, un tanglegrama o diagrama de laberinto, muestra las agrupaciones producidas por los métodos del centroide y la mediana. En ella se puede observar como el método de la mediana corrije la limitación del método del centroide.</p>
<div class="sourceCode" id="cb377"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb377-1"><a href="análisis-cluster-clusterización-jerárquica.html#cb377-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dendextend)</span>
<span id="cb377-2"><a href="análisis-cluster-clusterización-jerárquica.html#cb377-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(cluster)</span>
<span id="cb377-3"><a href="análisis-cluster-clusterización-jerárquica.html#cb377-3" aria-hidden="true" tabindex="-1"></a>hc_cent_dend <span class="ot">&lt;-</span> <span class="fu">as.dendrogram</span>(<span class="fu">hclust</span>(d_euclidea, <span class="at">method =</span> <span class="st">&quot;centroid&quot;</span>))</span>
<span id="cb377-4"><a href="análisis-cluster-clusterización-jerárquica.html#cb377-4" aria-hidden="true" tabindex="-1"></a>hc_med_dend <span class="ot">&lt;-</span> <span class="fu">as.dendrogram</span>(<span class="fu">hclust</span>(d_euclidea, <span class="at">method =</span> <span class="st">&quot;median&quot;</span>))</span>
<span id="cb377-5"><a href="análisis-cluster-clusterización-jerárquica.html#cb377-5" aria-hidden="true" tabindex="-1"></a><span class="fu">tanglegram</span>(hc_cent_dend, hc_med_dend)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:cluster-compara2"></span>
<img src="Ciencia_de_datos_con_r_files/figure-html/cluster-compara2-1.png" alt="Clusterización jerárquica con distancias euclídeas (tanglegrama): método del centroide vs. método de la mediana" width="60%" />
<p class="caption">
Figura 30.4: Clusterización jerárquica con distancias euclídeas (tanglegrama): método del centroide vs. método de la mediana
</p>
</div>
<ul>
<li><strong>Método de Ward.</strong></li>
</ul>
<p>El método de Ward agrupa, en cada etapa, los dos clusters que producen el menor incremento de la varianza total intra-cluster: <span class="math inline">\(W=\sum_g\sum_{i \in g} (x_{ig}- \bar{x}_g)^{\prime} (x_{ig}- \bar{x}_g)\)</span>, donde <span class="math inline">\(\bar{x}_g\)</span> es el centroide del grupo <span class="math inline">\(g\)</span>. Así, los grupos formados no distorsionan los datos originales.<a href="#fn77" class="footnote-ref" id="fnref77"><sup>77</sup></a></p>
<p>Es muy utilizado en la práctica, dado que tiene casi todas las ventajas del método de la media y suele ser más discriminatorio en la determinación de los niveles de agrupación. También suele crear conglomerados muy compactos de tamaño similar. Dado que el menor incremento de <span class="math inline">\(W\)</span> es proporcional a la distancia euclidea al cuadrado entre los centroides de los grupos fusionados, <span class="math inline">\(W\)</span> no es decreciente, solventándose los problemas de los otros métodos basados en centroides.</p>
<p>La Fig. <a href="análisis-cluster-clusterización-jerárquica.html#fig:plot-igraph">30.5</a>, muestra el filograma, diagrama filético en forma de árbol filogenético, generado por la librería <code>igraph</code> con el método de agrupación de Ward.</p>
<div class="sourceCode" id="cb378"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb378-1"><a href="análisis-cluster-clusterización-jerárquica.html#cb378-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;igraph&quot;</span>)</span>
<span id="cb378-2"><a href="análisis-cluster-clusterización-jerárquica.html#cb378-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">5665</span>)</span>
<span id="cb378-3"><a href="análisis-cluster-clusterización-jerárquica.html#cb378-3" aria-hidden="true" tabindex="-1"></a>hc_ward <span class="ot">&lt;-</span> <span class="fu">hcut</span>(tic, <span class="at">k =</span> <span class="dv">3</span>, <span class="at">hc_method =</span> <span class="st">&quot;ward.D2&quot;</span>)</span>
<span id="cb378-4"><a href="análisis-cluster-clusterización-jerárquica.html#cb378-4" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_dend</span>(</span>
<span id="cb378-5"><a href="análisis-cluster-clusterización-jerárquica.html#cb378-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> hc_ward,</span>
<span id="cb378-6"><a href="análisis-cluster-clusterización-jerárquica.html#cb378-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">k =</span> <span class="dv">3</span>,</span>
<span id="cb378-7"><a href="análisis-cluster-clusterización-jerárquica.html#cb378-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">&quot;phylogenic&quot;</span></span>
<span id="cb378-8"><a href="análisis-cluster-clusterización-jerárquica.html#cb378-8" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:plot-igraph"></span>
<img src="Ciencia_de_datos_con_r_files/figure-html/plot-igraph-1.png" alt="Clusterización jerárquica con distancias euclídeas al cuadrado (filograma): método de Ward" width="60%" />
<p class="caption">
Figura 30.5: Clusterización jerárquica con distancias euclídeas al cuadrado (filograma): método de Ward
</p>
</div>
<ul>
<li><strong>Método del encadenamiento intragrupos.</strong></li>
</ul>
<p>Según el método de la distancia promedio (o vinculación entre grupos) la distancia entre dos conglomerados se obtenía calculando las distancias de cada elemento de uno de los grupos con todos los del otro y computando, posteriormente, la media aritmética de dichas distancias. Con el método de la vinculación intragrupos se computa la distancia media entre la totalidad de los elementos de los conglomerados susceptibles de agrupación, con independencia de si pertenecen al mismo conglomerado inicial o a distinto conglomerado. Por ejemplo: si un conglomerado está formado por los elementos <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span>, y otro por los elementos <span class="math inline">\(c\)</span> y <span class="math inline">\(d\)</span>, la distancia intergrupos entre los dos conglomerados es:</p>
<p><span class="math display">\[d_{intergrupos}=\frac{d_{(a;c)}+d_{(a;d)}+d_{(b;c)}+d_{(b;d)}}{4}\]</span> mientras que la distancia intragrupos vendrá dada por la media de las distancias entre los elementos <span class="math inline">\(a,b,c\)</span> y <span class="math inline">\(d\)</span>: <span class="math display">\[d_{intergrupos}=\frac{d_{(a;b)}+d_{(a;c)}+d_{(a;d)}+d_{(b;c)}+d_{(b;d)}
     +d_{(c;d)}}{6}\]</span></p>
<ul>
<li><strong>Método flexible de Lance y Williams.</strong></li>
</ul>
<p>Calcula la distancia entre dos conglomerados (el primero formado por la unión de otros dos en la etapa previa) a partir de la siguiente expresión: <span class="math display">\[d_{\left(  g_{1}\cup g_{2}\right); g_{3}}=\alpha_{1}d_{(g_{1};g_{3})}
+\alpha_{2}d_{(g_{2};g_{3})}+\beta d_{(g_{1};g_{2})}+\gamma\left\vert
d_{(g_{1};g_{2})}-d_{(g_{2};g_{2})}\right\vert,\]</span> donde <span class="math inline">\(\alpha_{1}+\alpha_{2}+\beta=1; \alpha_{1}=\alpha_{2};\beta&lt;1;\gamma=0\)</span>, si bien Lance y Williams sugieren adicionalmente un pequeño valor negativo de <span class="math inline">\(\beta\)</span>. Por ejemplo <span class="math inline">\(\beta =-0,25\)</span>.</p>
<p>Los métodos anteriormente expuestos son casos particulares de éste. Denominando <span class="math inline">\(n_1\)</span>, <span class="math inline">\(n_2\)</span> y <span class="math inline">\(n_3\)</span> a los tamaños de los grupos <span class="math inline">\(g_1\)</span>, <span class="math inline">\(g_2\)</span> y <span class="math inline">\(g_3\)</span>, respectivamente, se tiene:</p>
<table>
<caption>Valores de <span class="math inline">\(\alpha_1\)</span>, <span class="math inline">\(\alpha_2\)</span>, <span class="math inline">\(\beta\)</span> y <span class="math inline">\(\gamma\)</span> para distintos procedimientos de agrupación</caption>
<colgroup>
<col width="38%" />
<col width="15%" />
<col width="15%" />
<col width="15%" />
<col width="15%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Método</th>
<th align="center"><span class="math inline">\(\alpha_1\)</span></th>
<th align="center"><span class="math inline">\(\alpha_2\)</span></th>
<th align="center"><span class="math inline">\(\beta\)</span></th>
<th align="center"><span class="math inline">\(\gamma\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Vecino más cercano</td>
<td align="center">0,5</td>
<td align="center">0,5</td>
<td align="center">0</td>
<td align="center">-0,5</td>
</tr>
<tr class="even">
<td align="center">Vecino más lejano</td>
<td align="center">0,5</td>
<td align="center">0,5</td>
<td align="center">0</td>
<td align="center">0,5</td>
</tr>
<tr class="odd">
<td align="center">Distancia media</td>
<td align="center"><span class="math inline">\(\frac{n_1}{n_1+n_2}\)</span></td>
<td align="center"><span class="math inline">\(\frac{n_2}{n_1+n_2}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center">Distancia entre centroides</td>
<td align="center"><span class="math inline">\(\frac{n_1}{n_1+n_2}\)</span></td>
<td align="center"><span class="math inline">\(\frac{n_2}{n_1+n_2}\)</span></td>
<td align="center"><span class="math inline">\(\frac{-n_1 n_2} {(n_1+n_2)^2}\)</span></td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center">Método de la mediana</td>
<td align="center">0,5</td>
<td align="center">0,5</td>
<td align="center">-0,25</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center">Ward</td>
<td align="center"><span class="math inline">\(\frac {n_1+n_3} {n_1+n_2+n_3}\)</span></td>
<td align="center"><span class="math inline">\(\frac {n_2+n_3} {n_1+n_2+n_3}\)</span></td>
<td align="center"><span class="math inline">\(\frac{-n_3} {n_1+n_2+n_3}\)</span></td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center">Flexible</td>
<td align="center"><span class="math inline">\(0,5(1-\beta)\)</span></td>
<td align="center"><span class="math inline">\(0,5(1-\beta)\)</span></td>
<td align="center"><span class="math inline">\(\beta\)</span></td>
<td align="center">0</td>
</tr>
</tbody>
</table>
</div>
<div id="técnicas-jerárquicas-divisivas" class="section level3 hasAnchor" number="30.4.3">
<h3><span class="header-section-number">30.4.3</span> Técnicas jerárquicas divisivas<a href="análisis-cluster-clusterización-jerárquica.html#técnicas-jerárquicas-divisivas" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En este caso, la secuencia de acontecimientos es justo la inversa. Se parte de un único conglomerado formado por todos los elementos y se llega a <span class="math inline">\(n\)</span> conglomerados formados cada uno de ellos por un único elemento (a veces el proceso termina cuando se llega a un número de grupos preestablecido). Ahora bien, dado que ahora se trata de subividir conglomerados, es decir, de identificar los elementos más distantes, o menos similares, para separarlos del resto del conglomerado, la estrategia a seguir estará basada en maximizar las distancias (o minimizar las similitudes). En el proceso disociativo surge una cuestión importante: cuándo debe dejar de dividirse un cluster determinado y pasar a dividir otro, cuestión que se resuelve por el procedimiento propuesto por <span class="citation">MacNaughton-Smith et al. (<a href="#ref-macnaughton_et_al1964" role="doc-biblioref">1964</a>)</span>. Las técnicas divisivas (también llamadas partitivas o disociativas), pueden ser monotéticas o politéticas. En el primer caso, las divisiones se basan en una sola característica o atributo. En el segundo, se tienen en cuenta todas.</p>
<p>Las técnicas divisivas son menos populares que las aglomerativas. Sin embargo, la probabilidad de que lleven a decisiones equivocadas (debido a la variabilidad estadística de los datos) en las etapas iniciales del proceso, lo cual distorsionaría el resultado final del mismo, es menor que en las aglomerativas. En este sentido, los métodos partitivos, al partir del total de elementos, se consideran más seguros que los aglomerativos. Los métodos disociativos más populares son los siguientes:</p>
<p><strong>Método de la distancia promedio</strong></p>
<p>Dentro de las técnicas politéticas, entre las que se cuentan todas las vistas en la clusterización jerárquica aglomerativa, quizás la más popular es la que utiliza para la partición el método de la distancia promedio. Para ilustrarla, supóngase que se tienen 5 elementos y que su matriz de distancias es la siguiente:</p>
<p><span class="math display">\[\bf X=\left(\begin{matrix} .&amp;.&amp;.&amp;.&amp;.\\
8&amp;.&amp;.&amp;.&amp;.\\
7&amp;4&amp;.&amp;.&amp;.\\
6&amp;1&amp;4&amp;.&amp;.\\
3&amp;4&amp;5&amp;4&amp;.
\end {matrix}\right)\]</span></p>
<p>En la primera etapa hay que dividir el grupo de cinco elementos en dos conglomerados. Hay <span class="math inline">\(2^{2n-1}-1\)</span> posibilidades, pero según el método de la distancia promedio, se calcula la distancia de cada elemento a los demás y se promedia, desgajándose el elemento con distancia promedio máxima. En nuestro caso, se desgajaría el primer elemento, y en la segunda etapa se partiría de dos grupos: <span class="math inline">\(\{e_1 \}\)</span> y <span class="math inline">\(\{e_2, e_3, e_4, e_5\}\)</span>.</p>
<p>A partir de la segunda etapa, se procede como sigue (véase Tabla 2.2):</p>
<ul>
<li><span class="math inline">\((i)\)</span> Se calculan las (4) distancias promedio de cada elemento del conglomerado principal al elemento desgajado;</li>
<li><span class="math inline">\((ii)\)</span> Se calculan las (4) distancias promedio de cada elemento del conglomerado principal al resto de elementos del mismo;</li>
<li><span class="math inline">\((iii)\)</span> Se computan las diferencias <span class="math inline">\((i)-(ii)\)</span> para cada uno de los 4 elementos del conglomerado principal;</li>
<li><span class="math inline">\((iv)\)</span> De entre aquéllos elementos del grupo principal en los que <span class="math inline">\((i)-(ii)&lt;0\)</span> se selecciona aquél para el cual es máxima. Tras esta segunda etapa los conglomerados son <span class="math inline">\(\{e_1, e_5\}\)</span> y <span class="math inline">\(\{e_2, e_3, e_4\}\)</span>.</li>
</ul>
<table>
<caption>Distancias entre conglomerados: segunda etapa</caption>
<colgroup>
<col width="24%" />
<col width="26%" />
<col width="24%" />
<col width="24%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Elemento</th>
<th align="center">Distancia promedio al grupo desgajado <span class="math inline">\(\{e_1\}\)</span></th>
<th align="center">Distancia promedio al grupo principal</th>
<th align="center">Diferencia</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\{e_2\}\)</span></td>
<td align="center">8</td>
<td align="center">3</td>
<td align="center">5</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\{e_3\}\)</span></td>
<td align="center">7</td>
<td align="center">3</td>
<td align="center">4</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\{e_4\}\)</span></td>
<td align="center">6</td>
<td align="center">3</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\{e_5\}\)</span></td>
<td align="center">3</td>
<td align="center">4,33</td>
<td align="center">-1,33</td>
</tr>
</tbody>
</table>
<p>En las siguientes etapas se procede de igual manera hasta que todas las diferencias son positivas (en nuestro caso esto ocurre en la tercera etapa; véase Tabla 2.3).</p>
<table>
<caption>Distancias entre conglomerados: tercera etapa</caption>
<colgroup>
<col width="24%" />
<col width="26%" />
<col width="24%" />
<col width="24%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Elemento</th>
<th align="center">Distancia promedio al grupo desgajado <span class="math inline">\(\{e_1,e_5\}\)</span></th>
<th align="center">Distancia promedio al grupo principal</th>
<th align="center">Diferencia</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\{e_2\}\)</span></td>
<td align="center">6</td>
<td align="center">2,5</td>
<td align="center">3,5</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\{e_3\}\)</span></td>
<td align="center">6</td>
<td align="center">4</td>
<td align="center">2</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\{e_4\}\)</span></td>
<td align="center">5</td>
<td align="center">2,5</td>
<td align="center">2,5</td>
</tr>
</tbody>
</table>
<p>Cuando esto ocurre, es decir, cuando todos los elementos del conglomerado principal están más cerca de los demás que lo componen que de los del conglomerado disociado, se vuelve a iniciar el algoritmo, pero esta vez para cada uno de los dos conglomerados generados <span class="citation">(<a href="#ref-macnaughton_et_al1964" role="doc-biblioref">MacNaughton-Smith et al. 1964</a>)</span>. En nuestro caso, en <span class="math inline">\(\{e_1, e_5\}\)</span> la única partición posible es <span class="math inline">\(\{e_1\}\)</span>, <span class="math inline">\(\{e_5\}\)</span>. En <span class="math inline">\(\{e_2, e_3, e_4\}\)</span> se desgaja el elemento con mayor distancia promedio a los demás del grupo. Como <span class="math inline">\(\frac{d_{(2,3)}+ d_{(2,4)}}{2}=2,5\)</span>, <span class="math inline">\(\frac{d_{(3,2)}+ d_{(3,4)}}{2}=4\)</span> y <span class="math inline">\(\frac {d_{(4,2)} + d_{(4,3)}} {2}=2,5\)</span>, se desgaja <span class="math inline">\(\{e_3\}\)</span>.</p>
<p>A continuación se aplica el algoritmo anteriormente expuesto a cada elemento del grupo principal <span class="math inline">\(\{e_2, e_4\}\)</span> y <span class="math inline">\(\{e_3\}\)</span> (Tabla 2.4), y como todas las distancias son positivas, se divide <span class="math inline">\(\{e_2, e_4\}\)</span> en <span class="math inline">\(\{e_2 \}\)</span> y <span class="math inline">\(\{e_4\}\)</span>.</p>
<table>
<caption>Distancia entre conglomerados: etapa final</caption>
<colgroup>
<col width="24%" />
<col width="26%" />
<col width="24%" />
<col width="24%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Elemento</th>
<th align="center">Distancia promedio al grupo desgajado <span class="math inline">\(\{e_3\}\)</span></th>
<th align="center">Distancia promedio al grupo principal</th>
<th align="center">Diferencia</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\{e_2\}\)</span></td>
<td align="center">4</td>
<td align="center">1</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\{e_4\}\)</span></td>
<td align="center">4</td>
<td align="center">1</td>
<td align="center">3</td>
</tr>
</tbody>
</table>
<p>El algoritmo DIvisive ANAlysis (DIANA) permite llevar a cabo la partición anterior utilizando el diámetro de los clusters para decidir el orden de partición clusters cuando se tienen varios con más de un elemento (véase capítulo 6 de <span class="citation">Kaufman and Rousseeuw (<a href="#ref-kauf_1990" role="doc-biblioref">1990</a>)</span>). Proporciona <span class="math inline">\((i\)</span>) el coeficiente divisivo (véase <code>diana.object</code>) que mide la cantidad de estructura de agrupamiento encontrada; y <span class="math inline">\((ii\)</span>) la pancarta, una novedosa presentación gráfica (véase <code>plot.diana</code>).</p>
<p>Para el ejemplo TIC, DIANA proporciona el dendrograma circular de la Fig. <a href="análisis-cluster-clusterización-jerárquica.html#fig:diana">30.6</a></p>
<div class="sourceCode" id="cb379"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb379-1"><a href="análisis-cluster-clusterización-jerárquica.html#cb379-1" aria-hidden="true" tabindex="-1"></a><span class="co"># compute divisive hierarchical clustering</span></span>
<span id="cb379-2"><a href="análisis-cluster-clusterización-jerárquica.html#cb379-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(cluster)</span>
<span id="cb379-3"><a href="análisis-cluster-clusterización-jerárquica.html#cb379-3" aria-hidden="true" tabindex="-1"></a>hc_diana <span class="ot">&lt;-</span> <span class="fu">diana</span>(tic, <span class="at">metric =</span> <span class="st">&quot;euclidea&quot;</span>)</span>
<span id="cb379-4"><a href="análisis-cluster-clusterización-jerárquica.html#cb379-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Divise coefficient. #los valores más cercanos a 1 sugieren una estructura de agrupación fuerte</span></span>
<span id="cb379-5"><a href="análisis-cluster-clusterización-jerárquica.html#cb379-5" aria-hidden="true" tabindex="-1"></a>hc_diana<span class="sc">$</span>dc</span>
<span id="cb379-6"><a href="análisis-cluster-clusterización-jerárquica.html#cb379-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.8043393</span></span>
<span id="cb379-7"><a href="análisis-cluster-clusterización-jerárquica.html#cb379-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb379-8"><a href="análisis-cluster-clusterización-jerárquica.html#cb379-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(factoextra)</span>
<span id="cb379-9"><a href="análisis-cluster-clusterización-jerárquica.html#cb379-9" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_dend</span>(</span>
<span id="cb379-10"><a href="análisis-cluster-clusterización-jerárquica.html#cb379-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> hc_diana,</span>
<span id="cb379-11"><a href="análisis-cluster-clusterización-jerárquica.html#cb379-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">k =</span> <span class="dv">3</span>,</span>
<span id="cb379-12"><a href="análisis-cluster-clusterización-jerárquica.html#cb379-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">&quot;circular&quot;</span>,</span>
<span id="cb379-13"><a href="análisis-cluster-clusterización-jerárquica.html#cb379-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">ggtheme =</span> <span class="fu">theme_minimal</span>()</span>
<span id="cb379-14"><a href="análisis-cluster-clusterización-jerárquica.html#cb379-14" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:diana"></span>
<img src="Ciencia_de_datos_con_r_files/figure-html/diana-1.png" alt="Clusterización jerárquica divisiva con DIANA" width="60%" />
<p class="caption">
Figura 30.6: Clusterización jerárquica divisiva con DIANA
</p>
</div>
<p><strong>Análisis de la asociación</strong></p>
<p>En caso de que los elementos vengan caracterizados por variables cualitativas o factores dicotómicos, <span class="math inline">\(F_1,F_2,..., F_n\)</span> (si alguno fuese politómico, cada una de sus categorías se consideraría como un factor dicotómico), el método del análisis de la asociación (o suma de estadísticos chi-cuadrado) es una técnica monotética muy utilizada que procede como sigue:</p>
<ul>
<li><span class="math inline">\((i)\)</span> Considérese <span class="math inline">\(F_1\)</span> y divídase el conjunto de elementos en dos grupos o categorías: uno con los elementos en los que <span class="math inline">\(F_1\)</span> esté presente y otro con aquellos en los que esté ausente. Hágase lo mismo con los demás factores.</li>
<li><span class="math inline">\((ii)\)</span> Constrúyanse las <span class="math inline">\(n\times(n-1)\)</span> tablas de contingencia <span class="math inline">\(2\times2\)</span> que cruzan cada factor con cada uno de los restantes (véase Capítulo <a href="tablas-contingencia.html#notac">23.1.2</a>).</li>
</ul>
<table>
<tbody>
<tr class="odd">
<td align="right"></td>
<td align="right"></td>
<td align="center">Presencia</td>
<td align="center">Factor <em>j</em></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="right"></td>
<td align="right"></td>
<td align="center">SI</td>
<td align="center">NO</td>
<td align="center"><strong>Total</strong></td>
</tr>
<tr class="odd">
<td align="right">Presencia</td>
<td align="right">SI</td>
<td align="center"><span class="math inline">\(n_{11}\)</span></td>
<td align="center"><span class="math inline">\(n_{21}\)</span></td>
<td align="center"><span class="math inline">\(n_{1\cdot}\)</span></td>
</tr>
<tr class="even">
<td align="right">Factor <em>i</em></td>
<td align="right">NO</td>
<td align="center"><span class="math inline">\(n_{21}\)</span></td>
<td align="center"><span class="math inline">\(n_{22}\)</span></td>
<td align="center"><span class="math inline">\(n_{2\cdot}\)</span></td>
</tr>
<tr class="odd">
<td align="right"></td>
<td align="right"><strong>Total</strong></td>
<td align="center"><span class="math inline">\(n_{\cdot1}\)</span></td>
<td align="center"><span class="math inline">\(n_{\cdot2}\)</span></td>
<td align="center"><strong>n</strong></td>
</tr>
</tbody>
</table>
<p>donde <span class="math inline">\(i\neq j\)</span>.</p>
<ul>
<li><span class="math inline">\((iii)\)</span> Calcúlese el estadístico chi-cuadrado (<span class="math inline">\(\chi_{ij}^2=\frac {n(n_{11}n_{22}-n_{12}n_{21})^2}{n_{1\cdot} n_{2\cdot}n_{\cdot1}n_{\cdot2}}\)</span> para una de dichas tablas (véase Capítulo <a href="tablas-contingencia.html#dise">23.2.5</a> y compútese <span class="math inline">\(\sum_{i\neq j}\chi_{ij}^2\)</span>.</li>
<li><span class="math inline">\((iii)\)</span> Desgájese del conglomerado inicial en dos: uno con los elementos que contienen el factor con la máxima <span class="math inline">\(\sum_{i\neq j}\chi_{ij}^2\)</span>; y otro con el resto de los elementos (donde dicho factor está ausente).</li>
<li><span class="math inline">\((iv)\)</span> Procédase así iterativamente.</li>
</ul>
<!-- Otras alternativas al criterio $\max \sum_{i\neq j}\chi_{ij}^2$ son: $\max \sqrt{\sum_{i\neq j}\chi_{ij}^2}$, $\max\sum_{i\neq j} (n_{11}n_{22}-n_{12}n_{21})^2$ y $\max\sum_{i\neq j} |n_{11}n_{22}-n_{12}n_{21}|$, entre otras. -->
<p><strong>Método del detector automático de interacciones (AID)</strong></p>
<p>No es propiamente un método de AC, sino de la esfera de los modelos lineales de rango no completo. Sin embargo, se menciona, siquiera mínimamente, porque se utiliza en algunas ocasiones con la finalidad combinar categorías de los factores utilizados con la finalidad de generar grupos que difieran lo más posible entre sí respecto de los valores de una variable dependiente medida en una escala métrica (con una escala proporcional o de intervalo) o ficticia (dicotómica con valores 0 y 1).
Específicamente, el AID procede con un ANOVA entre las categorías de la variable independiente, que maximiza la varianza secuencial que se realiza mediante divisiones dicotómicas de la variable dependiente que busca en cada etapa la partición intergrupos y minimiza la varianza intragrupos. La agrupación de categorías se efectúa probando todas las combinaciones binarias posibles de las variables. Se utiliza un test <span class="math inline">\(F\)</span> para seleccionar las mayores diferencias posibles.
En este algoritmo, el proceso de subdivisión del conjunto de elementos en grupos dicotómicos continúa hasta que se verifica algún criterio de parada.</p>
<p>Las limitaciones más importantes del AID son las siguientes:</p>
<ul>
<li>Tiende a seleccionar como más explicativas las variables con mayor número de categorías. Por eso no conviene utilizarlo cuando las variables explicativas difieran mucho en el número de categorías.</li>
<li>Las particiones resultantes dependen de la variable que elegida en primer lugar, condicionando las sucesivas particiones.</li>
<li>Su naturaleza exclusivamente dicotómica también es una limitación importante. Si se llevasen a cabo particiones con tres o más ramas producirían una mayor reducción de la varianza residual y, además, permitirían una mejor selección de otras variables.</li>
</ul>
<p>El AID basado en tablas de contingencia y el estadístico chi-cuadrado (CHAID) corrige la mayoría de estas limitaciones. Aunque inicialmente fue diseñado para variables categóricas, posteriormente se incluyó la posibilidad de trabajar con variables categóricas nominales, categóricas ordinales y variables continuas, permitiendo generar tanto árboles de decisión, para resolver problemas de clasificación, como árboles de regresión. Además, los nodos se pueden dividir en más de dos ramas.</p>
<!-- **GEMA: DIANA** -->
<!-- **diana se describe completamente en el capítulo 6 de Kaufman y Rousseeuw (1990). Probablemente sea único en el cálculo de una jerarquía divisiva, -->
<!-- Además, diana proporciona (a) el coeficiente divisivo (ver diana.object ) que mide la cantidad de estructura de agrupamiento encontrada; y (b) la pancarta, una novedosa presentación gráfica (ver plot.diana ). -->
<!-- El algoritmo diana construye una jerarquía de agrupaciones, comenzando con una agrupación grande que contiene todas las n observaciones. Los grupos se dividen hasta que cada grupo contiene solo una observación. -->
<!-- En cada etapa,se selecciona el clúster con el mayor diámetro.(El diámetro de un clúster es la mayor disimilitud entre dos de sus observaciones). -->
<!-- Para dividir el clúster seleccionado,el algoritmo busca primero su observación más dispar (es decir,la que tiene la mayor disimilitud media con las demás observaciones del clúster seleccionado).Esta observación inicia el "grupo de separación". En los pasos siguientes, el algoritmo reasigna las observaciones que están más cerca del "grupo escindido" que del "grupo antiguo". El resultado es una división del cluster seleccionado en dos nuevos clusters.** -->
</div>
</div>
<div id="calidad-de-la-agrupación-y-número-de-clusters" class="section level2 hasAnchor" number="30.5">
<h2><span class="header-section-number">30.5</span> Calidad de la agrupación y número de clusters<a href="análisis-cluster-clusterización-jerárquica.html#calidad-de-la-agrupación-y-número-de-clusters" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="el-coeficiente-de-correlación-lineal-cofenético" class="section level3 hasAnchor" number="30.5.1">
<h3><span class="header-section-number">30.5.1</span> El coeficiente de correlación lineal cofenético<a href="análisis-cluster-clusterización-jerárquica.html#el-coeficiente-de-correlación-lineal-cofenético" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Dado que las técnicas jerárquicas imponen una estructura sobre los datos y pueden producir distorsiones significativas en las relaciones entre los datos originales, una vez realizada la jerarquización de los elementos objeto de clusterización, surge la siguiente pregunta: ¿en qué medida la estructura final obtenida representa las similitudes o diferencias entre dichos objetos? En otros términos, ¿en qué medida el dendrograma representa la matriz de distancias o similitudes original?</p>
<p>El coeficiente de correlación lineal cofenético da respuesta a dichas preguntas. Se define como el coeficiente de correlación lineal entre los <span class="math inline">\(n(n-1)\)</span> elementos del triangulo superior de la matriz de distancias o similitudes y sus homónimos en la matriz cofenética, <span class="math inline">\(\bf C\)</span>, cuyos elementos <span class="math inline">\(\{c_{ij}\}\)</span> son las distancias o similitudes entre los elementos <span class="math inline">\((i,j)\)</span> tras la aplicación de la técnica de jerarquización. Obviamente, se utilizará la técnica jerárquica que origine el mayor coeficiente.</p>
<p>En el ejemplo TIC, el mayor coeficiente cofenético corresponde al método del promedio o del centroide, si bien la magnitud de los correspondientes a otras técnicas de agregación es bastante parecida.</p>
<div class="sourceCode" id="cb380"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb380-1"><a href="análisis-cluster-clusterización-jerárquica.html#cb380-1" aria-hidden="true" tabindex="-1"></a><span class="co"># comparamos con la distancia euclidea: d_euclidea</span></span>
<span id="cb380-2"><a href="análisis-cluster-clusterización-jerárquica.html#cb380-2" aria-hidden="true" tabindex="-1"></a>cof_simp <span class="ot">&lt;-</span> <span class="fu">cophenetic</span>(hc_simple)</span>
<span id="cb380-3"><a href="análisis-cluster-clusterización-jerárquica.html#cb380-3" aria-hidden="true" tabindex="-1"></a>cof_comp <span class="ot">&lt;-</span> <span class="fu">cophenetic</span>(hc_completo)</span>
<span id="cb380-4"><a href="análisis-cluster-clusterización-jerárquica.html#cb380-4" aria-hidden="true" tabindex="-1"></a>cof_prom <span class="ot">&lt;-</span> <span class="fu">cophenetic</span>(hc_promedio)</span>
<span id="cb380-5"><a href="análisis-cluster-clusterización-jerárquica.html#cb380-5" aria-hidden="true" tabindex="-1"></a>cof_ward <span class="ot">&lt;-</span> <span class="fu">cophenetic</span>(hc_ward)</span>
<span id="cb380-6"><a href="análisis-cluster-clusterización-jerárquica.html#cb380-6" aria-hidden="true" tabindex="-1"></a>cof_dia <span class="ot">&lt;-</span> <span class="fu">cophenetic</span>(hc_diana)</span>
<span id="cb380-7"><a href="análisis-cluster-clusterización-jerárquica.html#cb380-7" aria-hidden="true" tabindex="-1"></a>coef_cofeneticos <span class="ot">&lt;-</span> <span class="fu">cbind</span>(d_euclidea, cof_simp, cof_comp, cof_prom, cof_dia, cof_ward)</span>
<span id="cb380-8"><a href="análisis-cluster-clusterización-jerárquica.html#cb380-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb380-9"><a href="análisis-cluster-clusterización-jerárquica.html#cb380-9" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">cor</span>(coef_cofeneticos)[<span class="dv">1</span>, ], <span class="dv">2</span>)</span>
<span id="cb380-10"><a href="análisis-cluster-clusterización-jerárquica.html#cb380-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; d_euclidea   cof_simp   cof_comp   cof_prom    cof_dia   cof_ward </span></span>
<span id="cb380-11"><a href="análisis-cluster-clusterización-jerárquica.html#cb380-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       1.00       0.71       0.61       0.77       0.65       0.60</span></span></code></pre></div>
</div>
<div id="número-óptimo-de-clusters" class="section level3 hasAnchor" number="30.5.2">
<h3><span class="header-section-number">30.5.2</span> Número óptimo de clusters<a href="análisis-cluster-clusterización-jerárquica.html#número-óptimo-de-clusters" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Acabado el procedimiento de clusterización de los <span class="math inline">\(n\)</span> elementos disponibles, sea por un procedimiento jerárquico aglomerativo o divisivo, hay que tomar una decisión sobre el número de óptimo de clusters. Esta decisión es ardua y requiere un delicado equilibrio. Valores grandes de <span class="math inline">\(k\)</span> pueden mejorar la homogeneidad de los clusters; sin embargo, se corre el riesgo de sobreajuste. Lo contrario ocurre con un <span class="math inline">\(k\)</span> pequeño.</p>
<p>Para tomar esta decisión, además del sentido común y el conocimiento que se tenga del fenómeno en estudio, se puede echar mano de distintos procedimientos heurísticos. El primero se basa en el <strong>dendrograma</strong> y, en concreto, en la representación de las distintas etapas del algoritmo y las distancias a la que se producen las agrupaciones o particiones de los clusters. Para cada distancia, el dendrograma produce un numero determinado de clusters que aumenta (o disminuye) con la misma. Por tanto, el número de clusters dependerá de la distancia a la que se corte el dendrograma (eje de abcisas del dendrograma, height). Dicha distancia debería elegirse de tal forma que los conglomerados estuviesen bien determinados y fuesen interpretables. En las primeras etapas del proceso las distancias no varían mucho, pero en las etapas intermedias y, sobre todo, finales, las distancias aumentan mucho entre dos etapas consecutivas. Por ello, se suele cortar el dendrograma a la distancia a la cual las distancias entre dos etapas consecutivas del proceso empiecen a ser muy grandes, indicador de que los grupos empiezan a ser muy distintos. Otra posibilidad es utilizar el <strong>gráfico de sedimentación</strong> (<a href="acp.html#numcomp">32.4</a>, que relaciona la variablidad entre clusters (eje de ordenadas) con el el número de clusters (eje de abscisas). Normalmente, decrece bruscamente al principio, y posteriormente más despacio, hasta llegar a la parte de sedimentación (el codo del gráfico), donde el decrecimiento es muy lento. Pues bien, el número óptimo de conglomerados es el correspondiente al codo o comienzo del área de sedimentación del gráfico.</p>
<p>El algoritmo del gráfico de sedimentación es como sigue:</p>
<ol style="list-style-type: decimal">
<li>Clusterícese variando el número de grupos, <span class="math inline">\(k\)</span>, por ejemplo, de 1 a 10.</li>
<li>Para cada valor de <span class="math inline">\(k\)</span>, compútese la suma de cuadrados intragrupo (WSS).</li>
<li>Trácese la gráfica de WSS vs. <span class="math inline">\(k\)</span>.</li>
<li>Determínese el número óptimo de grupos.</li>
</ol>
<p>Con conjuntos de datos de tamaño pequeño a moderado, este proceso se puede realizar convenientemente con <code>factoextra::fviz_nbclust()</code>.</p>
<p>Otra opción es el <em>ancho de silueta promedio</em>.El coeficiente o ancho de silueta compara, por cociente, la distancia media a elementos en el mismo grupo con la distancia media a elementos en otros grupos.</p>
<p>Este método calcula el ancho de silueta promedio (avg.sil.wid.) de los elementos objeto de agrupación para diferentes valores de <span class="math inline">\(k\)</span>. Como un valor alto del ancho promedio indica una buena agrupación, el número óptimo de conglomerados es el que lo maximiza. El campo de variación del ancho de silueta es [-1, 1], donde 1 significa que los elementos están muy cerca de su propio clúster y lejos de otros clústeres, mientras que -1 indica que están cerca de los clústeres vecinos.</p>
<!-- El algoritmo es similar al del gráfico de sedimentación: -->
<p><!-- 1.  Realícese la clusterización variando el número de grupos, $k$, por ejemplo, de 1 a 10. -->
<!-- 2.  Para cada $k$, calcúlese: $(i)$ Para cada observación $i$, la disimilitud promedio $a_i$ entre ella y todos los demás elementos del grupo al que pertenece; $(ii)$ la disimilitud promedio $d(i,C_j)$ entre ella y todos los elementos de los conglomerados $C_j$ a los que no pertenece. La menor $d(i,C_j)$ se denota como $b_i$, la disimilitud entre $i$ y su grupo "vecino", es decir, el más cercano al que no pertenece; $(iii)$ Finalmente, compútese el ancho de la silueta de la observación $i$ como $S_i=(b_i - a_i)/max(a_i,b_i)$. -->
<!-- 3. Para cada $k$, compútese el promedio del ancho de silueta (avg.sil.wid.) de los elementos a agrupar. -->
<!-- 4.  Trácese la gráfica de avg.sil vs. $k$. -->
<!-- 5.  Determínese el número óptimo de grupos: aquel que corresponda al máximo de avg.sil.wid. --></p>
<p>El <strong>criterio del Gap (brecha)</strong>, similar al método del codo, tiene como finalidad encontrar la mayor diferencia o distancia que entre los diferentes grupos de elementos que se van formando en el proceso de clusterización y que se representan normalmente en un dendrograma. Se computan las distancias de cada uno de los enlaces que forman el dendrograma y se observa cuál es la mayor de ellas. El máximo del gráfico de estas diferencias vs. el número de clusters indica el número óptimo de clusters.</p>
<div class="sourceCode" id="cb381"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb381-1"><a href="análisis-cluster-clusterización-jerárquica.html#cb381-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot cluster results</span></span>
<span id="cb381-2"><a href="análisis-cluster-clusterización-jerárquica.html#cb381-2" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">fviz_nbclust</span>(tic,</span>
<span id="cb381-3"><a href="análisis-cluster-clusterización-jerárquica.html#cb381-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">FUN =</span> hcut, <span class="at">method =</span> <span class="st">&quot;wss&quot;</span>,</span>
<span id="cb381-4"><a href="análisis-cluster-clusterización-jerárquica.html#cb381-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">k.max =</span> <span class="dv">10</span></span>
<span id="cb381-5"><a href="análisis-cluster-clusterización-jerárquica.html#cb381-5" aria-hidden="true" tabindex="-1"></a>) <span class="sc">+</span></span>
<span id="cb381-6"><a href="análisis-cluster-clusterización-jerárquica.html#cb381-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Elbow&quot;</span>)</span>
<span id="cb381-7"><a href="análisis-cluster-clusterización-jerárquica.html#cb381-7" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">fviz_nbclust</span>(tic,</span>
<span id="cb381-8"><a href="análisis-cluster-clusterización-jerárquica.html#cb381-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">FUN =</span> hcut, <span class="at">method =</span> <span class="st">&quot;silhouette&quot;</span>,</span>
<span id="cb381-9"><a href="análisis-cluster-clusterización-jerárquica.html#cb381-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">k.max =</span> <span class="dv">10</span></span>
<span id="cb381-10"><a href="análisis-cluster-clusterización-jerárquica.html#cb381-10" aria-hidden="true" tabindex="-1"></a>) <span class="sc">+</span></span>
<span id="cb381-11"><a href="análisis-cluster-clusterización-jerárquica.html#cb381-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Silhouette&quot;</span>)</span>
<span id="cb381-12"><a href="análisis-cluster-clusterización-jerárquica.html#cb381-12" aria-hidden="true" tabindex="-1"></a>p3 <span class="ot">&lt;-</span> <span class="fu">fviz_nbclust</span>(tic,</span>
<span id="cb381-13"><a href="análisis-cluster-clusterización-jerárquica.html#cb381-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">FUN =</span> hcut, <span class="at">method =</span> <span class="st">&quot;gap_stat&quot;</span>,</span>
<span id="cb381-14"><a href="análisis-cluster-clusterización-jerárquica.html#cb381-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">k.max =</span> <span class="dv">10</span></span>
<span id="cb381-15"><a href="análisis-cluster-clusterización-jerárquica.html#cb381-15" aria-hidden="true" tabindex="-1"></a>) <span class="sc">+</span></span>
<span id="cb381-16"><a href="análisis-cluster-clusterización-jerárquica.html#cb381-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Gap&quot;</span>)</span>
<span id="cb381-17"><a href="análisis-cluster-clusterización-jerárquica.html#cb381-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb381-18"><a href="análisis-cluster-clusterización-jerárquica.html#cb381-18" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb381-19"><a href="análisis-cluster-clusterización-jerárquica.html#cb381-19" aria-hidden="true" tabindex="-1"></a>p1 <span class="sc">+</span> p2 <span class="sc">+</span> p3</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:plot-kresults-hc"></span>
<img src="Ciencia_de_datos_con_r_files/figure-html/plot-kresults-hc-1.png" alt="Métodos heurísticos para la determinación del número óptimo de clusters" width="60%" />
<p class="caption">
Figura 30.7: Métodos heurísticos para la determinación del número óptimo de clusters
</p>
</div>
<p>Finalmente, el <strong>índice de Dunn</strong> es el cociente entre la mínima distancia intergrupos y la máxima distancia intragrupos. A mayor índice, mayor calidad de clusterización.</p>
<div class="sourceCode" id="cb382"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb382-1"><a href="análisis-cluster-clusterización-jerárquica.html#cb382-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(clValid)</span>
<span id="cb382-2"><a href="análisis-cluster-clusterización-jerárquica.html#cb382-2" aria-hidden="true" tabindex="-1"></a>cut2_hc_prom <span class="ot">&lt;-</span> <span class="fu">cutree</span>(hc_promedio, <span class="at">k =</span> <span class="dv">2</span>)</span>
<span id="cb382-3"><a href="análisis-cluster-clusterización-jerárquica.html#cb382-3" aria-hidden="true" tabindex="-1"></a>cut3_hc_prom <span class="ot">&lt;-</span> <span class="fu">cutree</span>(hc_promedio, <span class="at">k =</span> <span class="dv">3</span>)</span>
<span id="cb382-4"><a href="análisis-cluster-clusterización-jerárquica.html#cb382-4" aria-hidden="true" tabindex="-1"></a>cut4_hc_prom <span class="ot">&lt;-</span> <span class="fu">cutree</span>(hc_promedio, <span class="at">k =</span> <span class="dv">4</span>)</span>
<span id="cb382-5"><a href="análisis-cluster-clusterización-jerárquica.html#cb382-5" aria-hidden="true" tabindex="-1"></a>cut5_hc_prom <span class="ot">&lt;-</span> <span class="fu">cutree</span>(hc_promedio, <span class="at">k =</span> <span class="dv">5</span>)</span>
<span id="cb382-6"><a href="análisis-cluster-clusterización-jerárquica.html#cb382-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb382-7"><a href="análisis-cluster-clusterización-jerárquica.html#cb382-7" aria-hidden="true" tabindex="-1"></a><span class="fu">dunn</span>(d_euclidea, cut2_hc_prom)</span>
<span id="cb382-8"><a href="análisis-cluster-clusterización-jerárquica.html#cb382-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.4465593</span></span>
<span id="cb382-9"><a href="análisis-cluster-clusterización-jerárquica.html#cb382-9" aria-hidden="true" tabindex="-1"></a><span class="fu">dunn</span>(d_euclidea, cut3_hc_prom)</span>
<span id="cb382-10"><a href="análisis-cluster-clusterización-jerárquica.html#cb382-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.3751942</span></span>
<span id="cb382-11"><a href="análisis-cluster-clusterización-jerárquica.html#cb382-11" aria-hidden="true" tabindex="-1"></a><span class="fu">dunn</span>(d_euclidea, cut4_hc_prom)</span>
<span id="cb382-12"><a href="análisis-cluster-clusterización-jerárquica.html#cb382-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.4074884</span></span>
<span id="cb382-13"><a href="análisis-cluster-clusterización-jerárquica.html#cb382-13" aria-hidden="true" tabindex="-1"></a><span class="fu">dunn</span>(d_euclidea, cut5_hc_prom)</span>
<span id="cb382-14"><a href="análisis-cluster-clusterización-jerárquica.html#cb382-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.4366356</span></span></code></pre></div>
=======
<meta name="date" content="2022-12-15" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="cap-boosting-xgboost.html"/>
<link rel="next" href="no-jerarquico.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<script src="libs/htmlwidgets-1.5.4/htmlwidgets.js"></script>
<link href="libs/wordcloud2-0.0.1/wordcloud.css" rel="stylesheet" />
<script src="libs/wordcloud2-0.0.1/wordcloud2-all.js"></script>
<script src="libs/wordcloud2-0.0.1/hover.js"></script>
<script src="libs/wordcloud2-binding-0.2.1/wordcloud2.js"></script>
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-33KQ1S5ZCJ"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-33KQ1S5ZCJ');
</script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./"> Ciencia de datos con <strong>R</strong></a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html"><i class="fa fa-check"></i>Prefacio</a>
<ul>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html#los-autores"><i class="fa fa-check"></i>Los autores</a></li>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html#por-qué-este-libro"><i class="fa fa-check"></i>¿Por qué este libro?</a></li>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html#características"><i class="fa fa-check"></i>Características</a></li>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html#el-paquete-cdr"><i class="fa fa-check"></i>El paquete <code>CDR</code></a></li>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html#a-quién-va-dirigido"><i class="fa fa-check"></i>¿A quién va dirigido?</a></li>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html#agradecimientos"><i class="fa fa-check"></i>Agradecimientos</a></li>
<li class="chapter" data-level="" data-path="prefacio.html"><a href="prefacio.html#información-del-software"><i class="fa fa-check"></i>Información del software</a></li>
</ul></li>
<li class="part"><span><b>I Introducción</b></span></li>
<li class="chapter" data-level="1" data-path="ciencia-datos.html"><a href="ciencia-datos.html"><i class="fa fa-check"></i><b>1</b> ¿Es la Ciencia de datos una Ciencia?</a>
<ul>
<li class="chapter" data-level="1.1" data-path="ciencia-datos.html"><a href="ciencia-datos.html#ciencia"><i class="fa fa-check"></i><b>1.1</b> ¿Qué se entiende por Ciencia?</a></li>
<li class="chapter" data-level="1.2" data-path="ciencia-datos.html"><a href="ciencia-datos.html#qué-es-la-ciencia-de-datos"><i class="fa fa-check"></i><b>1.2</b> ¿Qué es la Ciencia de Datos?</a></li>
<li class="chapter" data-level="1.3" data-path="ciencia-datos.html"><a href="ciencia-datos.html#lo-científico-de-la-ciencia-de-datos"><i class="fa fa-check"></i><b>1.3</b> Lo científico de la Ciencia de datos</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="metodología.html"><a href="metodología.html"><i class="fa fa-check"></i><b>2</b> Metodología para la Ciencia de datos</a>
<ul>
<li class="chapter" data-level="2.1" data-path="metodología.html"><a href="metodología.html#preliminares"><i class="fa fa-check"></i><b>2.1</b> Preliminares</a></li>
<li class="chapter" data-level="2.2" data-path="metodología.html"><a href="metodología.html#principales-metodologías-en-ciencia-de-datos"><i class="fa fa-check"></i><b>2.2</b> Principales metodologías en Ciencia de datos</a></li>
<li class="chapter" data-level="2.3" data-path="metodología.html"><a href="metodología.html#met-crisp-dm"><i class="fa fa-check"></i><b>2.3</b> CRISP-DM para Ciencia de datos</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="ch-110003.html"><a href="ch-110003.html"><i class="fa fa-check"></i><b>3</b> R para ciencia de datos</a>
<ul>
<li class="chapter" data-level="3.1" data-path="ch-110003.html"><a href="ch-110003.html#introducción"><i class="fa fa-check"></i><b>3.1</b> Introducción</a></li>
<li class="chapter" data-level="3.2" data-path="ch-110003.html"><a href="ch-110003.html#id_110003-bases"><i class="fa fa-check"></i><b>3.2</b> La sesión de <strong>R</strong></a></li>
<li class="chapter" data-level="3.3" data-path="ch-110003.html"><a href="ch-110003.html#instalación-de-r"><i class="fa fa-check"></i><b>3.3</b> Instalación de <strong>R</strong></a></li>
<li class="chapter" data-level="3.4" data-path="ch-110003.html"><a href="ch-110003.html#id_110003-proyectos"><i class="fa fa-check"></i><b>3.4</b> Trabajar con proyectos de RStudio</a></li>
<li class="chapter" data-level="3.5" data-path="ch-110003.html"><a href="ch-110003.html#tratamiento-de-datos-con-r"><i class="fa fa-check"></i><b>3.5</b> Tratamiento de datos con <strong>R</strong></a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="ch-110003.html"><a href="ch-110003.html#id_110003-estructuras"><i class="fa fa-check"></i><b>3.5.1</b> Estructuras y tipos de datos</a></li>
<li class="chapter" data-level="3.5.2" data-path="ch-110003.html"><a href="ch-110003.html#id_110003-importacion"><i class="fa fa-check"></i><b>3.5.2</b> Importación de datos</a></li>
<li class="chapter" data-level="3.5.3" data-path="ch-110003.html"><a href="ch-110003.html#exportación-y-archivos-de-datos-de-r"><i class="fa fa-check"></i><b>3.5.3</b> Exportación y archivos de datos de R</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="ch-110003.html"><a href="ch-110003.html#id_110003-tidyverse"><i class="fa fa-check"></i><b>3.6</b> Organización de datos con el <em>tidyverse</em></a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="ch-110003.html"><a href="ch-110003.html#el-tidyverse-y-su-flujo-de-trabajo"><i class="fa fa-check"></i><b>3.6.1</b> El <em>tidyverse</em> y su flujo de trabajo</a></li>
<li class="chapter" data-level="3.6.2" data-path="ch-110003.html"><a href="ch-110003.html#transformación-de-datos-con-dplyr"><i class="fa fa-check"></i><b>3.6.2</b> Transformación de datos con <code>dplyr</code></a></li>
<li class="chapter" data-level="3.6.3" data-path="ch-110003.html"><a href="ch-110003.html#combinación-de-datos"><i class="fa fa-check"></i><b>3.6.3</b> Combinación de datos</a></li>
<li class="chapter" data-level="3.6.4" data-path="ch-110003.html"><a href="ch-110003.html#reorganización-de-datos"><i class="fa fa-check"></i><b>3.6.4</b> Reorganización de datos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="cap-etica.html"><a href="cap-etica.html"><i class="fa fa-check"></i><b>4</b> La ciencia de datos y la ética</a>
<ul>
<li class="chapter" data-level="4.1" data-path="cap-etica.html"><a href="cap-etica.html#por-que-la-ética-en-la-ciencia-de-datos"><i class="fa fa-check"></i><b>4.1</b> ¿Por que la ética en la ciencia de datos?</a></li>
<li class="chapter" data-level="4.2" data-path="cap-etica.html"><a href="cap-etica.html#los-principios-éticos"><i class="fa fa-check"></i><b>4.2</b> Los principios éticos</a></li>
<li class="chapter" data-level="4.3" data-path="cap-etica.html"><a href="cap-etica.html#la-importancia-de-los-sesgos"><i class="fa fa-check"></i><b>4.3</b> La importancia de los sesgos</a></li>
<li class="chapter" data-level="4.4" data-path="cap-etica.html"><a href="cap-etica.html#es-necesaria-la-explicabilidad"><i class="fa fa-check"></i><b>4.4</b> ¿Es necesaria la explicabilidad?</a></li>
<li class="chapter" data-level="4.5" data-path="cap-etica.html"><a href="cap-etica.html#recursos-en-r-parar-trabajar-en-sesgos-y-explicabilidad"><i class="fa fa-check"></i><b>4.5</b> Recursos en R parar trabajar en sesgos y explicabilidad</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="datos-sql.html"><a href="datos-sql.html"><i class="fa fa-check"></i><b>5</b> Gestión y operación de datos con bases de datos relacionales</a>
<ul>
<li class="chapter" data-level="5.1" data-path="datos-sql.html"><a href="datos-sql.html#introducción-1"><i class="fa fa-check"></i><b>5.1</b> Introducción</a></li>
<li class="chapter" data-level="5.2" data-path="datos-sql.html"><a href="datos-sql.html#concepto-de-base-de-datos"><i class="fa fa-check"></i><b>5.2</b> Concepto de Base de datos</a>
<ul>
<li class="chapter" data-level="5.2.1" data-path="datos-sql.html"><a href="datos-sql.html#gestión-de-los-datos-en-una-base-o-repositorio-de-datos"><i class="fa fa-check"></i><b>5.2.1</b> Gestión de los datos en una base o repositorio de datos</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="datos-sql.html"><a href="datos-sql.html#el-lenguaje-estructurado-de-consulta-sql"><i class="fa fa-check"></i><b>5.3</b> El Lenguaje Estructurado de Consulta (SQL)</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="datos-sql.html"><a href="datos-sql.html#sql-como-lenguaje-de-definición-de-datos-ldd"><i class="fa fa-check"></i><b>5.3.1</b> SQL como Lenguaje de Definición de Datos (LDD)</a></li>
<li class="chapter" data-level="5.3.2" data-path="datos-sql.html"><a href="datos-sql.html#sql-como-lenguaje-de-manipulación-de-datos-lmd"><i class="fa fa-check"></i><b>5.3.2</b> SQL como Lenguaje de Manipulación de Datos (LMD)</a></li>
<li class="chapter" data-level="5.3.3" data-path="datos-sql.html"><a href="datos-sql.html#sql-como-lenguaje-de-administración-de-datos-lad"><i class="fa fa-check"></i><b>5.3.3</b> SQL como Lenguaje de Administración de Datos (LAD)</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="datos-sql.html"><a href="datos-sql.html#usando-bases-de-datos-desde-r"><i class="fa fa-check"></i><b>5.4</b> Usando bases de datos desde R</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="datos-sql.html"><a href="datos-sql.html#conexión-a-una-base-de-datos"><i class="fa fa-check"></i><b>5.4.1</b> Conexión a una base de datos</a></li>
<li class="chapter" data-level="5.4.2" data-path="datos-sql.html"><a href="datos-sql.html#operaciones-de-lectura-selección-read-de-datos"><i class="fa fa-check"></i><b>5.4.2</b> Operaciones de lectura / selección (<em>read</em>) de datos</a></li>
<li class="chapter" data-level="5.4.3" data-path="datos-sql.html"><a href="datos-sql.html#operaciones-de-inserción-create-y-actualización-update-de-datos"><i class="fa fa-check"></i><b>5.4.3</b> Operaciones de inserción (<em>create</em>) y actualización (<em>update</em>) de datos</a></li>
<li class="chapter" data-level="5.4.4" data-path="datos-sql.html"><a href="datos-sql.html#operaciones-de-borrado-de-datos-delete"><i class="fa fa-check"></i><b>5.4.4</b> Operaciones de Borrado de datos (<em>delete</em>)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="datos-no-sql.html"><a href="datos-no-sql.html"><i class="fa fa-check"></i><b>6</b> Gestión y operación de datos masivos (BigData) con bases de datos NoSQL</a>
<ul>
<li class="chapter" data-level="6.1" data-path="datos-no-sql.html"><a href="datos-no-sql.html#introducción-al-big-data"><i class="fa fa-check"></i><b>6.1</b> Introducción al Big Data</a></li>
<li class="chapter" data-level="6.2" data-path="datos-no-sql.html"><a href="datos-no-sql.html#VsBigData"><i class="fa fa-check"></i><b>6.2</b> Las V’s del Big Data</a></li>
<li class="chapter" data-level="6.3" data-path="datos-no-sql.html"><a href="datos-no-sql.html#fuentes-de-datos-en-entornos-big-data"><i class="fa fa-check"></i><b>6.3</b> Fuentes de Datos en entornos Big Data</a></li>
<li class="chapter" data-level="6.4" data-path="datos-no-sql.html"><a href="datos-no-sql.html#bases-de-datos-relacionales-vs.-nosql"><i class="fa fa-check"></i><b>6.4</b> Bases de datos Relacionales vs. NoSQL</a></li>
<li class="chapter" data-level="6.5" data-path="datos-no-sql.html"><a href="datos-no-sql.html#bases-de-datos-nosql"><i class="fa fa-check"></i><b>6.5</b> Bases de datos NoSQL</a>
<ul>
<li class="chapter" data-level="6.5.1" data-path="datos-no-sql.html"><a href="datos-no-sql.html#definición-de-bases-de-datos-nosql"><i class="fa fa-check"></i><b>6.5.1</b> Definición de bases de datos NoSQL</a></li>
<li class="chapter" data-level="6.5.2" data-path="datos-no-sql.html"><a href="datos-no-sql.html#necesidades-no-cubiertas-por-las-bases-de-datos-relacionales"><i class="fa fa-check"></i><b>6.5.2</b> Necesidades no cubiertas por las bases de datos relacionales</a></li>
<li class="chapter" data-level="6.5.3" data-path="datos-no-sql.html"><a href="datos-no-sql.html#tipos-de-almacenamiento-en-bases-de-datos-nosql"><i class="fa fa-check"></i><b>6.5.3</b> Tipos de almacenamiento en bases de datos NoSQL</a></li>
<li class="chapter" data-level="6.5.4" data-path="datos-no-sql.html"><a href="datos-no-sql.html#limitaciones-de-las-bases-de-datos-nosql"><i class="fa fa-check"></i><b>6.5.4</b> Limitaciones de las bases de datos NoSQL</a></li>
</ul></li>
<li class="chapter" data-level="6.6" data-path="datos-no-sql.html"><a href="datos-no-sql.html#ejemplo-de-integración-de-una-base-de-datos-nosql-y-análisis-de-datos-en-r"><i class="fa fa-check"></i><b>6.6</b> Ejemplo de integración de una base de datos NoSQL y análisis de datos en R</a>
<ul>
<li class="chapter" data-level="6.6.1" data-path="datos-no-sql.html"><a href="datos-no-sql.html#introMongo"><i class="fa fa-check"></i><b>6.6.1</b> Introducción a MongoDB</a></li>
<li class="chapter" data-level="6.6.2" data-path="datos-no-sql.html"><a href="datos-no-sql.html#paquetesCaso"><i class="fa fa-check"></i><b>6.6.2</b> Plataforma tecnológica para el caso práctico</a></li>
<li class="chapter" data-level="6.6.3" data-path="datos-no-sql.html"><a href="datos-no-sql.html#conexionMongo"><i class="fa fa-check"></i><b>6.6.3</b> Conexión y acceso a MongoDB desde R</a></li>
<li class="chapter" data-level="6.6.4" data-path="datos-no-sql.html"><a href="datos-no-sql.html#consultaViajes"><i class="fa fa-check"></i><b>6.6.4</b> Obtención de datos en R desde MongoDB</a></li>
<li class="chapter" data-level="6.6.5" data-path="datos-no-sql.html"><a href="datos-no-sql.html#analisisViajes"><i class="fa fa-check"></i><b>6.6.5</b> Analizando datos de MongoDB en R</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>II Manipulación de datos con R. Técnicas y herramientas</b></span></li>
<li class="chapter" data-level="7" data-path="id_120006-aed.html"><a href="id_120006-aed.html"><i class="fa fa-check"></i><b>7</b> Análisis exploratorio de datos</a>
<ul>
<li class="chapter" data-level="7.1" data-path="id_120006-aed.html"><a href="id_120006-aed.html#introducción-2"><i class="fa fa-check"></i><b>7.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="7.1.1" data-path="id_120006-aed.html"><a href="id_120006-aed.html#el-cuarterto-de-anscombe"><i class="fa fa-check"></i><b>7.1.1</b> El cuarterto de Anscombe</a></li>
<li class="chapter" data-level="7.1.2" data-path="id_120006-aed.html"><a href="id_120006-aed.html#conceptos-generales"><i class="fa fa-check"></i><b>7.1.2</b> Conceptos generales</a></li>
<li class="chapter" data-level="7.1.3" data-path="id_120006-aed.html"><a href="id_120006-aed.html#componentes-de-un-gráfico-y-su-representación-en-r"><i class="fa fa-check"></i><b>7.1.3</b> Componentes de un gráfico y su representación en R</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="id_120006-aed.html"><a href="id_120006-aed.html#id_120006-aeduni"><i class="fa fa-check"></i><b>7.2</b> Análisis exploratorio de una característica</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="id_120006-aed.html"><a href="id_120006-aed.html#variables-cualitativas"><i class="fa fa-check"></i><b>7.2.1</b> Variables cualitativas</a></li>
<li class="chapter" data-level="7.2.2" data-path="id_120006-aed.html"><a href="id_120006-aed.html#variables-cuantitativas"><i class="fa fa-check"></i><b>7.2.2</b> Variables cuantitativas</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="id_120006-aed.html"><a href="id_120006-aed.html#id_120006-aedmulti"><i class="fa fa-check"></i><b>7.3</b> Análisis exploratorio de varias características</a>
<ul>
<li class="chapter" data-level="7.3.1" data-path="id_120006-aed.html"><a href="id_120006-aed.html#variables-cualitativas-1"><i class="fa fa-check"></i><b>7.3.1</b> Variables cualitativas</a></li>
<li class="chapter" data-level="7.3.2" data-path="id_120006-aed.html"><a href="id_120006-aed.html#variables-cuantitativas-1"><i class="fa fa-check"></i><b>7.3.2</b> Variables cuantitativas</a></li>
<li class="chapter" data-level="7.3.3" data-path="id_120006-aed.html"><a href="id_120006-aed.html#variables-cualitativas-y-cuantitativas"><i class="fa fa-check"></i><b>7.3.3</b> Variables cualitativas y cuantitativas</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="8" data-path="DGDQM.html"><a href="DGDQM.html"><i class="fa fa-check"></i><b>8</b> Gobierno y gestión de calidad de Datos</a>
<ul>
<li class="chapter" data-level="8.1" data-path="DGDQM.html"><a href="DGDQM.html#introducción-3"><i class="fa fa-check"></i><b>8.1</b> Introducción</a></li>
<li class="chapter" data-level="8.2" data-path="DGDQM.html"><a href="DGDQM.html#concepto-de-gobierno-de-datos"><i class="fa fa-check"></i><b>8.2</b> Concepto de Gobierno de datos</a>
<ul>
<li class="chapter" data-level="8.2.1" data-path="DGDQM.html"><a href="DGDQM.html#beneficiosDG"><i class="fa fa-check"></i><b>8.2.1</b> Beneficios del Gobierno de Datos</a></li>
<li class="chapter" data-level="8.2.2" data-path="DGDQM.html"><a href="DGDQM.html#artefactosDG"><i class="fa fa-check"></i><b>8.2.2</b> Artefactos de un sistema de Gobierno de Datos</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="DGDQM.html"><a href="DGDQM.html#marcos-y-metodologías-existentes-de-gobierno-de-datos"><i class="fa fa-check"></i><b>8.3</b> Marcos y metodologías existentes de Gobierno de Datos</a>
<ul>
<li class="chapter" data-level="8.3.1" data-path="DGDQM.html"><a href="DGDQM.html#modelo-alarcos-de-mejora-de-datos-mamd"><i class="fa fa-check"></i><b>8.3.1</b> Modelo Alarcos de Mejora de Datos (MAMD)</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="DGDQM.html"><a href="DGDQM.html#gestión-de-calidad-de-datos"><i class="fa fa-check"></i><b>8.4</b> Gestión de calidad de datos</a>
<ul>
<li class="chapter" data-level="8.4.1" data-path="DGDQM.html"><a href="DGDQM.html#medición-de-calidad-de-datos-vs-perfilado-de-datos"><i class="fa fa-check"></i><b>8.4.1</b> Medición de calidad de datos vs perfilado de datos</a></li>
<li class="chapter" data-level="8.4.2" data-path="DGDQM.html"><a href="DGDQM.html#mejora-de-datos"><i class="fa fa-check"></i><b>8.4.2</b> Mejora de datos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="id_130009.html"><a href="id_130009.html"><i class="fa fa-check"></i><b>9</b> Integración y limpieza de datos</a>
<ul>
<li class="chapter" data-level="9.1" data-path="id_130009.html"><a href="id_130009.html#introducción-4"><i class="fa fa-check"></i><b>9.1</b> Introducción</a></li>
<li class="chapter" data-level="9.2" data-path="id_130009.html"><a href="id_130009.html#problemas-de-calidad-de-datos"><i class="fa fa-check"></i><b>9.2</b> Problemas de calidad de datos</a></li>
<li class="chapter" data-level="9.3" data-path="id_130009.html"><a href="id_130009.html#niveles-inadecuados-de-completitud-valores-missing"><i class="fa fa-check"></i><b>9.3</b> Niveles inadecuados de completitud: Valores <em>missing</em></a>
<ul>
<li class="chapter" data-level="9.3.1" data-path="id_130009.html"><a href="id_130009.html#visualización"><i class="fa fa-check"></i><b>9.3.1</b> Visualización</a></li>
<li class="chapter" data-level="9.3.2" data-path="id_130009.html"><a href="id_130009.html#imputacion"><i class="fa fa-check"></i><b>9.3.2</b> Técnicas de Imputación</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="id_130009.html"><a href="id_130009.html#mejorando-la-exactitud-y-la-precisión-eliminación-del-ruido-estadístico"><i class="fa fa-check"></i><b>9.4</b> Mejorando la exactitud y la precisión: eliminación del ruido estadístico</a></li>
<li class="chapter" data-level="9.5" data-path="id_130009.html"><a href="id_130009.html#integración-de-datos"><i class="fa fa-check"></i><b>9.5</b> Integración de datos </a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="id_130010.html"><a href="id_130010.html"><i class="fa fa-check"></i><b>10</b> Feature Selection and Engineering</a>
<ul>
<li class="chapter" data-level="10.1" data-path="id_130010.html"><a href="id_130010.html#introducción-5"><i class="fa fa-check"></i><b>10.1</b> Introducción</a></li>
<li class="chapter" data-level="10.2" data-path="id_130010.html"><a href="id_130010.html#feature-selection-selección-de-variables"><i class="fa fa-check"></i><b>10.2</b> <em>Feature Selection</em> (Selección de variables)</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="id_130010.html"><a href="id_130010.html#métodos-de-selección-tipo-filtro"><i class="fa fa-check"></i><b>10.2.1</b> Métodos de selección tipo Filtro</a></li>
<li class="chapter" data-level="10.2.2" data-path="id_130010.html"><a href="id_130010.html#métodos-de-selección-de-variables-tipo-wrapper"><i class="fa fa-check"></i><b>10.2.2</b> Métodos de selección de variables tipo <em>wrapper</em></a></li>
<li class="chapter" data-level="10.2.3" data-path="id_130010.html"><a href="id_130010.html#métodos-de-selección-tipo-embedded"><i class="fa fa-check"></i><b>10.2.3</b> Métodos de selección tipo Embedded </a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="id_130010.html"><a href="id_130010.html#transformaciones-de-escala-y-de-la-distribución-de-la-variable-objetivo"><i class="fa fa-check"></i><b>10.3</b> Transformaciones de escala y de la distribución de la variable objetivo</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="id_130010.html"><a href="id_130010.html#id_31"><i class="fa fa-check"></i><b>10.3.1</b> Transformaciones de la variable objetivo</a></li>
<li class="chapter" data-level="10.3.2" data-path="id_130010.html"><a href="id_130010.html#escalado-de-datos"><i class="fa fa-check"></i><b>10.3.2</b> Escalado de datos</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="id_130010.html"><a href="id_130010.html#feature-engineering"><i class="fa fa-check"></i><b>10.4</b> <em>Feature engineering</em></a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="id_130010.html"><a href="id_130010.html#binning"><i class="fa fa-check"></i><b>10.4.1</b> <em>Binning</em> </a></li>
<li class="chapter" data-level="10.4.2" data-path="id_130010.html"><a href="id_130010.html#codificación"><i class="fa fa-check"></i><b>10.4.2</b> Codificación </a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="id_130010.html"><a href="id_130010.html#reducción-de-dimensionalidad"><i class="fa fa-check"></i><b>10.5</b> Reducción de dimensionalidad</a></li>
<li class="chapter" data-level="10.6" data-path="id_130010.html"><a href="id_130010.html#otras-transformaciones"><i class="fa fa-check"></i><b>10.6</b> Otras transformaciones</a>
<ul>
<li class="chapter" data-level="10.6.1" data-path="id_130010.html"><a href="id_130010.html#particionado-de-datos"><i class="fa fa-check"></i><b>10.6.1</b> Particionado de datos </a></li>
<li class="chapter" data-level="10.6.2" data-path="id_130010.html"><a href="id_130010.html#técnicas-para-manejar-datos-no-balanceados"><i class="fa fa-check"></i><b>10.6.2</b> Técnicas para manejar datos no balanceados </a></li>
<li class="chapter" data-level="10.6.3" data-path="id_130010.html"><a href="id_130010.html#métodos-de-remuestreo"><i class="fa fa-check"></i><b>10.6.3</b> Métodos de remuestreo </a></li>
<li class="chapter" data-level="10.6.4" data-path="id_130010.html"><a href="id_130010.html#ajuste-de-hiperparámetros"><i class="fa fa-check"></i><b>10.6.4</b> Ajuste de hiperparámetros</a></li>
<li class="chapter" data-level="10.6.5" data-path="id_130010.html"><a href="id_130010.html#evaluación-de-modelos"><i class="fa fa-check"></i><b>10.6.5</b> Evaluación de modelos</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>III Modelización estadística</b></span></li>
<li class="chapter" data-level="11" data-path="Funda-probab.html"><a href="Funda-probab.html"><i class="fa fa-check"></i><b>11</b> Fundamentos de probabilidad</a>
<ul>
<li class="chapter" data-level="11.1" data-path="Funda-probab.html"><a href="Funda-probab.html#introducción-a-la-probabilidad"><i class="fa fa-check"></i><b>11.1</b> Introducción a la probabilidad</a></li>
<li class="chapter" data-level="11.2" data-path="Funda-probab.html"><a href="Funda-probab.html#probabilidad-elementos-básicos-definición-y-teoremas"><i class="fa fa-check"></i><b>11.2</b> Probabilidad: elementos básicos, definición y teoremas</a></li>
<li class="chapter" data-level="11.3" data-path="Funda-probab.html"><a href="Funda-probab.html#variable-aleatoria-y-su-distribución-tipos-de-variables-aleatorias"><i class="fa fa-check"></i><b>11.3</b> Variable aleatoria y su distribución: tipos de variables aleatorias</a></li>
<li class="chapter" data-level="11.4" data-path="Funda-probab.html"><a href="Funda-probab.html#modelos-de-distribución-de-probabilidad"><i class="fa fa-check"></i><b>11.4</b> Modelos de distribución de probabilidad</a>
<ul>
<li class="chapter" data-level="11.4.1" data-path="Funda-probab.html"><a href="Funda-probab.html#modelos-discretos"><i class="fa fa-check"></i><b>11.4.1</b> Modelos discretos</a></li>
<li class="chapter" data-level="11.4.2" data-path="Funda-probab.html"><a href="Funda-probab.html#modelos-continuos"><i class="fa fa-check"></i><b>11.4.2</b> Modelos continuos</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="Funda-probab.html"><a href="Funda-probab.html#tcl"><i class="fa fa-check"></i><b>11.5</b> Teorema central del límite (TCL)</a></li>
<li class="chapter" data-level="11.6" data-path="Funda-probab.html"><a href="Funda-probab.html#ejemplo-de-distribuciones-usando-r"><i class="fa fa-check"></i><b>11.6</b> Ejemplo de distribuciones usando <strong>R</strong></a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="Fundainfer.html"><a href="Fundainfer.html"><i class="fa fa-check"></i><b>12</b> Fundamentos de Inferencia Estadística</a>
<ul>
<li class="chapter" data-level="12.1" data-path="Fundainfer.html"><a href="Fundainfer.html#introinfer"><i class="fa fa-check"></i><b>12.1</b> Introducción a la Inferencia Estadística</a></li>
<li class="chapter" data-level="12.2" data-path="Fundainfer.html"><a href="Fundainfer.html#mas"><i class="fa fa-check"></i><b>12.2</b> Muestreo aleatorio simple</a></li>
<li class="chapter" data-level="12.3" data-path="Fundainfer.html"><a href="Fundainfer.html#estimpuntual"><i class="fa fa-check"></i><b>12.3</b> Estimación puntual</a></li>
<li class="chapter" data-level="12.4" data-path="Fundainfer.html"><a href="Fundainfer.html#estimintervalos"><i class="fa fa-check"></i><b>12.4</b> Estimación por intervalos</a></li>
<li class="chapter" data-level="12.5" data-path="Fundainfer.html"><a href="Fundainfer.html#contrhip"><i class="fa fa-check"></i><b>12.5</b> Contrastes de hipótesis</a></li>
<li class="chapter" data-level="12.6" data-path="Fundainfer.html"><a href="Fundainfer.html#pobnormales"><i class="fa fa-check"></i><b>12.6</b> Inferencia estadística paramétrica sobre poblaciones normales</a></li>
<li class="chapter" data-level="12.7" data-path="Fundainfer.html"><a href="Fundainfer.html#ejemplopobnorm"><i class="fa fa-check"></i><b>12.7</b> Inferencia sobre poblaciones normales con <strong>R</strong></a></li>
<li class="chapter" data-level="12.8" data-path="Fundainfer.html"><a href="Fundainfer.html#contrnormalidad"><i class="fa fa-check"></i><b>12.8</b> Inferencia estadística no paramétrica: contrastes de normalidad</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="muestreo.html"><a href="muestreo.html"><i class="fa fa-check"></i><b>13</b> Métodos de muestreo y remuestreo</a>
<ul>
<li class="chapter" data-level="13.1" data-path="muestreo.html"><a href="muestreo.html#introducción-al-muestreo"><i class="fa fa-check"></i><b>13.1</b> Introducción al muestreo</a></li>
<li class="chapter" data-level="13.2" data-path="muestreo.html"><a href="muestreo.html#muestreo-aleatorio-simple-1"><i class="fa fa-check"></i><b>13.2</b> Muestreo aleatorio simple</a></li>
<li class="chapter" data-level="13.3" data-path="muestreo.html"><a href="muestreo.html#muestestra"><i class="fa fa-check"></i><b>13.3</b> Muestreo estratificado</a></li>
<li class="chapter" data-level="13.4" data-path="muestreo.html"><a href="muestreo.html#otros-tipos-de-muestreo-probabilístico"><i class="fa fa-check"></i><b>13.4</b> Otros tipos de muestreo probabilístico</a></li>
<li class="chapter" data-level="13.5" data-path="muestreo.html"><a href="muestreo.html#técnicas-de-remuestreo-bootstrap."><i class="fa fa-check"></i><b>13.5</b> Técnicas de remuestreo: Bootstrap.</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="cap-lm.html"><a href="cap-lm.html"><i class="fa fa-check"></i><b>14</b> Modelización lineal</a>
<ul>
<li class="chapter" data-level="14.1" data-path="cap-lm.html"><a href="cap-lm.html#modelización"><i class="fa fa-check"></i><b>14.1</b> Modelización</a></li>
<li class="chapter" data-level="14.2" data-path="cap-lm.html"><a href="cap-lm.html#procedimiento-de-modelización"><i class="fa fa-check"></i><b>14.2</b> Procedimiento de modelización</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="cap-lm.html"><a href="cap-lm.html#Bondad"><i class="fa fa-check"></i><b>14.2.1</b> Estimación del modelo</a></li>
<li class="chapter" data-level="14.2.2" data-path="cap-lm.html"><a href="cap-lm.html#validación-del-modelo"><i class="fa fa-check"></i><b>14.2.2</b> Validación del modelo</a></li>
<li class="chapter" data-level="14.2.3" data-path="cap-lm.html"><a href="cap-lm.html#interpretación-de-los-coeficientes"><i class="fa fa-check"></i><b>14.2.3</b> Interpretación de los coeficientes</a></li>
<li class="chapter" data-level="14.2.4" data-path="cap-lm.html"><a href="cap-lm.html#predicción"><i class="fa fa-check"></i><b>14.2.4</b> Predicción</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="cap-lm.html"><a href="cap-lm.html#procedimiento-con-r-la-función-lm"><i class="fa fa-check"></i><b>14.3</b> Procedimiento con R: la función <code>lm</code></a></li>
<li class="chapter" data-level="14.4" data-path="cap-lm.html"><a href="cap-lm.html#Casos"><i class="fa fa-check"></i><b>14.4</b> Casos prácticos</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="cap-lm.html"><a href="cap-lm.html#estimación-de-los-coeficientes"><i class="fa fa-check"></i><b>14.4.1</b> Estimación de los coeficientes</a></li>
<li class="chapter" data-level="14.4.2" data-path="cap-lm.html"><a href="cap-lm.html#validación"><i class="fa fa-check"></i><b>14.4.2</b> Validación</a></li>
<li class="chapter" data-level="14.4.3" data-path="cap-lm.html"><a href="cap-lm.html#interpretación-de-los-coeficientes-1"><i class="fa fa-check"></i><b>14.4.3</b> Interpretación de los coeficientes</a></li>
<li class="chapter" data-level="14.4.4" data-path="cap-lm.html"><a href="cap-lm.html#predicción-1"><i class="fa fa-check"></i><b>14.4.4</b> Predicción</a></li>
<li class="chapter" data-level="14.4.5" data-path="cap-lm.html"><a href="cap-lm.html#nuevo-ajuste-con-logozone"><i class="fa fa-check"></i><b>14.4.5</b> Nuevo ajuste con <code>log(Ozone)</code></a></li>
<li class="chapter" data-level="14.4.6" data-path="cap-lm.html"><a href="cap-lm.html#coeficientes-de-variables-categóricas"><i class="fa fa-check"></i><b>14.4.6</b> Coeficientes de variables categóricas</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="cap-lm.html"><a href="cap-lm.html#comentarios-finales"><i class="fa fa-check"></i><b>14.5</b> Comentarios finales</a>
<ul>
<li class="chapter" data-level="" data-path="cap-lm.html"><a href="cap-lm.html#resumen"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="15" data-path="cap-glm.html"><a href="cap-glm.html"><i class="fa fa-check"></i><b>15</b> Modelos lineales generalizados</a>
<ul>
<li class="chapter" data-level="15.1" data-path="cap-glm.html"><a href="cap-glm.html#motivación"><i class="fa fa-check"></i><b>15.1</b> Motivación</a></li>
<li class="chapter" data-level="15.2" data-path="cap-glm.html"><a href="cap-glm.html#modelo-y-sus-componentes"><i class="fa fa-check"></i><b>15.2</b> Modelo y sus componentes</a>
<ul>
<li class="chapter" data-level="15.2.1" data-path="cap-glm.html"><a href="cap-glm.html#función-enlace"><i class="fa fa-check"></i><b>15.2.1</b> Función enlace </a></li>
<li class="chapter" data-level="15.2.2" data-path="cap-glm.html"><a href="cap-glm.html#glms-en-r"><i class="fa fa-check"></i><b>15.2.2</b> GLMs en <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="cap-glm.html"><a href="cap-glm.html#regresión-logística"><i class="fa fa-check"></i><b>15.3</b> Regresión logística</a>
<ul>
<li class="chapter" data-level="15.3.1" data-path="cap-glm.html"><a href="cap-glm.html#procedimiento-de-ajuste"><i class="fa fa-check"></i><b>15.3.1</b> Procedimiento de ajuste</a></li>
<li class="chapter" data-level="15.3.2" data-path="cap-glm.html"><a href="cap-glm.html#adecuación-del-modelo"><i class="fa fa-check"></i><b>15.3.2</b> Adecuación del modelo</a></li>
<li class="chapter" data-level="15.3.3" data-path="cap-glm.html"><a href="cap-glm.html#SECCinterp"><i class="fa fa-check"></i><b>15.3.3</b> Interpretación de resultados</a></li>
<li class="chapter" data-level="15.3.4" data-path="cap-glm.html"><a href="cap-glm.html#predicción.-curva-roc-y-auc"><i class="fa fa-check"></i><b>15.3.4</b> Predicción. Curva ROC y AUC</a></li>
</ul></li>
<li class="chapter" data-level="15.4" data-path="cap-glm.html"><a href="cap-glm.html#regresión-de-poisson"><i class="fa fa-check"></i><b>15.4</b> Regresión de Poisson</a></li>
<li class="chapter" data-level="15.5" data-path="cap-glm.html"><a href="cap-glm.html#casos-prácticos"><i class="fa fa-check"></i><b>15.5</b> Casos prácticos</a>
<ul>
<li class="chapter" data-level="15.5.1" data-path="cap-glm.html"><a href="cap-glm.html#ejemplos-de-regresión-logística"><i class="fa fa-check"></i><b>15.5.1</b> Ejemplos de regresión logística</a></li>
<li class="chapter" data-level="15.5.2" data-path="cap-glm.html"><a href="cap-glm.html#ejemplo-de-regresión-de-poisson"><i class="fa fa-check"></i><b>15.5.2</b> Ejemplo de regresión de Poisson</a></li>
<li class="chapter" data-level="" data-path="cap-glm.html"><a href="cap-glm.html#resumen-1"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="16" data-path="cap-gam.html"><a href="cap-gam.html"><i class="fa fa-check"></i><b>16</b> Modelos aditivos generalizados</a>
<ul>
<li class="chapter" data-level="16.1" data-path="cap-gam.html"><a href="cap-gam.html#introducción-6"><i class="fa fa-check"></i><b>16.1</b> Introducción</a></li>
<li class="chapter" data-level="16.2" data-path="cap-gam.html"><a href="cap-gam.html#splines-con-penalizaciones"><i class="fa fa-check"></i><b>16.2</b> Splines con penalizaciones</a></li>
<li class="chapter" data-level="16.3" data-path="cap-gam.html"><a href="cap-gam.html#aspectos-metodológicos"><i class="fa fa-check"></i><b>16.3</b> Aspectos metodológicos</a>
<ul>
<li class="chapter" data-level="16.3.1" data-path="cap-gam.html"><a href="cap-gam.html#estimación-de-los-paraámetros-del-modelo"><i class="fa fa-check"></i><b>16.3.1</b> Estimación de los paraámetros del modelo</a></li>
<li class="chapter" data-level="16.3.2" data-path="cap-gam.html"><a href="cap-gam.html#inferencia-sobre-las-funciones-suaves"><i class="fa fa-check"></i><b>16.3.2</b> Inferencia sobre las funciones suaves</a></li>
<li class="chapter" data-level="16.3.3" data-path="cap-gam.html"><a href="cap-gam.html#suavizado-mutidimensional-y-para-datos-no-gaussianos"><i class="fa fa-check"></i><b>16.3.3</b> Suavizado mutidimensional y para datos no Gaussianos</a></li>
</ul></li>
<li class="chapter" data-level="16.4" data-path="cap-gam.html"><a href="cap-gam.html#la-función-gam-del-paquete-mgcv"><i class="fa fa-check"></i><b>16.4</b> La función <code>gam</code> del paquete <code>mgcv</code></a></li>
<li class="chapter" data-level="16.5" data-path="cap-gam.html"><a href="cap-gam.html#casos-prácticos-1"><i class="fa fa-check"></i><b>16.5</b> Casos prácticos</a>
<ul>
<li class="chapter" data-level="16.5.1" data-path="cap-gam.html"><a href="cap-gam.html#modelo-unidimensional-con-fossil"><i class="fa fa-check"></i><b>16.5.1</b> Modelo unidimensional con <code>fossil</code></a></li>
<li class="chapter" data-level="16.5.2" data-path="cap-gam.html"><a href="cap-gam.html#modelo-aditivo-con-airquality"><i class="fa fa-check"></i><b>16.5.2</b> Modelo aditivo con <code>airquality</code></a></li>
<li class="chapter" data-level="16.5.3" data-path="cap-gam.html"><a href="cap-gam.html#modelo-semiparamétrico-con-onions"><i class="fa fa-check"></i><b>16.5.3</b> Modelo semiparamétrico con <code>onions</code></a></li>
<li class="chapter" data-level="16.5.4" data-path="cap-gam.html"><a href="cap-gam.html#modelo-aditivo-generalizado-y-multidimensional-con-smacker"><i class="fa fa-check"></i><b>16.5.4</b> Modelo aditivo generalizado y multidimensional, con <code>smacker</code></a></li>
<li class="chapter" data-level="" data-path="cap-gam.html"><a href="cap-gam.html#resumen-2"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="17" data-path="cap-mxm.html"><a href="cap-mxm.html"><i class="fa fa-check"></i><b>17</b> Modelos mixtos</a>
<ul>
<li class="chapter" data-level="17.1" data-path="cap-mxm.html"><a href="cap-mxm.html#conceptos-básicos"><i class="fa fa-check"></i><b>17.1</b> Conceptos básicos</a>
<ul>
<li class="chapter" data-level="17.1.1" data-path="cap-mxm.html"><a href="cap-mxm.html#tipo-y-estructura-de-los-datos"><i class="fa fa-check"></i><b>17.1.1</b> Tipo y estructura de los datos</a></li>
<li class="chapter" data-level="17.1.2" data-path="cap-mxm.html"><a href="cap-mxm.html#efectos-fijos-o-aleatorios"><i class="fa fa-check"></i><b>17.1.2</b> ¿Efectos fijos o aleatorios?</a></li>
</ul></li>
<li class="chapter" data-level="17.2" data-path="cap-mxm.html"><a href="cap-mxm.html#formulación-del-modelo-con-efectos-aleatorios-o-modelos-mixtos"><i class="fa fa-check"></i><b>17.2</b> Formulación del modelo con efectos aleatorios o modelos mixtos</a>
<ul>
<li class="chapter" data-level="17.2.1" data-path="cap-mxm.html"><a href="cap-mxm.html#formulación-general"><i class="fa fa-check"></i><b>17.2.1</b> Formulación general</a></li>
<li class="chapter" data-level="17.2.2" data-path="cap-mxm.html"><a href="cap-mxm.html#inferencia-y-selección-del-modelo"><i class="fa fa-check"></i><b>17.2.2</b> Inferencia y selección del modelo</a></li>
<li class="chapter" data-level="17.2.3" data-path="cap-mxm.html"><a href="cap-mxm.html#diagnosis-del-modelo"><i class="fa fa-check"></i><b>17.2.3</b> Diagnosis del modelo</a></li>
</ul></li>
<li class="chapter" data-level="17.3" data-path="cap-mxm.html"><a href="cap-mxm.html#funciones-de-r-para-ajustar-modelos-mixtos"><i class="fa fa-check"></i><b>17.3</b> Funciones de <code>R</code> para ajustar modelos mixtos</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="cap-mxm.html"><a href="cap-mxm.html#la-función-lmer"><i class="fa fa-check"></i><b>17.3.1</b> La función <code>lmer()</code></a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="cap-mxm.html"><a href="cap-mxm.html#caso-práctico"><i class="fa fa-check"></i><b>17.4</b> Caso práctico</a>
<ul>
<li class="chapter" data-level="17.4.1" data-path="cap-mxm.html"><a href="cap-mxm.html#modelo-con-ordenada-en-el-origen-aleatoria"><i class="fa fa-check"></i><b>17.4.1</b> Modelo con ordenada en el origen aleatoria</a></li>
<li class="chapter" data-level="17.4.2" data-path="cap-mxm.html"><a href="cap-mxm.html#modelo-con-pendiente-aleatoria"><i class="fa fa-check"></i><b>17.4.2</b> Modelo con pendiente aleatoria</a></li>
<li class="chapter" data-level="17.4.3" data-path="cap-mxm.html"><a href="cap-mxm.html#cómo-construir-el-modelo-en-la-práctica"><i class="fa fa-check"></i><b>17.4.3</b> ¿Cómo construir el modelo en la práctica?</a></li>
<li class="chapter" data-level="" data-path="cap-mxm.html"><a href="cap-mxm.html#resumen-3"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="18" data-path="cap-sparse.html"><a href="cap-sparse.html"><i class="fa fa-check"></i><b>18</b> Modelos sparse y métodos penalizados de regresión</a>
<ul>
<li class="chapter" data-level="18.1" data-path="cap-sparse.html"><a href="cap-sparse.html#introducción-7"><i class="fa fa-check"></i><b>18.1</b> Introducción</a></li>
<li class="chapter" data-level="18.2" data-path="cap-sparse.html"><a href="cap-sparse.html#selección-del-mejor-subconjunto"><i class="fa fa-check"></i><b>18.2</b> Selección del mejor subconjunto</a>
<ul>
<li class="chapter" data-level="18.2.1" data-path="cap-sparse.html"><a href="cap-sparse.html#ejemplo-sueldo-de-jugadores-de-béisbol"><i class="fa fa-check"></i><b>18.2.1</b> Ejemplo: Sueldo de jugadores de béisbol</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="cap-sparse.html"><a href="cap-sparse.html#selección-stepwise"><i class="fa fa-check"></i><b>18.3</b> Selección <em>Stepwise</em></a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="cap-sparse.html"><a href="cap-sparse.html#forward-stepwise"><i class="fa fa-check"></i><b>18.3.1</b> Forward stepwise</a></li>
<li class="chapter" data-level="18.3.2" data-path="cap-sparse.html"><a href="cap-sparse.html#backward-stepwise"><i class="fa fa-check"></i><b>18.3.2</b> Backward stepwise</a></li>
<li class="chapter" data-level="18.3.3" data-path="cap-sparse.html"><a href="cap-sparse.html#ejemplo-sueldo-de-jugadores-de-béisbol-1"><i class="fa fa-check"></i><b>18.3.3</b> Ejemplo: Sueldo de jugadores de béisbol</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="cap-sparse.html"><a href="cap-sparse.html#métodos-shrinkage"><i class="fa fa-check"></i><b>18.4</b> Métodos Shrinkage</a>
<ul>
<li class="chapter" data-level="18.4.1" data-path="cap-sparse.html"><a href="cap-sparse.html#regresión-ridge"><i class="fa fa-check"></i><b>18.4.1</b> Regresión ridge</a></li>
<li class="chapter" data-level="18.4.2" data-path="cap-sparse.html"><a href="cap-sparse.html#selección-del-parámetro-de-tuneado"><i class="fa fa-check"></i><b>18.4.2</b> Selección del parámetro de tuneado</a></li>
<li class="chapter" data-level="18.4.3" data-path="cap-sparse.html"><a href="cap-sparse.html#regresión-lasso"><i class="fa fa-check"></i><b>18.4.3</b> Regresión Lasso</a></li>
<li class="chapter" data-level="18.4.4" data-path="cap-sparse.html"><a href="cap-sparse.html#elastic-net"><i class="fa fa-check"></i><b>18.4.4</b> Elastic net </a></li>
<li class="chapter" data-level="" data-path="cap-sparse.html"><a href="cap-sparse.html#resumen-4"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="19" data-path="cap-series-temp.html"><a href="cap-series-temp.html"><i class="fa fa-check"></i><b>19</b> Modelización de series temporales</a>
<ul>
<li class="chapter" data-level="19.1" data-path="cap-series-temp.html"><a href="cap-series-temp.html#conceptos-básicos-1"><i class="fa fa-check"></i><b>19.1</b> Conceptos básicos</a></li>
<li class="chapter" data-level="19.2" data-path="cap-series-temp.html"><a href="cap-series-temp.html#modelos-arima"><i class="fa fa-check"></i><b>19.2</b> Modelos ARIMA</a></li>
<li class="chapter" data-level="19.3" data-path="cap-series-temp.html"><a href="cap-series-temp.html#análisis-de-series-temporales-con-r"><i class="fa fa-check"></i><b>19.3</b> Análisis de series temporales con R</a>
<ul>
<li class="chapter" data-level="19.3.1" data-path="cap-series-temp.html"><a href="cap-series-temp.html#identificación-o-especificación-del-modelo"><i class="fa fa-check"></i><b>19.3.1</b> Identificación o especificación del modelo</a></li>
<li class="chapter" data-level="19.3.2" data-path="cap-series-temp.html"><a href="cap-series-temp.html#estimación-del-modelo"><i class="fa fa-check"></i><b>19.3.2</b> Estimación del modelo</a></li>
<li class="chapter" data-level="19.3.3" data-path="cap-series-temp.html"><a href="cap-series-temp.html#diagnosis-validación-y-contrastación"><i class="fa fa-check"></i><b>19.3.3</b> Diagnosis, validación y contrastación</a></li>
<li class="chapter" data-level="19.3.4" data-path="cap-series-temp.html"><a href="cap-series-temp.html#predicción-2"><i class="fa fa-check"></i><b>19.3.4</b> Predicción</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="20" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html"><i class="fa fa-check"></i><b>20</b> Análisis de tablas de contingencia</a>
<ul>
<li class="chapter" data-level="20.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#introducción-8"><i class="fa fa-check"></i><b>20.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="20.1.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#motiv"><i class="fa fa-check"></i><b>20.1.1</b> Motivación</a></li>
<li class="chapter" data-level="20.1.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#notac"><i class="fa fa-check"></i><b>20.1.2</b> Notación</a></li>
<li class="chapter" data-level="20.1.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#diseños-experimentales-o-procedimientos-de-muestreo-que-dan-lugar-a-una-tabla-de-contingencia"><i class="fa fa-check"></i><b>20.1.3</b> Diseños experimentales o procedimientos de muestreo que dan lugar a una tabla de contingencia</a></li>
</ul></li>
<li class="chapter" data-level="20.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contraste-de-independencia-en-tablas-2times-2"><i class="fa fa-check"></i><b>20.2</b> Contraste de independencia en tablas <span class="math inline">\((2\times 2)\)</span></a>
<ul>
<li class="chapter" data-level="20.2.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#introducción-9"><i class="fa fa-check"></i><b>20.2.1</b> Introducción</a></li>
<li class="chapter" data-level="20.2.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#plantgen"><i class="fa fa-check"></i><b>20.2.2</b> Planteamiento general del contraste exacto de independencia</a></li>
<li class="chapter" data-level="20.2.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#algoritmo"><i class="fa fa-check"></i><b>20.2.3</b> Algoritmo para la realización del contraste exacto de independencia</a></li>
<li class="chapter" data-level="20.2.4" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contraste-de-independencia-diseño-tipo-1"><i class="fa fa-check"></i><b>20.2.4</b> Contraste de independencia: Diseño Tipo 1</a></li>
<li class="chapter" data-level="20.2.5" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#dise"><i class="fa fa-check"></i><b>20.2.5</b> Contraste de independencia: Diseños Tipo 2 y Tipo 3</a></li>
</ul></li>
<li class="chapter" data-level="20.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contraste-de-independencia-en-tablas-rtimes-c"><i class="fa fa-check"></i><b>20.3</b> Contraste de independencia en tablas <span class="math inline">\(R\times C\)</span></a>
<ul>
<li class="chapter" data-level="20.3.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#IntroRxC"><i class="fa fa-check"></i><b>20.3.1</b> Introducción</a></li>
<li class="chapter" data-level="20.3.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contaprox"><i class="fa fa-check"></i><b>20.3.2</b> Contrastes aproximados</a></li>
<li class="chapter" data-level="20.3.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contraste-aproximado-con-corrección-de-continuidad-1"><i class="fa fa-check"></i><b>20.3.3</b> Contraste aproximado con corrección de continuidad</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#medidas"><i class="fa fa-check"></i><b>20.4</b> Medidas de asociación en tablas <span class="math inline">\(2\times 2\)</span></a>
<ul>
<li class="chapter" data-level="20.4.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#introducción-10"><i class="fa fa-check"></i><b>20.4.1</b> Introducción</a></li>
<li class="chapter" data-level="20.4.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#la-hatq-de-yule"><i class="fa fa-check"></i><b>20.4.2</b> La <span class="math inline">\(\hat{Q}\)</span> de Yule</a></li>
<li class="chapter" data-level="20.4.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#otras-medidas-de-asociación-para-tablas-2times-2"><i class="fa fa-check"></i><b>20.4.3</b> Otras medidas de asociación para tablas <span class="math inline">\(2\times 2\)</span></a></li>
</ul></li>
<li class="chapter" data-level="20.5" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#medidas-de-asociación-en-tablas-rtimes-c"><i class="fa fa-check"></i><b>20.5</b> Medidas de asociación en tablas <span class="math inline">\(R\times C\)</span></a>
<ul>
<li class="chapter" data-level="20.5.1" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#introducción-11"><i class="fa fa-check"></i><b>20.5.1</b> Introducción</a></li>
<li class="chapter" data-level="20.5.2" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#medidas-derivadas-del-estadístico-chi-cuadrado"><i class="fa fa-check"></i><b>20.5.2</b> Medidas derivadas del estadístico Chi-cuadrado</a></li>
<li class="chapter" data-level="20.5.3" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#medidas-basadas-en-la-reducción-proporcional-del-error-lambda-de-goodman-y-kruskal"><i class="fa fa-check"></i><b>20.5.3</b> Medidas basadas en la reducción proporcional del error: <span class="math inline">\(\lambda\)</span> de Goodman y Kruskal</a></li>
<li class="chapter" data-level="20.5.4" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#determinación-de-las-fuentes-de-asociación"><i class="fa fa-check"></i><b>20.5.4</b> Determinación de las fuentes de asociación</a></li>
</ul></li>
<li class="chapter" data-level="20.6" data-path="tablas-contingencia.html"><a href="tablas-contingencia.html#contrastes-de-independencia-en-tablas-multidimensionales"><i class="fa fa-check"></i><b>20.6</b> Contrastes de independencia en tablas multidimensionales</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="correspondencias.html"><a href="correspondencias.html"><i class="fa fa-check"></i><b>21</b> Análisis de correspondencias</a>
<ul>
<li class="chapter" data-level="21.1" data-path="correspondencias.html"><a href="correspondencias.html#introducción-12"><i class="fa fa-check"></i><b>21.1</b> Introducción</a></li>
<li class="chapter" data-level="21.2" data-path="correspondencias.html"><a href="correspondencias.html#metodología-del-análisis-de-correspondencias"><i class="fa fa-check"></i><b>21.2</b> Metodología del análisis de correspondencias</a>
<ul>
<li class="chapter" data-level="21.2.1" data-path="correspondencias.html"><a href="correspondencias.html#proyecciones-fila-columna-y-simétrica"><i class="fa fa-check"></i><b>21.2.1</b> Proyecciones fila, columna y simétrica</a></li>
</ul></li>
<li class="chapter" data-level="21.3" data-path="correspondencias.html"><a href="correspondencias.html#ejemplos-de-análisis-de-correspondencias-con-r"><i class="fa fa-check"></i><b>21.3</b> Ejemplos de análisis de correspondencias con <strong>R</strong></a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="cap-conjunto.html"><a href="cap-conjunto.html"><i class="fa fa-check"></i><b>22</b> Análisis conjunto</a>
<ul>
<li class="chapter" data-level="22.1" data-path="cap-conjunto.html"><a href="cap-conjunto.html#introducción-conceptos-clave-y-tipos-de-análisis"><i class="fa fa-check"></i><b>22.1</b> Introducción, conceptos clave y tipos de análisis</a></li>
<li class="chapter" data-level="22.2" data-path="cap-conjunto.html"><a href="cap-conjunto.html#aplicación-del-análisis-conjunto-etapas"><i class="fa fa-check"></i><b>22.2</b> Aplicación del Análisis Conjunto (etapas):</a></li>
<li class="chapter" data-level="22.3" data-path="cap-conjunto.html"><a href="cap-conjunto.html#ejemplo-utilizando-r"><i class="fa fa-check"></i><b>22.3</b> Ejemplo utilizando R:</a></li>
</ul></li>
<li class="chapter" data-level="23" data-path="cap-discriminante.html"><a href="cap-discriminante.html"><i class="fa fa-check"></i><b>23</b> Análisis discriminante</a>
<ul>
<li class="chapter" data-level="23.1" data-path="cap-discriminante.html"><a href="cap-discriminante.html#introducción-13"><i class="fa fa-check"></i><b>23.1</b> Introducción</a></li>
<li class="chapter" data-level="23.2" data-path="cap-discriminante.html"><a href="cap-discriminante.html#tipos-de-análisis-discriminantes"><i class="fa fa-check"></i><b>23.2</b> Tipos de análisis discriminantes:</a></li>
<li class="chapter" data-level="23.3" data-path="cap-discriminante.html"><a href="cap-discriminante.html#ejemplos"><i class="fa fa-check"></i><b>23.3</b> Ejemplos:</a></li>
</ul></li>
<li class="part"><span><b>IV Machine learning supervisado</b></span></li>
<li class="chapter" data-level="24" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html"><i class="fa fa-check"></i><b>24</b> Árboles de clasificación y regresión </a>
<ul>
<li class="chapter" data-level="24.1" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#introducción-14"><i class="fa fa-check"></i><b>24.1</b> Introducción </a></li>
<li class="chapter" data-level="24.2" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#aprendizaje-con-árboles-de-decisión"><i class="fa fa-check"></i><b>24.2</b> Aprendizaje con árboles de decisión</a></li>
<li class="chapter" data-level="24.3" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#cómo-se-va-dividiendo-el-árbol"><i class="fa fa-check"></i><b>24.3</b> ¿Cómo se va dividiendo el árbol? </a>
<ul>
<li class="chapter" data-level="24.3.1" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#impureza-de-gini"><i class="fa fa-check"></i><b>24.3.1</b> Impureza de Gini</a></li>
<li class="chapter" data-level="24.3.2" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#entropía"><i class="fa fa-check"></i><b>24.3.2</b> Entropía </a></li>
<li class="chapter" data-level="24.3.3" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#ganancia-de-información"><i class="fa fa-check"></i><b>24.3.3</b> Ganancia de información</a></li>
<li class="chapter" data-level="24.3.4" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#suma-residual-de-cuadrados-mínima"><i class="fa fa-check"></i><b>24.3.4</b> Suma residual de cuadrados mínima</a></li>
</ul></li>
<li class="chapter" data-level="24.4" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#sobreajuste"><i class="fa fa-check"></i><b>24.4</b> Sobreajuste </a></li>
<li class="chapter" data-level="24.5" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#cuánto-debe-crecer-un-árbol"><i class="fa fa-check"></i><b>24.5</b> ¿Cuánto debe crecer un árbol? </a>
<ul>
<li class="chapter" data-level="24.5.1" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#la-parada-temprana"><i class="fa fa-check"></i><b>24.5.1</b> La parada temprana </a></li>
<li class="chapter" data-level="24.5.2" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#la-poda"><i class="fa fa-check"></i><b>24.5.2</b> La poda </a></li>
</ul></li>
<li class="chapter" data-level="24.6" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#el-algoritmo-id3-para-la-construcción-de-un-árbol-de-decisión"><i class="fa fa-check"></i><b>24.6</b> El algoritmo ID3 para la construcción de un árbol de decisión</a></li>
<li class="chapter" data-level="24.7" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#procedimiento-con-r-la-funcion-rpart"><i class="fa fa-check"></i><b>24.7</b> Procedimiento con R: la funcion <code>rpart</code></a></li>
<li class="chapter" data-level="24.8" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#aplicaciones-de-los-árboles-de-decisión"><i class="fa fa-check"></i><b>24.8</b> Aplicaciones de los árboles de decisión</a>
<ul>
<li class="chapter" data-level="24.8.1" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#el-caso-de-negocio"><i class="fa fa-check"></i><b>24.8.1</b> El caso de negocio</a></li>
<li class="chapter" data-level="24.8.2" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#árbol-de-clasificación-para-determinar-la-intención-de-compra"><i class="fa fa-check"></i><b>24.8.2</b> Árbol de clasificación para determinar la intención de compra</a></li>
<li class="chapter" data-level="24.8.3" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#árbol-de-regresión-para-estimar-el-número-de-días-hospitalizado"><i class="fa fa-check"></i><b>24.8.3</b> Árbol de regresión para estimar el número de días hospitalizado</a></li>
<li class="chapter" data-level="" data-path="árboles-de-clasificación-y-regresión.html"><a href="árboles-de-clasificación-y-regresión.html#resumen-5"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="25" data-path="cap-svm.html"><a href="cap-svm.html"><i class="fa fa-check"></i><b>25</b> Máquinas de Vector Soporte</a>
<ul>
<li class="chapter" data-level="25.1" data-path="cap-svm.html"><a href="cap-svm.html#introducción-15"><i class="fa fa-check"></i><b>25.1</b> Introducción</a></li>
<li class="chapter" data-level="25.2" data-path="cap-svm.html"><a href="cap-svm.html#algoritmo-svm-para-clasificación-binaria"><i class="fa fa-check"></i><b>25.2</b> Algoritmo SVM para clasificación binaria</a></li>
<li class="chapter" data-level="25.3" data-path="cap-svm.html"><a href="cap-svm.html#y-si-tengo-más-de-dos-clases"><i class="fa fa-check"></i><b>25.3</b> ¿Y si tengo más de dos clases?</a></li>
<li class="chapter" data-level="25.4" data-path="cap-svm.html"><a href="cap-svm.html#truco-del-kernel-tratando-con-la-no-linearidad"><i class="fa fa-check"></i><b>25.4</b> Truco del Kernel: Tratando con la no linearidad</a>
<ul>
<li class="chapter" data-level="25.4.1" data-path="cap-svm.html"><a href="cap-svm.html#algunos-kernels-populares"><i class="fa fa-check"></i><b>25.4.1</b> Algunos kernels populares</a></li>
</ul></li>
<li class="chapter" data-level="25.5" data-path="cap-svm.html"><a href="cap-svm.html#procedimiento-con-r-la-funcion-svm"><i class="fa fa-check"></i><b>25.5</b> Procedimiento con R: la funcion <code>svm</code></a></li>
<li class="chapter" data-level="25.6" data-path="cap-svm.html"><a href="cap-svm.html#aplicación-de-un-modelo-svm-radial-con-ajuste-automático-en-r"><i class="fa fa-check"></i><b>25.6</b> Aplicación de un modelo SVM Radial con ajuste automático en R</a>
<ul>
<li class="chapter" data-level="25.6.1" data-path="cap-svm.html"><a href="cap-svm.html#importancia-de-las-variables"><i class="fa fa-check"></i><b>25.6.1</b> Importancia de las variables</a></li>
<li class="chapter" data-level="" data-path="cap-svm.html"><a href="cap-svm.html#resumen-6"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="26" data-path="cap-knn.html"><a href="cap-knn.html"><i class="fa fa-check"></i><b>26</b> Clasificador k-vecinos más próximos</a>
<ul>
<li class="chapter" data-level="26.1" data-path="cap-knn.html"><a href="cap-knn.html#introducción-16"><i class="fa fa-check"></i><b>26.1</b> Introducción</a></li>
<li class="chapter" data-level="26.2" data-path="cap-knn.html"><a href="cap-knn.html#decisiones-a-tener-en-cuenta"><i class="fa fa-check"></i><b>26.2</b> Decisiones a tener en cuenta</a>
<ul>
<li class="chapter" data-level="26.2.1" data-path="cap-knn.html"><a href="cap-knn.html#función-de-distancia-a-utilizar"><i class="fa fa-check"></i><b>26.2.1</b> Función de distancia a utilizar</a></li>
<li class="chapter" data-level="26.2.2" data-path="cap-knn.html"><a href="cap-knn.html#número-de-vecinos-k-seleccionados"><i class="fa fa-check"></i><b>26.2.2</b> Número de vecinos (k) seleccionados</a></li>
</ul></li>
<li class="chapter" data-level="26.3" data-path="cap-knn.html"><a href="cap-knn.html#procedimiento-con-r-la-funcion-knn"><i class="fa fa-check"></i><b>26.3</b> Procedimiento con R: la funcion knn</a></li>
<li class="chapter" data-level="26.4" data-path="cap-knn.html"><a href="cap-knn.html#aplicación-del-modelo-knn-en-r"><i class="fa fa-check"></i><b>26.4</b> Aplicación del modelo KNN en R</a>
<ul>
<li class="chapter" data-level="" data-path="cap-knn.html"><a href="cap-knn.html#resumen-7"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="27" data-path="cap-naive-bayes.html"><a href="cap-naive-bayes.html"><i class="fa fa-check"></i><b>27</b> Naive Bayes</a>
<ul>
<li class="chapter" data-level="27.1" data-path="cap-naive-bayes.html"><a href="cap-naive-bayes.html#introducción-17"><i class="fa fa-check"></i><b>27.1</b> Introducción</a></li>
<li class="chapter" data-level="27.2" data-path="cap-naive-bayes.html"><a href="cap-naive-bayes.html#teorema-de-bayes"><i class="fa fa-check"></i><b>27.2</b> Teorema de Bayes</a></li>
<li class="chapter" data-level="27.3" data-path="cap-naive-bayes.html"><a href="cap-naive-bayes.html#el-algoritmo-naive-bayes"><i class="fa fa-check"></i><b>27.3</b> El algoritmo Naive Bayes</a></li>
<li class="chapter" data-level="27.4" data-path="cap-naive-bayes.html"><a href="cap-naive-bayes.html#procedimiento-con-r-la-funcion-naive_bayes"><i class="fa fa-check"></i><b>27.4</b> Procedimiento con R: la funcion <code>naive_bayes</code></a></li>
<li class="chapter" data-level="27.5" data-path="cap-naive-bayes.html"><a href="cap-naive-bayes.html#aplicación-del-modelo-naive-bayes"><i class="fa fa-check"></i><b>27.5</b> Aplicación del modelo Naive Bayes</a>
<ul>
<li class="chapter" data-level="" data-path="cap-naive-bayes.html"><a href="cap-naive-bayes.html#resumen-8"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="28" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html"><i class="fa fa-check"></i><b>28</b> Bagging. Random Forest </a>
<ul>
<li class="chapter" data-level="28.1" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#introducción-metodos-de-ensamble"><i class="fa fa-check"></i><b>28.1</b> Introducción: Metodos de Ensamble</a></li>
<li class="chapter" data-level="28.2" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#bagging"><i class="fa fa-check"></i><b>28.2</b> Bagging</a></li>
<li class="chapter" data-level="28.3" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#procedimiento-con-r-la-función-bagging"><i class="fa fa-check"></i><b>28.3</b> Procedimiento con R: la función <code>bagging</code> </a></li>
<li class="chapter" data-level="28.4" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#implementando-bagging-en-r"><i class="fa fa-check"></i><b>28.4</b> Implementando bagging en R</a>
<ul>
<li class="chapter" data-level="28.4.1" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#interpretación-de-variables-en-el-bagging"><i class="fa fa-check"></i><b>28.4.1</b> Interpretación de variables en el bagging</a></li>
</ul></li>
<li class="chapter" data-level="28.5" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#random-forest"><i class="fa fa-check"></i><b>28.5</b> Random Forest</a>
<ul>
<li class="chapter" data-level="28.5.1" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#número-de-árboles-k"><i class="fa fa-check"></i><b>28.5.1</b> Número de árboles (<span class="math inline">\(K\)</span>)</a></li>
<li class="chapter" data-level="28.5.2" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#número-de-variables-a-considerar-mtry"><i class="fa fa-check"></i><b>28.5.2</b> Número de variables a considerar (<span class="math inline">\(mtry\)</span>)</a></li>
<li class="chapter" data-level="28.5.3" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#complejidad-de-los-árboles"><i class="fa fa-check"></i><b>28.5.3</b> Complejidad de los árboles</a></li>
<li class="chapter" data-level="28.5.4" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#esquema-de-muestreo"><i class="fa fa-check"></i><b>28.5.4</b> Esquema de muestreo</a></li>
<li class="chapter" data-level="28.5.5" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#regla-de-división"><i class="fa fa-check"></i><b>28.5.5</b> Regla de división</a></li>
</ul></li>
<li class="chapter" data-level="28.6" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#procedimiento-con-r-la-función-randomforest"><i class="fa fa-check"></i><b>28.6</b> Procedimiento con R: la función <code>randomForest</code></a></li>
<li class="chapter" data-level="28.7" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#aplicación-del-modelo-random-forest-en-r"><i class="fa fa-check"></i><b>28.7</b> Aplicación del modelo Random Forest en R</a>
<ul>
<li class="chapter" data-level="28.7.1" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#aplicación-del-random-forest"><i class="fa fa-check"></i><b>28.7.1</b> Aplicación del Random Forest</a></li>
<li class="chapter" data-level="" data-path="bagging.-random-forest.html"><a href="bagging.-random-forest.html#resumen-9"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="29" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html"><i class="fa fa-check"></i><b>29</b> Boosting. XGBoost.</a>
<ul>
<li class="chapter" data-level="29.1" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#introducción.-boosting."><i class="fa fa-check"></i><b>29.1</b> Introducción. Boosting.</a></li>
<li class="chapter" data-level="29.2" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#gradient-boosting"><i class="fa fa-check"></i><b>29.2</b> Gradient Boosting</a>
<ul>
<li class="chapter" data-level="29.2.1" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#hiperparámetros-del-modelo-gradient-boosting"><i class="fa fa-check"></i><b>29.2.1</b> Hiperparámetros del modelo gradient boosting</a></li>
<li class="chapter" data-level="29.2.2" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#estrategia-de-ajuste-de-hiperparametros"><i class="fa fa-check"></i><b>29.2.2</b> Estrategia de ajuste de hiperparametros</a></li>
</ul></li>
<li class="chapter" data-level="29.3" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#procedimiento-con-r-la-funcion-gbm"><i class="fa fa-check"></i><b>29.3</b> Procedimiento con R: la funcion <code>gbm</code></a></li>
<li class="chapter" data-level="29.4" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#aplicación-del-modelo-gbm-en-r"><i class="fa fa-check"></i><b>29.4</b> Aplicación del modelo GBM en R</a>
<ul>
<li class="chapter" data-level="29.4.1" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#gbm-con-ajuste-automático"><i class="fa fa-check"></i><b>29.4.1</b> GBM con ajuste automático</a></li>
</ul></li>
<li class="chapter" data-level="29.5" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#extreme-gradient-boosting-xgb"><i class="fa fa-check"></i><b>29.5</b> eXtreme Gradient Boosting (XGB)</a>
<ul>
<li class="chapter" data-level="29.5.1" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#hiperparametros-del-modelo-xgboost"><i class="fa fa-check"></i><b>29.5.1</b> Hiperparametros del modelo XGBoost</a></li>
</ul></li>
<li class="chapter" data-level="29.6" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#procedimiento-con-r-la-funcion-xgboost"><i class="fa fa-check"></i><b>29.6</b> Procedimiento con R: la funcion <code>xgboost</code></a></li>
<li class="chapter" data-level="29.7" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#aplicación-del-módelo-xgboost-en-r"><i class="fa fa-check"></i><b>29.7</b> Aplicación del módelo XGBoost en R</a>
<ul>
<li class="chapter" data-level="29.7.1" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#xgboost-y-ajuste-automático"><i class="fa fa-check"></i><b>29.7.1</b> XGBoost y ajuste automático</a></li>
<li class="chapter" data-level="" data-path="cap-boosting-xgboost.html"><a href="cap-boosting-xgboost.html#resumen-10"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>V Machine learning no supervisado</b></span></li>
<li class="chapter" data-level="30" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html"><i class="fa fa-check"></i><b>30</b> Análisis cluster: clusterización jerárquica</a>
<ul>
<li class="chapter" data-level="30.1" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#origen-cluster"><i class="fa fa-check"></i><b>30.1</b> Introducción</a></li>
<li class="chapter" data-level="30.2" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#selección-de-las-variables"><i class="fa fa-check"></i><b>30.2</b> Selección de las variables</a></li>
<li class="chapter" data-level="30.3" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#elección-de-la-distancia-entre-elementos"><i class="fa fa-check"></i><b>30.3</b> Elección de la distancia entre elementos</a></li>
<li class="chapter" data-level="30.4" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#técnicas-de-agrupación-jerárquicas"><i class="fa fa-check"></i><b>30.4</b> Técnicas de agrupación jerárquicas</a>
<ul>
<li class="chapter" data-level="30.4.1" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#introac"><i class="fa fa-check"></i><b>30.4.1</b> Introducción</a></li>
<li class="chapter" data-level="30.4.2" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#técnicas-jerárquicas-aglomerativas"><i class="fa fa-check"></i><b>30.4.2</b> Técnicas jerárquicas aglomerativas</a></li>
<li class="chapter" data-level="30.4.3" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#técnicas-jerárquicas-divisivas"><i class="fa fa-check"></i><b>30.4.3</b> Técnicas jerárquicas divisivas</a></li>
</ul></li>
<li class="chapter" data-level="30.5" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#calidad-de-la-agrupación-y-número-de-clusters"><i class="fa fa-check"></i><b>30.5</b> Calidad de la agrupación y número de clusters</a>
<ul>
<li class="chapter" data-level="30.5.1" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#el-coeficiente-de-correlación-lineal-cofenético"><i class="fa fa-check"></i><b>30.5.1</b> El coeficiente de correlación lineal cofenético</a></li>
<li class="chapter" data-level="30.5.2" data-path="análisis-cluster-clusterización-jerárquica.html"><a href="análisis-cluster-clusterización-jerárquica.html#número-óptimo-de-clusters"><i class="fa fa-check"></i><b>30.5.2</b> Número óptimo de clusters</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="31" data-path="no-jerarquico.html"><a href="no-jerarquico.html"><i class="fa fa-check"></i><b>31</b> Análisis cluster: clusterización no jerárquica</a>
<ul>
<li class="chapter" data-level="31.1" data-path="no-jerarquico.html"><a href="no-jerarquico.html#métodos-de-reasignación"><i class="fa fa-check"></i><b>31.1</b> Métodos de reasignación</a>
<ul>
<li class="chapter" data-level="31.1.1" data-path="no-jerarquico.html"><a href="no-jerarquico.html#técnicas-basadas-en-centroides-métodos-de-forgy-y-bf-k-medias"><i class="fa fa-check"></i><b>31.1.1</b> Técnicas basadas en centroides: métodos de Forgy y <span class="math inline">\(\bf k\)</span>-medias</a></li>
<li class="chapter" data-level="31.1.2" data-path="no-jerarquico.html"><a href="no-jerarquico.html#técnicas-basadas-en-medoides"><i class="fa fa-check"></i><b>31.1.2</b> Técnicas basadas en medoides</a></li>
<li class="chapter" data-level="31.1.3" data-path="no-jerarquico.html"><a href="no-jerarquico.html#técnicas-basadas-en-medianas-bf-k-medianas"><i class="fa fa-check"></i><b>31.1.3</b> Técnicas basadas en medianas: <span class="math inline">\(\bf k\)</span>-medianas</a></li>
</ul></li>
<li class="chapter" data-level="31.2" data-path="no-jerarquico.html"><a href="no-jerarquico.html#métodos-basados-en-la-densidad-de-puntos"><i class="fa fa-check"></i><b>31.2</b> Métodos basados en la densidad de puntos</a></li>
<li class="chapter" data-level="31.3" data-path="no-jerarquico.html"><a href="no-jerarquico.html#otros-métodos"><i class="fa fa-check"></i><b>31.3</b> Otros métodos</a></li>
<li class="chapter" data-level="31.4" data-path="no-jerarquico.html"><a href="no-jerarquico.html#nota-final"><i class="fa fa-check"></i><b>31.4</b> Nota final</a></li>
</ul></li>
<li class="chapter" data-level="32" data-path="acp.html"><a href="acp.html"><i class="fa fa-check"></i><b>32</b> Análisis de componentes principales</a>
<ul>
<li class="chapter" data-level="32.1" data-path="acp.html"><a href="acp.html#introducción-18"><i class="fa fa-check"></i><b>32.1</b> Introducción</a></li>
<li class="chapter" data-level="32.2" data-path="acp.html"><a href="acp.html#obtención-de-las-componentes-principales"><i class="fa fa-check"></i><b>32.2</b> Obtención de las componentes principales</a>
<ul>
<li class="chapter" data-level="32.2.1" data-path="acp.html"><a href="acp.html#descripción-formal-del-proceso"><i class="fa fa-check"></i><b>32.2.1</b> Descripción formal del proceso</a></li>
<li class="chapter" data-level="32.2.2" data-path="acp.html"><a href="acp.html#cuestiones-importantes-en-el-análisis-de-componentes-principales"><i class="fa fa-check"></i><b>32.2.2</b> Cuestiones importantes en el análisis de componentes principales</a></li>
</ul></li>
<li class="chapter" data-level="32.3" data-path="acp.html"><a href="acp.html#estimación-de-las-componentes-principales"><i class="fa fa-check"></i><b>32.3</b> Estimación de las componentes principales</a></li>
<li class="chapter" data-level="32.4" data-path="acp.html"><a href="acp.html#numcomp"><i class="fa fa-check"></i><b>32.4</b> Número de componentes a retener</a></li>
<li class="chapter" data-level="32.5" data-path="acp.html"><a href="acp.html#interpretación-de-las-componentes-principales"><i class="fa fa-check"></i><b>32.5</b> Interpretación de las componentes principales</a></li>
<li class="chapter" data-level="32.6" data-path="acp.html"><a href="acp.html#reproducción-de-los-datos-tipificados-y-de-r-a-partir-de-las-componentes-principales"><i class="fa fa-check"></i><b>32.6</b> Reproducción de los datos tipificados y de R a partir de las componentes principales</a></li>
<li class="chapter" data-level="32.7" data-path="acp.html"><a href="acp.html#limitaciones-del-análisis-de-componentes-principales"><i class="fa fa-check"></i><b>32.7</b> Limitaciones del análisis de componentes principales</a></li>
</ul></li>
<li class="chapter" data-level="33" data-path="análisis-factorial.html"><a href="análisis-factorial.html"><i class="fa fa-check"></i><b>33</b> Análisis factorial</a>
<ul>
<li class="chapter" data-level="33.1" data-path="análisis-factorial.html"><a href="análisis-factorial.html#introaf"><i class="fa fa-check"></i><b>33.1</b> Introducción</a></li>
<li class="chapter" data-level="33.2" data-path="análisis-factorial.html"><a href="análisis-factorial.html#elementos-teóricos-del-análisis-factorial"><i class="fa fa-check"></i><b>33.2</b> Elementos teóricos del análisis factorial</a>
<ul>
<li class="chapter" data-level="33.2.1" data-path="análisis-factorial.html"><a href="análisis-factorial.html#modelobasicoaf"><i class="fa fa-check"></i><b>33.2.1</b> Modelo básico y terminología</a></li>
<li class="chapter" data-level="33.2.2" data-path="análisis-factorial.html"><a href="análisis-factorial.html#patrón-y-estructura-factoriales"><i class="fa fa-check"></i><b>33.2.2</b> Patrón y estructura factoriales</a></li>
</ul></li>
<li class="chapter" data-level="33.3" data-path="análisis-factorial.html"><a href="análisis-factorial.html#el-análisis-factorial-en-la-práctica"><i class="fa fa-check"></i><b>33.3</b> El análisis factorial en la práctica</a>
<ul>
<li class="chapter" data-level="33.3.1" data-path="análisis-factorial.html"><a href="análisis-factorial.html#pre-análisis-factorial"><i class="fa fa-check"></i><b>33.3.1</b> Pre-análisis factorial</a></li>
<li class="chapter" data-level="33.3.2" data-path="análisis-factorial.html"><a href="análisis-factorial.html#análisis-factorial-1"><i class="fa fa-check"></i><b>33.3.2</b> Análisis factorial</a></li>
<li class="chapter" data-level="33.3.3" data-path="análisis-factorial.html"><a href="análisis-factorial.html#postanalisis"><i class="fa fa-check"></i><b>33.3.3</b> Post-análisis factorial</a></li>
<li class="chapter" data-level="33.3.4" data-path="análisis-factorial.html"><a href="análisis-factorial.html#puntuaciones-factoriales."><i class="fa fa-check"></i><b>33.3.4</b> Puntuaciones factoriales.</a></li>
</ul></li>
<li class="chapter" data-level="33.4" data-path="análisis-factorial.html"><a href="análisis-factorial.html#relaciones-y-diferencias-entre-el-análisis-factorial-y-el-de-componentes-principales"><i class="fa fa-check"></i><b>33.4</b> Relaciones y diferencias entre el análisis factorial y el de componentes principales</a></li>
</ul></li>
<li class="chapter" data-level="34" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html"><i class="fa fa-check"></i><b>34</b> Escalamiento multidimensional</a>
<ul>
<li class="chapter" data-level="34.1" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html#introducción-19"><i class="fa fa-check"></i><b>34.1</b> Introducción</a></li>
<li class="chapter" data-level="34.2" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html#medición-de-distancias-y-similitudes"><i class="fa fa-check"></i><b>34.2</b> Medición de distancias y similitudes</a></li>
<li class="chapter" data-level="34.3" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html#modelo-escalamiento-multidimensional."><i class="fa fa-check"></i><b>34.3</b> Modelo escalamiento multidimensional.</a></li>
<li class="chapter" data-level="34.4" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html#tipos-de-escalamiento-multidimensional"><i class="fa fa-check"></i><b>34.4</b> Tipos de escalamiento multidimensional</a>
<ul>
<li class="chapter" data-level="34.4.1" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html#escalado-multidimensional-métrico"><i class="fa fa-check"></i><b>34.4.1</b> Escalado multidimensional métrico</a></li>
<li class="chapter" data-level="34.4.2" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html#escalado-multidimensional-no-métrico"><i class="fa fa-check"></i><b>34.4.2</b> Escalado multidimensional no-métrico</a></li>
</ul></li>
<li class="chapter" data-level="34.5" data-path="escalamiento-multidimensional.html"><a href="escalamiento-multidimensional.html#biblio"><i class="fa fa-check"></i><b>34.5</b> Referencias bibliográficas</a></li>
</ul></li>
<li class="part"><span><b>VI Deep learning</b></span></li>
<li class="chapter" data-level="35" data-path="capNN.html"><a href="capNN.html"><i class="fa fa-check"></i><b>35</b> Redes neuronales artificiales</a>
<ul>
<li class="chapter" data-level="35.1" data-path="capNN.html"><a href="capNN.html#qué-es-el-deep-learning"><i class="fa fa-check"></i><b>35.1</b> ¿Qué es el <em>deep learning</em>?</a>
<ul>
<li class="chapter" data-level="35.1.1" data-path="capNN.html"><a href="capNN.html#diferencias-entre-las-técnicas-de-machine-learning-tradicional-y-el-deep-learning"><i class="fa fa-check"></i><b>35.1.1</b> Diferencias entre las técnicas de <em>machine learning</em> tradicional y el <em>deep learning</em></a></li>
</ul></li>
<li class="chapter" data-level="35.2" data-path="capNN.html"><a href="capNN.html#aplicaciones-del-deep-learning"><i class="fa fa-check"></i><b>35.2</b> Aplicaciones del <em>deep learning</em></a></li>
<li class="chapter" data-level="35.3" data-path="capNN.html"><a href="capNN.html#redes-neuronales"><i class="fa fa-check"></i><b>35.3</b> Redes Neuronales</a></li>
<li class="chapter" data-level="35.4" data-path="capNN.html"><a href="capNN.html#perceptrón-o-neurona"><i class="fa fa-check"></i><b>35.4</b> Perceptrón o Neurona</a>
<ul>
<li class="chapter" data-level="35.4.1" data-path="capNN.html"><a href="capNN.html#aprendizaje"><i class="fa fa-check"></i><b>35.4.1</b> Aprendizaje</a></li>
<li class="chapter" data-level="35.4.2" data-path="capNN.html"><a href="capNN.html#convergencia"><i class="fa fa-check"></i><b>35.4.2</b> Convergencia</a></li>
</ul></li>
<li class="chapter" data-level="35.5" data-path="capNN.html"><a href="capNN.html#perceptrón-multiclase"><i class="fa fa-check"></i><b>35.5</b> Perceptrón Multiclase</a></li>
<li class="chapter" data-level="35.6" data-path="capNN.html"><a href="capNN.html#funciones-de-activación"><i class="fa fa-check"></i><b>35.6</b> Funciones de activación</a></li>
<li class="chapter" data-level="35.7" data-path="capNN.html"><a href="capNN.html#perceptrón-multicapa"><i class="fa fa-check"></i><b>35.7</b> Perceptrón Multicapa</a>
<ul>
<li class="chapter" data-level="35.7.1" data-path="capNN.html"><a href="capNN.html#aprendizaje-1"><i class="fa fa-check"></i><b>35.7.1</b> Aprendizaje</a></li>
</ul></li>
<li class="chapter" data-level="35.8" data-path="capNN.html"><a href="capNN.html#instalación-de-librerías-de-deep-learning-en-r-tensorflowkeras"><i class="fa fa-check"></i><b>35.8</b> Instalación de librerías de <em>deep learning</em> en <strong>R</strong>: Tensorflow/Keras</a></li>
<li class="chapter" data-level="35.9" data-path="capNN.html"><a href="capNN.html#ejemplo-de-red-para-clasificación"><i class="fa fa-check"></i><b>35.9</b> Ejemplo de red para clasificación</a>
<ul>
<li class="chapter" data-level="35.9.1" data-path="capNN.html"><a href="capNN.html#carga-y-visualización-de-los-datos"><i class="fa fa-check"></i><b>35.9.1</b> Carga y visualización de los datos</a></li>
<li class="chapter" data-level="35.9.2" data-path="capNN.html"><a href="capNN.html#preprocesamiento"><i class="fa fa-check"></i><b>35.9.2</b> Preprocesamiento</a></li>
<li class="chapter" data-level="35.9.3" data-path="capNN.html"><a href="capNN.html#nngen"><i class="fa fa-check"></i><b>35.9.3</b> Generación de la red neuronal</a></li>
<li class="chapter" data-level="35.9.4" data-path="capNN.html"><a href="capNN.html#nntrain"><i class="fa fa-check"></i><b>35.9.4</b> Entrenamiento</a></li>
<li class="chapter" data-level="35.9.5" data-path="capNN.html"><a href="capNN.html#test"><i class="fa fa-check"></i><b>35.9.5</b> Test</a></li>
<li class="chapter" data-level="35.9.6" data-path="capNN.html"><a href="capNN.html#guardado-y-reutilización-del-modelo"><i class="fa fa-check"></i><b>35.9.6</b> Guardado y reutilización del modelo</a></li>
</ul></li>
<li class="chapter" data-level="35.10" data-path="capNN.html"><a href="capNN.html#ejemplo-de-red-para-regresión"><i class="fa fa-check"></i><b>35.10</b> Ejemplo de red para regresión</a>
<ul>
<li class="chapter" data-level="35.10.1" data-path="capNN.html"><a href="capNN.html#carga-y-visualización-de-los-datos-1"><i class="fa fa-check"></i><b>35.10.1</b> Carga y visualización de los datos</a></li>
<li class="chapter" data-level="35.10.2" data-path="capNN.html"><a href="capNN.html#preprocesamiento-1"><i class="fa fa-check"></i><b>35.10.2</b> Preprocesamiento</a></li>
<li class="chapter" data-level="35.10.3" data-path="capNN.html"><a href="capNN.html#generación-de-la-red-neuronal"><i class="fa fa-check"></i><b>35.10.3</b> Generación de la red neuronal</a></li>
<li class="chapter" data-level="35.10.4" data-path="capNN.html"><a href="capNN.html#entrenamiento"><i class="fa fa-check"></i><b>35.10.4</b> Entrenamiento</a></li>
<li class="chapter" data-level="35.10.5" data-path="capNN.html"><a href="capNN.html#test-1"><i class="fa fa-check"></i><b>35.10.5</b> Test</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="36" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html"><i class="fa fa-check"></i><b>36</b> Redes neuronales convolucionales</a>
<ul>
<li class="chapter" data-level="36.1" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#introducción-20"><i class="fa fa-check"></i><b>36.1</b> Introducción</a></li>
<li class="chapter" data-level="36.2" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#convolución"><i class="fa fa-check"></i><b>36.2</b> Convolución</a></li>
<li class="chapter" data-level="36.3" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#neuronas-convolucionales"><i class="fa fa-check"></i><b>36.3</b> Neuronas convolucionales</a></li>
<li class="chapter" data-level="36.4" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#relleno-del-borde"><i class="fa fa-check"></i><b>36.4</b> Relleno del borde</a>
<ul>
<li class="chapter" data-level="36.4.1" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#desplazamiento"><i class="fa fa-check"></i><b>36.4.1</b> Desplazamiento</a></li>
</ul></li>
<li class="chapter" data-level="36.5" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#capas-de-agrupación"><i class="fa fa-check"></i><b>36.5</b> Capas de agrupación</a></li>
<li class="chapter" data-level="36.6" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#desvanecimiento-del-gradiente"><i class="fa fa-check"></i><b>36.6</b> Desvanecimiento del gradiente</a></li>
<li class="chapter" data-level="36.7" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#sobreajuste-1"><i class="fa fa-check"></i><b>36.7</b> Sobreajuste</a></li>
<li class="chapter" data-level="36.8" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#generación-de-datos-de-entrenamiento-artificiales"><i class="fa fa-check"></i><b>36.8</b> Generación de datos de entrenamiento artificiales</a></li>
<li class="chapter" data-level="36.9" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#ejemplo-para-el-conjunto-de-datos-cifar10"><i class="fa fa-check"></i><b>36.9</b> Ejemplo para el conjunto de datos CIFAR10</a>
<ul>
<li class="chapter" data-level="36.9.1" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#visualizacion"><i class="fa fa-check"></i><b>36.9.1</b> Carga y visualización de los datos</a></li>
<li class="chapter" data-level="36.9.2" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#preprocesamiento-2"><i class="fa fa-check"></i><b>36.9.2</b> Preprocesamiento</a></li>
<li class="chapter" data-level="36.9.3" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#generación-de-la-red-neuronal-1"><i class="fa fa-check"></i><b>36.9.3</b> Generación de la red neuronal</a></li>
<li class="chapter" data-level="36.9.4" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#entrenamiento-1"><i class="fa fa-check"></i><b>36.9.4</b> Entrenamiento</a></li>
<li class="chapter" data-level="36.9.5" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#test-2"><i class="fa fa-check"></i><b>36.9.5</b> Test</a></li>
<li class="chapter" data-level="36.9.6" data-path="cap-redes-convol.html"><a href="cap-redes-convol.html#otros-ejemplos-de-interés"><i class="fa fa-check"></i><b>36.9.6</b> Otros ejemplos de interés</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>VII Ciencia de datos espaciales</b></span></li>
<li class="chapter" data-level="37" data-path="datos-espaciles.html"><a href="datos-espaciles.html"><i class="fa fa-check"></i><b>37</b> Trabajando con datos espaciales</a>
<ul>
<li class="chapter" data-level="37.1" data-path="datos-espaciles.html"><a href="datos-espaciles.html#conceptos-clave"><i class="fa fa-check"></i><b>37.1</b> Conceptos clave</a>
<ul>
<li class="chapter" data-level="37.1.1" data-path="datos-espaciles.html"><a href="datos-espaciles.html#CRS"><i class="fa fa-check"></i><b>37.1.1</b> Sistema de Referencia de Coordenadas</a></li>
<li class="chapter" data-level="37.1.2" data-path="datos-espaciles.html"><a href="datos-espaciles.html#formatos"><i class="fa fa-check"></i><b>37.1.2</b> Formatos de datos espaciales</a></li>
</ul></li>
<li class="chapter" data-level="37.2" data-path="datos-espaciles.html"><a href="datos-espaciles.html#primer-mapa"><i class="fa fa-check"></i><b>37.2</b> Mi primer mapa</a></li>
<li class="chapter" data-level="37.3" data-path="datos-espaciles.html"><a href="datos-espaciles.html#no-mentir"><i class="fa fa-check"></i><b>37.3</b> ¿Cómo (no) mentir con la visualización?</a></li>
<li class="chapter" data-level="37.4" data-path="datos-espaciles.html"><a href="datos-espaciles.html#mapas-espacio-temporales"><i class="fa fa-check"></i><b>37.4</b> Mapas espacio-temporales</a></li>
<li class="chapter" data-level="37.5" data-path="datos-espaciles.html"><a href="datos-espaciles.html#mapas-interactivos"><i class="fa fa-check"></i><b>37.5</b> Mapas interactivos</a></li>
<li class="chapter" data-level="37.6" data-path="datos-espaciles.html"><a href="datos-espaciles.html#estadística-para-datos-espaciales"><i class="fa fa-check"></i><b>37.6</b> Estadística para datos espaciales</a></li>
</ul></li>
<li class="chapter" data-level="38" data-path="geo.html"><a href="geo.html"><i class="fa fa-check"></i><b>38</b> Geoestadística</a>
<ul>
<li class="chapter" data-level="38.1" data-path="geo.html"><a href="geo.html#introducción-21"><i class="fa fa-check"></i><b>38.1</b> Introducción</a></li>
<li class="chapter" data-level="38.2" data-path="geo.html"><a href="geo.html#preliminares-geo"><i class="fa fa-check"></i><b>38.2</b> Preliminares</a></li>
<li class="chapter" data-level="38.3" data-path="geo.html"><a href="geo.html#ana-estructural"><i class="fa fa-check"></i><b>38.3</b> Análisis estructural de la dependencia espacial</a>
<ul>
<li class="chapter" data-level="38.3.1" data-path="geo.html"><a href="geo.html#semivariograma"><i class="fa fa-check"></i><b>38.3.1</b> Semivariograma</a></li>
<li class="chapter" data-level="38.3.2" data-path="geo.html"><a href="geo.html#modelos-de-semivariogramas-válidos"><i class="fa fa-check"></i><b>38.3.2</b> Modelos de semivariogramas válidos</a></li>
<li class="chapter" data-level="38.3.3" data-path="geo.html"><a href="geo.html#semivariograma-empírico"><i class="fa fa-check"></i><b>38.3.3</b> Semivariograma empírico</a></li>
<li class="chapter" data-level="38.3.4" data-path="geo.html"><a href="geo.html#ajuste-semivariográfico"><i class="fa fa-check"></i><b>38.3.4</b> Ajuste semivariográfico</a></li>
</ul></li>
<li class="chapter" data-level="38.4" data-path="geo.html"><a href="geo.html#kriging"><i class="fa fa-check"></i><b>38.4</b> Kriging</a></li>
</ul></li>
<li class="chapter" data-level="39" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html"><i class="fa fa-check"></i><b>39</b> Procesos de punto</a>
<ul>
<li class="chapter" data-level="39.1" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html#spatial-point-patterns-on-mathbb-r2"><i class="fa fa-check"></i><b>39.1</b> Spatial point patterns on <span class="math inline">\(\mathbb R^2\)</span></a>
<ul>
<li class="chapter" data-level="39.1.1" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html#kernel-based-intensity-estimation"><i class="fa fa-check"></i><b>39.1.1</b> Kernel-based intensity estimation</a></li>
<li class="chapter" data-level="39.1.2" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html#practical-examples"><i class="fa fa-check"></i><b>39.1.2</b> Practical examples</a></li>
<li class="chapter" data-level="39.1.3" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html#kernel-based-intensity-estimation-over-irregular-domains"><i class="fa fa-check"></i><b>39.1.3</b> Kernel-based intensity estimation over irregular domains</a></li>
<li class="chapter" data-level="39.1.4" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html#voronoi-based-intensity-estimators"><i class="fa fa-check"></i><b>39.1.4</b> Voronoi-based intensity estimators</a></li>
<li class="chapter" data-level="39.1.5" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html#second-order-summary-statistics"><i class="fa fa-check"></i><b>39.1.5</b> Second-order summary statistics</a></li>
</ul></li>
<li class="chapter" data-level="39.2" data-path="procesos-de-punto.html"><a href="procesos-de-punto.html#spatial-point-patterns-on-linear-networks"><i class="fa fa-check"></i><b>39.2</b> Spatial point patterns on linear networks</a></li>
</ul></li>
<li class="chapter" data-level="40" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html"><i class="fa fa-check"></i><b>40</b> Modelos econométricos espaciales</a>
<ul>
<li class="chapter" data-level="40.1" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#la-dependencia-espacial"><i class="fa fa-check"></i><b>40.1</b> La dependencia espacial </a>
<ul>
<li class="chapter" data-level="40.1.1" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#modelización-del-espacio-la-matriz-w"><i class="fa fa-check"></i><b>40.1.1</b> Modelización del espacio: La matriz W</a></li>
</ul></li>
<li class="chapter" data-level="40.2" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#medidas-de-autocorrelación"><i class="fa fa-check"></i><b>40.2</b> Medidas de Autocorrelación </a>
<ul>
<li class="chapter" data-level="40.2.1" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#el-indicador-i-de-moran"><i class="fa fa-check"></i><b>40.2.1</b> El indicador <em>I</em> de Moran</a></li>
</ul></li>
<li class="chapter" data-level="40.3" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#modelos-econométricos-espaciales-de-corte-transversal"><i class="fa fa-check"></i><b>40.3</b> Modelos econométricos espaciales de corte transversal </a>
<ul>
<li class="chapter" data-level="40.3.1" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#estimación-sar"><i class="fa fa-check"></i><b>40.3.1</b> Estimación SAR</a></li>
<li class="chapter" data-level="40.3.2" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#comparando-sar-contra-sdm"><i class="fa fa-check"></i><b>40.3.2</b> Comparando SAR contra SDM</a></li>
<li class="chapter" data-level="40.3.3" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#interpretación-de-los-estimadores-de-los-modelos-de-autocorrelación-espacial"><i class="fa fa-check"></i><b>40.3.3</b> Interpretación de los estimadores de los modelos de autocorrelación espacial </a></li>
<li class="chapter" data-level="40.3.4" data-path="cap-econom-esp.html"><a href="cap-econom-esp.html#impacto-del-sar"><i class="fa fa-check"></i><b>40.3.4</b> Impacto del SAR</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>VIII Otros tipos de datos</b></span></li>
<li class="chapter" data-level="41" data-path="mineria-textos.html"><a href="mineria-textos.html"><i class="fa fa-check"></i><b>41</b> Minería de textos</a>
<ul>
<li class="chapter" data-level="41.1" data-path="mineria-textos.html"><a href="mineria-textos.html#introducción-22"><i class="fa fa-check"></i><b>41.1</b> Introducción</a></li>
<li class="chapter" data-level="41.2" data-path="mineria-textos.html"><a href="mineria-textos.html#secCONCEPTOS"><i class="fa fa-check"></i><b>41.2</b> Conceptos y tareas fundamentales</a>
<ul>
<li class="chapter" data-level="41.2.1" data-path="mineria-textos.html"><a href="mineria-textos.html#preparación-de-los-datos"><i class="fa fa-check"></i><b>41.2.1</b> Preparación de los datos</a></li>
<li class="chapter" data-level="41.2.2" data-path="mineria-textos.html"><a href="mineria-textos.html#secTOKEN"><i class="fa fa-check"></i><b>41.2.2</b> Segmentación del texto: tokenización</a></li>
<li class="chapter" data-level="41.2.3" data-path="mineria-textos.html"><a href="mineria-textos.html#secESTILOM"><i class="fa fa-check"></i><b>41.2.3</b> Campos de aplicación de la minería de textos</a></li>
<li class="chapter" data-level="41.2.4" data-path="mineria-textos.html"><a href="mineria-textos.html#minería-de-textos-en-r"><i class="fa fa-check"></i><b>41.2.4</b> Minería de textos en <code>R</code></a></li>
</ul></li>
<li class="chapter" data-level="41.3" data-path="mineria-textos.html"><a href="mineria-textos.html#secSENTIM"><i class="fa fa-check"></i><b>41.3</b> Análisis de sentimientos</a></li>
<li class="chapter" data-level="41.4" data-path="mineria-textos.html"><a href="mineria-textos.html#caso-de-aplicación"><i class="fa fa-check"></i><b>41.4</b> Caso de aplicación</a>
<ul>
<li class="chapter" data-level="41.4.1" data-path="mineria-textos.html"><a href="mineria-textos.html#declaración-institucional-del-estado-de-alarma-2020"><i class="fa fa-check"></i><b>41.4.1</b> Declaración institucional del estado de alarma 2020</a></li>
<li class="chapter" data-level="41.4.2" data-path="mineria-textos.html"><a href="mineria-textos.html#segmentación-en-palabras-y-oraciones"><i class="fa fa-check"></i><b>41.4.2</b> Segmentación en palabras y oraciones</a></li>
<li class="chapter" data-level="41.4.3" data-path="mineria-textos.html"><a href="mineria-textos.html#análisis-exploratorio"><i class="fa fa-check"></i><b>41.4.3</b> Análisis exploratorio</a></li>
<li class="chapter" data-level="41.4.4" data-path="mineria-textos.html"><a href="mineria-textos.html#secSENTYEMO"><i class="fa fa-check"></i><b>41.4.4</b> Análisis de sentimientos y detección de emociones</a></li>
<li class="chapter" data-level="41.4.5" data-path="mineria-textos.html"><a href="mineria-textos.html#n-gramas"><i class="fa fa-check"></i><b>41.4.5</b> <em>N-gramas</em></a></li>
<li class="chapter" data-level="41.4.6" data-path="mineria-textos.html"><a href="mineria-textos.html#análisis-de-redes"><i class="fa fa-check"></i><b>41.4.6</b> Análisis de redes</a></li>
<li class="chapter" data-level="" data-path="mineria-textos.html"><a href="mineria-textos.html#resumen-11"><i class="fa fa-check"></i>Resumen</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="42" data-path="grafos.html"><a href="grafos.html"><i class="fa fa-check"></i><b>42</b> Análisis de grafos y redes sociales</a>
<ul>
<li class="chapter" data-level="42.1" data-path="grafos.html"><a href="grafos.html#introducción-23"><i class="fa fa-check"></i><b>42.1</b> Introducción</a></li>
<li class="chapter" data-level="42.2" data-path="grafos.html"><a href="grafos.html#teoría-de-grafos"><i class="fa fa-check"></i><b>42.2</b> Teoría de grafos</a></li>
<li class="chapter" data-level="42.3" data-path="grafos.html"><a href="grafos.html#elementos-de-un-grafo"><i class="fa fa-check"></i><b>42.3</b> Elementos de un grafo</a></li>
<li class="chapter" data-level="42.4" data-path="grafos.html"><a href="grafos.html#el-paquete-igraph"><i class="fa fa-check"></i><b>42.4</b> El paquete <code>igraph</code></a></li>
<li class="chapter" data-level="42.5" data-path="grafos.html"><a href="grafos.html#análisis-de-influencia-en-un-grafo-aplicado-a-redes-sociales"><i class="fa fa-check"></i><b>42.5</b> Análisis de influencia en un grafo aplicado a redes sociales</a></li>
<li class="chapter" data-level="42.6" data-path="grafos.html"><a href="grafos.html#otras-utilidades-de-grafos"><i class="fa fa-check"></i><b>42.6</b> Otras utilidades de grafos</a></li>
</ul></li>
<li class="part"><span><b>IX Tópicos en ciencia de datos</b></span></li>
<li class="chapter" data-level="43" data-path="shiny.html"><a href="shiny.html"><i class="fa fa-check"></i><b>43</b> Aplicaciones webs interactivas con Shiny</a>
<ul>
<li class="chapter" data-level="43.1" data-path="shiny.html"><a href="shiny.html#introducción-24"><i class="fa fa-check"></i><b>43.1</b> Introducción</a></li>
<li class="chapter" data-level="43.2" data-path="shiny.html"><a href="shiny.html#partes-mínimas-de-una-aplicación-shiny-y-disposición-básica"><i class="fa fa-check"></i><b>43.2</b> Partes mínimas de una aplicación <code>Shiny</code> y disposición básica</a></li>
<li class="chapter" data-level="43.3" data-path="shiny.html"><a href="shiny.html#diseño-de-una-aplicación-shiny"><i class="fa fa-check"></i><b>43.3</b> Diseño de una aplicación <code>Shiny</code></a>
<ul>
<li class="chapter" data-level="43.3.1" data-path="shiny.html"><a href="shiny.html#diseño-de-las-páginas-fluidpage"><i class="fa fa-check"></i><b>43.3.1</b> Diseño de las páginas: fluidPage()</a></li>
<li class="chapter" data-level="43.3.2" data-path="shiny.html"><a href="shiny.html#segmentación-de-diseños-tabsetpanel-y-navlistpanel"><i class="fa fa-check"></i><b>43.3.2</b> Segmentación de diseños: tabsetPanel() y navlistPanel()</a></li>
</ul></li>
<li class="chapter" data-level="43.4" data-path="shiny.html"><a href="shiny.html#elementos-para-entrada-de-datos"><i class="fa fa-check"></i><b>43.4</b> Elementos para entrada de datos</a>
<ul>
<li class="chapter" data-level="43.4.1" data-path="shiny.html"><a href="shiny.html#lectura-de-ficheros-de-datos"><i class="fa fa-check"></i><b>43.4.1</b> Lectura de ficheros de datos</a></li>
</ul></li>
<li class="chapter" data-level="43.5" data-path="shiny.html"><a href="shiny.html#elementos-para-visualización-salida"><i class="fa fa-check"></i><b>43.5</b> Elementos para visualización (salida)</a></li>
<li class="chapter" data-level="43.6" data-path="shiny.html"><a href="shiny.html#reactividad"><i class="fa fa-check"></i><b>43.6</b> Reactividad</a>
<ul>
<li class="chapter" data-level="43.6.1" data-path="shiny.html"><a href="shiny.html#conductores-reactivos-y-control-de-la-reactividad"><i class="fa fa-check"></i><b>43.6.1</b> Conductores reactivos y control de la reactividad</a></li>
</ul></li>
<li class="chapter" data-level="43.7" data-path="shiny.html"><a href="shiny.html#publicación-de-la-aplicación-en-la-web"><i class="fa fa-check"></i><b>43.7</b> Publicación de la aplicación en la web</a></li>
<li class="chapter" data-level="43.8" data-path="shiny.html"><a href="shiny.html#extensiones-de-shiny"><i class="fa fa-check"></i><b>43.8</b> Extensiones de <code>Shiny</code></a></li>
</ul></li>
<li class="chapter" data-level="44" data-path="id_120007-informes.html"><a href="id_120007-informes.html"><i class="fa fa-check"></i><b>44</b> Informes reproducibles con R Markdown y Quarto</a>
<ul>
<li class="chapter" data-level="44.1" data-path="id_120007-informes.html"><a href="id_120007-informes.html#introducción-25"><i class="fa fa-check"></i><b>44.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="44.1.1" data-path="id_120007-informes.html"><a href="id_120007-informes.html#por-qué-informes-reproducibles"><i class="fa fa-check"></i><b>44.1.1</b> ¿Por qué informes reproducibles?</a></li>
<li class="chapter" data-level="44.1.2" data-path="id_120007-informes.html"><a href="id_120007-informes.html#markdown-r-markdown-quarto-y-rstudio"><i class="fa fa-check"></i><b>44.1.2</b> Markdown, R Markdown, Quarto y RStudio</a></li>
</ul></li>
<li class="chapter" data-level="44.2" data-path="id_120007-informes.html"><a href="id_120007-informes.html#documentos-quarto"><i class="fa fa-check"></i><b>44.2</b> Documentos Quarto</a>
<ul>
<li class="chapter" data-level="44.2.1" data-path="id_120007-informes.html"><a href="id_120007-informes.html#encabezado-yaml-y-configuración"><i class="fa fa-check"></i><b>44.2.1</b> Encabezado YAML y configuración</a></li>
<li class="chapter" data-level="44.2.2" data-path="id_120007-informes.html"><a href="id_120007-informes.html#formateado-de-texto"><i class="fa fa-check"></i><b>44.2.2</b> Formateado de texto</a></li>
<li class="chapter" data-level="44.2.3" data-path="id_120007-informes.html"><a href="id_120007-informes.html#inclusión-de-código-en-el-documento"><i class="fa fa-check"></i><b>44.2.3</b> Inclusión de código en el documento</a></li>
<li class="chapter" data-level="44.2.4" data-path="id_120007-informes.html"><a href="id_120007-informes.html#opciones-de-los-bloques-de-código-chunks"><i class="fa fa-check"></i><b>44.2.4</b> Opciones de los bloques de código (<em>chunks</em>)</a></li>
<li class="chapter" data-level="44.2.5" data-path="id_120007-informes.html"><a href="id_120007-informes.html#referencias-cruzadas-y-formateo-de-tablas"><i class="fa fa-check"></i><b>44.2.5</b> Referencias cruzadas y formateo de tablas</a></li>
</ul></li>
<li class="chapter" data-level="44.3" data-path="id_120007-informes.html"><a href="id_120007-informes.html#otros-formatos"><i class="fa fa-check"></i><b>44.3</b> Otros formatos</a></li>
</ul></li>
<li class="chapter" data-level="45" data-path="github.html"><a href="github.html"><i class="fa fa-check"></i><b>45</b> Git y GitHub en R</a>
<ul>
<li class="chapter" data-level="45.1" data-path="github.html"><a href="github.html#qué-es-git"><i class="fa fa-check"></i><b>45.1</b> ¿Qué es Git?</a></li>
<li class="chapter" data-level="45.2" data-path="github.html"><a href="github.html#qué-es-github"><i class="fa fa-check"></i><b>45.2</b> ¿Qué es GitHub?</a></li>
<li class="chapter" data-level="45.3" data-path="github.html"><a href="github.html#por-qué-usar-git-y-github"><i class="fa fa-check"></i><b>45.3</b> ¿Por qué usar Git y GitHub?</a></li>
<li class="chapter" data-level="45.4" data-path="github.html"><a href="github.html#configuración"><i class="fa fa-check"></i><b>45.4</b> Configuración</a></li>
<li class="chapter" data-level="45.5" data-path="github.html"><a href="github.html#configurar-git"><i class="fa fa-check"></i><b>45.5</b> Configurar git</a></li>
<li class="chapter" data-level="45.6" data-path="github.html"><a href="github.html#workflow"><i class="fa fa-check"></i><b>45.6</b> Workflow</a></li>
</ul></li>
<li class="chapter" data-level="46" data-path="cap-geoprocesamiento.html"><a href="cap-geoprocesamiento.html"><i class="fa fa-check"></i><b>46</b> Geoprocesamiento en nube</a>
<ul>
<li class="chapter" data-level="46.1" data-path="cap-geoprocesamiento.html"><a href="cap-geoprocesamiento.html#sintaxis-de-google-earth-engine"><i class="fa fa-check"></i><b>46.1</b> Sintaxis de Google Earth Engine</a></li>
<li class="chapter" data-level="46.2" data-path="cap-geoprocesamiento.html"><a href="cap-geoprocesamiento.html#primeros-pasos"><i class="fa fa-check"></i><b>46.2</b> Primeros pasos</a></li>
<li class="chapter" data-level="46.3" data-path="cap-geoprocesamiento.html"><a href="cap-geoprocesamiento.html#cálculo-de-anomalias"><i class="fa fa-check"></i><b>46.3</b> Cálculo de anomalias</a>
<ul>
<li class="chapter" data-level="46.3.1" data-path="cap-geoprocesamiento.html"><a href="cap-geoprocesamiento.html#definiciones-previas"><i class="fa fa-check"></i><b>46.3.1</b> Definiciones previas</a></li>
<li class="chapter" data-level="46.3.2" data-path="cap-geoprocesamiento.html"><a href="cap-geoprocesamiento.html#promedio-estival"><i class="fa fa-check"></i><b>46.3.2</b> Promedio estival</a></li>
</ul></li>
</ul></li>
<li class="part"><span><b>X Casos de estudio en ciencia de datos</b></span></li>
<li class="chapter" data-level="47" data-path="cap-crimen.html"><a href="cap-crimen.html"><i class="fa fa-check"></i><b>47</b> Análisis de una red criminal</a>
<ul>
<li class="chapter" data-level="47.1" data-path="cap-crimen.html"><a href="cap-crimen.html#el-dataset-oversize"><i class="fa fa-check"></i><b>47.1</b> El <em>dataset Oversize</em></a></li>
<li class="chapter" data-level="47.2" data-path="cap-crimen.html"><a href="cap-crimen.html#creación-del-grafo"><i class="fa fa-check"></i><b>47.2</b> Creación del grafo</a></li>
<li class="chapter" data-level="47.3" data-path="cap-crimen.html"><a href="cap-crimen.html#visualización-del-grafo"><i class="fa fa-check"></i><b>47.3</b> Visualización del grafo</a></li>
<li class="chapter" data-level="47.4" data-path="cap-crimen.html"><a href="cap-crimen.html#importancia-de-los-actores"><i class="fa fa-check"></i><b>47.4</b> Importancia de los actores</a></li>
<li class="chapter" data-level="47.5" data-path="cap-crimen.html"><a href="cap-crimen.html#identificación-de-comunidades"><i class="fa fa-check"></i><b>47.5</b> Identificación de comunidades</a></li>
<li class="chapter" data-level="47.6" data-path="cap-crimen.html"><a href="cap-crimen.html#visualización-de-comunidades"><i class="fa fa-check"></i><b>47.6</b> Visualización de comunidades</a></li>
</ul></li>
<li class="chapter" data-level="48" data-path="cap-publidiad.html"><a href="cap-publidiad.html"><i class="fa fa-check"></i><b>48</b> Optimizando las inversiones publicitarias a través de ciencia de datos</a>
<ul>
<li class="chapter" data-level="48.1" data-path="cap-publidiad.html"><a href="cap-publidiad.html#metodologías-para-optimizar-las-inversiones-publicitarias"><i class="fa fa-check"></i><b>48.1</b> Metodologías para optimizar las inversiones publicitarias</a></li>
<li class="chapter" data-level="48.2" data-path="cap-publidiad.html"><a href="cap-publidiad.html#robyn-como-alternativa-open-source-en-r"><i class="fa fa-check"></i><b>48.2</b> Robyn como alternativa open-source en R</a></li>
</ul></li>
<li class="chapter" data-level="49" data-path="paro-clm.html"><a href="paro-clm.html"><i class="fa fa-check"></i><b>49</b> Cambios en la estructura del paro registrado en Castilla-La Mancha</a>
<ul>
<li class="chapter" data-level="49.1" data-path="paro-clm.html"><a href="paro-clm.html#planteamiento"><i class="fa fa-check"></i><b>49.1</b> Planteamiento</a></li>
<li class="chapter" data-level="49.2" data-path="paro-clm.html"><a href="paro-clm.html#evolución-del-número-total-de-parados"><i class="fa fa-check"></i><b>49.2</b> Evolución del número total de parados</a></li>
<li class="chapter" data-level="49.3" data-path="paro-clm.html"><a href="paro-clm.html#evolución-de-la-edad-y-el-sexo-en-la-población-parada"><i class="fa fa-check"></i><b>49.3</b> Evolución de la edad y el sexo en la población parada</a></li>
<li class="chapter" data-level="49.4" data-path="paro-clm.html"><a href="paro-clm.html#evolución-del-tiempo-de-búsqueda-de-empleo-en-la-población-parada"><i class="fa fa-check"></i><b>49.4</b> Evolución del tiempo de búsqueda de empleo en la población parada</a></li>
<li class="chapter" data-level="49.5" data-path="paro-clm.html"><a href="paro-clm.html#evolución-del-paro-registrado-según-sexo-edad-y-sector-de-procedencia"><i class="fa fa-check"></i><b>49.5</b> Evolución del paro registrado según sexo, edad y sector de procedencia</a></li>
<li class="chapter" data-level="49.6" data-path="paro-clm.html"><a href="paro-clm.html#conclusiones"><i class="fa fa-check"></i><b>49.6</b> Conclusiones</a></li>
</ul></li>
<li class="chapter" data-level="50" data-path="cap-rfm.html"><a href="cap-rfm.html"><i class="fa fa-check"></i><b>50</b> Segmentación de clientes en retail</a>
<ul>
<li class="chapter" data-level="50.1" data-path="cap-rfm.html"><a href="cap-rfm.html#motivación-y-conceptos-clave"><i class="fa fa-check"></i><b>50.1</b> Motivación y conceptos clave</a></li>
<li class="chapter" data-level="50.2" data-path="cap-rfm.html"><a href="cap-rfm.html#del-modelo-rfm-tradicional-al-modelo-rfm-extendido-mejoras-propuestas"><i class="fa fa-check"></i><b>50.2</b> Del Modelo RFM tradicional al Modelo RFM extendido, mejoras propuestas</a></li>
<li class="chapter" data-level="50.3" data-path="cap-rfm.html"><a href="cap-rfm.html#modelo-rfm-extendido"><i class="fa fa-check"></i><b>50.3</b> Modelo RFM extendido</a>
<ul>
<li class="chapter" data-level="50.3.1" data-path="cap-rfm.html"><a href="cap-rfm.html#recopilación-y-comprensión-de-los-datos"><i class="fa fa-check"></i><b>50.3.1</b> Recopilación y comprensión de los datos</a></li>
<li class="chapter" data-level="50.3.2" data-path="cap-rfm.html"><a href="cap-rfm.html#cálculo-de-las-variables-del-modelo-rfm"><i class="fa fa-check"></i><b>50.3.2</b> Cálculo de las variables del Modelo RFM</a></li>
<li class="chapter" data-level="50.3.3" data-path="cap-rfm.html"><a href="cap-rfm.html#breve-análisis-exploratorio-de-las-variables-del-modelo-rfm"><i class="fa fa-check"></i><b>50.3.3</b> Breve análisis exploratorio de las variables del Modelo RFM</a></li>
<li class="chapter" data-level="50.3.4" data-path="cap-rfm.html"><a href="cap-rfm.html#cálculo-del-ranking-de-percentiles"><i class="fa fa-check"></i><b>50.3.4</b> Cálculo del Ranking de percentiles</a></li>
<li class="chapter" data-level="50.3.5" data-path="cap-rfm.html"><a href="cap-rfm.html#modelado-rfm-mediante-k-means"><i class="fa fa-check"></i><b>50.3.5</b> Modelado: RFM mediante k-means</a></li>
<li class="chapter" data-level="50.3.6" data-path="cap-rfm.html"><a href="cap-rfm.html#descriptivos-e-interpretación-de-los-segmentos"><i class="fa fa-check"></i><b>50.3.6</b> Descriptivos e interpretación de los segmentos</a></li>
<li class="chapter" data-level="50.3.7" data-path="cap-rfm.html"><a href="cap-rfm.html#puesta-en-producción"><i class="fa fa-check"></i><b>50.3.7</b> Puesta en producción</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="51" data-path="cap-medicina.html"><a href="cap-medicina.html"><i class="fa fa-check"></i><b>51</b> Ciencia de datos en medicina</a>
<ul>
<li class="chapter" data-level="51.1" data-path="cap-medicina.html"><a href="cap-medicina.html#justificación"><i class="fa fa-check"></i><b>51.1</b> Justificación</a></li>
<li class="chapter" data-level="51.2" data-path="cap-medicina.html"><a href="cap-medicina.html#mecovid"><i class="fa fa-check"></i><b>51.2</b> MeCOVID</a>
<ul>
<li class="chapter" data-level="51.2.1" data-path="cap-medicina.html"><a href="cap-medicina.html#artículos-de-investigación"><i class="fa fa-check"></i><b>51.2.1</b> Artículos de investigación</a></li>
<li class="chapter" data-level="51.2.2" data-path="cap-medicina.html"><a href="cap-medicina.html#análisis-de-supervivencia"><i class="fa fa-check"></i><b>51.2.2</b> Análisis de supervivencia</a></li>
</ul></li>
<li class="chapter" data-level="51.3" data-path="cap-medicina.html"><a href="cap-medicina.html#conclusión"><i class="fa fa-check"></i><b>51.3</b> Conclusión</a></li>
</ul></li>
<li class="chapter" data-level="52" data-path="cap-idealista.html"><a href="cap-idealista.html"><i class="fa fa-check"></i><b>52</b> Valoración del precio de la vivienda, una aproximación espacial bayesiana</a>
<ul>
<li class="chapter" data-level="52.1" data-path="cap-idealista.html"><a href="cap-idealista.html#introducción-26"><i class="fa fa-check"></i><b>52.1</b> Introducción</a></li>
<li class="chapter" data-level="52.2" data-path="cap-idealista.html"><a href="cap-idealista.html#conjunto-de-datos"><i class="fa fa-check"></i><b>52.2</b> Conjunto de datos</a></li>
<li class="chapter" data-level="52.3" data-path="cap-idealista.html"><a href="cap-idealista.html#estimación-del-modelo-1"><i class="fa fa-check"></i><b>52.3</b> Estimación del Modelo</a></li>
</ul></li>
<li class="chapter" data-level="53" data-path="cap-climatico.html"><a href="cap-climatico.html"><i class="fa fa-check"></i><b>53</b> Lo que nos cuentan los datos sobre el cambio climático</a>
<ul>
<li class="chapter" data-level="53.1" data-path="cap-climatico.html"><a href="cap-climatico.html#consideraciones-iniciales"><i class="fa fa-check"></i><b>53.1</b> Consideraciones iniciales</a></li>
<li class="chapter" data-level="53.2" data-path="cap-climatico.html"><a href="cap-climatico.html#paquetes"><i class="fa fa-check"></i><b>53.2</b> Paquetes</a></li>
<li class="chapter" data-level="53.3" data-path="cap-climatico.html"><a href="cap-climatico.html#visualización-de-mapas-de-pequeños-múltiples"><i class="fa fa-check"></i><b>53.3</b> Visualización de mapas de pequeños múltiples</a>
<ul>
<li class="chapter" data-level="53.3.1" data-path="cap-climatico.html"><a href="cap-climatico.html#datos"><i class="fa fa-check"></i><b>53.3.1</b> Datos</a></li>
<li class="chapter" data-level="53.3.2" data-path="cap-climatico.html"><a href="cap-climatico.html#preparar-los-datos"><i class="fa fa-check"></i><b>53.3.2</b> Preparar los datos</a></li>
<li class="chapter" data-level="53.3.3" data-path="cap-climatico.html"><a href="cap-climatico.html#construir-el-gráfico-de-múltiples-mapas"><i class="fa fa-check"></i><b>53.3.3</b> Construir el gráfico de múltiples mapas</a></li>
<li class="chapter" data-level="53.3.4" data-path="cap-climatico.html"><a href="cap-climatico.html#mapa-de-orientación"><i class="fa fa-check"></i><b>53.3.4</b> Mapa de orientación</a></li>
<li class="chapter" data-level="53.3.5" data-path="cap-climatico.html"><a href="cap-climatico.html#exportar-mapa-final"><i class="fa fa-check"></i><b>53.3.5</b> Exportar mapa final</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="54" data-path="cap-ree.html"><a href="cap-ree.html"><i class="fa fa-check"></i><b>54</b> Predicción de demanda eléctrica con deep learning</a>
<ul>
<li class="chapter" data-level="54.1" data-path="cap-ree.html"><a href="cap-ree.html#motivación-1"><i class="fa fa-check"></i><b>54.1</b> Motivación</a></li>
<li class="chapter" data-level="54.2" data-path="cap-ree.html"><a href="cap-ree.html#datos-de-entrada"><i class="fa fa-check"></i><b>54.2</b> Datos de entrada</a></li>
<li class="chapter" data-level="54.3" data-path="cap-ree.html"><a href="cap-ree.html#caso-de-estudio"><i class="fa fa-check"></i><b>54.3</b> Caso de estudio</a></li>
</ul></li>
<li class="chapter" data-level="55" data-path="implementación-de-un-sistema-experto-en-el-ámbito-pediátrico.html"><a href="implementación-de-un-sistema-experto-en-el-ámbito-pediátrico.html"><i class="fa fa-check"></i><b>55</b> Implementación de un sistema experto en el ámbito pediátrico</a>
<ul>
<li class="chapter" data-level="55.1" data-path="implementación-de-un-sistema-experto-en-el-ámbito-pediátrico.html"><a href="implementación-de-un-sistema-experto-en-el-ámbito-pediátrico.html#introducción-27"><i class="fa fa-check"></i><b>55.1</b> Introducción</a></li>
<li class="chapter" data-level="55.2" data-path="implementación-de-un-sistema-experto-en-el-ámbito-pediátrico.html"><a href="implementación-de-un-sistema-experto-en-el-ámbito-pediátrico.html#marco-teórico"><i class="fa fa-check"></i><b>55.2</b> Marco teórico</a>
<ul>
<li class="chapter" data-level="55.2.1" data-path="implementación-de-un-sistema-experto-en-el-ámbito-pediátrico.html"><a href="implementación-de-un-sistema-experto-en-el-ámbito-pediátrico.html#razonamiento"><i class="fa fa-check"></i><b>55.2.1</b> Razonamiento</a></li>
</ul></li>
<li class="chapter" data-level="55.3" data-path="implementación-de-un-sistema-experto-en-el-ámbito-pediátrico.html"><a href="implementación-de-un-sistema-experto-en-el-ámbito-pediátrico.html#sistema-experto-para-el-ámbito-pediátrico-en-atención-primaria"><i class="fa fa-check"></i><b>55.3</b> Sistema experto para el ámbito pediátrico en atención primaria</a></li>
</ul></li>
<li class="chapter" data-level="56" data-path="procesamiento-del-lenguaje-natural-para-identificar-tendencias-de-moda-en-textil.html"><a href="procesamiento-del-lenguaje-natural-para-identificar-tendencias-de-moda-en-textil.html"><i class="fa fa-check"></i><b>56</b> Procesamiento del lenguaje natural para identificar tendencias de moda en textil</a></li>
<li class="chapter" data-level="57" data-path="cap-fraude.html"><a href="cap-fraude.html"><i class="fa fa-check"></i><b>57</b> Dectectando el fraude en tarjetas de crédito</a></li>
<li class="appendix"><span><b>Appendix</b></span></li>
<li class="divider"></li>
<li><a href="https://cdr-book.github.io/"> Ciencia de datos con R </a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Ciencia de datos con R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="análisis-cluster-clusterización-jerárquica" class="section level1 hasAnchor" number="30">
<h1><span class="header-section-number">Capítulo 30</span> Análisis cluster: clusterización jerárquica<a href="análisis-cluster-clusterización-jerárquica.html#análisis-cluster-clusterización-jerárquica" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><em>José-María Montero y Gema Fernández-Avilés</em></p>
<p></p>
<div id="origen-cluster" class="section level2 hasAnchor" number="30.1">
<h2><span class="header-section-number">30.1</span> Introducción<a href="análisis-cluster-clusterización-jerárquica.html#origen-cluster" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El origen de la actividad agrupatoria, hoy en día conocida como análisis cluster o de conglomerados (AC), taxonomía numérica o reconocimiento de patrones, entre otras denominaciones, se remonta a tiempos de Aristóteles y su discípulo Teofrasto. Por tanto, tiene unas profundas raíces y hoy en día se aplica en todos los campos del saber. Se ha evitado la palabra “clasificación” porque existe una pequeña diferencia entre agrupación y clasificación. En la actividad clasificatoria se conoce el número de grupos y qué observaciones del conjunto de datos pertenecen a cada uno, siendo el objetivo clasificar nuevas observaciones en los grupos ya existentes. En la actividad agrupatoria, el número de grupos puede ser conocido (normalmente no lo es), pero no las observaciones que pertenecen a cada uno de ellos, siendo el objetivo la asignación de dichas observaciones a diferentes grupos. Este y los dos siguientes capítulos se centran en este último problema y nos referiremos a él por su denominación más popular: AC.</p>
<p>AC está orientado a la síntesis de la información contenida en un conjunto de datos, normalmente una muestra relativa a objetos, individuos o, en general, elementos, definidos por una serie de características, con vistas a establecer una agrupación de los mismos en función de su mayor o menor homogeneidad. En otros términos, AC trata de agrupar dichos elementos en grupos mutuamente excluyentes, de tal forma que los elementos de cada grupo sean lo más parecidos posible entre sí y lo más diferentes posible de los pertenecientes a otros grupos (Fig. <a href="análisis-cluster-clusterización-jerárquica.html#fig:cluster-sim-ch27">30.1</a>).</p>
<div class="sourceCode" id="cb374"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb374-1"><a href="análisis-cluster-clusterización-jerárquica.html#cb374-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(ggplot2)</span>
<span id="cb374-2"><a href="análisis-cluster-clusterización-jerárquica.html#cb374-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1980</span>)</span>
<span id="cb374-3"><a href="análisis-cluster-clusterización-jerárquica.html#cb374-3" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rnorm</span>(<span class="dv">1500</span>, <span class="at">mean =</span> <span class="sc">-</span><span class="dv">4</span>), <span class="fu">rnorm</span>(<span class="dv">1500</span>, <span class="at">mean =</span> <span class="dv">0</span>))</span>
<span id="cb374-4"><a href="análisis-cluster-clusterización-jerárquica.html#cb374-4" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">rnorm</span>(<span class="dv">1500</span>, <span class="at">mean =</span> <span class="dv">0</span>), <span class="fu">rnorm</span>(<span class="dv">1500</span>, <span class="at">mean =</span> <span class="fl">1.5</span>))</span>
<span id="cb374-5"><a href="análisis-cluster-clusterización-jerárquica.html#cb374-5" aria-hidden="true" tabindex="-1"></a>cluster <span class="ot">&lt;-</span> <span class="fu">as.factor</span>(<span class="fu">c</span>(<span class="fu">rep</span>(<span class="st">&quot;A&quot;</span>, <span class="dv">1500</span>), <span class="fu">rep</span>(<span class="st">&quot;B&quot;</span>, <span class="dv">1500</span>)))</span>
<span id="cb374-6"><a href="análisis-cluster-clusterización-jerárquica.html#cb374-6" aria-hidden="true" tabindex="-1"></a>xy <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(x, y, cluster)</span>
<span id="cb374-7"><a href="análisis-cluster-clusterización-jerárquica.html#cb374-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb374-8"><a href="análisis-cluster-clusterización-jerárquica.html#cb374-8" aria-hidden="true" tabindex="-1"></a><span class="fu">ggplot</span>(<span class="at">data =</span> xy, <span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y)) <span class="sc">+</span></span>
<span id="cb374-9"><a href="análisis-cluster-clusterización-jerárquica.html#cb374-9" aria-hidden="true" tabindex="-1"></a>  <span class="fu">geom_point</span>(<span class="fu">aes</span>(<span class="at">color =</span> cluster)) <span class="sc">+</span></span>
<span id="cb374-10"><a href="análisis-cluster-clusterización-jerárquica.html#cb374-10" aria-hidden="true" tabindex="-1"></a>  <span class="fu">scale_color_manual</span>(<span class="at">values =</span> <span class="fu">c</span>(<span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>))</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:cluster-sim-ch27"></span>
<img src="Ciencia_de_datos_con_r_files/figure-html/cluster-sim-ch27-1.png" alt="Datos simulados que presentan clusters" width="60%" />
<p class="caption">
Figura 30.1: Datos simulados que presentan clusters
</p>
</div>
<p>Para llevar a cabo un AC, se deben tomar una serie de decisiones:</p>
<ul>
<li>Selección de las variables en función de las cuales se van a agrupar los elementos.</li>
<li>Elección del tipo de distancia o medida de similitud que se va a utilizar para medir la disimilitud entre los elementos objeto de clasificación.</li>
<li>Elección de la técnica para formar los grupos o conglomerados.</li>
<li>Determinación del número óptimo de clusters (si no se determina a priori).</li>
</ul>
<p>En este capítulo se abordarán la primera y, sobre todo, la segunda cuestión, dejando las otras dos para los dos capítulos siguientes.</p>
<p>Como ilustración práctica, se utilizará la base de datos <code>TIC2021</code> del paquete <code>cdr</code>, relativa a las estadísticas de uso de las TIC en la Unión Europea en 2021.</p>
<div class="sourceCode" id="cb375"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb375-1"><a href="análisis-cluster-clusterización-jerárquica.html#cb375-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(CDR)</span>
<span id="cb375-2"><a href="análisis-cluster-clusterización-jerárquica.html#cb375-2" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(<span class="st">&quot;TIC2021&quot;</span>)</span></code></pre></div>
</div>
<div id="selección-de-las-variables" class="section level2 hasAnchor" number="30.2">
<h2><span class="header-section-number">30.2</span> Selección de las variables<a href="análisis-cluster-clusterización-jerárquica.html#selección-de-las-variables" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La selección de las <span class="math inline">\(p\)</span> variables o características, <span class="math inline">\(\{X_1, X_2, ..., X_p\}\)</span>, en función de las cuales se va a proceder a la agrupación de los <span class="math inline">\(n\)</span> elementos disponibles es crucial, ya que determina la agrupación final, independientemente de los procedimientos técnicos utilizados. Una vez determinadas éstas, la información disponible, para los elementos objeto de agrupación será:</p>
<table>
<caption><span id="tab:info-muestral">Tabla 30.1: </span> Información muestral</caption>
<thead>
<tr class="header">
<th align="center"></th>
<th><span class="math inline">\(X_1\)</span></th>
<th><span class="math inline">\(X_2\)</span></th>
<th><span class="math inline">\(X_3\)</span></th>
<th><span class="math inline">\(\cdots\)</span></th>
<th><span class="math inline">\(X_p\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Elemento <span class="math inline">\(1\)</span></td>
<td><span class="math inline">\(x_{11}\)</span></td>
<td><span class="math inline">\(x_{12}\)</span></td>
<td><span class="math inline">\(x_{13}\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(x_{1p}\)</span></td>
</tr>
<tr class="even">
<td align="center">Elemento <span class="math inline">\(2\)</span></td>
<td><span class="math inline">\(x_{21}\)</span></td>
<td><span class="math inline">\(x_{22}\)</span></td>
<td><span class="math inline">\(x_{23}\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(x_{2p}\)</span></td>
</tr>
<tr class="odd">
<td align="center">Elemento <span class="math inline">\(3\)</span></td>
<td><span class="math inline">\(x_{31}\)</span></td>
<td><span class="math inline">\(x_{32}\)</span></td>
<td><span class="math inline">\(x_{33}\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(x_{3p}\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
</tr>
<tr class="odd">
<td align="center">Elemento <span class="math inline">\(n\)</span></td>
<td><span class="math inline">\(x_{n1}\)</span></td>
<td><span class="math inline">\(x_{n2}\)</span></td>
<td><span class="math inline">\(x_{n3}\)</span></td>
<td><span class="math inline">\(\cdots\)</span></td>
<td><span class="math inline">\(x_{3p}\)</span></td>
</tr>
</tbody>
</table>
<p>En definitiva, la información de partida es una matriz <span class="math inline">\(\bf X_{\textit n\times \textit p}\)</span> donde cada elemento viene representado por un punto en el espacio <span class="math inline">\(p\)</span>-dimensional de variables, es decir, una matriz que proporciona los valores de las variables para cada elemento<a href="#fn72" class="footnote-ref" id="fnref72"><sup>72</sup></a>.</p>
<p>Una cuestión a tener en cuenta es el número de variables a considerar en el AC. La exclusión de variables relevantes generará una agrupación deficiente. La inclusión de variables irrelevantes complicará el proceso de agrupamiento sin procurar ganancias sustantivas. Dado que el miedo del investigador vendrá por el lado de la exclusión de variables relevantes, tenderá a incluir un número excesivo de variables (muchas de ellas correlacionadas). Por ello, se recomienda realizar previamente un ACP (véase Capítulo <a href="acp.html#acp">32</a>, lo que reduce la dimensionalidad del problema, y llevar a cabo el AC a partir de las componentes principales retenidas (incorreladas, evitando así redundancias). La eliminación de información redundante es una cuestión importante en el proceso de clusterización, porque dicha información estaría sobreponderada en el resultado obtenido. Una solución menos drástica a este problema es la utilización de la distancia de Mahalanobis, que, como se verá posteriormente, corrige estas redundancias.</p>
<p>Otra cuestión importante en este momento es decidir si las variables (o componentes principales en su caso) seleccionadas se utilizarán estandarizadas o no. No existe consenso sobre la cuestión, si bien se suele recomendar su estandarización para evitar consecuencias no deseadas derivadas de la distinta escala y/o unidades de medida. No obstante, autores tan relevantes como Edelborck (1979) y Everitt (1993), están en contra y proponen las siguientes alternativas: (<span class="math inline">\(i\)</span>) recategorizar todas las variables en variables binarias, y aplicar a éstas una distancia apropiada para ese tipo de medidas; <span class="math inline">\((ii)\)</span> realizar distintos AC con grupos de variables homogéneas (en cuanto a su métrica) y sintetizar después los diferentes resultados; y <span class="math inline">\((iii)\)</span> utilizar la distancia de Gower, que es aplicable con cualquier tipo de métrica.</p>
<div class="sourceCode" id="cb376"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb376-1"><a href="análisis-cluster-clusterización-jerárquica.html#cb376-1" aria-hidden="true" tabindex="-1"></a>tic <span class="ot">&lt;-</span> <span class="fu">scale</span>(TIC2021)</span></code></pre></div>
</div>
<div id="elección-de-la-distancia-entre-elementos" class="section level2 hasAnchor" number="30.3">
<h2><span class="header-section-number">30.3</span> Elección de la distancia entre elementos<a href="análisis-cluster-clusterización-jerárquica.html#elección-de-la-distancia-entre-elementos" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Una vez se dispone de la matriz de información <span class="math inline">\(\bf X_{\textit n\times \textit p}\)</span> , la segunda etapa en el AC consiste en la creación de una nueva matriz <span class="math inline">\(\bf D_{\textit n\times \textit n}\)</span> cuyos elementos <span class="math inline">\(\{d_{ij}\}\)</span> sean las distancias o disimilaridades entre los elementos objeto de agrupamiento.</p>
<p>En caso de variables cuantitativas, la distancia entre dos elementos en un espacio de <span class="math inline">\(p\)</span> dimensiones, <span class="math inline">\(d({\bf x}_i;{\bf{x}}_{j})\)</span>, se define como una función que a cada dos puntos de <span class="math inline">\(\mathbb{R}^{p}\)</span> le asocia un número real y que verifica:<a href="#fn73" class="footnote-ref" id="fnref73"><sup>73</sup></a></p>
<ul>
<li><p><span class="math inline">\(d({\bf x}_i;{\bf{x}}_{j}) \geq0\)</span>,</p></li>
<li><p><span class="math inline">\(d({\bf x}_i;{\bf{x}}_{j})=0\)</span> si y sólo si <span class="math inline">\({\bf{x}}_{i}={\bf x}_{j}\)</span>,</p></li>
<li><p><span class="math inline">\(d({\bf x}_i;{\bf{x}}_{j})=d({\bf x}_j;{\bf{x}}_{i})\)</span>,</p></li>
<li><p><span class="math inline">\(d({\bf x}_i;{\bf{x}}_{j})+d({\bf x}_j;{\bf{x}}_{k}) \geq d({\bf x}_i;{\bf{x}}_{k}), \quad \forall{\bf{x}}_{k} \in \mathbb{R}^{p}\)</span>,</p></li>
</ul>
<p>Con variables cualitativas, la similitud entre dos elementos, <span class="math inline">\(s({\bf x}_i;{\bf{x}}_{j})\)</span>, es una función que a cada dos puntos de <span class="math inline">\(\mathbb{R}^{p}\)</span> le asocia un número real, y que verifica:</p>
<ul>
<li><span class="math inline">\(s({\bf x}_i;{\bf{x}}_{j}) \leq s_0\)</span>, donde <span class="math inline">\(s_0\)</span> es un número real finito arbitrario (normalmente 1).</li>
<li><span class="math inline">\(s({\bf x}_i;{\bf{x}}_{j})=s_0\)</span> si y sólo si <span class="math inline">\({\bf{x}}_{i}={\bf x}_{j}\)</span>,</li>
<li><span class="math inline">\(s({\bf x}_i;{\bf{x}}_{j})=s({\bf x}_j;{\bf{x}}_{i})\)</span>,</li>
<li><span class="math inline">\(|s({\bf x}_i;{\bf{x}}_{j})+s({\bf x}_j;{\bf{x}}_{k})|s({\bf x}_i;{\bf{x}}_{z}) \geq d({\bf x}_i;{\bf{x}}_{k})s({\bf x}_j;{\bf{x}}_{k}) \in \mathbb{R}^{p}\)</span>.</li>
</ul>
<p>Son numerosas las formas de medir las distancias o similaridades entre dos elementos, que satisfacen las condiciones expuestas. Las más populares son las siguientes:</p>
<p><strong>Variables cuantitativas</strong></p>
<ul>
<li><strong>Distancia euclídea.</strong> Se define como: <span class="math display">\[\begin{equation}
d_{e}({\bf x}_i;{\bf{x}}_{j})=\sqrt{\sum_{k=1}^{p}\left(  x_{ik}-x_{jk}\right)  ^{2}}
\end{equation}\]</span></li>
</ul>
<p>Ignora las unidades de medida de las variables y, en consecuencia, aunque es invariante a los cambios de origen, no lo es a los cambios de escala. También ignora las relaciones entre ellas. Resulta de utilidad con variables cuantitativas incorreladas y medidas en las mismas unidades. El cuadrado de la distancia euclídea también suele utilizarse como distancia.</p>
<div class="sourceCode" id="cb377"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb377-1"><a href="análisis-cluster-clusterización-jerárquica.html#cb377-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(factoextra)</span>
<span id="cb377-2"><a href="análisis-cluster-clusterización-jerárquica.html#cb377-2" aria-hidden="true" tabindex="-1"></a>d_euclidea <span class="ot">&lt;-</span> <span class="fu">get_dist</span>(<span class="at">x =</span> tic, <span class="at">method =</span> <span class="st">&quot;euclidea&quot;</span>)</span>
<span id="cb377-3"><a href="análisis-cluster-clusterización-jerárquica.html#cb377-3" aria-hidden="true" tabindex="-1"></a><span class="fu">as.matrix</span>(d_euclidea)[<span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>, <span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>]</span>
<span id="cb377-4"><a href="análisis-cluster-clusterización-jerárquica.html#cb377-4" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;          1        2        3        4        5</span></span>
<span id="cb377-5"><a href="análisis-cluster-clusterización-jerárquica.html#cb377-5" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 1 0.000000 6.421631 2.417212 1.870962 2.304686</span></span>
<span id="cb377-6"><a href="análisis-cluster-clusterización-jerárquica.html#cb377-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 2 6.421631 0.000000 4.616177 7.988106 4.871235</span></span>
<span id="cb377-7"><a href="análisis-cluster-clusterización-jerárquica.html#cb377-7" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 3 2.417212 4.616177 0.000000 3.765714 1.366011</span></span>
<span id="cb377-8"><a href="análisis-cluster-clusterización-jerárquica.html#cb377-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 4 1.870962 7.988106 3.765714 0.000000 3.607589</span></span>
<span id="cb377-9"><a href="análisis-cluster-clusterización-jerárquica.html#cb377-9" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; 5 2.304686 4.871235 1.366011 3.607589 0.000000</span></span></code></pre></div>
<p>La Fig. <a href="análisis-cluster-clusterización-jerárquica.html#fig:plot-dist-euclidea">30.2</a> muestra un heatmap<a href="#fn74" class="footnote-ref" id="fnref74"><sup>74</sup></a> de distancias euclideas entre los países de la UE27 a partir deen la Uni las estadísticas de uso de las TIC en 2021.</p>
<div class="sourceCode" id="cb378"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb378-1"><a href="análisis-cluster-clusterización-jerárquica.html#cb378-1" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_dist</span>(<span class="at">dist.obj =</span> d_euclidea, <span class="at">lab_size =</span> <span class="dv">10</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:plot-dist-euclidea"></span>
<img src="Ciencia_de_datos_con_r_files/figure-html/plot-dist-euclidea-1.png" alt="Heatmap de  distancias euclídeas: datos `TIC2021` del paquete `cdr`" width="60%" />
<p class="caption">
Figura 30.2: Heatmap de distancias euclídeas: datos <code>TIC2021</code> del paquete <code>cdr</code>
</p>
</div>
<ul>
<li><strong>Distancia Manhattan o city block.</strong> Se define como: <span class="math display">\[\begin{equation}
d_{MAN}({\bf x}_i;{\bf{x}}_{j})=\sum_{k=1}^{p}\left\vert x_{ik}-x_{jk}\right\vert.
\end{equation}\]</span></li>
</ul>
<p>Viene afectada por los cambios de escala en alguna de las variables y es menos sensible que la distancia euclídea a los valores extremos. Por ello, es recomendable cuando las variables son cuantitativas, con las mismas unidades de medida, sin relaciones entre ellas y con valores extremos.</p>
<ul>
<li><strong>Distancia de Minkowski.</strong> Se define como: <span class="math display">\[\begin{equation}
d_{MIN}({\bf x}_i;{\bf{x}}_{j})=\left(  \sum_{k=1}^{p}\left\vert x_{ik}-x_{jk}\right\vert
^{\lambda}\right)  ^{\frac{1}{\lambda}}.
\end{equation}\]</span></li>
</ul>
<p>Las distancias euclídea y Manhattan son casos particulares de la distancia de Minkowski. En la distancia euclídea <span class="math inline">\(\lambda=2\)</span> y en la Manhattan <span class="math inline">\(\lambda=1.\)</span></p>
<ul>
<li><strong>Norma del supremo o distancia de Chebychev.</strong> Su expresión es: <span class="math display">\[\begin{equation}
d_{CHE}({\bf x}_i;{\bf{x}}_{j})=\max_{1\leq k\leq p}\sum_{k=1}^{p}\left\vert x_{ik}%
-x_{jk}\right\vert.
\end{equation}\]</span></li>
</ul>
<p>Únicamente influye en ella la variable con los valores más extremos y, en este sentido, es muy sensible a los cambios de escala en una de las variables.</p>
<ul>
<li><strong>Distancia de Mahalanobis.</strong> Se define como: <span class="math display">\[\begin{equation}
d_{MAH}=({\bf x}_i;{\bf{x}}_{j})=(\mathbf{x}_{i}-\mathbf{x}_{j})^{\prime}\mathbf{S}^{-1} (\mathbf{x}_{i}-\mathbf{x}_{j})
\end{equation}\]</span></li>
</ul>
<p>Coincide con la distancia euclídea calculada sobre las componentes principales. Es invariante a cambios de origen y de escala (por tanto, se puede sustituir <span class="math inline">\(\bf S\)</span> por <span class="math inline">\(\bf R\)</span>. Además, tiene en cuenta, explícitamente, las correlaciones lineales que puedan existir entre las variables, corrigiendo así el efecto redundancia. Es, por tanto, es apropiada con variables cuantitativas con relaciones aproximadamente lineales. Su principal desventaja es que <span class="math inline">\(\bf S\)</span> involucra, conjuntamente, a todos los elementos, y no únicamente, y de forma separada, a los elementos de cada cluster.</p>
<ul>
<li><strong>Coeficiente de correlación de Pearson.</strong> Se define como:
<span class="math display">\[\begin{equation}
d_{P}({\bf x}_i;{\bf{x}}_{j})=\frac{\sum_{k=1}^{p}\left(  x_{ik}-\overline{x}_{i}\right)  \left(  x_{jk}-\overline{x}_{j}\right)  }{\sqrt{\sum_{k=1}%
^{p}\left(  x_{ik}-\overline{x}_{i}\right)  ^{2}\sum_{k=1}^{p}\left(
x_{jk}-\overline{x}_{j}\right)  ^{2}}}.
\end{equation}\]</span></li>
</ul>
<p>No es una distancia sino un indicador de similitud. Por tanto, valores altos indican elementos similares y valores bajos elementos distintos.</p>
<p>Su campo de variación es <span class="math inline">\([-1,1]\)</span>, por lo que se toma su valor absoluto. Cuando las variables están centradas, se denomina coeficiente de congruencia o distancia coseno, puesto que coincide con el coseno formado por los vectores representativos de cada pareja de elementos. Tiene un inconveniente importante: un valor unitario no significa que los dos elementos sean iguales puesto que también pueden obtenerse valores unitarios cuando los valores de las <span class="math inline">\(p\)</span> variables en uno de los elementos sean combinación lineal de los valores de las <span class="math inline">\(p\)</span> variables del otro.</p>
<p>Se utiliza, en ocasiones, preferentemente con datos cuantitativos y con el algoritmo de distancia mínima. Los coeficientes de correlación por rangos de Kendall y Spearman se utilizan, también, en casos de variables ordinales.</p>
<p>A efectos prácticos, cambiando el argumento <code>method</code> de la función <code>get_dist</code> (<code>euclidea</code>, `<code>maximum</code>, <code>manhattan</code>, <code>minkowski</code>, <code>pearson</code>, <code>spearman</code>, <code>kendall</code>) se obtienen distintas matrices de distancias entre los elementos.</p>
<p><strong>Variables cualitativas (dicotómicas)</strong></p>
<p>En este caso, se pueden establecer distintas medidas de similaridad en base a la siguiente tabla de contingencia <span class="math inline">\(2\times 2\)</span>:</p>
<table>
<thead>
<tr class="header">
<th align="right"></th>
<th align="left"></th>
<th align="center">Elem. <span class="math inline">\(j\)</span></th>
<th align="center"></th>
<th align="center"></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right"></td>
<td align="left"></td>
<td align="center">Presencia</td>
<td align="center">Ausencia</td>
<td align="center">Total</td>
</tr>
<tr class="even">
<td align="right">Elem. <span class="math inline">\(i\)</span></td>
<td align="left">Presencia</td>
<td align="center"><span class="math inline">\(n_{11}\)</span></td>
<td align="center"><span class="math inline">\(n_{12}\)</span></td>
<td align="center"><span class="math inline">\(n_{1\cdot}\)</span></td>
</tr>
<tr class="odd">
<td align="right"></td>
<td align="left">Ausencia</td>
<td align="center"><span class="math inline">\(n_{21}\)</span></td>
<td align="center"><span class="math inline">\(n_{22}\)</span></td>
<td align="center"><span class="math inline">\(n_{2\cdot}\)</span></td>
</tr>
<tr class="even">
<td align="right"></td>
<td align="left">Total</td>
<td align="center"><span class="math inline">\(n_{\cdot1}\)</span></td>
<td align="center"><span class="math inline">\(n_{\cdot2}\)</span></td>
<td align="center"><span class="math inline">\(p\)</span></td>
</tr>
</tbody>
</table>
<p>A partir de la tabla anterior, la similaridad entre dos elementos se puede medir a partir de las coincidencias, ya sea de presencias y ausencias como de solo presencias.</p>
<p>Entre las medidas de similaridad que involucran tanto presencias como ausencias comunes están:</p>
<ul>
<li>El <strong>coeficiente de coincidencias simple</strong>: <span class="math inline">\(c_{cs}=\frac{(n_{11} + n_{22})} {2}\)</span></li>
<li>El <strong>coeficiente de Rogers-Tanimoto</strong>: <span class="math inline">\(c_{RT}=\frac{(n_{11} + n_{22})} {2 (n_{11} + n_{22})+ n_{12}+n_{21}}\)</span></li>
</ul>
<p>Estos dos coeficientes tienen una relación monotónica (si la distancia entre dos elementos es igual o superior a la distancia entre otros dos con una de las medidas, también lo es con la otra). Esto es importante dado que algunos procedimientos de agrupación no se ven afectados por la medida utilizada siempre y cuando el ordenamiento establecido por ellas sea el mismo.</p>
<p>Entre aquellas que identifican similaridad con presencias destacan:</p>
<ul>
<li><p>El <strong>coeficiente de Jacard</strong>: <span class="math inline">\(c_J=\frac{n_{11}} {n_{11} + n_{12}+ n_{21}}\)</span></p></li>
<li><p>El <strong>coeficiente de Czekanowski</strong>: <span class="math inline">\(c_{C}=\frac{2 n_{11}} {2n_{11} + n_{12}+ n_{21}}\)</span></p></li>
<li><p>El <strong>coeficiente de Sokal y Sneath</strong>: <span class="math inline">\(c_{SS}=\frac{n_{11} } {n_{11} + 2(n_{12}+n_{21})}\)</span></p></li>
<li><p>El <strong>coeficiente de Russell y Rao</strong>: <span class="math inline">\(c_{RR}=\frac {n_{11}}{p}\)</span></p></li>
</ul>
<p>Los tres primeros coeficientes disfutan de la relación de monotonicidad en el sentido anteriormente apuntado, siendo las dos primeros las más utilizados en la práctica.</p>
<p>También se usan como indicadores de similitud las medidas de asociación para tablas <span class="math inline">\(2\times2\)</span>, sobre todo <span class="math inline">\(Q\)</span> y <span class="math inline">\(\phi\)</span> (capítulo <a href="tablas-contingencia.html#medidas">20.4</a>).</p>
<p><strong>Variables cualitativas (politómicas)</strong></p>
<p>Cuando todas las variables sean cualitativas y alguna sea politómica, se generan para estas ultimas tantas variables dicotómicas como categorías tienen, denotando con 1 la presencia y con 0 la ausencia.</p>
<p><strong>Variables cuantitativas y cualitativas</strong></p>
<p>Si las variables no son del mismo tipo, se utiliza la medida de similaridad de Gower:</p>
<p><span class="math display">\[\begin{equation}
    S_{ij}({\bf x}_i;{\bf{x}}_{j})=\frac{\sum_{k=1}^{p}s_{ij}}{\sum_{k=1}^{p}w_{ij}}
    \end{equation}\]</span></p>
<p>donde <span class="math inline">\(w_{ij}\)</span> vale siempre la unidad salvo para variables binarias si los dos elementos presentan el valor cero. En cuanto al valor de <span class="math inline">\(S_{ij}\)</span>, se distinguen tres casos:</p>
<ul>
<li>Variables cualitativas de más de dos niveles: 1 si ambos elementos son iguales en la <em>k</em>-ésima variable; 0 si son diferentes.</li>
<li>Variables dicotómicas: 1 si la variable considerada está presente en ambos elementos; 0 en los demás casos.</li>
<li>Variables cuantitativas: <span class="math inline">\(1-\frac {|x_{ik}-x_{jk}|}{R_k}\)</span>, donde <span class="math inline">\(R\)</span> es el rango de la variable <em>k</em>.</li>
</ul>
<p>No es recomendable cuando las variables cuantitativas sean muy asimétricas. En este caso, hay dos procedimientos aproximados: <span class="math inline">\((i)\)</span> calcular medidas separadas para las variables cuantitativas y cualitativas y combinarlas estableciendo algún tipo de de ponderación; <span class="math inline">\((ii)\)</span> pasar las variables cuantitativas a cualitativas y utilizar las medidas propuestas para este tipo de variables.</p>
</div>
<div id="técnicas-de-agrupación-jerárquicas" class="section level2 hasAnchor" number="30.4">
<h2><span class="header-section-number">30.4</span> Técnicas de agrupación jerárquicas<a href="análisis-cluster-clusterización-jerárquica.html#técnicas-de-agrupación-jerárquicas" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="introac" class="section level3 hasAnchor" number="30.4.1">
<h3><span class="header-section-number">30.4.1</span> Introducción<a href="análisis-cluster-clusterización-jerárquica.html#introac" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Una vez se han seleccionado las variables en función de las cuales se van a agrupar en clusters o conglomerados los elementos disponibles, así como se ha decidido qué distancia utilizar para tal propósito, el siguiente paso del AC es la selección de un criterio o técnica de agrupamiento para formar los conglomerados. Dichas técnicas se pueden clasificar en <span class="math inline">\((i)\)</span> jerárquicas y <span class="math inline">\((ii)\)</span> no jerárquicas.</p>
<div class="infobox">
<p><strong>TÉCNICAS DE CLUSTERIZACIÓN</strong>:</p>
<ol style="list-style-type: decimal">
<li><strong>Jerárquicas</strong>:
<ul>
<li><em>Aglomerativas</em>:
<ul>
<li>Vecino más cerano o encadenamiento simple</li>
<li>Vecino más lejano o encadenamiento completo</li>
<li>Método de la distancia media</li>
<li>Método de la distancia entre centroides</li>
<li>Método de la mediana</li>
<li>Método de Ward</li>
<li>Encadenamiento intragrupos</li>
<li>Método flexible de Lance y Williams</li>
</ul></li>
<li><em>Divisivas</em>:
<ul>
<li>Vecino más cerano o encadenamiento simple</li>
<li>Vecino más lejano o encadenamiento completo</li>
<li>Método de la distancia media</li>
<li>Método de la distancia entre centroides</li>
<li>Método de la mediana</li>
<li>Método de Ward</li>
<li>Encadenamiento intragrupos</li>
<li>Análisis de la asociación</li>
<li>Detector automático de interacciones</li>
</ul></li>
</ul></li>
<li><strong>No jerárquicas</strong>:
<ul>
<li><em>Técnicas de reasignación</em>:
<ul>
<li>Basadas en centroides: Método de Forgy, <span class="math inline">\(k\)</span>-medias</li>
<li>Basadas en medoides: <span class="math inline">\(k\)</span>-medoides, PAM, CLARA, CLARANS</li>
<li>Basadas en medianas: <span class="math inline">\(k\)</span>-medianas</li>
</ul></li>
<li><em>Técnicas basadas en la densidad de puntos (mode-seeking)</em>:
<ul>
<li>Aproximación tipológica: Análisis modal, métodos taxmap, de Fortin, de Gitman y Levine, de Catel y Coulter</li>
<li>Aproximación probabilística: método de Wolf</li>
<li>DBSCAN</li>
</ul></li>
<li><em>Otras técnicas no jerárquicas</em>
<ul>
<li>Métodos directos: block-; bi; co-; two-mode clustering</li>
<li>Métodos de reducción de la dimensionalidad: modelos
Q- y R-factorial</li>
<li>Clustering difuso</li>
<li>Métodos basados en mixturas de modelos</li>
</ul></li>
</ul></li>
</ol>
</div>
<p>Los procedimientos jerárquicos no particionan el conjunto de elementos de una sola vez, sino que realizan particiones sucesivas a distintos niveles de agrupamiento; es decir, establecen una jerarquía de clusters, de ahí su nombre. Forman los conglomerados, bien agrupando los elementos en grupos cada vez más grandes, fusionando grupos en cada paso, (jerárquicos aglomerativos), o bien desagregándolos en conglomerados cada vez más pequeños (jerárquicos divisivos).</p>
<p>Las técnicas no jerárquicas se caracterizan porque <span class="math inline">\((i)\)</span> el número de clusters se suele determinar a priori; <span class="math inline">\((ii)\)</span> utilizan directamente los datos originales, si necesidad de calcular una matriz de distancias o similaridades; y <span class="math inline">\((iii)\)</span> los clusters resultantes no están anidados unos en otros, sino que están separados. La caja informativa proporciona un detalle mayor de la tipología de técnicas de agrupación a la que nos vamos a referir<a href="#fn75" class="footnote-ref" id="fnref75"><sup>75</sup></a>. En lo que sigue, nos centramos en las técnicas jerárquicas, abordando las no jerárquicas en el Capítulo <a href="no-jerarquico.html#no-jerarquico">31</a>.</p>
</div>
<div id="técnicas-jerárquicas-aglomerativas" class="section level3 hasAnchor" number="30.4.2">
<h3><span class="header-section-number">30.4.2</span> Técnicas jerárquicas aglomerativas<a href="análisis-cluster-clusterización-jerárquica.html#técnicas-jerárquicas-aglomerativas" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Las técnicas jerárquicas aglomerativas, de amplia utilización, parten de tantos conglomerados como elementos y llegan a un único conglomerado final.</p>
<p>Se parte de un conglomerado constituido por los dos elementos más próximos, de tal manera que en la segunda etapa el conglomerado formado actuará a modo de elemento (como si se tuviesen <span class="math inline">\(n-1\)</span> elementos). En la segunda etapa, de nuevo se agrupan de nuevo los dos elementos más cercanos, que pueden ser dos elementos simples o uno simple y otro compuesto (el conglomerado anterior); en el primer caso se tendrían dos conglomerados (cada uno de ellos formado por dos elementos) y en el segundo, un conglomerado con tres elementos y otro con uno. Sea cual sea el caso, al final de la segunda etapa se tienen <span class="math inline">\(n-2\)</span> elementos, dos de los cuales son conglomerados. En las etapas siguientes se procede de idéntica manera: agrupación de los dos elementos (sean elementos simples o conglomerados formados en las etapas anteriores) más cercanos, y así sucesivamente hasta formar un único conglomerado integrado por todos los elementos. Es importante resaltar que un elemento, una vez forma parte de un conglomerado, ya no sale de él.</p>
<p>La pregunta que surge en este momento es: en el proceso de agrupamiento descrito, ¿cómo se mide la distancia de un elemento a un conglomerado, o entre dos conglomerados?<a href="#fn76" class="footnote-ref" id="fnref76"><sup>76</sup></a> Los métodos más populares son los siguientes:</p>
<ul>
<li><strong>Método del encadenamiento simple o vecino más cercano.</strong> </li>
</ul>
<p>Utiliza el criterio de “<em>la distancia mas cercana</em>”. Por tanto, <span class="math inline">\((i)\)</span> la distancia entre un elemento y un conglomerado es la menor de las distancias entre dicho elemento y cada uno de los elementos del conglomerado; <span class="math inline">\((ii)\)</span> la distancia entre dos conglomerados viene dada por la distancia entre sus dos elementos más cercanos. Una vez computada la matriz de distancias se seleccionan los conglomerados más cercanos.</p>
<ul>
<li><strong>Método del encadenamiento completo o vecino más lejano.</strong></li>
</ul>
<p>Funciona igual que el anterior, pero ahora el criterio es “<em>la distancia más lejana</em>”.</p>
<p>Nótese que mientras que con el método del vecino más cerano la distancia entre los elementos más próximos de un cluster es siempre menor que la distancia entre elementos de distintos clusters, con el criterio del vecino más lejano la distancia entre los dos elementos más alejados de un cluster es siempre menor que la distancia entre cualquiera de sus elementos y los elementos más alejados de los demás clusters. Nótese también que mientras que el método del vecino más lejano tiende a separar a los individuos en menor medida que la indicada por sus disimilaridades iniciales (es espacio-contractivo), el criterio del vecino más lejano es espacio-dilatante, es decir, tiende a separar a los individuos en mayor medida que la indicada por sus disimilaridades iniciales <span class="citation">(<a href="#ref-gallardoyvera2004" role="doc-biblioref">Gallardo-San Salvador and Vera-Vera 2004</a>)</span>.</p>
<ul>
<li><strong>Método de la distancia media.</strong></li>
</ul>
<p>Surge como una solución a la constricción o dilatación del espacio que provocan los dos métodos anteriores (por eso se dice que es espacio-conservativo y es muy utilizado), utilizando “<em>la distancia promedio</em>” , es decir, la distancia entre un elemento y un conglomerado es la media aritmética de las distancias de dicho elemento a cada uno de los elementos del conglomerado. En caso de dos conglomerados, la distancia entre ellos viene dada por el promedio aritmético de las distancias, dos a dos, un elemento de cada conglomerado. Igual que los dos métodos precedentes, es invariante a transformaciones monótonas de la distancia utilizada.</p>
<p>En la Fig. <a href="análisis-cluster-clusterización-jerárquica.html#fig:cluster-compara">30.3</a> se puede ver la constricción, dilatación y conservación del espacio que producen los métodos del vecino más cercano, más lejano y de la distancia media, respectivamente. En este caso se utiliza como representación gráfica el dendrograma(diagrama de árbol). En figuras posteriores se utilizarán otras alternativas al dendrograma, con el objetivo de mostrar las más populares.</p>
<div class="sourceCode" id="cb379"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb379-1"><a href="análisis-cluster-clusterización-jerárquica.html#cb379-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(factoextra)</span>
<span id="cb379-2"><a href="análisis-cluster-clusterización-jerárquica.html#cb379-2" aria-hidden="true" tabindex="-1"></a>hc_simple <span class="ot">&lt;-</span> <span class="fu">hcut</span>(tic, <span class="at">k =</span> <span class="dv">3</span>, <span class="at">hc_method =</span> <span class="st">&quot;single&quot;</span>)</span>
<span id="cb379-3"><a href="análisis-cluster-clusterización-jerárquica.html#cb379-3" aria-hidden="true" tabindex="-1"></a>hc_completo <span class="ot">&lt;-</span> <span class="fu">hcut</span>(tic, <span class="at">k =</span> <span class="dv">3</span>, <span class="at">hc_method =</span> <span class="st">&quot;complete&quot;</span>)</span>
<span id="cb379-4"><a href="análisis-cluster-clusterización-jerárquica.html#cb379-4" aria-hidden="true" tabindex="-1"></a>hc_promedio <span class="ot">&lt;-</span> <span class="fu">hcut</span>(tic, <span class="at">k =</span> <span class="dv">3</span>, <span class="at">hc_method =</span> <span class="st">&quot;average&quot;</span>)</span>
<span id="cb379-5"><a href="análisis-cluster-clusterización-jerárquica.html#cb379-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb379-6"><a href="análisis-cluster-clusterización-jerárquica.html#cb379-6" aria-hidden="true" tabindex="-1"></a>d1 <span class="ot">&lt;-</span> <span class="fu">fviz_dend</span>(hc_simple, <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">k =</span> <span class="dv">3</span>, <span class="at">main =</span> <span class="st">&quot;Vecino más cercano&quot;</span>)</span>
<span id="cb379-7"><a href="análisis-cluster-clusterización-jerárquica.html#cb379-7" aria-hidden="true" tabindex="-1"></a>d2 <span class="ot">&lt;-</span> <span class="fu">fviz_dend</span>(hc_completo, <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">k =</span> <span class="dv">3</span>, <span class="at">main =</span> <span class="st">&quot;Vecino más lejano&quot;</span>)</span>
<span id="cb379-8"><a href="análisis-cluster-clusterización-jerárquica.html#cb379-8" aria-hidden="true" tabindex="-1"></a>d3 <span class="ot">&lt;-</span> <span class="fu">fviz_dend</span>(hc_promedio, <span class="at">cex =</span> <span class="fl">0.5</span>, <span class="at">k =</span> <span class="dv">3</span>, <span class="at">main =</span> <span class="st">&quot;Distancia promedio&quot;</span>)</span>
<span id="cb379-9"><a href="análisis-cluster-clusterización-jerárquica.html#cb379-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb379-10"><a href="análisis-cluster-clusterización-jerárquica.html#cb379-10" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb379-11"><a href="análisis-cluster-clusterización-jerárquica.html#cb379-11" aria-hidden="true" tabindex="-1"></a>d1 <span class="sc">+</span> d2 <span class="sc">+</span> d3</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:cluster-compara"></span>
<img src="Ciencia_de_datos_con_r_files/figure-html/cluster-compara-1.png" alt="Clusterización jerárquica con distancias euclídeas (dendrograma): métodos del vecino más cercano, vecino más lejano y distancia media" width="60%" />
<p class="caption">
Figura 30.3: Clusterización jerárquica con distancias euclídeas (dendrograma): métodos del vecino más cercano, vecino más lejano y distancia media
</p>
</div>
<ul>
<li><strong>Método de la distancia entre centroides.</strong></li>
</ul>
<p>Según este método, la distancia entre dos grupos o conglomerados es la distancia entre sus centroides, entendiendo por centroide del grupo <span class="math inline">\(g\)</span>: <span class="math inline">\(c_{g}=\left(\overline{x}_{1g},\overline{x}_{2g},...,\overline{x}_{pg}\right),\)</span> donde <span class="math inline">\(\overline{x}_{jg}\)</span> es la media de la <span class="math inline">\(j\)</span>-ésima variable en dicho grupo.</p>
<p>Igual que el método de la media, este método es también espacio-conservativo. Sin embargo, tiene la limitación de que cuando se agrupan dos conglomerados de diferente tamaño, el conglomerado resultante queda más cerca del conglomerado mayor y más alejado del menor, de forma proporcional a la diferencia de tamaños, lo que lleva a que a lo largo del proceso de clusterización se vayan perdiendo las propiedades de los conglomerados pequeños <span class="citation">(<a href="#ref-gallardo2022" role="doc-biblioref">Gallardo San-Salvador 2022</a>)</span>.</p>
<ul>
<li><strong>Método de la mediana.</strong></li>
</ul>
<p> Viene a superar la limitación del método del centroide. Para ello, la estrategia natural es suponer que los grupos son de igual tamaño. Dicha estrategia se plasma en suponer que la distancia entre un elemento (o un conglomerado, <span class="math inline">\(k\)</span>) y el conglomerado formado por la agrupación de los conglomerados <span class="math inline">\(i\)</span> y <span class="math inline">\(j\)</span> viene dada por la mediana del triángulo formado por sus centroides (de ahí su nombre). Se trata de un método espacio conservativo, pero, igual que el método del centroide, no es invariante a transformaciones monótonas de la distancia utilizada.</p>
<p>La Fig. <a href="análisis-cluster-clusterización-jerárquica.html#fig:cluster-compara2">30.4</a>, un tanglegrama o diagrama de laberinto, muestra las agrupaciones producidas por los métodos del centroide y la mediana. En ella se puede observar como el método de la mediana corrije la limitación del método del centroide.</p>
<div class="sourceCode" id="cb380"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb380-1"><a href="análisis-cluster-clusterización-jerárquica.html#cb380-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dendextend)</span>
<span id="cb380-2"><a href="análisis-cluster-clusterización-jerárquica.html#cb380-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(cluster)</span>
<span id="cb380-3"><a href="análisis-cluster-clusterización-jerárquica.html#cb380-3" aria-hidden="true" tabindex="-1"></a>hc_cent_dend <span class="ot">&lt;-</span> <span class="fu">as.dendrogram</span>(<span class="fu">hclust</span>(d_euclidea, <span class="at">method =</span> <span class="st">&quot;centroid&quot;</span>))</span>
<span id="cb380-4"><a href="análisis-cluster-clusterización-jerárquica.html#cb380-4" aria-hidden="true" tabindex="-1"></a>hc_med_dend <span class="ot">&lt;-</span> <span class="fu">as.dendrogram</span>(<span class="fu">hclust</span>(d_euclidea, <span class="at">method =</span> <span class="st">&quot;median&quot;</span>))</span>
<span id="cb380-5"><a href="análisis-cluster-clusterización-jerárquica.html#cb380-5" aria-hidden="true" tabindex="-1"></a><span class="fu">tanglegram</span>(hc_cent_dend, hc_med_dend)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:cluster-compara2"></span>
<img src="Ciencia_de_datos_con_r_files/figure-html/cluster-compara2-1.png" alt="Clusterización jerárquica con distancias euclídeas (tanglegrama): método del centroide vs. método de la mediana" width="60%" />
<p class="caption">
Figura 30.4: Clusterización jerárquica con distancias euclídeas (tanglegrama): método del centroide vs. método de la mediana
</p>
</div>
<ul>
<li><strong>Método de Ward.</strong></li>
</ul>
<p>El método de Ward agrupa, en cada etapa, los dos clusters que producen el menor incremento de la varianza total intra-cluster: <span class="math inline">\(W=\sum_g\sum_{i \in g} (x_{ig}- \bar{x}_g)^{\prime} (x_{ig}- \bar{x}_g)\)</span>, donde <span class="math inline">\(\bar{x}_g\)</span> es el centroide del grupo <span class="math inline">\(g\)</span>. Así, los grupos formados no distorsionan los datos originales.<a href="#fn77" class="footnote-ref" id="fnref77"><sup>77</sup></a></p>
<p>Es muy utilizado en la práctica, dado que tiene casi todas las ventajas del método de la media y suele ser más discriminatorio en la determinación de los niveles de agrupación. También suele crear conglomerados muy compactos de tamaño similar. Dado que el menor incremento de <span class="math inline">\(W\)</span> es proporcional a la distancia euclidea al cuadrado entre los centroides de los grupos fusionados, <span class="math inline">\(W\)</span> no es decreciente, solventándose los problemas de los otros métodos basados en centroides.</p>
<p>La Fig. <a href="análisis-cluster-clusterización-jerárquica.html#fig:plot-igraph">30.5</a>, muestra el filograma, diagrama filético en forma de árbol filogenético, generado por la librería <code>igraph</code> con el método de agrupación de Ward.</p>
<div class="sourceCode" id="cb381"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb381-1"><a href="análisis-cluster-clusterización-jerárquica.html#cb381-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;igraph&quot;</span>)</span>
<span id="cb381-2"><a href="análisis-cluster-clusterización-jerárquica.html#cb381-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">5665</span>)</span>
<span id="cb381-3"><a href="análisis-cluster-clusterización-jerárquica.html#cb381-3" aria-hidden="true" tabindex="-1"></a>hc_ward <span class="ot">&lt;-</span> <span class="fu">hcut</span>(tic, <span class="at">k =</span> <span class="dv">3</span>, <span class="at">hc_method =</span> <span class="st">&quot;ward.D2&quot;</span>)</span>
<span id="cb381-4"><a href="análisis-cluster-clusterización-jerárquica.html#cb381-4" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_dend</span>(</span>
<span id="cb381-5"><a href="análisis-cluster-clusterización-jerárquica.html#cb381-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> hc_ward,</span>
<span id="cb381-6"><a href="análisis-cluster-clusterización-jerárquica.html#cb381-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">k =</span> <span class="dv">3</span>,</span>
<span id="cb381-7"><a href="análisis-cluster-clusterización-jerárquica.html#cb381-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">&quot;phylogenic&quot;</span></span>
<span id="cb381-8"><a href="análisis-cluster-clusterización-jerárquica.html#cb381-8" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:plot-igraph"></span>
<img src="Ciencia_de_datos_con_r_files/figure-html/plot-igraph-1.png" alt="Clusterización jerárquica con distancias euclídeas al cuadrado (filograma): método de Ward" width="60%" />
<p class="caption">
Figura 30.5: Clusterización jerárquica con distancias euclídeas al cuadrado (filograma): método de Ward
</p>
</div>
<ul>
<li><strong>Método del encadenamiento intragrupos.</strong></li>
</ul>
<p>Según el método de la distancia promedio (o vinculación entre grupos) la distancia entre dos conglomerados se obtenía calculando las distancias de cada elemento de uno de los grupos con todos los del otro y computando, posteriormente, la media aritmética de dichas distancias. Con el método de la vinculación intragrupos se computa la distancia media entre la totalidad de los elementos de los conglomerados susceptibles de agrupación, con independencia de si pertenecen al mismo conglomerado inicial o a distinto conglomerado. Por ejemplo: si un conglomerado está formado por los elementos <span class="math inline">\(a\)</span> y <span class="math inline">\(b\)</span>, y otro por los elementos <span class="math inline">\(c\)</span> y <span class="math inline">\(d\)</span>, la distancia intergrupos entre los dos conglomerados es:</p>
<p><span class="math display">\[d_{intergrupos}=\frac{d_{(a;c)}+d_{(a;d)}+d_{(b;c)}+d_{(b;d)}}{4}\]</span> mientras que la distancia intragrupos vendrá dada por la media de las distancias entre los elementos <span class="math inline">\(a,b,c\)</span> y <span class="math inline">\(d\)</span>: <span class="math display">\[d_{intergrupos}=\frac{d_{(a;b)}+d_{(a;c)}+d_{(a;d)}+d_{(b;c)}+d_{(b;d)}
     +d_{(c;d)}}{6}\]</span></p>
<ul>
<li><strong>Método flexible de Lance y Williams.</strong></li>
</ul>
<p>Calcula la distancia entre dos conglomerados (el primero formado por la unión de otros dos en la etapa previa) a partir de la siguiente expresión: <span class="math display">\[d_{\left(  g_{1}\cup g_{2}\right); g_{3}}=\alpha_{1}d_{(g_{1};g_{3})}
+\alpha_{2}d_{(g_{2};g_{3})}+\beta d_{(g_{1};g_{2})}+\gamma\left\vert
d_{(g_{1};g_{2})}-d_{(g_{2};g_{2})}\right\vert,\]</span> donde <span class="math inline">\(\alpha_{1}+\alpha_{2}+\beta=1; \alpha_{1}=\alpha_{2};\beta&lt;1;\gamma=0\)</span>, si bien Lance y Williams sugieren adicionalmente un pequeño valor negativo de <span class="math inline">\(\beta\)</span>. Por ejemplo <span class="math inline">\(\beta =-0,25\)</span>.</p>
<p>Los métodos anteriormente expuestos son casos particulares de éste. Denominando <span class="math inline">\(n_1\)</span>, <span class="math inline">\(n_2\)</span> y <span class="math inline">\(n_3\)</span> a los tamaños de los grupos <span class="math inline">\(g_1\)</span>, <span class="math inline">\(g_2\)</span> y <span class="math inline">\(g_3\)</span>, respectivamente, se tiene:</p>
<table>
<caption>Valores de <span class="math inline">\(\alpha_1\)</span>, <span class="math inline">\(\alpha_2\)</span>, <span class="math inline">\(\beta\)</span> y <span class="math inline">\(\gamma\)</span> para distintos procedimientos de agrupación</caption>
<colgroup>
<col width="38%" />
<col width="15%" />
<col width="15%" />
<col width="15%" />
<col width="15%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Método</th>
<th align="center"><span class="math inline">\(\alpha_1\)</span></th>
<th align="center"><span class="math inline">\(\alpha_2\)</span></th>
<th align="center"><span class="math inline">\(\beta\)</span></th>
<th align="center"><span class="math inline">\(\gamma\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center">Vecino más cercano</td>
<td align="center">0,5</td>
<td align="center">0,5</td>
<td align="center">0</td>
<td align="center">-0,5</td>
</tr>
<tr class="even">
<td align="center">Vecino más lejano</td>
<td align="center">0,5</td>
<td align="center">0,5</td>
<td align="center">0</td>
<td align="center">0,5</td>
</tr>
<tr class="odd">
<td align="center">Distancia media</td>
<td align="center"><span class="math inline">\(\frac{n_1}{n_1+n_2}\)</span></td>
<td align="center"><span class="math inline">\(\frac{n_2}{n_1+n_2}\)</span></td>
<td align="center">0</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center">Distancia entre centroides</td>
<td align="center"><span class="math inline">\(\frac{n_1}{n_1+n_2}\)</span></td>
<td align="center"><span class="math inline">\(\frac{n_2}{n_1+n_2}\)</span></td>
<td align="center"><span class="math inline">\(\frac{-n_1 n_2} {(n_1+n_2)^2}\)</span></td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center">Método de la mediana</td>
<td align="center">0,5</td>
<td align="center">0,5</td>
<td align="center">-0,25</td>
<td align="center">0</td>
</tr>
<tr class="even">
<td align="center">Ward</td>
<td align="center"><span class="math inline">\(\frac {n_1+n_3} {n_1+n_2+n_3}\)</span></td>
<td align="center"><span class="math inline">\(\frac {n_2+n_3} {n_1+n_2+n_3}\)</span></td>
<td align="center"><span class="math inline">\(\frac{-n_3} {n_1+n_2+n_3}\)</span></td>
<td align="center">0</td>
</tr>
<tr class="odd">
<td align="center">Flexible</td>
<td align="center"><span class="math inline">\(0,5(1-\beta)\)</span></td>
<td align="center"><span class="math inline">\(0,5(1-\beta)\)</span></td>
<td align="center"><span class="math inline">\(\beta\)</span></td>
<td align="center">0</td>
</tr>
</tbody>
</table>
</div>
<div id="técnicas-jerárquicas-divisivas" class="section level3 hasAnchor" number="30.4.3">
<h3><span class="header-section-number">30.4.3</span> Técnicas jerárquicas divisivas<a href="análisis-cluster-clusterización-jerárquica.html#técnicas-jerárquicas-divisivas" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En este caso, la secuencia de acontecimientos es justo la inversa. Se parte de un único conglomerado formado por todos los elementos y se llega a <span class="math inline">\(n\)</span> conglomerados formados cada uno de ellos por un único elemento (a veces el proceso termina cuando se llega a un número de grupos preestablecido). Ahora bien, dado que ahora se trata de subividir conglomerados, es decir, de identificar los elementos más distantes, o menos similares, para separarlos del resto del conglomerado, la estrategia a seguir estará basada en maximizar las distancias (o minimizar las similitudes). En el proceso disociativo surge una cuestión importante: cuándo debe dejar de dividirse un cluster determinado y pasar a dividir otro, cuestión que se resuelve por el procedimiento propuesto por <span class="citation">MacNaughton-Smith et al. (<a href="#ref-macnaughton_et_al1964" role="doc-biblioref">1964</a>)</span>. Las técnicas divisivas (también llamadas partitivas o disociativas), pueden ser monotéticas o politéticas. En el primer caso, las divisiones se basan en una sola característica o atributo. En el segundo, se tienen en cuenta todas.</p>
<p>Las técnicas divisivas son menos populares que las aglomerativas. Sin embargo, la probabilidad de que lleven a decisiones equivocadas (debido a la variabilidad estadística de los datos) en las etapas iniciales del proceso, lo cual distorsionaría el resultado final del mismo, es menor que en las aglomerativas. En este sentido, los métodos partitivos, al partir del total de elementos, se consideran más seguros que los aglomerativos. Los métodos disociativos más populares son los siguientes:</p>
<p><strong>Método de la distancia promedio</strong></p>
<p>Dentro de las técnicas politéticas, entre las que se cuentan todas las vistas en la clusterización jerárquica aglomerativa, quizás la más popular es la que utiliza para la partición el método de la distancia promedio. Para ilustrarla, supóngase que se tienen 5 elementos y que su matriz de distancias es la siguiente:</p>
<p><span class="math display">\[\bf X=\left(\begin{matrix} .&amp;.&amp;.&amp;.&amp;.\\
8&amp;.&amp;.&amp;.&amp;.\\
7&amp;4&amp;.&amp;.&amp;.\\
6&amp;1&amp;4&amp;.&amp;.\\
3&amp;4&amp;5&amp;4&amp;.
\end {matrix}\right)\]</span></p>
<p>En la primera etapa hay que dividir el grupo de cinco elementos en dos conglomerados. Hay <span class="math inline">\(2^{2n-1}-1\)</span> posibilidades, pero según el método de la distancia promedio, se calcula la distancia de cada elemento a los demás y se promedia, desgajándose el elemento con distancia promedio máxima. En nuestro caso, se desgajaría el primer elemento, y en la segunda etapa se partiría de dos grupos: <span class="math inline">\(\{e_1 \}\)</span> y <span class="math inline">\(\{e_2, e_3, e_4, e_5\}\)</span>.</p>
<p>A partir de la segunda etapa, se procede como sigue (véase Tabla 2.2):</p>
<ul>
<li><span class="math inline">\((i)\)</span> Se calculan las (4) distancias promedio de cada elemento del conglomerado principal al elemento desgajado;</li>
<li><span class="math inline">\((ii)\)</span> Se calculan las (4) distancias promedio de cada elemento del conglomerado principal al resto de elementos del mismo;</li>
<li><span class="math inline">\((iii)\)</span> Se computan las diferencias <span class="math inline">\((i)-(ii)\)</span> para cada uno de los 4 elementos del conglomerado principal;</li>
<li><span class="math inline">\((iv)\)</span> De entre aquéllos elementos del grupo principal en los que <span class="math inline">\((i)-(ii)&lt;0\)</span> se selecciona aquél para el cual es máxima. Tras esta segunda etapa los conglomerados son <span class="math inline">\(\{e_1, e_5\}\)</span> y <span class="math inline">\(\{e_2, e_3, e_4\}\)</span>.</li>
</ul>
<table>
<caption>Distancias entre conglomerados: segunda etapa</caption>
<colgroup>
<col width="24%" />
<col width="26%" />
<col width="24%" />
<col width="24%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Elemento</th>
<th align="center">Distancia promedio al grupo desgajado <span class="math inline">\(\{e_1\}\)</span></th>
<th align="center">Distancia promedio al grupo principal</th>
<th align="center">Diferencia</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\{e_2\}\)</span></td>
<td align="center">8</td>
<td align="center">3</td>
<td align="center">5</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\{e_3\}\)</span></td>
<td align="center">7</td>
<td align="center">3</td>
<td align="center">4</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\{e_4\}\)</span></td>
<td align="center">6</td>
<td align="center">3</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\{e_5\}\)</span></td>
<td align="center">3</td>
<td align="center">4,33</td>
<td align="center">-1,33</td>
</tr>
</tbody>
</table>
<p>En las siguientes etapas se procede de igual manera hasta que todas las diferencias son positivas (en nuestro caso esto ocurre en la tercera etapa; véase Tabla 2.3).</p>
<table>
<caption>Distancias entre conglomerados: tercera etapa</caption>
<colgroup>
<col width="24%" />
<col width="26%" />
<col width="24%" />
<col width="24%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Elemento</th>
<th align="center">Distancia promedio al grupo desgajado <span class="math inline">\(\{e_1,e_5\}\)</span></th>
<th align="center">Distancia promedio al grupo principal</th>
<th align="center">Diferencia</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\{e_2\}\)</span></td>
<td align="center">6</td>
<td align="center">2,5</td>
<td align="center">3,5</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\{e_3\}\)</span></td>
<td align="center">6</td>
<td align="center">4</td>
<td align="center">2</td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\{e_4\}\)</span></td>
<td align="center">5</td>
<td align="center">2,5</td>
<td align="center">2,5</td>
</tr>
</tbody>
</table>
<p>Cuando esto ocurre, es decir, cuando todos los elementos del conglomerado principal están más cerca de los demás que lo componen que de los del conglomerado disociado, se vuelve a iniciar el algoritmo, pero esta vez para cada uno de los dos conglomerados generados <span class="citation">(<a href="#ref-macnaughton_et_al1964" role="doc-biblioref">MacNaughton-Smith et al. 1964</a>)</span>. En nuestro caso, en <span class="math inline">\(\{e_1, e_5\}\)</span> la única partición posible es <span class="math inline">\(\{e_1\}\)</span>, <span class="math inline">\(\{e_5\}\)</span>. En <span class="math inline">\(\{e_2, e_3, e_4\}\)</span> se desgaja el elemento con mayor distancia promedio a los demás del grupo. Como <span class="math inline">\(\frac{d_{(2,3)}+ d_{(2,4)}}{2}=2,5\)</span>, <span class="math inline">\(\frac{d_{(3,2)}+ d_{(3,4)}}{2}=4\)</span> y <span class="math inline">\(\frac {d_{(4,2)} + d_{(4,3)}} {2}=2,5\)</span>, se desgaja <span class="math inline">\(\{e_3\}\)</span>.</p>
<p>A continuación se aplica el algoritmo anteriormente expuesto a cada elemento del grupo principal <span class="math inline">\(\{e_2, e_4\}\)</span> y <span class="math inline">\(\{e_3\}\)</span> (Tabla 2.4), y como todas las distancias son positivas, se divide <span class="math inline">\(\{e_2, e_4\}\)</span> en <span class="math inline">\(\{e_2 \}\)</span> y <span class="math inline">\(\{e_4\}\)</span>.</p>
<table>
<caption>Distancia entre conglomerados: etapa final</caption>
<colgroup>
<col width="24%" />
<col width="26%" />
<col width="24%" />
<col width="24%" />
</colgroup>
<thead>
<tr class="header">
<th align="center">Elemento</th>
<th align="center">Distancia promedio al grupo desgajado <span class="math inline">\(\{e_3\}\)</span></th>
<th align="center">Distancia promedio al grupo principal</th>
<th align="center">Diferencia</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\{e_2\}\)</span></td>
<td align="center">4</td>
<td align="center">1</td>
<td align="center">3</td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\{e_4\}\)</span></td>
<td align="center">4</td>
<td align="center">1</td>
<td align="center">3</td>
</tr>
</tbody>
</table>
<p>El algoritmo DIvisive ANAlysis (DIANA) permite llevar a cabo la partición anterior utilizando el diámetro de los clusters para decidir el orden de partición clusters cuando se tienen varios con más de un elemento (véase capítulo 6 de <span class="citation">Kaufman and Rousseeuw (<a href="#ref-kauf_1990" role="doc-biblioref">1990</a>)</span>). Proporciona <span class="math inline">\((i\)</span>) el coeficiente divisivo (véase <code>diana.object</code>) que mide la cantidad de estructura de agrupamiento encontrada; y <span class="math inline">\((ii\)</span>) la pancarta, una novedosa presentación gráfica (véase <code>plot.diana</code>).</p>
<p>Para el ejemplo TIC, DIANA proporciona el dendrograma circular de la Fig. <a href="análisis-cluster-clusterización-jerárquica.html#fig:diana">30.6</a></p>
<div class="sourceCode" id="cb382"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb382-1"><a href="análisis-cluster-clusterización-jerárquica.html#cb382-1" aria-hidden="true" tabindex="-1"></a><span class="co"># compute divisive hierarchical clustering</span></span>
<span id="cb382-2"><a href="análisis-cluster-clusterización-jerárquica.html#cb382-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(cluster)</span>
<span id="cb382-3"><a href="análisis-cluster-clusterización-jerárquica.html#cb382-3" aria-hidden="true" tabindex="-1"></a>hc_diana <span class="ot">&lt;-</span> <span class="fu">diana</span>(tic, <span class="at">metric =</span> <span class="st">&quot;euclidea&quot;</span>)</span>
<span id="cb382-4"><a href="análisis-cluster-clusterización-jerárquica.html#cb382-4" aria-hidden="true" tabindex="-1"></a><span class="co"># Divise coefficient. #los valores más cercanos a 1 sugieren una estructura de agrupación fuerte</span></span>
<span id="cb382-5"><a href="análisis-cluster-clusterización-jerárquica.html#cb382-5" aria-hidden="true" tabindex="-1"></a>hc_diana<span class="sc">$</span>dc</span>
<span id="cb382-6"><a href="análisis-cluster-clusterización-jerárquica.html#cb382-6" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.8043393</span></span>
<span id="cb382-7"><a href="análisis-cluster-clusterización-jerárquica.html#cb382-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb382-8"><a href="análisis-cluster-clusterización-jerárquica.html#cb382-8" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(factoextra)</span>
<span id="cb382-9"><a href="análisis-cluster-clusterización-jerárquica.html#cb382-9" aria-hidden="true" tabindex="-1"></a><span class="fu">fviz_dend</span>(</span>
<span id="cb382-10"><a href="análisis-cluster-clusterización-jerárquica.html#cb382-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> hc_diana,</span>
<span id="cb382-11"><a href="análisis-cluster-clusterización-jerárquica.html#cb382-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">k =</span> <span class="dv">3</span>,</span>
<span id="cb382-12"><a href="análisis-cluster-clusterización-jerárquica.html#cb382-12" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">&quot;circular&quot;</span>,</span>
<span id="cb382-13"><a href="análisis-cluster-clusterización-jerárquica.html#cb382-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">ggtheme =</span> <span class="fu">theme_minimal</span>()</span>
<span id="cb382-14"><a href="análisis-cluster-clusterización-jerárquica.html#cb382-14" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:diana"></span>
<img src="Ciencia_de_datos_con_r_files/figure-html/diana-1.png" alt="Clusterización jerárquica divisiva con DIANA" width="60%" />
<p class="caption">
Figura 30.6: Clusterización jerárquica divisiva con DIANA
</p>
</div>
<p><strong>Análisis de la asociación</strong></p>
<p>En caso de que los elementos vengan caracterizados por variables cualitativas o factores dicotómicos, <span class="math inline">\(F_1,F_2,..., F_n\)</span> (si alguno fuese politómico, cada una de sus categorías se consideraría como un factor dicotómico), el método del análisis de la asociación (o suma de estadísticos chi-cuadrado) es una técnica monotética muy utilizada que procede como sigue:</p>
<ul>
<li><span class="math inline">\((i)\)</span> Considérese <span class="math inline">\(F_1\)</span> y divídase el conjunto de elementos en dos grupos o categorías: uno con los elementos en los que <span class="math inline">\(F_1\)</span> esté presente y otro con aquellos en los que esté ausente. Hágase lo mismo con los demás factores.</li>
<li><span class="math inline">\((ii)\)</span> Constrúyanse las <span class="math inline">\(n\times(n-1)\)</span> tablas de contingencia <span class="math inline">\(2\times2\)</span> que cruzan cada factor con cada uno de los restantes (véase Capítulo <a href="tablas-contingencia.html#notac">20.1.2</a>).</li>
</ul>
<table>
<tbody>
<tr class="odd">
<td align="right"></td>
<td align="right"></td>
<td align="center">Presencia</td>
<td align="center">Factor <em>j</em></td>
<td align="center"></td>
</tr>
<tr class="even">
<td align="right"></td>
<td align="right"></td>
<td align="center">SI</td>
<td align="center">NO</td>
<td align="center"><strong>Total</strong></td>
</tr>
<tr class="odd">
<td align="right">Presencia</td>
<td align="right">SI</td>
<td align="center"><span class="math inline">\(n_{11}\)</span></td>
<td align="center"><span class="math inline">\(n_{21}\)</span></td>
<td align="center"><span class="math inline">\(n_{1\cdot}\)</span></td>
</tr>
<tr class="even">
<td align="right">Factor <em>i</em></td>
<td align="right">NO</td>
<td align="center"><span class="math inline">\(n_{21}\)</span></td>
<td align="center"><span class="math inline">\(n_{22}\)</span></td>
<td align="center"><span class="math inline">\(n_{2\cdot}\)</span></td>
</tr>
<tr class="odd">
<td align="right"></td>
<td align="right"><strong>Total</strong></td>
<td align="center"><span class="math inline">\(n_{\cdot1}\)</span></td>
<td align="center"><span class="math inline">\(n_{\cdot2}\)</span></td>
<td align="center"><strong>n</strong></td>
</tr>
</tbody>
</table>
<p>donde <span class="math inline">\(i\neq j\)</span>.</p>
<ul>
<li><span class="math inline">\((iii)\)</span> Calcúlese el estadístico chi-cuadrado (<span class="math inline">\(\chi_{ij}^2=\frac {n(n_{11}n_{22}-n_{12}n_{21})^2}{n_{1\cdot} n_{2\cdot}n_{\cdot1}n_{\cdot2}}\)</span> para una de dichas tablas (véase Capítulo <a href="tablas-contingencia.html#dise">20.2.5</a> y compútese <span class="math inline">\(\sum_{i\neq j}\chi_{ij}^2\)</span>.</li>
<li><span class="math inline">\((iii)\)</span> Desgájese del conglomerado inicial en dos: uno con los elementos que contienen el factor con la máxima <span class="math inline">\(\sum_{i\neq j}\chi_{ij}^2\)</span>; y otro con el resto de los elementos (donde dicho factor está ausente).</li>
<li><span class="math inline">\((iv)\)</span> Procédase así iterativamente.</li>
</ul>
<!-- Otras alternativas al criterio $\max \sum_{i\neq j}\chi_{ij}^2$ son: $\max \sqrt{\sum_{i\neq j}\chi_{ij}^2}$, $\max\sum_{i\neq j} (n_{11}n_{22}-n_{12}n_{21})^2$ y $\max\sum_{i\neq j} |n_{11}n_{22}-n_{12}n_{21}|$, entre otras. -->
<p><strong>Método del detector automático de interacciones (AID)</strong></p>
<p>No es propiamente un método de AC, sino de la esfera de los modelos lineales de rango no completo. Sin embargo, se menciona, siquiera mínimamente, porque se utiliza en algunas ocasiones con la finalidad combinar categorías de los factores utilizados con la finalidad de generar grupos que difieran lo más posible entre sí respecto de los valores de una variable dependiente medida en una escala métrica (con una escala proporcional o de intervalo) o ficticia (dicotómica con valores 0 y 1).
Específicamente, el AID procede con un ANOVA entre las categorías de la variable independiente, que maximiza la varianza secuencial que se realiza mediante divisiones dicotómicas de la variable dependiente que busca en cada etapa la partición intergrupos y minimiza la varianza intragrupos. La agrupación de categorías se efectúa probando todas las combinaciones binarias posibles de las variables. Se utiliza un test <span class="math inline">\(F\)</span> para seleccionar las mayores diferencias posibles.
En este algoritmo, el proceso de subdivisión del conjunto de elementos en grupos dicotómicos continúa hasta que se verifica algún criterio de parada.</p>
<p>Las limitaciones más importantes del AID son las siguientes:</p>
<ul>
<li>Tiende a seleccionar como más explicativas las variables con mayor número de categorías. Por eso no conviene utilizarlo cuando las variables explicativas difieran mucho en el número de categorías.</li>
<li>Las particiones resultantes dependen de la variable que elegida en primer lugar, condicionando las sucesivas particiones.</li>
<li>Su naturaleza exclusivamente dicotómica también es una limitación importante. Si se llevasen a cabo particiones con tres o más ramas producirían una mayor reducción de la varianza residual y, además, permitirían una mejor selección de otras variables.</li>
</ul>
<p>El AID basado en tablas de contingencia y el estadístico chi-cuadrado (CHAID) corrige la mayoría de estas limitaciones. Aunque inicialmente fue diseñado para variables categóricas, posteriormente se incluyó la posibilidad de trabajar con variables categóricas nominales, categóricas ordinales y variables continuas, permitiendo generar tanto árboles de decisión, para resolver problemas de clasificación, como árboles de regresión. Además, los nodos se pueden dividir en más de dos ramas.</p>
<!-- **GEMA: DIANA** -->
<!-- **diana se describe completamente en el capítulo 6 de Kaufman y Rousseeuw (1990). Probablemente sea único en el cálculo de una jerarquía divisiva, -->
<!-- Además, diana proporciona (a) el coeficiente divisivo (ver diana.object ) que mide la cantidad de estructura de agrupamiento encontrada; y (b) la pancarta, una novedosa presentación gráfica (ver plot.diana ). -->
<!-- El algoritmo diana construye una jerarquía de agrupaciones, comenzando con una agrupación grande que contiene todas las n observaciones. Los grupos se dividen hasta que cada grupo contiene solo una observación. -->
<!-- En cada etapa,se selecciona el clúster con el mayor diámetro.(El diámetro de un clúster es la mayor disimilitud entre dos de sus observaciones). -->
<!-- Para dividir el clúster seleccionado,el algoritmo busca primero su observación más dispar (es decir,la que tiene la mayor disimilitud media con las demás observaciones del clúster seleccionado).Esta observación inicia el "grupo de separación". En los pasos siguientes, el algoritmo reasigna las observaciones que están más cerca del "grupo escindido" que del "grupo antiguo". El resultado es una división del cluster seleccionado en dos nuevos clusters.** -->
</div>
</div>
<div id="calidad-de-la-agrupación-y-número-de-clusters" class="section level2 hasAnchor" number="30.5">
<h2><span class="header-section-number">30.5</span> Calidad de la agrupación y número de clusters<a href="análisis-cluster-clusterización-jerárquica.html#calidad-de-la-agrupación-y-número-de-clusters" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="el-coeficiente-de-correlación-lineal-cofenético" class="section level3 hasAnchor" number="30.5.1">
<h3><span class="header-section-number">30.5.1</span> El coeficiente de correlación lineal cofenético<a href="análisis-cluster-clusterización-jerárquica.html#el-coeficiente-de-correlación-lineal-cofenético" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Dado que las técnicas jerárquicas imponen una estructura sobre los datos y pueden producir distorsiones significativas en las relaciones entre los datos originales, una vez realizada la jerarquización de los elementos objeto de clusterización, surge la siguiente pregunta: ¿en qué medida la estructura final obtenida representa las similitudes o diferencias entre dichos objetos? En otros términos, ¿en qué medida el dendrograma representa la matriz de distancias o similitudes original?</p>
<p>El coeficiente de correlación lineal cofenético da respuesta a dichas preguntas. Se define como el coeficiente de correlación lineal entre los <span class="math inline">\(n(n-1)\)</span> elementos del triangulo superior de la matriz de distancias o similitudes y sus homónimos en la matriz cofenética, <span class="math inline">\(\bf C\)</span>, cuyos elementos <span class="math inline">\(\{c_{ij}\}\)</span> son las distancias o similitudes entre los elementos <span class="math inline">\((i,j)\)</span> tras la aplicación de la técnica de jerarquización. Obviamente, se utilizará la técnica jerárquica que origine el mayor coeficiente.</p>
<p>En el ejemplo TIC, el mayor coeficiente cofenético corresponde al método del promedio o del centroide, si bien la magnitud de los correspondientes a otras técnicas de agregación es bastante parecida.</p>
<div class="sourceCode" id="cb383"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb383-1"><a href="análisis-cluster-clusterización-jerárquica.html#cb383-1" aria-hidden="true" tabindex="-1"></a><span class="co"># comparamos con la distancia euclidea: d_euclidea</span></span>
<span id="cb383-2"><a href="análisis-cluster-clusterización-jerárquica.html#cb383-2" aria-hidden="true" tabindex="-1"></a>cof_simp <span class="ot">&lt;-</span> <span class="fu">cophenetic</span>(hc_simple)</span>
<span id="cb383-3"><a href="análisis-cluster-clusterización-jerárquica.html#cb383-3" aria-hidden="true" tabindex="-1"></a>cof_comp <span class="ot">&lt;-</span> <span class="fu">cophenetic</span>(hc_completo)</span>
<span id="cb383-4"><a href="análisis-cluster-clusterización-jerárquica.html#cb383-4" aria-hidden="true" tabindex="-1"></a>cof_prom <span class="ot">&lt;-</span> <span class="fu">cophenetic</span>(hc_promedio)</span>
<span id="cb383-5"><a href="análisis-cluster-clusterización-jerárquica.html#cb383-5" aria-hidden="true" tabindex="-1"></a>cof_ward <span class="ot">&lt;-</span> <span class="fu">cophenetic</span>(hc_ward)</span>
<span id="cb383-6"><a href="análisis-cluster-clusterización-jerárquica.html#cb383-6" aria-hidden="true" tabindex="-1"></a>cof_dia <span class="ot">&lt;-</span> <span class="fu">cophenetic</span>(hc_diana)</span>
<span id="cb383-7"><a href="análisis-cluster-clusterización-jerárquica.html#cb383-7" aria-hidden="true" tabindex="-1"></a>coef_cofeneticos <span class="ot">&lt;-</span> <span class="fu">cbind</span>(d_euclidea, cof_simp, cof_comp, cof_prom, cof_dia, cof_ward)</span>
<span id="cb383-8"><a href="análisis-cluster-clusterización-jerárquica.html#cb383-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb383-9"><a href="análisis-cluster-clusterización-jerárquica.html#cb383-9" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">cor</span>(coef_cofeneticos)[<span class="dv">1</span>, ], <span class="dv">2</span>)</span>
<span id="cb383-10"><a href="análisis-cluster-clusterización-jerárquica.html#cb383-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; d_euclidea   cof_simp   cof_comp   cof_prom    cof_dia   cof_ward </span></span>
<span id="cb383-11"><a href="análisis-cluster-clusterización-jerárquica.html#cb383-11" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt;       1.00       0.71       0.61       0.77       0.65       0.60</span></span></code></pre></div>
</div>
<div id="número-óptimo-de-clusters" class="section level3 hasAnchor" number="30.5.2">
<h3><span class="header-section-number">30.5.2</span> Número óptimo de clusters<a href="análisis-cluster-clusterización-jerárquica.html#número-óptimo-de-clusters" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Acabado el procedimiento de clusterización de los <span class="math inline">\(n\)</span> elementos disponibles, sea por un procedimiento jerárquico aglomerativo o divisivo, hay que tomar una decisión sobre el número de óptimo de clusters. Esta decisión es ardua y requiere un delicado equilibrio. Valores grandes de <span class="math inline">\(k\)</span> pueden mejorar la homogeneidad de los clusters; sin embargo, se corre el riesgo de sobreajuste. Lo contrario ocurre con un <span class="math inline">\(k\)</span> pequeño.</p>
<p>Para tomar esta decisión, además del sentido común y el conocimiento que se tenga del fenómeno en estudio, se puede echar mano de distintos procedimientos heurísticos. El primero se basa en el <strong>dendrograma</strong> y, en concreto, en la representación de las distintas etapas del algoritmo y las distancias a la que se producen las agrupaciones o particiones de los clusters. Para cada distancia, el dendrograma produce un numero determinado de clusters que aumenta (o disminuye) con la misma. Por tanto, el número de clusters dependerá de la distancia a la que se corte el dendrograma (eje de abcisas del dendrograma, height). Dicha distancia debería elegirse de tal forma que los conglomerados estuviesen bien determinados y fuesen interpretables. En las primeras etapas del proceso las distancias no varían mucho, pero en las etapas intermedias y, sobre todo, finales, las distancias aumentan mucho entre dos etapas consecutivas. Por ello, se suele cortar el dendrograma a la distancia a la cual las distancias entre dos etapas consecutivas del proceso empiecen a ser muy grandes, indicador de que los grupos empiezan a ser muy distintos. Otra posibilidad es utilizar el <strong>gráfico de sedimentación</strong> (<a href="acp.html#numcomp">32.4</a>, que relaciona la variablidad entre clusters (eje de ordenadas) con el el número de clusters (eje de abscisas). Normalmente, decrece bruscamente al principio, y posteriormente más despacio, hasta llegar a la parte de sedimentación (el codo del gráfico), donde el decrecimiento es muy lento. Pues bien, el número óptimo de conglomerados es el correspondiente al codo o comienzo del área de sedimentación del gráfico.</p>
<p>El algoritmo del gráfico de sedimentación es como sigue:</p>
<ol style="list-style-type: decimal">
<li>Clusterícese variando el número de grupos, <span class="math inline">\(k\)</span>, por ejemplo, de 1 a 10.</li>
<li>Para cada valor de <span class="math inline">\(k\)</span>, compútese la suma de cuadrados intragrupo (WSS).</li>
<li>Trácese la gráfica de WSS vs. <span class="math inline">\(k\)</span>.</li>
<li>Determínese el número óptimo de grupos.</li>
</ol>
<p>Con conjuntos de datos de tamaño pequeño a moderado, este proceso se puede realizar convenientemente con <code>factoextra::fviz_nbclust()</code>.</p>
<p>Otra opción es el <em>ancho de silueta promedio</em>.El coeficiente o ancho de silueta compara, por cociente, la distancia media a elementos en el mismo grupo con la distancia media a elementos en otros grupos.</p>
<p>Este método calcula el ancho de silueta promedio (avg.sil.wid.) de los elementos objeto de agrupación para diferentes valores de <span class="math inline">\(k\)</span>. Como un valor alto del ancho promedio indica una buena agrupación, el número óptimo de conglomerados es el que lo maximiza. El campo de variación del ancho de silueta es [-1, 1], donde 1 significa que los elementos están muy cerca de su propio clúster y lejos de otros clústeres, mientras que -1 indica que están cerca de los clústeres vecinos.</p>
<!-- El algoritmo es similar al del gráfico de sedimentación: -->
<p><!-- 1.  Realícese la clusterización variando el número de grupos, $k$, por ejemplo, de 1 a 10. -->
<!-- 2.  Para cada $k$, calcúlese: $(i)$ Para cada observación $i$, la disimilitud promedio $a_i$ entre ella y todos los demás elementos del grupo al que pertenece; $(ii)$ la disimilitud promedio $d(i,C_j)$ entre ella y todos los elementos de los conglomerados $C_j$ a los que no pertenece. La menor $d(i,C_j)$ se denota como $b_i$, la disimilitud entre $i$ y su grupo "vecino", es decir, el más cercano al que no pertenece; $(iii)$ Finalmente, compútese el ancho de la silueta de la observación $i$ como $S_i=(b_i - a_i)/max(a_i,b_i)$. -->
<!-- 3. Para cada $k$, compútese el promedio del ancho de silueta (avg.sil.wid.) de los elementos a agrupar. -->
<!-- 4.  Trácese la gráfica de avg.sil vs. $k$. -->
<!-- 5.  Determínese el número óptimo de grupos: aquel que corresponda al máximo de avg.sil.wid. --></p>
<p>El <strong>criterio del Gap (brecha)</strong>, similar al método del codo, tiene como finalidad encontrar la mayor diferencia o distancia que entre los diferentes grupos de elementos que se van formando en el proceso de clusterización y que se representan normalmente en un dendrograma. Se computan las distancias de cada uno de los enlaces que forman el dendrograma y se observa cuál es la mayor de ellas. El máximo del gráfico de estas diferencias vs. el número de clusters indica el número óptimo de clusters.</p>
<div class="sourceCode" id="cb384"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb384-1"><a href="análisis-cluster-clusterización-jerárquica.html#cb384-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Plot cluster results</span></span>
<span id="cb384-2"><a href="análisis-cluster-clusterización-jerárquica.html#cb384-2" aria-hidden="true" tabindex="-1"></a>p1 <span class="ot">&lt;-</span> <span class="fu">fviz_nbclust</span>(tic,</span>
<span id="cb384-3"><a href="análisis-cluster-clusterización-jerárquica.html#cb384-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">FUN =</span> hcut, <span class="at">method =</span> <span class="st">&quot;wss&quot;</span>,</span>
<span id="cb384-4"><a href="análisis-cluster-clusterización-jerárquica.html#cb384-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">k.max =</span> <span class="dv">10</span></span>
<span id="cb384-5"><a href="análisis-cluster-clusterización-jerárquica.html#cb384-5" aria-hidden="true" tabindex="-1"></a>) <span class="sc">+</span></span>
<span id="cb384-6"><a href="análisis-cluster-clusterización-jerárquica.html#cb384-6" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Elbow&quot;</span>)</span>
<span id="cb384-7"><a href="análisis-cluster-clusterización-jerárquica.html#cb384-7" aria-hidden="true" tabindex="-1"></a>p2 <span class="ot">&lt;-</span> <span class="fu">fviz_nbclust</span>(tic,</span>
<span id="cb384-8"><a href="análisis-cluster-clusterización-jerárquica.html#cb384-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">FUN =</span> hcut, <span class="at">method =</span> <span class="st">&quot;silhouette&quot;</span>,</span>
<span id="cb384-9"><a href="análisis-cluster-clusterización-jerárquica.html#cb384-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">k.max =</span> <span class="dv">10</span></span>
<span id="cb384-10"><a href="análisis-cluster-clusterización-jerárquica.html#cb384-10" aria-hidden="true" tabindex="-1"></a>) <span class="sc">+</span></span>
<span id="cb384-11"><a href="análisis-cluster-clusterización-jerárquica.html#cb384-11" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Silhouette&quot;</span>)</span>
<span id="cb384-12"><a href="análisis-cluster-clusterización-jerárquica.html#cb384-12" aria-hidden="true" tabindex="-1"></a>p3 <span class="ot">&lt;-</span> <span class="fu">fviz_nbclust</span>(tic,</span>
<span id="cb384-13"><a href="análisis-cluster-clusterización-jerárquica.html#cb384-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">FUN =</span> hcut, <span class="at">method =</span> <span class="st">&quot;gap_stat&quot;</span>,</span>
<span id="cb384-14"><a href="análisis-cluster-clusterización-jerárquica.html#cb384-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">k.max =</span> <span class="dv">10</span></span>
<span id="cb384-15"><a href="análisis-cluster-clusterización-jerárquica.html#cb384-15" aria-hidden="true" tabindex="-1"></a>) <span class="sc">+</span></span>
<span id="cb384-16"><a href="análisis-cluster-clusterización-jerárquica.html#cb384-16" aria-hidden="true" tabindex="-1"></a>  <span class="fu">ggtitle</span>(<span class="st">&quot;Gap&quot;</span>)</span>
<span id="cb384-17"><a href="análisis-cluster-clusterización-jerárquica.html#cb384-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb384-18"><a href="análisis-cluster-clusterización-jerárquica.html#cb384-18" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(patchwork)</span>
<span id="cb384-19"><a href="análisis-cluster-clusterización-jerárquica.html#cb384-19" aria-hidden="true" tabindex="-1"></a>p1 <span class="sc">+</span> p2 <span class="sc">+</span> p3</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:plot-kresults-hc"></span>
<img src="Ciencia_de_datos_con_r_files/figure-html/plot-kresults-hc-1.png" alt="Métodos heurísticos para la determinación del número óptimo de clusters" width="60%" />
<p class="caption">
Figura 30.7: Métodos heurísticos para la determinación del número óptimo de clusters
</p>
</div>
<p>Finalmente, el <strong>índice de Dunn</strong> es el cociente entre la mínima distancia intergrupos y la máxima distancia intragrupos. A mayor índice, mayor calidad de clusterización.</p>
<div class="sourceCode" id="cb385"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb385-1"><a href="análisis-cluster-clusterización-jerárquica.html#cb385-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(clValid)</span>
<span id="cb385-2"><a href="análisis-cluster-clusterización-jerárquica.html#cb385-2" aria-hidden="true" tabindex="-1"></a>cut2_hc_prom <span class="ot">&lt;-</span> <span class="fu">cutree</span>(hc_promedio, <span class="at">k =</span> <span class="dv">2</span>)</span>
<span id="cb385-3"><a href="análisis-cluster-clusterización-jerárquica.html#cb385-3" aria-hidden="true" tabindex="-1"></a>cut3_hc_prom <span class="ot">&lt;-</span> <span class="fu">cutree</span>(hc_promedio, <span class="at">k =</span> <span class="dv">3</span>)</span>
<span id="cb385-4"><a href="análisis-cluster-clusterización-jerárquica.html#cb385-4" aria-hidden="true" tabindex="-1"></a>cut4_hc_prom <span class="ot">&lt;-</span> <span class="fu">cutree</span>(hc_promedio, <span class="at">k =</span> <span class="dv">4</span>)</span>
<span id="cb385-5"><a href="análisis-cluster-clusterización-jerárquica.html#cb385-5" aria-hidden="true" tabindex="-1"></a>cut5_hc_prom <span class="ot">&lt;-</span> <span class="fu">cutree</span>(hc_promedio, <span class="at">k =</span> <span class="dv">5</span>)</span>
<span id="cb385-6"><a href="análisis-cluster-clusterización-jerárquica.html#cb385-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb385-7"><a href="análisis-cluster-clusterización-jerárquica.html#cb385-7" aria-hidden="true" tabindex="-1"></a><span class="fu">dunn</span>(d_euclidea, cut2_hc_prom)</span>
<span id="cb385-8"><a href="análisis-cluster-clusterización-jerárquica.html#cb385-8" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.4465593</span></span>
<span id="cb385-9"><a href="análisis-cluster-clusterización-jerárquica.html#cb385-9" aria-hidden="true" tabindex="-1"></a><span class="fu">dunn</span>(d_euclidea, cut3_hc_prom)</span>
<span id="cb385-10"><a href="análisis-cluster-clusterización-jerárquica.html#cb385-10" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.3751942</span></span>
<span id="cb385-11"><a href="análisis-cluster-clusterización-jerárquica.html#cb385-11" aria-hidden="true" tabindex="-1"></a><span class="fu">dunn</span>(d_euclidea, cut4_hc_prom)</span>
<span id="cb385-12"><a href="análisis-cluster-clusterización-jerárquica.html#cb385-12" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.4074884</span></span>
<span id="cb385-13"><a href="análisis-cluster-clusterización-jerárquica.html#cb385-13" aria-hidden="true" tabindex="-1"></a><span class="fu">dunn</span>(d_euclidea, cut5_hc_prom)</span>
<span id="cb385-14"><a href="análisis-cluster-clusterización-jerárquica.html#cb385-14" aria-hidden="true" tabindex="-1"></a><span class="co">#&gt; [1] 0.4366356</span></span></code></pre></div>
>>>>>>> branch 'main' of https://github.com/cdr-book/cdr-book.github.io.git
<p>En nuestro ejemplo TIC, el gráfico de sedimentación y criterio del gap indican un número óptimo de clusters de 3. El ancho de silueta alcanza su máximo con dos clusters, si bien la altura del gráfico para tres clusters es prácticamente la misma. Por ello, se opta por 3 clusters a pesar de que el índice de Dunn también se decanta por dos. El primero lo forman Rumanía, Bulgaria y Grecia, la franja sudeste de la UE27, que se caracteriza por tener los peores guarismos en dotación y uso de las TIC, tanto a nivel de hogar como de empresa. El segundo lo integran el resto de la franja este más las tres primeras economías de la Unión y Portugal. Tienen unos elevados porcentajes en todas las variables, pero no los mayores, que corresponden a los demás países de la UE27, el tercer conglomerado.</p>
<p>Además de los procedimientos anteriores, hay otros, no tan populares, <span class="math inline">\((i)\)</span> basados en la contrastación de hipótesis, suponiendo que los datos siguen alguna distribución multivariante (casi siempre la normal) o <span class="math inline">\((ii)\)</span> procedentes de la abstracción de procedimientos inherentes al análisis multivariante paramétrico; los detalles pueden verse en <span class="citation">Gallardo San-Salvador (<a href="#ref-gallardo2022" role="doc-biblioref">2022</a>)</span>. El paquete <code>NbClust</code> de R contiene la función NbClust() que calcula 30 índices para valorar el número óptimo de clústers.</p>
<!-- Otra opción complementaria es echar mano de técnicas multivariantes como ANOVA y el análisis discriminante. El ANOVA se aplica a cada una de las variables para estimar las diferencias existentes entre los grupos finales. Si dichas diferencias no fueran significativas, dicha variable o factor debería ser eliminada del proceso de clusterización y proceder a una nueva clusterización con distinto número de grupos. Se trata, pues, de conocer hasta qué punto cada una de las variables o factores es de utilidad para diferenciar significativamente los elementos de cada conglomerado. Con el  análisis discriminante, se calcula el porcentaje de elementos asignados correctamente. En caso de que dicho porcentaje no sea satisfactorio, el investigador debe replantearse el proceso de clusterización realizado. -->
<div class="infobox_resume">
<p><strong>RESUMEN</strong>
El análisis cluster está orientado a la agrupación de un conjunto de elementos en grupos, en función de una serie de características, tal que los elementos de cada grupo sean lo más parecidos posible entre sí y lo más diferentes posible de los de otros grupos. Este proceso implica <span class="math inline">\((i)\)</span> la selección de las variables en función de las cuales se van a agrupar; <span class="math inline">\((ii)\)</span> la elección de la distancia o medida de similitud entre ellos; <span class="math inline">\((iii)\)</span> la elección de la técnica para formar los grupos; y <span class="math inline">\((iv)\)</span> la determinación del número óptimo de clusters, cuando sea menester. Estas son las cuestiones que se estudian en este capítulo, si bien, por cuestiones de espacio, en <span class="math inline">\((iii\)</span> solo se abordan las técnicas de clusterización jerárquicas, estudiandose las no jerárquicas en el siguiente capítulo.</p>
</div>
</div>
</div>
</div>
<h3>References</h3>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-gallardo2022" class="csl-entry">
Gallardo San-Salvador, J. A. 2022. <em>Introducción Al Análisis Cluster</em>. <a href="https://www.ugr.es/~gallardo/pdf/cluster-g.pdf">https://www.ugr.es/~gallardo/pdf/cluster-g.pdf</a>.
</div>
<div id="ref-gallardoyvera2004" class="csl-entry">
Gallardo-San Salvador, J. A., and J. F. Vera-Vera. 2004. <em>Técnicas Aplicadas de Análisis de Datos Multivariantes</em>. Granada, Spain: Universidad de Grananda.
</div>
<div id="ref-kassambara2017" class="csl-entry">
Kassambara, A. 2017. <em>Practical Guide to Cluster Analysis in r: Unsupervised Machine Learning (Multivariate Analysis) 1st Ed.</em> sthada.com.
</div>
<div id="ref-kauf_1990" class="csl-entry">
Kaufman, L., and P. J. Rousseeuw. 1990. <span>“Divisive Analysis (Program DIANA).”</span> In <em>Finding Groups in Data: An Introduction to Cluster Analysis</em>, edited by L. Kaufman and P. J. Rousseeuw, 68–125. Hoboken: John Wiley; Sons, Inc.
</div>
<div id="ref-macnaughton_et_al1964" class="csl-entry">
MacNaughton-Smith, P., W. T. Williams, M. B. Dale, L. G. Mockett, and C. Dunn. 1964. <span>“Dissimilarity Analysis: A New Technique of Hierarchical Sub-Division.”</span> <em>Nature</em> 202: 1034–35. https://doi.org/<a href="https://doi.org/10.1038/2021034a0">https://doi.org/10.1038/2021034a0</a>.
</div>
</div>
<div class="footnotes">
<hr />
<ol start="72">
<li id="fn72"><p>También podría observarse <span class="math inline">\(\bf X\)</span> por columnas (la <em>j</em>-ésima columna muestra los valores de la <em>j</em>-ésima variable para cada elemento de la muestra). Aparentemente, no hay razón para no poder clasificar las variables que describen cada elemento (cluster por variables en vez de por elementos).<a href="análisis-cluster-clusterización-jerárquica.html#fnref72" class="footnote-back">↩︎</a></p></li>
<li id="fn73"><p>Si se cumple el cuarto requisito la función distancia suele llamarse distancia métrica.<a href="análisis-cluster-clusterización-jerárquica.html#fnref73" class="footnote-back">↩︎</a></p></li>
<li id="fn74"><p>Representación visual de fácil lectura e interpretación basada en un código de colores, típica del analytics de páginas web. Normalmente proporcionan un patrón visual en forma de”F”, que es el del seguimiento ocular de un sitio o plataforma tecnológica.<a href="análisis-cluster-clusterización-jerárquica.html#fnref74" class="footnote-back">↩︎</a></p></li>
<li id="fn75"><p>Elaboración propia en base a <span class="citation">Kassambara (<a href="#ref-kassambara2017" role="doc-biblioref">2017</a>)</span>.<a href="análisis-cluster-clusterización-jerárquica.html#fnref75" class="footnote-back">↩︎</a></p></li>
<li id="fn76"><p>El criterio de inclusión de los elementos en dichos conglomerados citado en <a href="análisis-cluster-clusterización-jerárquica.html#origen-cluster">30.1</a>.<a href="análisis-cluster-clusterización-jerárquica.html#fnref76" class="footnote-back">↩︎</a></p></li>
<li id="fn77"><p>Específicamente, la propuesta de Ward es que la pérdida de información que se produce al integrar los distintos individuos en clusters sea la mínima posible.<a href="análisis-cluster-clusterización-jerárquica.html#fnref77" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="cap-boosting-xgboost.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="no-jerarquico.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": null,
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["Ciencia_de_datos_con_r.pdf", "Ciencia_de_datos_con_r.epub"],
"search": {
"engine": "lunr",
"options": null
},
"toc": {
"collapse": "section",
"scroll_highlight": true
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
